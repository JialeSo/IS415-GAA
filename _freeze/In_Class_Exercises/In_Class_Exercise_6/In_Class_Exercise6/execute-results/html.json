{
  "hash": "08155a320293aa8e548d30990fb95c94",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"In Class Exercise 6 : Geospatial Data Science\"\nauthor: \"Jiale SO\"\ndate: \"August 18, 2024\"\ndate-modified: \"last-modified\"\nexecute: \n  eval: true\n  echo: true\n  freeze: true\n---\n\n\n# 1.0 Installing and Loading the R Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf, spdep, tmap, tidyverse, sfdep)\n```\n:::\n\n\n# 2.0 Importing the data\n\nTwo data sets will be used in this hands-on exercise, they are:\n\n-   Hunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\n\n-   Hunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n::: panel-tabset\n## ShapeFile\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan <- st_read(dsn = \"data/geospatial\", layer = \"Hunan\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Hunan' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\In_Class_Exercises\\In_Class_Exercise_6\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\nhunan <- st_transform(hunan, crs = 4490)\n```\n:::\n\n\n## CSVFile with Left Join\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\") \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nhunan_GDPPC <- left_join(hunan,hunan2012) %>% \n  select(1:4, 7, 15)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(County)`\n```\n\n\n:::\n:::\n\n:::\n\n# 3.0 Global Measures of Spatial Association\n\n## 3.1 Step 1: Deriving Queen's Contiguity Weights: SFDep Methods\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_q <- hunan_GDPPC %>%\n  mutate(\n        nb = st_contiguity(geometry),\n        wt = st_weights(nb, style = \"W\"),\n        .before = 1\n  )\n```\n:::\n\n\n## 3.2 Step 2:  Computing Global Moran' I\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmoranI <- global_moran(wm_q$GDPPC, \n                       wm_q$nb,\n                       wm_q$wt\n                       )\n\nglimpse(moranI)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n```\n\n\n:::\n:::\n\n\nK is the average number that they found\n\n## 3.3 Step 3: performing Global Moran's I Test\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_moran_test(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt\n                  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMoran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n```\n\n\n:::\n:::\n\n\nThis is basically the idea that MORAN I shows there's clustering but not a strong one and since the P value is low, we do it.\n\nLook at the p-value first, then we do not have the statistical analysis.\n\n## 3.4 Step 4: Performing Global Moran's I Permutation Test (Use this for Take Home -2)\n\nDo this for statistical test, to ensure it's reproducible, set seed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99\n                  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMonte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\n\nThis simulates and permutates the the test permutation test. So basically we do 100 test and see if the p-value to reject or not.\n\n# 4.0 Local Measures of Spatial Association\n\nCompute Local Moran's I of GDPPC at county level by using local_moran() of spdep package\n\n-   The code takes the `wq_q` data frame (which contains geographical data and information about spatial neighbors and weights).\n\n-   It calculates the **Local Moran's I** for the **GDPPC** variable, taking into account the spatial relationships (through `nb` and `wt`) and running 99 simulations to evaluate significance.\n\n-   The results of the **Local Moran's I** (which may include the Moran’s I statistic, z-scores, and pseudo p-values) are placed in a new column called `local_moran`.\n\n-   Finally, **`unnest()`** flattens the result, so all the relevant information (e.g., Moran's I statistic, p-value) is available in separate columns for easier interpretation.\n\nSummary of steps\n\n-   **Calculate Local Moran's I** for GDPPC.\n\n-   **Incorporate the contiguity neighbor list and spatial weights**.\n\n-   **Run 99 simulations** to determine statistical significance.\n\n-   **Unnest** the results to make them easier to analyze\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlisa <- wm_q %>%\n  mutate( local_moran = local_moran(\n    GDPPC, nb ,wt, nsim = 99),\n    .before = 1) %>%\n    unnest(local_moran)\n\nlisa\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 88 features and 20 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  China Geodetic Coordinate System 2000\n# A tibble: 88 × 21\n         ii        eii     var_ii    z_ii    p_ii p_ii_sim p_folded_sim skewness\n      <dbl>      <dbl>      <dbl>   <dbl>   <dbl>    <dbl>        <dbl>    <dbl>\n 1 -0.00147  0.00177   0.000418   -0.158  0.874       0.82         0.41   -0.812\n 2  0.0259   0.00641   0.0105      0.190  0.849       0.96         0.48   -1.09 \n 3 -0.0120  -0.0374    0.102       0.0796 0.937       0.76         0.38    0.824\n 4  0.00102 -0.0000349 0.00000437  0.506  0.613       0.64         0.32    1.04 \n 5  0.0148  -0.00340   0.00165     0.449  0.654       0.5          0.25    1.64 \n 6 -0.0388  -0.00339   0.00545    -0.480  0.631       0.82         0.41    0.614\n 7  3.37    -0.198     1.41        3.00   0.00266     0.08         0.04    1.46 \n 8  1.56    -0.265     0.804       2.04   0.0417      0.08         0.04    0.459\n 9  4.42     0.0450    1.79        3.27   0.00108     0.02         0.01    0.746\n10 -0.399   -0.0505    0.0859     -1.19   0.234       0.28         0.14   -0.685\n# ℹ 78 more rows\n# ℹ 13 more variables: kurtosis <dbl>, mean <fct>, median <fct>, pysal <fct>,\n#   nb <nb>, wt <list>, NAME_2 <chr>, ID_3 <int>, NAME_3 <chr>,\n#   ENGTYPE_3 <chr>, County <chr>, GDPPC <dbl>, geometry <POLYGON [°]>\n```\n\n\n:::\n:::\n\n\nThere will be three p_values,\n\n1.  `P_ii` is the base method\n2.  `P_ii_sim` base on simulation\n3.  `P_folded_sim` (use kfold)\n\nstay consistent and use `p_ii_sum` .\n\nMean, median pysal for how deviation\n\nIF Skew follows normal distribution, use median,\n\nIf Skewness is close to 0 use mean.\n\n1.  `Mean` -\\> for clustering\n2.  `Median ->` for clustering\n3.  `pysal`\n\n## 4.1 Visualising the Local Moran's I\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\ntmap mode set to plotting\n```\n\n\n:::\n\n```{.r .cell-code}\ntm_shape(lisa) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 2)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](In_Class_Exercise6_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n##  \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\ntmap mode set to plotting\n```\n\n\n:::\n\n```{.r .cell-code}\ntm_shape(lisa) +\n  tm_fill(\"p_ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 2)\n```\n\n::: {.cell-output-display}\n![](In_Class_Exercise6_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n## 4.3 Visualising the Local Moran's I P value and II\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmap1 <-\ntm_shape(lisa) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 2) \n\nmap2 <- tm_shape(lisa) +\n  tm_fill(\"p_ii\") +\n  # breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf) \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 2)\n\ntmap_arrange(map1, map2, ncol =2)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](In_Class_Exercise6_files/figure-html/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n# 5.0 Visualising LISA Map\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlisa_sig <- lisa %>%\n  filter(p_ii < 0.05)\n\ntmap_mode(\"plot\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\ntmap mode set to plotting\n```\n\n\n:::\n\n```{.r .cell-code}\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") +\n  tm_borders(alpha = 0.4)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](In_Class_Exercise6_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n# 6.0 Computing Local Gi\\* statssitics \n\nspatial weight matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_idw <- hunan_GDPPC %>%\n  mutate( nb = st_contiguity(geometry),\n          wts = st_inverse_distance(nb, geometry,\n                                    scale = 1,\n                                    alpha = 1),\n          .before = 1)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n! Polygon provided. Using point on surface.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n```\n\n\n:::\n:::\n\n\n::: callout-note\nGI\\* and Local Gi\\* are distanced-based spatial statistics. Hence, distance methods instead of contiguity methods should be used to derive the spatial weight matrix.\n:::\n\nCompute the local Gi\\* by using the code cchunk\n\n\n::: {.cell}\n\n```{.r .cell-code}\nHCSA <- wm_idw %>%\n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wy, nsim = 99),\n    .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  China Geodetic Coordinate System 2000\n# A tibble: 88 × 19\n   gi_star cluster   e_gi     var_gi std_dev p_value p_sim p_folded_sim skewness\n     <dbl> <fct>    <dbl>      <dbl>   <dbl>   <dbl> <dbl>        <dbl>    <dbl>\n 1  0.0416 Low     0.0114 0.00000641  0.0493 9.61e-1  0.7          0.35    0.875\n 2 -0.333  Low     0.0106 0.00000384 -0.0941 9.25e-1  1            0.5     0.661\n 3  0.281  High    0.0126 0.00000751 -0.151  8.80e-1  0.9          0.45    0.640\n 4  0.411  High    0.0118 0.00000922  0.264  7.92e-1  0.6          0.3     0.853\n 5  0.387  High    0.0115 0.00000956  0.339  7.34e-1  0.62         0.31    1.07 \n 6 -0.368  High    0.0118 0.00000591 -0.583  5.60e-1  0.72         0.36    0.594\n 7  3.56   High    0.0151 0.00000731  2.61   9.01e-3  0.06         0.03    1.09 \n 8  2.52   High    0.0136 0.00000614  1.49   1.35e-1  0.2          0.1     1.12 \n 9  4.56   High    0.0144 0.00000584  3.53   4.17e-4  0.04         0.02    1.23 \n10  1.16   Low     0.0104 0.00000370  1.82   6.86e-2  0.12         0.06    0.416\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis <dbl>, nb <nb>, wts <list>, NAME_2 <chr>,\n#   ID_3 <int>, NAME_3 <chr>, ENGTYPE_3 <chr>, County <chr>, GDPPC <dbl>,\n#   geometry <POLYGON [°]>\n```\n\n\n:::\n:::\n\n\n# 7.0 visualisating Gi\\* \n\nBe clear on the hotspot and clustering. terminology . LISA keep it to cluster, and HSCA hot/cold\n\n## Visualising hotspot and cold spot areas. with signifcant values\n\n\n::: {.cell}\n\n```{.r .cell-code}\nHCSA_sig <- HCSA %>%\n  filter(p_sim <0.05)\n\ntmap_mode(\"plot\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\ntmap mode set to plotting\n```\n\n\n:::\n\n```{.r .cell-code}\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.4)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](In_Class_Exercise6_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "In_Class_Exercise6_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}