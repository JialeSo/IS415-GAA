[
  {
    "objectID": "template.html",
    "href": "template.html",
    "title": "In Class Exercise 1: Geospatial Data Science",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_2/In_Class_Exercise2.html#importing-2014-shpz-file",
    "href": "In_Class_Exercises/In_Class_Exercise_2/In_Class_Exercise2.html#importing-2014-shpz-file",
    "title": "In Class Exercise 2: Working with Master Plan Planning Sub-zone Data",
    "section": "3.1 Importing 2014 SHPZ File",
    "text": "3.1 Importing 2014 SHPZ File\n\nTask at HandSHPZ File ImportingKML File Importing\n\n\n\nGo to data.gov.sg and download the 2014 Master Subzone SHP and KML File\nImport and read the SHP and KML File in R.\n\n\n\nWe can use the st_read function to import the data.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\In_Class_Exercises\\In_Class_Exercise_2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nSimilarly we can use the st_read function to import the data.\n\nmspz_kml &lt;- st_read(\"data/geospatial/MasterPlan2014SubzoneBoundaryWebKML.kml\")\n\nError: Cannot open \"C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\In_Class_Exercises\\In_Class_Exercise_2\\data\\geospatial\\MasterPlan2014SubzoneBoundaryWebKML.kml\"; The source could be corrupt or not supported. See `st_drivers()` for a list of supported formats.\n\n\nHowever, the data on data.gov.sg is corrupted. Hence we will do a workaround, where we can create a new kml file base on the shp file and read it.\nStep 1: using the st_write to create a kml file from the shapefile\nStep 2: using the st_read function to read the generated kml file.\n\nst_write(mpsz, \"data/geospatial/MP14_SUBZONE_WEB_PL.kml\", driver = \"KML\")\n\nLayer MP14_SUBZONE_WEB_PL in dataset data/geospatial/MP14_SUBZONE_WEB_PL.kml already exists:\nuse either append=TRUE to append to layer or append=FALSE to overwrite layer\n\n\nError in eval(expr, envir, enclos): Dataset already exists.\n\nmpsz_kml &lt;- st_read(\"data/geospatial/MP14_SUBZONE_WEB_PL.kml\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\In_Class_Exercises\\In_Class_Exercise_2\\data\\geospatial\\MP14_SUBZONE_WEB_PL.kml' \n  using driver `KML'\nSimple feature collection with 323 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_2/In_Class_Exercise2.html#importing-2019-shpz-file",
    "href": "In_Class_Exercises/In_Class_Exercise_2/In_Class_Exercise2.html#importing-2019-shpz-file",
    "title": "In Class Exercise 2: Working with Master Plan Planning Sub-zone Data",
    "section": "3.2 Importing 2019 SHPZ File",
    "text": "3.2 Importing 2019 SHPZ File\n\nTask At HandImporting the SHP FileImporting KML File\n\n\n\nGo to data.gov.sg and download the 2019 KML File\nImport and read the KML File in R.\n\n\n\n\nmpsz19_shp &lt;- st_read(dsn = \"data/geospatial\", layer = \"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\In_Class_Exercises\\In_Class_Exercise_2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\n\n\nmpsz19_kml &lt;- st_read(\"data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\In_Class_Exercises\\In_Class_Exercise_2\\data\\geospatial\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_2/In_Class_Exercise2.html#comparison-the-difference-between-shp-and-kml-file-and-formatting-the-crs.",
    "href": "In_Class_Exercises/In_Class_Exercise_2/In_Class_Exercise2.html#comparison-the-difference-between-shp-and-kml-file-and-formatting-the-crs.",
    "title": "In Class Exercise 2: Working with Master Plan Planning Sub-zone Data",
    "section": "3.3 Comparison the difference between SHP and KML File and formatting the CRS.",
    "text": "3.3 Comparison the difference between SHP and KML File and formatting the CRS.\n\n3.3.1 Understanding SHP and KML Files\nUse glimpse() and head() to compare the attributes available in each file. For instance, SHP files might have more detailed attribute tables with multiple fields, while KML files are more streamlined with fewer attributes.\n\nSHP FileKML FILE\n\n\n\nglimpse(mpsz19_shp)\n\nRows: 332\nColumns: 7\n$ SUBZONE_N  &lt;chr&gt; \"MARINA EAST\", \"INSTITUTION HILL\", \"ROBERTSON QUAY\", \"JURON…\n$ SUBZONE_C  &lt;chr&gt; \"MESZ01\", \"RVSZ05\", \"SRSZ01\", \"WISZ01\", \"MUSZ02\", \"MPSZ05\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA EAST\", \"RIVER VALLEY\", \"SINGAPORE RIVER\", \"WESTERN …\n$ PLN_AREA_C &lt;chr&gt; \"ME\", \"RV\", \"SR\", \"WI\", \"MU\", \"MP\", \"WI\", \"WI\", \"SI\", \"SI\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"WEST…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"WR\", \"CR\", \"CR\", \"WR\", \"WR\", \"CR\", \"CR\",…\n$ geometry   &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((103.8802 1...., MULTIPOLYGON (…\n\n\n\nhead(mpsz19_shp)\n\nSimple feature collection with 6 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6537 ymin: 1.216215 xmax: 103.8988 ymax: 1.297462\nGeodetic CRS:  WGS 84\n                SUBZONE_N SUBZONE_C      PLN_AREA_N PLN_AREA_C       REGION_N\n1             MARINA EAST    MESZ01     MARINA EAST         ME CENTRAL REGION\n2        INSTITUTION HILL    RVSZ05    RIVER VALLEY         RV CENTRAL REGION\n3          ROBERTSON QUAY    SRSZ01 SINGAPORE RIVER         SR CENTRAL REGION\n4 JURONG ISLAND AND BUKOM    WISZ01 WESTERN ISLANDS         WI    WEST REGION\n5            FORT CANNING    MUSZ02          MUSEUM         MU CENTRAL REGION\n6        MARINA EAST (MP)    MPSZ05   MARINE PARADE         MP CENTRAL REGION\n  REGION_C                       geometry\n1       CR MULTIPOLYGON (((103.8802 1....\n2       CR MULTIPOLYGON (((103.8376 1....\n3       CR MULTIPOLYGON (((103.8341 1....\n4       WR MULTIPOLYGON (((103.7125 1....\n5       CR MULTIPOLYGON (((103.8472 1....\n6       CR MULTIPOLYGON (((103.8987 1....\n\n\n\n\n\nglimpse(mpsz19_kml)\n\nRows: 332\nColumns: 3\n$ Name        &lt;chr&gt; \"kml_1\", \"kml_2\", \"kml_3\", \"kml_4\", \"kml_5\", \"kml_6\", \"kml…\n$ Description &lt;chr&gt; \"&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Att…\n$ geometry    &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON Z (((103.8145 ..., MULTIPOLYGON …\n\n\n\nhead(mpsz19_kml)\n\nSimple feature collection with 6 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XYZ\nBounding box:  xmin: 103.8013 ymin: 1.274155 xmax: 103.8532 ymax: 1.286517\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n   Name\n1 kml_1\n2 kml_2\n3 kml_3\n4 kml_4\n5 kml_5\n6 kml_6\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Description\n1     &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;SUBZONE_NO&lt;/th&gt; &lt;td&gt;12&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;SUBZONE_N&lt;/th&gt; &lt;td&gt;DEPOT ROAD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;SUBZONE_C&lt;/th&gt; &lt;td&gt;BMSZ12&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CA_IND&lt;/th&gt; &lt;td&gt;N&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PLN_AREA_N&lt;/th&gt; &lt;td&gt;BUKIT MERAH&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;PLN_AREA_C&lt;/th&gt; &lt;td&gt;BM&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;REGION_N&lt;/th&gt; &lt;td&gt;CENTRAL REGION&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;REGION_C&lt;/th&gt; &lt;td&gt;CR&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;C22DED671DE2A940&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20191223152313&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n2     &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;SUBZONE_NO&lt;/th&gt; &lt;td&gt;2&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;SUBZONE_N&lt;/th&gt; &lt;td&gt;BUKIT MERAH&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;SUBZONE_C&lt;/th&gt; &lt;td&gt;BMSZ02&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CA_IND&lt;/th&gt; &lt;td&gt;N&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PLN_AREA_N&lt;/th&gt; &lt;td&gt;BUKIT MERAH&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;PLN_AREA_C&lt;/th&gt; &lt;td&gt;BM&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;REGION_N&lt;/th&gt; &lt;td&gt;CENTRAL REGION&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;REGION_C&lt;/th&gt; &lt;td&gt;CR&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;085EF219A5A1AEAD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20191223152313&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n3            &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;SUBZONE_NO&lt;/th&gt; &lt;td&gt;3&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;SUBZONE_N&lt;/th&gt; &lt;td&gt;CHINATOWN&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;SUBZONE_C&lt;/th&gt; &lt;td&gt;OTSZ03&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CA_IND&lt;/th&gt; &lt;td&gt;Y&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PLN_AREA_N&lt;/th&gt; &lt;td&gt;OUTRAM&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;PLN_AREA_C&lt;/th&gt; &lt;td&gt;OT&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;REGION_N&lt;/th&gt; &lt;td&gt;CENTRAL REGION&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;REGION_C&lt;/th&gt; &lt;td&gt;CR&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;EF2B9A91AF49E025&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20191223152313&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n4       &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;SUBZONE_NO&lt;/th&gt; &lt;td&gt;4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;SUBZONE_N&lt;/th&gt; &lt;td&gt;PHILLIP&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;SUBZONE_C&lt;/th&gt; &lt;td&gt;DTSZ04&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CA_IND&lt;/th&gt; &lt;td&gt;Y&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PLN_AREA_N&lt;/th&gt; &lt;td&gt;DOWNTOWN CORE&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;PLN_AREA_C&lt;/th&gt; &lt;td&gt;DT&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;REGION_N&lt;/th&gt; &lt;td&gt;CENTRAL REGION&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;REGION_C&lt;/th&gt; &lt;td&gt;CR&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;615D4EDDEF809F8E&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20191223152313&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n5 &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;SUBZONE_NO&lt;/th&gt; &lt;td&gt;5&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;SUBZONE_N&lt;/th&gt; &lt;td&gt;RAFFLES PLACE&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;SUBZONE_C&lt;/th&gt; &lt;td&gt;DTSZ05&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CA_IND&lt;/th&gt; &lt;td&gt;Y&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PLN_AREA_N&lt;/th&gt; &lt;td&gt;DOWNTOWN CORE&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;PLN_AREA_C&lt;/th&gt; &lt;td&gt;DT&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;REGION_N&lt;/th&gt; &lt;td&gt;CENTRAL REGION&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;REGION_C&lt;/th&gt; &lt;td&gt;CR&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;72107B11807074F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20191223152313&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n6         &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;SUBZONE_NO&lt;/th&gt; &lt;td&gt;4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;SUBZONE_N&lt;/th&gt; &lt;td&gt;CHINA SQUARE&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;SUBZONE_C&lt;/th&gt; &lt;td&gt;OTSZ04&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CA_IND&lt;/th&gt; &lt;td&gt;Y&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PLN_AREA_N&lt;/th&gt; &lt;td&gt;OUTRAM&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;PLN_AREA_C&lt;/th&gt; &lt;td&gt;OT&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;REGION_N&lt;/th&gt; &lt;td&gt;CENTRAL REGION&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;REGION_C&lt;/th&gt; &lt;td&gt;CR&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;B609DF5587626C8F&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20191223152313&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n                        geometry\n1 MULTIPOLYGON Z (((103.8145 ...\n2 MULTIPOLYGON Z (((103.8221 ...\n3 MULTIPOLYGON Z (((103.8438 ...\n4 MULTIPOLYGON Z (((103.8496 ...\n5 MULTIPOLYGON Z (((103.8525 ...\n6 MULTIPOLYGON Z (((103.8486 ...\n\n\n\n\n\n\n\nSHP vs. KML: Key Differences\n\n\nSummary Table:\n\n\n\n\n\n\n\n\nProperty\nSHP (Shapefile)\nKML (Keyhole Markup Language)\n\n\n\n\nFile Structure\nMultiple files for geometries and attributes\nSingle file for visualization\n\n\nAttributes\nDetailed, diverse data types\nLimited, mostly descriptive\n\n\nGeometry Types\nComplex, suited for GIS analysis\nBasic, suited for display\n\n\nCRS Information\nExplicit and configurable (e.g., EPSG:3414)\nTypically defaults to WGS84\n\n\nUsage Context\nGIS analysis, mapping\nWeb-based visualization\n\n\nPerformance\nSlower with large datasets\nLightweight and quick for display\n\n\n\n\n\n3.3.2 CRS (Coordinate Reference System)\n\nSHP File CRS: Shapefiles often come with a defined CRS. In this case, we ensure that it is aligned with Singapore’s local system (EPSG:3414).\nKML File CRS: KML files typically default to WGS84 (EPSG:4326), which is used in web applications and is latitude/longitude-based.\n\n\n\n\n\n\n\nHow to know which CRS to use ? We can simply go to epsg.io to check https://epsg.io/?q=singapore\n\n\n\n\nst_crs(mpsz19_shp)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\nmpsz19_shp_crs3414 &lt;- st_read(dsn = \"data/geospatial\", layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\In_Class_Exercises\\In_Class_Exercise_2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nst_crs(mpsz19_shp_crs3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_2/In_Class_Exercise2.html#import-and-simple-data-transformation",
    "href": "In_Class_Exercises/In_Class_Exercise_2/In_Class_Exercise2.html#import-and-simple-data-transformation",
    "title": "In Class Exercise 2: Working with Master Plan Planning Sub-zone Data",
    "section": "4.1 Import and Simple Data Transformation",
    "text": "4.1 Import and Simple Data Transformation\n\nThe TaskCode\n\n\nGo toSingStat Website and download 2023’s dataset for our popuplation data. We then group them by age and subzone\n\n\n\npopdata &lt;- read_csv(\"data/respopagesextod2023.csv\")\npopdata2023 &lt;- popdata %&gt;%\n  group_by(PA, SZ, AG) %&gt;%  # Ensure data is grouped by 'AG' if needed\n  summarise(POP = sum(Pop, na.rm = TRUE)) %&gt;%  # Summarise population\n  pivot_wider(names_from = AG, values_from = POP) %&gt;%  # Pivot to wider format\n  ungroup()  # Ungroup the data\n\n# Check the column names\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\""
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_2/In_Class_Exercise2.html#simply-join-the-data-and-then-map-it-out",
    "href": "In_Class_Exercises/In_Class_Exercise_2/In_Class_Exercise2.html#simply-join-the-data-and-then-map-it-out",
    "title": "In Class Exercise 2: Working with Master Plan Planning Sub-zone Data",
    "section": "4.2 Simply join the data and then map it out",
    "text": "4.2 Simply join the data and then map it out\n\n4.2.1 Join the data\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper))\n\n#Step 5: Merge the spatial data with the population data\nmpsz_pop2020 &lt;- left_join(mpsz19_shp_crs3414, popdata2023,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\n\n4.2.2 Plot the map\n\ntmap_mode(\"plot\")\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"0_to_4\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"0_to_4\") +\n  tm_layout(main.title = \"Distribution of 0_to_4 by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_2/data/geospatial/MPSZ-2019.html",
    "href": "In_Class_Exercises/In_Class_Exercise_2/data/geospatial/MPSZ-2019.html",
    "title": "IS415-GAA: JialeSo",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_1/downloaded Files/MPSZ-2019/MPSZ-2019.html",
    "href": "In_Class_Exercises/In_Class_Exercise_1/downloaded Files/MPSZ-2019/MPSZ-2019.html",
    "title": "IS415-GAA: JialeSo",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to my IS415 Journey :) Jiale So here!",
    "section": "",
    "text": "Welcome to my website ! I’m a student currently enrolled in this course, where I’ll be diving deep into the world of geospatial analysis and geographic information systems (GIS). Through hands-on exercises, in-class activities, and take-home assignments, I’ll be exploring the practical applications of geospatial technologies.\n\n\nIS415-GAA is designed to introduce students to the key concepts and tools used in geospatial analysis. We will cover topics like spatial data collection, visualization, and analysis. By the end of the course, I aim to have a solid understanding of how to apply GIS principles to solve real-world problems.\n\n\n\nHands-On Exercises: This section includes practical exercises designed to apply what we learn in class. These exercises will help reinforce concepts and develop technical skills in GIS.\nIn-Class Exercises: These activities are done during class sessions to help us grasp key concepts quickly and collaboratively.\nTake-Home Exercises: Assignments to be completed independently, giving us the opportunity to dive deeper into specific topics at our own pace.\n\n\n\n\n\nI chose IS415-GAA because of its relevance in today’s data-driven world. Geospatial analysis is becoming increasingly important across many industries, and I’m excited to build the skills that can help me make data-driven decisions and contribute to meaningful projects.\n\n\n\nThroughout the course, I’ll be documenting my progress, reflecting on key learning points, and sharing interesting insights I discover along the way. Stay tuned as I embark on this exciting journey into the realm of geospatial analysis!\n\nTo navigate the site, use the links in the navigation bar at the top."
  },
  {
    "objectID": "index.html#about-this-module",
    "href": "index.html#about-this-module",
    "title": "Welcome to my IS415 Journey :) Jiale So here!",
    "section": "",
    "text": "IS415-GAA is designed to introduce students to the key concepts and tools used in geospatial analysis. We will cover topics like spatial data collection, visualization, and analysis. By the end of the course, I aim to have a solid understanding of how to apply GIS principles to solve real-world problems.\n\n\n\nHands-On Exercises: This section includes practical exercises designed to apply what we learn in class. These exercises will help reinforce concepts and develop technical skills in GIS.\nIn-Class Exercises: These activities are done during class sessions to help us grasp key concepts quickly and collaboratively.\nTake-Home Exercises: Assignments to be completed independently, giving us the opportunity to dive deeper into specific topics at our own pace."
  },
  {
    "objectID": "index.html#why-i-chose-this-module",
    "href": "index.html#why-i-chose-this-module",
    "title": "Welcome to my IS415 Journey :) Jiale So here!",
    "section": "",
    "text": "I chose IS415-GAA because of its relevance in today’s data-driven world. Geospatial analysis is becoming increasingly important across many industries, and I’m excited to build the skills that can help me make data-driven decisions and contribute to meaningful projects."
  },
  {
    "objectID": "index.html#what-to-expect",
    "href": "index.html#what-to-expect",
    "title": "Welcome to my IS415 Journey :) Jiale So here!",
    "section": "",
    "text": "Throughout the course, I’ll be documenting my progress, reflecting on key learning points, and sharing interesting insights I discover along the way. Stay tuned as I embark on this exciting journey into the realm of geospatial analysis!\n\nTo navigate the site, use the links in the navigation bar at the top."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html",
    "href": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "Using TMap, we will learn how to plot functional and truthful choropleth maps. Through Geo visualization, we allow our audiences to understand the dataset easier with their spatial cognition."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#importing-the-geo-spatial-data",
    "href": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#importing-the-geo-spatial-data",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "2.1 Importing the Geo-spatial Data",
    "text": "2.1 Importing the Geo-spatial Data\nSimply use the st_read() function to import the shapefile into R.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n2.1.1 Understanding the data\nWe can easily examine the content of mpsz by calling the variable:\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\nQuestion -&gt; Notice that only the first ten records will be displayed. Do you know why?\n\nOnly 10 records are shown because displaying a subset of rows makes it easier to inspect the data without loading the entire dataset. This optimization helps improve processing time for large datasets. Often, these first 10 records provide users with a quick preview of the dataset.\nRemember, we can always explore the content of mpsz using the following functions. If we want to preview more than 10 records, we can simply use head(mpsz, 20) to view more rows.\n\nst_geometry: Prints basic information about the feature class, such as the type of geometry.\nglimpse: Displays associated attribute information in the data frame.\nhead: Reveals complete information of a feature object.\n\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\nhead(mpsz, n = 20)\n\nSimple feature collection with 20 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 8012.578 ymin: 15748.72 xmax: 33316.59 ymax: 31081.67\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nThrough glimpse and head, we can map the following columns to their description for ease of use.\n\n\n\n\n\n\n\n\n\nVariable Name\nDescription\nCluster (Y/N)\nData Type / Example Values\n\n\n\n\nOBJECTID\nUnique identifier for each row in the dataset.\nN\n&lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, …\n\n\nSUBZONE_NO\nNumeric code representing the specific subzone within the planning area.\nY\n&lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, …\n\n\nSUBZONE_N\nThe name of the subzone (e.g., “MARINA SOUTH,” “PEARL’S HILL”).\nY\n&lt;chr&gt; “MARINA SOUTH”, “PEARL’S HILL”, “BOAT QUAY”, …\n\n\nSUBZONE_C\nShort code representing the subzone, typically an abbreviation.\nY\n&lt;chr&gt; “MSSZ01”, “OTSZ01”, “SRSZ03”, “BMSZ08”, …\n\n\nCA_IND\nIndicates if the subzone is a Central Area subzone (“Y” for Yes, “N” for No).\nY\n&lt;chr&gt; “Y”, “Y”, “Y”, “N”, “N”, “N”, “N”, …\n\n\nPLN_AREA_N\nThe name of the planning area that the subzone belongs to (e.g., “OUTRAM”).\nY\n&lt;chr&gt; “MARINA SOUTH”, “OUTRAM”, “SINGAPORE RIVER”, …\n\n\nPLN_AREA_C\nShort code representing the planning area (abbreviation).\nY\n&lt;chr&gt; “MS”, “OT”, “SR”, “BM”, “BM”, “BM”, …\n\n\nREGION_N\nThe name of the broader region (e.g., “CENTRAL REGION,” “WEST REGION”).\nY\n&lt;chr&gt; “CENTRAL REGION”, “CENTRAL REGION”, “CENTRAL REGION”, …\n\n\nREGION_C\nShort code representing the region (e.g., “CR” for Central Region).\nY\n&lt;chr&gt; “CR”, “CR”, “CR”, “CR”, “CR”, “CR”, …\n\n\nINC_CRC\nInternal checksum code for data integrity; not relevant for clustering.\nN\n&lt;chr&gt; “5ED7EB253F99252E”, “8C7149B9EB32EEFC”, “C35FEFF02B13E0E5”, …\n\n\nFMEL_UPD_D\nDate when the data was last updated (e.g., “2014-12-05”).\nN\n&lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, …\n\n\nX_ADDR\nX coordinate of the subzone’s centroid or key location.\nY\n&lt;dbl&gt; 31595.84, 28679.06, 29654.96, …\n\n\nY_ADDR\nY coordinate of the subzone’s centroid or key location.\nY\n&lt;dbl&gt; 29220.19, 29782.05, 29974.66, …\n\n\nSHAPE_Leng\nThe length of the subzone boundary (in meters).\nY\n&lt;dbl&gt; 5267.381, 3506.107, 1740.926, …\n\n\nSHAPE_Area\nThe area of the subzone (in square meters).\nY\n&lt;dbl&gt; 1630379.27, 559816.25, 160807.50, …\n\n\ngeometry\nGeographic shape data (MULTIPOLYGON) representing the subzone’s boundaries.\nY\n&lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30…, MULTIPOLYGON (((29092.28 30…, …"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#importing-attribute-data---singapore-population-data",
    "href": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#importing-attribute-data---singapore-population-data",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "2.2 Importing Attribute Data - Singapore Population Data",
    "text": "2.2 Importing Attribute Data - Singapore Population Data\nWe can simply use the read_csv function from the readr package:\n\npopdata &lt;- read_csv(\"data/respopagesextod2011to2020.csv\")\n\n\n2.2.1 Understanding the data\nWe can perform the same exploration to understand this data set, or simply refer to the data source website here. For a quick analysis, use head() and glimpse():\n\nhead(popdata, n = 20)\n\n# A tibble: 20 × 7\n   PA         SZ                     AG     Sex     TOD                Pop  Time\n   &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;\n 1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 1- and 2-Ro…     0  2011\n 2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 3-Room Flats    10  2011\n 3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 4-Room Flats    30  2011\n 4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 5-Room and …    50  2011\n 5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HUDC Flats (exc…     0  2011\n 6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Landed Properti…     0  2011\n 7 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Condominiums an…    40  2011\n 8 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Others               0  2011\n 9 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 1- and 2-Ro…     0  2011\n10 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 3-Room Flats    10  2011\n11 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 4-Room Flats    30  2011\n12 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 5-Room and …    60  2011\n13 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HUDC Flats (exc…     0  2011\n14 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females Landed Properti…     0  2011\n15 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females Condominiums an…    40  2011\n16 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females Others               0  2011\n17 Ang Mo Kio Ang Mo Kio Town Centre 5_to_9 Males   HDB 1- and 2-Ro…     0  2011\n18 Ang Mo Kio Ang Mo Kio Town Centre 5_to_9 Males   HDB 3-Room Flats    10  2011\n19 Ang Mo Kio Ang Mo Kio Town Centre 5_to_9 Males   HDB 4-Room Flats    30  2011\n20 Ang Mo Kio Ang Mo Kio Town Centre 5_to_9 Males   HDB 5-Room and …    60  2011\n\nglimpse(popdata, n = 2000)\n\nRows: 984,656\nColumns: 7\n$ PA   &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo K…\n$ SZ   &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo Kio T…\n$ AG   &lt;chr&gt; \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to…\n$ Sex  &lt;chr&gt; \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"M…\n$ TOD  &lt;chr&gt; \"HDB 1- and 2-Room Flats\", \"HDB 3-Room Flats\", \"HDB 4-Room Flats\"…\n$ Pop  &lt;dbl&gt; 0, 10, 30, 50, 0, 0, 40, 0, 0, 10, 30, 60, 0, 0, 40, 0, 0, 10, 30…\n$ Time &lt;dbl&gt; 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011,…\n\n\n\n\n\nColumn Name\nColumn Full Name\nDescription\n\n\n\n\nPA\nPlanning Area\n\n\n\nSZ\nSubzone\n\n\n\nAG\nAge Group\n\n\n\nSEX\nSex\n\n\n\nTOD\nType Of Dwelling\n\n\n\nPOP\nResident count\n\n\n\nTime\nTime / Period\n\n\n\n\n\n\n2.2.2 Data Preparation\nBased on the data provided, we aim to create a thematic map focusing on 2020 values:\nClustering of age group\n\nYOUNG: Age groups 0 to 4 until age groups 20 to 24.\nECONOMY ACTIVE: Age groups 25-29 until age groups 60-64.\nAGED: Age groups 65 and above.\nTOTAL: All age groups combined.\nDEPENDENCY: The ratio of young and aged populations relative to the economy active population.\n\n\nData Transformation Process\n1. First get all the possible agegroup in a variable.\n2. filter the data set for only 2020 values.\n2. Then from there group them base on young, which is 0~4 to 20~24. etc.\n4. Summarmise the data between the population\n5. Join the Datasetss with left join\n\n\nnames(popdata) # Get the colum names of the popdata\n\n[1] \"PA\"   \"SZ\"   \"AG\"   \"Sex\"  \"TOD\"  \"Pop\"  \"Time\"\n\nage_categories &lt;- unique(popdata$AG)\n\n#Step 1\nnames(popdata)\n\n[1] \"PA\"   \"SZ\"   \"AG\"   \"Sex\"  \"TOD\"  \"Pop\"  \"Time\"\n\npopdata_2020 &lt;- popdata[popdata$Time == 2020, ]\npopdata_2020 &lt;- popdata_2020 %&gt;%\n  mutate(\n    age_group = case_when(\n      AG %in% age_categories[1:5] ~ \"Young\",  # Age groups 0_to_4 until 20_to_24\n      AG %in% age_categories[6:13] ~ \"Economy Active\",  # Age groups 25_to_29 until 60_to_64\n      AG %in% age_categories[14:length(age_categories)] ~ \"Aged\",  # Age groups 65 and above\n      TRUE ~ \"Other\"\n    )\n  )\n\n# Step 2: Group by PA, SZ, and age_group, then sum the population\ngrouped_popdata &lt;- popdata_2020 %&gt;%\n  group_by(PA, SZ, age_group) %&gt;%\n  summarise(total_population = sum(Pop, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# Step 3: Pivot the data to have separate columns for Young, Economy Active, and Aged\npivoted_data &lt;- grouped_popdata %&gt;%\n  pivot_wider(\n    names_from = age_group,\n    values_from = total_population,\n    values_fill = 0  # Fill missing values with 0\n  )\n\n# Step 4: Calculate TOTAL and DEPENDENCY columns\nfinal_data_2020 &lt;- pivoted_data %&gt;%\n  mutate(\n    TOTAL = Young + `Economy Active` + Aged,\n    DEPENDENCY = (Young + Aged) / `Economy Active`\n  )\n\n# Ensure all PA and SZ values are uppercase for consistency\nfinal_data_2020 &lt;- final_data_2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper))\n\n#Step 5: Merge the spatial data with the population data\nmpsz_pop2020 &lt;- left_join(mpsz, final_data_2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#quick-thematic-map-qtm",
    "href": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#quick-thematic-map-qtm",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "3.1 Quick Thematic Map: qtm()",
    "text": "3.1 Quick Thematic Map: qtm()\nThe qtm() function provides a fast and simple way to create maps.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, fill = \"DEPENDENCY\")"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#customizing-tmap-elements",
    "href": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#customizing-tmap-elements",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "3.2 Customizing tmap elements",
    "text": "3.2 Customizing tmap elements\nExplore the core tmap elements, including layers, aesthetics, and customization options.\n\n3.2.1 Intro to TMAP\nA basic map can be created with the following code:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n3.2.1.1 Explanation of tmap Elements:\n\ntm_shape(mpsz_pop2020): Defines the spatial object to be visualized, in this case, the mpsz_pop2020 dataset.\ntm_fill(): Adds a fill layer to the map based on the DEPENDENCY variable.\n\nstyle = \"quantile\": Classifies data into quantiles for better visual distribution.\npalette = \"Blues\": Specifies the color scheme for the map, using a sequential palette.\ntitle = \"Dependency ratio\": Sets the title for the legend.\n\ntm_layout(): Customizes the overall map layout.\n\nmain.title and its options: Adds a centered title to the map with customized size and positioning.\nlegend.height and legend.width: Adjusts the size of the legend.\nframe = TRUE: Adds a border around the map.\n\ntm_borders(alpha = 0.5): Adds semi-transparent borders to the map, enhancing visual separation between areas.\ntm_compass(type = \"8star\", size = 2): Adds a decorative compass with an eight-point star design to the map.\ntm_scale_bar(): Includes a scale bar, providing a reference for distance.\ntm_grid(alpha = 0.2): Adds a faint grid to the background, aiding spatial orientation.\ntm_credits(): Displays credits and data sources in the bottom-left corner of the map.\n\n\n\n3.2.1.2 Additional T-Map Elements\n\nDots and Symbols: Use tm_dots() for point data and tm_symbols() for more complex symbol mapping.\nLines: Add linear features using tm_lines(), which allows customization of line color, width, and style.\nText Labels: The tm_text() function displays labels on the map, with options for adjusting text size, color, and positioning.\nFaceting (Small Multiples): tm_facets() is useful for comparing data across time periods, categories, or regions.\nStacking Layers: Multiple tm_shape() calls can overlay different spatial objects, allowing mixed data types.\nRaster Data: For continuous surface data like heatmaps, use tm_raster().\nLegends: The tm_legend() function offers finer control over legend appearance.\nInteractive Viewing: When building interactive maps, tm_view() supports zooming and panning for web applications.\nGraticules and Grid Lines: Use tm_graticules() to add latitude and longitude lines for spatial orientation.\n\n\n\n\n3.2.2 Drawing Maps\n\n3.2.2.1 Set up the base map\n\ntm_shape(mpsz_pop2020) + tm_polygons()\n\n\n\n\n\n\n\n\n\n\n3.2.2.2 Set up choropleth map with TMAP and TM_Polygons\n\ntm_shape(mpsz_pop2020) + tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n3.2.2.3 Drawing a choropleth map using tm_fill() and *tm_border()\n\ntm_shape(mpsz_pop2020)+ tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n#With Borders\ntm_shape(mpsz_pop2020)+tm_fill(\"DEPENDENCY\") + tm_borders(lwd = 0.1,  alpha = 1)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#data-classification",
    "href": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#data-classification",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "3.3 data classification",
    "text": "3.3 data classification\n\n3.3.1 Understanding Data Classification\nTechniques for categorizing continuous or categorical data into classes for better readability. tmap offers ten classification methods, including fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\n\nmap_quantile &lt;-\n  tm_shape(mpsz_pop2020) + \n    tm_fill(\"DEPENDENCY\", n = 5, style = \"quantile\") + \n    tm_borders(alpha = 0.5) + \n    tm_layout(title = \"quantile\", legend.outside = TRUE, legend.outside.size = 0.2)\n\nmap_equal &lt;- \n  tm_shape(mpsz_pop2020) + \n    tm_fill(\"DEPENDENCY\", n = 5, style = \"equal\") + \n    tm_borders(alpha = 0.5) + \n    tm_layout(title = \"equal\", legend.outside = TRUE, legend.outside.size = 0.2)\n\nmap_pretty &lt;-\n  tm_shape(mpsz_pop2020) + \n    tm_fill(\"DEPENDENCY\", n = 5, style = \"pretty\") + \n    tm_borders(alpha = 0.5) + \n    tm_layout(title = \"pretty\", legend.outside = TRUE, legend.outside.size = 0.2)\n\nmap_fisher &lt;-\n  tm_shape(mpsz_pop2020) + \n    tm_fill(\"DEPENDENCY\", n = 5, style = \"fisher\") + \n    tm_borders(alpha = 0.5) + \n    tm_layout(title = \"fisher\", legend.outside = TRUE, legend.outside.size = 0.2)\n\nmap_kmeans &lt;-\n  tm_shape(mpsz_pop2020) + \n    tm_fill(\"DEPENDENCY\", n = 5, style = \"kmeans\") + \n    tm_borders(alpha = 0.5) + \n    tm_layout(title = \"kmeans\", legend.outside = TRUE, legend.outside.size = 0.2)\n\n# Arrange maps with all legends displayed outside and scaled\ntmap_arrange(map_quantile, map_equal, map_pretty, \n             map_fisher, map_kmeans,\n             ncol = 2, nrow = 3)\n\n\n\n\n\n\n\n\n\n\n3.3.2 Classification and Data manipulation\nData lies all the time and it’s no difference from Maps, be careful on what are the classification method that we choose! Notice the different when we have different number of classification size.\n\n# Quantile Maps\nmap_quantile_2 &lt;-\n  tm_shape(mpsz_pop2020) + \n    tm_fill(\"DEPENDENCY\", n = 2, style = \"quantile\") + \n    tm_borders(alpha = 0.5) + \n    tm_layout(\n      main.title = \"Distribution Dependency - (Quantile - 2 classes)\", \n      main.title.position = \"center\", \n      main.title.size = 0.5, \n      main.title.fontface = \"bold\", # Bold main title\n      legend.outside = TRUE, \n      legend.outside.size = 0.2\n    )\n\nmap_quantile_6 &lt;-\n  tm_shape(mpsz_pop2020) + \n    tm_fill(\"DEPENDENCY\", n = 6, style = \"quantile\") + \n    tm_borders(alpha = 0.5) + \n    tm_layout(\n      main.title = \"Distribution Dependency - (Quantile - 6 classes)\", \n      main.title.position = \"center\", \n      main.title.size = 0.5, \n      main.title.fontface = \"bold\", # Bold main title\n      legend.outside = TRUE, \n      legend.outside.size = 0.2\n    )\n\nmap_quantile_10 &lt;-\n  tm_shape(mpsz_pop2020) + \n    tm_fill(\"DEPENDENCY\", n = 10, style = \"quantile\") + \n    tm_borders(alpha = 0.5) + \n    tm_layout(\n      main.title = \"Distribution Dependency - (Quantile - 10 classes)\", \n      main.title.position = \"center\", \n      main.title.size = 0.5, \n      main.title.fontface = \"bold\", # Bold main title\n      legend.outside = TRUE, \n      legend.outside.size = 0.2\n    )\n\nmap_quantile_20 &lt;-\n  tm_shape(mpsz_pop2020) + \n    tm_fill(\"DEPENDENCY\", n = 20, style = \"quantile\") + \n    tm_borders(alpha = 0.5) + \n    tm_layout(\n      main.title = \"Distribution Dependency - (Quantile - 20 classes)\", \n      main.title.position = \"center\", \n      main.title.size = 0.5, \n      main.title.fontface = \"bold\", # Bold main title\n      legend.outside = TRUE, \n      legend.outside.size = 0.2\n    )\n\n# Arrange the quantile maps in a grid\ntmap_arrange(map_quantile_2, map_quantile_6, map_quantile_10, map_quantile_20,\n             ncol = 2, nrow = 2)\n\n\n\n\n\n\n\n# Equal Interval Maps\nmap_equal_2 &lt;-\n  tm_shape(mpsz_pop2020) + \n    tm_fill(\"DEPENDENCY\", n = 2, style = \"equal\") + \n    tm_borders(alpha = 0.5) + \n    tm_layout(\n      main.title = \"Distribution Dependency - (Equal - 2 classes)\", \n      main.title.position = \"center\", \n      main.title.size = 0.5, \n      main.title.fontface = \"bold\", # Bold main title\n      legend.outside = TRUE, \n      legend.outside.size = 0.2\n    )\n\nmap_equal_6 &lt;-\n  tm_shape(mpsz_pop2020) + \n    tm_fill(\"DEPENDENCY\", n = 6, style = \"equal\") + \n    tm_borders(alpha = 0.5) + \n    tm_layout(\n      main.title = \"Distribution Dependency - (Equal - 6 classes)\", \n      main.title.position = \"center\", \n      main.title.size = 0.5, \n      main.title.fontface = \"bold\", # Bold main title\n      legend.outside = TRUE, \n      legend.outside.size = 0.2\n    )\n\nmap_equal_10 &lt;-\n  tm_shape(mpsz_pop2020) + \n    tm_fill(\"DEPENDENCY\", n = 10, style = \"equal\") + \n    tm_borders(alpha = 0.5) + \n    tm_layout(\n      main.title = \"Distribution Dependency - (Equal - 10 classes)\", \n      main.title.position = \"center\", \n      main.title.size = 0.5, \n      main.title.fontface = \"bold\", # Bold main title\n      legend.outside = TRUE, \n      legend.outside.size = 0.2\n    )\n\nmap_equal_20 &lt;-\n  tm_shape(mpsz_pop2020) + \n    tm_fill(\"DEPENDENCY\", n = 20, style = \"equal\") + \n    tm_borders(alpha = 0.5) + \n    tm_layout(\n      main.title = \"Distribution Dependency - (Equal - 20 classes)\", \n      main.title.position = \"center\", \n      main.title.size = 0.5, \n      main.title.fontface = \"bold\", # Bold main title\n      legend.outside = TRUE, \n      legend.outside.size = 0.2\n    )\n\n# Arrange the equal interval maps in a grid\ntmap_arrange(map_equal_2, map_equal_6, map_equal_10, map_equal_20,\n             ncol = 2, nrow = 2)\n\n\n\n\n\n\n\n\nThe choice between a smaller or larger n (number of classes) depends on the level of detail we want to show:\n\nSmaller n (e.g., 2 or 3 classes): Best for broad, simplified comparisons or when you want to emphasize clear distinctions between categories. Useful for general audiences or when the data has clear breakpoints.\nLarger n (e.g., 10 or 20 classes): Ideal for showing fine-grained differences and detecting subtle patterns. More useful when detailed analysis is needed, but it can overwhelm or confuse the viewer if not carefully chosen.\n\nThe decision is less about standard deviation and more about the purpose of your analysis: high n captures more detail, while low n simplifies the data.\n\n3.3.2.4 Custom Break\nAlternatively, we can always just use summary function to get some descriptive statistic and set custom breakpoints.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6519  0.7025  0.7742  0.7645 19.0000      92 \n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#color-scheme",
    "href": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#color-scheme",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "3.4 color scheme",
    "text": "3.4 color scheme\nChoosing effective color schemes to enhance visual communication, with a focus on sequential, diverging, and categorical palettes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(\n      main.title = \"Blue Color Scheme\", \n      main.title.position = \"center\", \n      main.title.size = 1.5, \n      main.title.fontface = \"bold\", # Bold main title\n      legend.outside = TRUE, \n      legend.outside.size = 0.2\n    )\n\n\n\n\n\n\n\n# Reverse color\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(\n      main.title = \"Reverse Green Color Scheme\", \n      main.title.position = \"center\", \n      main.title.size = 1.5, \n      main.title.fontface = \"bold\", # Bold main title\n      legend.outside = TRUE, \n      legend.outside.size = 0.2\n    )"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#map-layouts",
    "href": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#map-layouts",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "3.5 map layouts",
    "text": "3.5 map layouts\nCustomizing map layouts, including titles, legends, scale bars, and other cartographic elements.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n# Map Style\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n# tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#drawing-small-multiple-choropelth-maps",
    "href": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#drawing-small-multiple-choropelth-maps",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "3.6 drawing small multiple choropelth maps",
    "text": "3.6 drawing small multiple choropelth maps\nGenerate multiple maps in a single visual output to compare different variables or time periods. Small multiple maps (facet maps) allow visualization of how spatial patterns change across categories.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"Young\", \"Aged\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"Aged\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"Young\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"Aged\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#mapping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#mapping-spatial-object-meeting-a-selection-criterion",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "3.7 mapping spatial object meeting a selection criterion",
    "text": "3.7 mapping spatial object meeting a selection criterion\nFilter and map spatial objects that satisfy specific conditions or criteria.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#age-cluster-by-years-and-sub-zones.",
    "href": "Hands_On_Exercises/Hands_On_Exercise_2/Hands_On_Exercise2.html#age-cluster-by-years-and-sub-zones.",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "4.1 Age Cluster By Years and Sub zones.",
    "text": "4.1 Age Cluster By Years and Sub zones.\nLet’s push the boundaries a bit! The goal is to visualize how the age clusters within each subzone have evolved over time. Although we haven’t fully explored interactivity yet, we can take on the challenge of creating a video GIF that sequentially combines maps for each year. We’ll wrap it up with a bird’s-eye comparison of the different years side by side.\n\n4.1.1 Preparing the data set\n\nWe Need to read the data set in\nFind and cluster the age groups\n\nFirst Get all the age group categories\nThen cluster then to young, economy active and aged.\n\nThen we full join the map to their individual values.\n\n\npopulation_data &lt;- read.csv(\"data/respopagesextod2011to2020.csv\")\n# Load the population data\n# Categorize age groups\nage_categories &lt;- unique(popdata$AG)\npopulation_data &lt;- population_data %&gt;%\n  mutate(\n    Age_Category = case_when(\n      AG %in% age_categories[1:5] ~ \"Young\",  # Age groups 0_to_4 until 20_to_24\n      AG %in% age_categories[6:13] ~ \"Economy Active\",  # Age groups 25_to_29 until 60_to_64\n      AG %in% age_categories[14:length(age_categories)] ~ \"Aged\",  # Age groups 65 and above\n      TRUE ~ \"Other\"\n    )\n  )\nanimation_maps &lt;- list()\nage_clusters &lt;- unique(population_data$Age_Category)\n\n\naggregated_data &lt;- population_data %&gt;%\n  group_by(SZ,Time,Age_Category) %&gt;%\n  summarise(Total_Population = sum(Pop, na.rm = TRUE)) %&gt;%\n  ungroup()\n\naggregated_data &lt;- aggregated_data %&gt;%\n  mutate_at(.vars = vars(SZ), \n          .funs = list(toupper))\n\n# Now join the aggregated population data into the expanded spatial data\nfinal_map_data &lt;- full_join(mpsz, aggregated_data, by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\n4.1.1.1 Difference in the number of MPZ’s sub-zone versus Population’s sub-zones.\nWhile analyzing the data, we noticed that in the year 2020, there are more subzones than the usual 323 MPZ subzones. To address this, we can apply a simple filter to remove the excess subzones using the following code:\n\nunique_sz &lt;- unique(aggregated_data$SZ)\nunique_mpsz_sz &lt;- unique(mpsz$SUBZONE_N)\n\n# Find subzones in aggregated_data but not in mpsz\nmissing_in_mpsz &lt;- setdiff(unique_sz, unique_mpsz_sz)\ncat(\"Subzones in aggregated_data but not in mpsz:\\n\")\n\nSubzones in aggregated_data but not in mpsz:\n\nprint(missing_in_mpsz)\n\n [1] \"BAHAR\"                    \"BRICKLAND\"               \n [3] \"CLEANTECH\"                \"FOREST HILL\"             \n [5] \"GARDEN\"                   \"LAKESIDE (BUSINESS)\"     \n [7] \"LAKESIDE (LEISURE)\"       \"MURAI\"                   \n [9] \"NICOLL\"                   \"PARK\"                    \n[11] \"PLANTATION\"               \"TENGAH INDUSTRIAL ESTATE\"\n\n# Find subzones in mpsz but not in aggregated_data\nmissing_in_aggregated &lt;- setdiff(unique_mpsz_sz, unique_sz)\ncat(\"Subzones in mpsz but not in aggregated_data:\\n\")\n\nSubzones in mpsz but not in aggregated_data:\n\nprint(missing_in_aggregated)\n\ncharacter(0)\n\ncommon_subzones &lt;- intersect(unique(mpsz$SUBZONE_N), unique(aggregated_data$SZ))\nfinal_map_data &lt;- final_map_data %&gt;%\n  filter(SUBZONE_N %in% common_subzones)\n\n\n\n\n4.1.2 Generating the Gifs\n\n4.1.2.1 Logic and Steps\n\nStep 1; we categorize the data into different age clusters.\nFor each cluster, we filter the dataset,\ngenerate a map for each year, and then consolidate them.\nFinally, we create the GIF to visualize the changes over time.\n\n\nlibrary(tmap)\n\nage_clusters &lt;- unique(final_map_data$Age_Category)\n\n# Loop through each age category and generate a GIF\nfor (age_cluster in age_clusters) {\n  # Filter the data for the current age category\n  age_category_data &lt;- final_map_data %&gt;%\n    filter(Age_Category == age_cluster)\n  \n  # List to store each year’s map for the GIF\n  animation_frames &lt;- list()\n  \n  # Loop through each year and generate frames\n  years &lt;- unique(age_category_data$Time)\n  for (year in years) {\n    year_data &lt;- age_category_data %&gt;%\n      filter(Time == year)\n    \n    if (nrow(year_data) &gt; 0) {  # Ensure there is data for the year\n      # Create the map for the current year\n      map &lt;- tm_shape(year_data) +\n        tm_polygons(\"Total_Population\", style = \"quantile\", palette = \"-RdYlBu\", \n                    title = paste(age_cluster, \"Population in\", year)) +\n        tm_layout(\n          main.title = paste(\"Population Distribution for\", age_cluster, \"in\", year),\n          main.title.size = 1.0,  # Increase the title size for better visibility\n          main.title.fontface = \"bold\",  # Make the title bold\n          main.title.position = c(\"center\", \"top\"),  # Center align the title at the top\n          legend.position = c(\"center\", \"bottom\"),  # Move the legend below the map\n          legend.stack = \"horizontal\",  # Ensure the legend is stacked horizontally\n          frame = FALSE\n        )\n      \n      # Add the map to the list of frames\n      animation_frames[[as.character(year)]] &lt;- map\n    }\n  }\n  \n  # Dynamically create a single comparison map using tm_facets\n  comparison_map &lt;- tm_shape(age_category_data) +\n    tm_polygons(\"Total_Population\", style = \"quantile\", palette = \"-RdYlBu\", \n                title = paste(age_cluster, \"Population Comparison (2011-2020)\")) +\n    tm_facets(by = \"Time\", ncol = 2, free.coords = FALSE) +  # Arrange facets in 2 columns\n    tm_layout(\n      main.title = paste(\"Population Comparison for\", age_cluster, \"Across All Years\"),\n      main.title.size = 2,  # Max out the title size for the final frame\n      main.title.fontface = \"bold\",  # Make the title bold\n      main.title.position = c(\"center\", \"top\"),  # Center align the title at the top\n      legend.position = c(\"center\", \"bottom\"),  # Move the legend to the bottom\n      legend.stack = \"horizontal\",  # Ensure the legend is stacked horizontally for better fit\n      frame = FALSE\n    )\n  \n  # Add the comparison map as the final frame multiple times to extend its duration\n  for (i in 1:5) {  # Adding the final frame 5 times to simulate a 10-second delay (5 x 2 seconds)\n    animation_frames[[paste0(\"comparison_\", i)]] &lt;- comparison_map\n  }\n  \n  # Save the animation as a GIF with the correct delays\n  tmap_animation(animation_frames, \n                 filename = paste0(\"population_time_series_\", age_cluster, \".gif\"), \n                 delay = 200,  # 2 seconds per frame (2000 ms)\n                 width = 1500, height = 1200)  # Increase the size for better visibility\n  \n  cat(paste(\"Saved GIF for Age Category:\", age_cluster, \"\\n\"))\n}\n\nCreating frames\n=====\n\n\n======\n\n\n=====\n\n\n=====\n\n\n======\n\n\n=====\n\n\n=====\n\n\n======\n\n\n=====\n\n\n=====\n\n\n======\n\n\n=====\n\n\n=====\n\n\n======\n\n\n=====\n\n\n\nCreating animation\nAnimation saved to C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_2\\population_time_series_Aged.gif \nSaved GIF for Age Category: Aged \nCreating frames\n=====\n\n\n======\n\n\n=====\n\n\n=====\n\n\n======\n\n\n=====\n\n\n=====\n\n\n======\n\n\n=====\n\n\n=====\n\n\n======\n\n\n=====\n\n\n=====\n\n\n======\n\n\n=====\n\n\n\nCreating animation\nAnimation saved to C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_2\\population_time_series_Economy Active.gif \nSaved GIF for Age Category: Economy Active \nCreating frames\n=====\n\n\n======\n\n\n=====\n\n\n=====\n\n\n======\n\n\n=====\n\n\n=====\n\n\n======\n\n\n=====\n\n\n=====\n\n\n======\n\n\n=====\n\n\n=====\n\n\n======\n\n\n=====\n\n\n\nCreating animation\nAnimation saved to C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_2\\population_time_series_Young.gif \nSaved GIF for Age Category: Young \n\ncat(\"All GIFs have been created.\\n\")\n\nAll GIFs have been created.\n\n\n\n\n\n4.1.3 Visualization of the GIFS.\n\n4.1.3.1 Age\n\n\n\n4.1.3.2 Economic Active\n\n\n\n4.1.3.3 Young"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html",
    "href": "Hands_On_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html",
    "title": "Hands-On Exercise 1",
    "section": "",
    "text": "The code chunk below uses the p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\n  pacman::p_load(sf, tidyverse)\n\nImporting the data"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html#install-and-launching-r-packages",
    "href": "Hands_On_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html#install-and-launching-r-packages",
    "title": "Hands-On Exercise 1",
    "section": "",
    "text": "The code chunk below uses the p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\n  pacman::p_load(sf, tidyverse)\n\nImporting the data"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html#methods-of-importing-geospatial-data",
    "href": "Hands_On_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html#methods-of-importing-geospatial-data",
    "title": "Hands-On Exercise 1",
    "section": "Methods Of Importing Geospatial Data",
    "text": "Methods Of Importing Geospatial Data\n\nImporting polygon feature data in shapefile format\nUses st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame.\n\n  mpsz  = st_read(dsn = \"data/layer\", layer= \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_1\\data\\layer' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nImporting polygon feature data in shapefile form\nUses st_read() function of sf package to import CyclingPath shapefile into R as line feature data frame.\n\n  cyclingpath = st_read(dsn = \"data/CyclingPath_Jul2024\", layer= \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_1\\data\\CyclingPath_Jul2024' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\nImporting GIS data in kml format\nUses KML or Geojson to read instead\n\n  preschool = st_read(dsn = \"data/PreSchoolsLocation.geojson\")\n\nReading layer `PreSchoolsLocation' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_1\\data\\PreSchoolsLocation.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands_On_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-On Exercise 1",
    "section": "Checking the Content of A Simple Feature Data Frame",
    "text": "Checking the Content of A Simple Feature Data Frame\n\nst_geometry()\nPrint only displays basic information of the feature class such as type of geometry\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\n\n\nglimpse()\nPrints Associated attribute information in the data frame\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\nhead()\nreveal complete information of a feature object\n\nhead(mpsz, n=5)  \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html#plotting-the-geospatial-data",
    "href": "Hands_On_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html#plotting-the-geospatial-data",
    "title": "Hands-On Exercise 1",
    "section": "Plotting the Geospatial Data",
    "text": "Plotting the Geospatial Data\nsimple plot by R\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html#working-with-projection",
    "href": "Hands_On_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html#working-with-projection",
    "title": "Hands-On Exercise 1",
    "section": "Working with Projection",
    "text": "Working with Projection\n\nAssigning EPSG code to a simple feature data frame\nAn Common issue faced when importing geospatial data into R is that the coordinate system of the source data was either missing, we can use ST_CRS to map\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nNotice that sometimes, that EPSG code is wrong, and we can use st_set_crs to remap it\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nTransforming the projection of preschool from wgs84 to svy21\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\nst_crs(preschool3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (25089.46 31299.16 0)\n\n\nPOINT Z (27189.07 32792.54 0)\n\n\nPOINT Z (28844.56 36773.76 0)\n\n\nPOINT Z (24821.92 46303.16 0)\n\n\nPOINT Z (28637.82 35038.49 0)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html#importing-and-converting-an-aspatial-data",
    "href": "Hands_On_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html#importing-and-converting-an-aspatial-data",
    "title": "Hands-On Exercise 1",
    "section": "Importing and Converting An Aspatial Data",
    "text": "Importing and Converting An Aspatial Data\n\nImporting the aspatial data\n\nlistings &lt;- read_csv(\"data/listings.csv\")\n\nRows: 3540 Columns: 75\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (26): listing_url, source, name, description, neighborhood_overview, pi...\ndbl  (38): id, scrape_id, host_id, host_listings_count, host_total_listings_...\nlgl   (6): host_is_superhost, host_has_profile_pic, host_identity_verified, ...\ndate  (5): last_scraped, host_since, calendar_last_scraped, first_review, la...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,540 × 75\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.02e13 2024-06-29   previ… Ensu… For 3 room…\n 2  71896 https://www.airbnb.co…   2.02e13 2024-06-29   city … B&B … &lt;NA&gt;       \n 3  71903 https://www.airbnb.co…   2.02e13 2024-06-29   city … Room… Like your …\n 4 275343 https://www.airbnb.co…   2.02e13 2024-06-29   city … 10mi… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.02e13 2024-06-29   city … 15 m… Lovely hom…\n 6 289234 https://www.airbnb.co…   2.02e13 2024-06-29   previ… Book… This whole…\n 7 294281 https://www.airbnb.co…   2.02e13 2024-06-29   city … 5 mi… I have 3 b…\n 8 324945 https://www.airbnb.co…   2.02e13 2024-06-29   city … Comf… **IMPORTAN…\n 9 330095 https://www.airbnb.co…   2.02e13 2024-06-29   city … Rela… **IMPORTAN…\n10 344803 https://www.airbnb.co…   2.02e13 2024-06-29   city … Budg… Direct bus…\n# ℹ 3,530 more rows\n# ℹ 68 more variables: neighborhood_overview &lt;chr&gt;, picture_url &lt;chr&gt;,\n#   host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;, host_since &lt;date&gt;,\n#   host_location &lt;chr&gt;, host_about &lt;chr&gt;, host_response_time &lt;chr&gt;,\n#   host_response_rate &lt;chr&gt;, host_acceptance_rate &lt;chr&gt;,\n#   host_is_superhost &lt;lgl&gt;, host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;,\n#   host_neighbourhood &lt;chr&gt;, host_listings_count &lt;dbl&gt;, …\n\n\n\n\nCreating a simple feature data frame from an aspatial data frame\nConverts listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 74\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.024063e+13, 2.024063e+1…\n$ last_scraped                                 &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ source                                       &lt;chr&gt; \"previous scrape\", \"city …\n$ name                                         &lt;chr&gt; \"Ensuite Room (Room 1 & 2…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1 …\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within an hour\", \"within…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"99%…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ host_total_listings_count                    &lt;dbl&gt; 11, 11, 11, 73, 73, 11, 8…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 3, 1, 2, 1, 1, 4, 2, 1, 1…\n$ bathrooms                                    &lt;dbl&gt; NA, 0.5, 0.5, 2.0, 2.5, N…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; 2, 1, 1, 1, 1, 3, 2, 1, 1…\n$ beds                                         &lt;dbl&gt; NA, 1, 2, 1, 1, NA, 1, 1,…\n$ amenities                                    &lt;chr&gt; \"[\\\"Free parking on premi…\n$ price                                        &lt;chr&gt; NA, \"$80.00\", \"$80.00\", \"…\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 30, 30, 30, 28, 0, 29, 30…\n$ availability_60                              &lt;dbl&gt; 59, 53, 60, 58, 0, 58, 60…\n$ availability_90                              &lt;dbl&gt; 89, 83, 90, 62, 0, 88, 90…\n$ availability_365                             &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 3…\n$ calendar_last_scraped                        &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ number_of_reviews                            &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 1…\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 6, 49…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html#geoprocessing-with-sf-package",
    "href": "Hands_On_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html#geoprocessing-with-sf-package",
    "title": "Hands-On Exercise 1",
    "section": "Geoprocessing with sf package",
    "text": "Geoprocessing with sf package\n\nBuffering\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\n\n\nPoint-in-polygon count\n\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\n\n\nsolution:\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 18 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count          Area\n1    4339824 MULTIPOLYGON (((42196.76 38...           72 4339824 [m^2]\n    PreSch Density\n1 16.59053 [1/m^2]"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html#exploratory-data-analysis-eda",
    "href": "Hands_On_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html#exploratory-data-analysis-eda",
    "title": "Hands-On Exercise 1",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#importing-spatial-data",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#importing-spatial-data",
    "title": "Spatial Point Patterns Analysis",
    "section": "4.1 Importing Spatial Data",
    "text": "4.1 Importing Spatial Data\n\nChildcare dataCostal Outlinemp14_subzone\n\n\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_3\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_3\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_3\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\n4.1.1 DIY:Use the appropriate SF function to retrieve the referencing system information of these geospatial data.\nSimple, use the st_crs function from SF to check and print the crs information\n\n# Retrieve CRS information\nchildcare_crs &lt;- st_crs(childcare_sf)\nsg_crs &lt;- st_crs(sg_sf)\nmpsz_crs &lt;- st_crs(mpsz_sf)\n\n# Print CRS information\nprint(childcare_crs)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\nprint(sg_crs)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\nprint(mpsz_crs)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\n\n4.1.2 DIY: Assign the correct CRS to MPSZ_SF and SG_SF Simple Feature Data frames.\nnotice that the MPSZ_SF and SG_SF is in World Geodetic System 1984 format, we need set the correct crs to these data and we can do so using the st transform. We can do so using the transform method\n\nChanging to CRSCheck if its the right CRS\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", layer = \"MP14_SUBZONE_WEB_PL\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_3\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nsg_sf &lt;- st_read(dsn = \"data\", layer = \"CostalOutline\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `CostalOutline' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_3\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\n\n\nprint(st_crs(mpsz_sf))\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\nprint(st_crs(sg_sf))\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\n\n\n4.1.3 Change the referencing System to Singapore National Projected Coordinate System\n\n\n\n\n\n\nNote\n\n\n\nUnderstanding the CRS in Our Data:\n\nMPZ and Coastal Data:\n\nCRS: SVY21, which is the Singapore National Projected Coordinate System based on WGS84.\nDescription: This is a common projected coordinate system used in Singapore for accurate mapping.\n\nChildcare Data:\n\nCRS: SVY21 / Singapore TM (Transverse Mercator projection).\nDescription: This is also a projection based on SVY21, specifically using the Transverse Mercator projection. It is very close to the SVY21 system, with minor differences in how the projection is handled.\n\n\nGiven that the map file serves as the base, we want all spatial data to overlay correctly, we should:\n\nTransform the GeoJSON Data to Match the Map File’s CRS:\n\nSince our MPZ and Coastal data are already in SVY21 (EPSG:3414), transform the GeoJSON data to EPSG:3414 as well.\n\nRationale:\n\nThis approach ensures that the childcare locations from the GeoJSON data will be accurately plotted within the boundaries and context provided by the map file (MPZ and Coastal data).\nIt avoids potential issues with misalignment, especially since oour base map data is already set up in a local projection suitable for Singapore.\n\n\n\n\n\n# Transform Childcare data to match the base map's CRS (EPSG:3414)\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_3\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n# Now, all datasets should be aligned in the same CRS\n\n\n\n4.1.4 Checking for validity of maps\nWhen working with spatial data, it’s crucial to ensure that all geometries are valid. Invalid geometries can cause errors in analysis and visualization.\n\nChecking Validity with st_is_valid():\nIdentifying Invalid Geometries:\nFixing Invalid Geometries with st_make_valid()\n\n\nMPZSGChildcare\n\n\n\nmpsz_validity &lt;- st_is_valid(mpsz_sf)\nmpsz_invalid &lt;- which(!mpsz_validity)\nif (length(mpsz_invalid) &gt; 0) {\n  print(\"MPZ Invalid!\")\n  print(mpsz_sf[mpsz_invalid, ])\n} else {\n  print(\"it's valid!\")\n}\n\n[1] \"MPZ Invalid!\"\nSimple feature collection with 9 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 12535.88 ymin: 21678.35 xmax: 56396.44 ymax: 49291.03\nProjected CRS: SVY21 / Singapore TM\n    OBJECTID SUBZONE_NO             SUBZONE_N SUBZONE_C CA_IND\n19        19          2        SOUTHERN GROUP    SISZ02      N\n20        20          1               SENTOSA    SISZ01      N\n24        24          1       MARITIME SQUARE    BMSZ01      N\n122      122          9           JURONG PORT    JESZ09      N\n123      123          3               SAMULUN    BLSZ03      N\n128      128          9                PANDAN    CLSZ09      N\n258      258          4        PASIR RIS PARK    PRSZ04      N\n302      302          1 NORTH-EASTERN ISLANDS    NESZ01      N\n320      320          9           NORTH COAST    WDSZ09      N\n               PLN_AREA_N PLN_AREA_C          REGION_N REGION_C\n19       SOUTHERN ISLANDS         SI    CENTRAL REGION       CR\n20       SOUTHERN ISLANDS         SI    CENTRAL REGION       CR\n24            BUKIT MERAH         BM    CENTRAL REGION       CR\n122           JURONG EAST         JE       WEST REGION       WR\n123              BOON LAY         BL       WEST REGION       WR\n128              CLEMENTI         CL       WEST REGION       WR\n258             PASIR RIS         PR       EAST REGION       ER\n302 NORTH-EASTERN ISLANDS         NE NORTH-EAST REGION      NER\n320             WOODLANDS         WD      NORTH REGION       NR\n             INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng SHAPE_Area\n19  5809FC547293EA2D 2014-12-05 29815.09 23412.59  25626.977    2206319\n20  A6FCDC9C447952CB 2014-12-05 27593.94 25813.35  17496.194    4919132\n24  C1AC31ABF9978DDB 2014-12-05 25805.79 27911.42  13737.116    2701634\n122 0664CA7EF6504AE5 2014-12-05 15250.74 32183.92  11355.002    2464857\n123 F78E0287D3F24214 2014-12-05 13418.49 32264.59   8738.679    1940693\n128 A6EE4A49376B69C4 2014-12-05 19228.60 32265.40   5689.647    1312923\n258 9856E3CDCF57AD96 2014-12-05 41529.80 40218.94   8533.964    1719705\n302 92BC3E09C68F3B52 2014-12-05 50424.79 42612.88  62436.235   67250563\n320 898B2436858382A1 2014-12-05 22147.04 48031.55  10847.882    2450784\n                          geometry\n19  MULTIPOLYGON (((29712.51 23...\n20  MULTIPOLYGON (((26858.1 266...\n24  MULTIPOLYGON (((26514.58 28...\n122 MULTIPOLYGON (((14483.48 31...\n123 MULTIPOLYGON (((12861.38 32...\n128 MULTIPOLYGON (((19680.06 31...\n258 MULTIPOLYGON (((41343.11 40...\n302 MULTIPOLYGON (((52567.43 46...\n320 MULTIPOLYGON (((21693.06 48...\n\n\nNotice that MPZ has 9 invalidity of sub zones here, so we have to make it valid through the function make valid. Once it’s valid we then check again\n\nmpsz_sf &lt;- st_make_valid(mpsz_sf)\nmpsz_validity &lt;- st_is_valid(mpsz_sf)\nmpsz_invalid &lt;- which(!mpsz_validity)\nif (length(mpsz_invalid) &gt; 0) {\n  print(\"MPZ Invalid!\")\n  print(mpsz_sf[mpsz_invalid, ])\n} else {\n  print(\"it's valid!\")\n}\n\n[1] \"it's valid!\"\n\n\n\n\n\nsg_validity &lt;- st_is_valid(sg_sf)\nsg_invalid &lt;- which(!sg_validity)\nif (length(sg_invalid) &gt; 0) {\n  print(\"SG Invalid!\")\n  print(mpsz_sf[mpsz_invalid, ])\n} else {\n  print(\"it's valid!\")\n}\n\n[1] \"SG Invalid!\"\nSimple feature collection with 0 features and 15 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n [1] OBJECTID   SUBZONE_NO SUBZONE_N  SUBZONE_C  CA_IND     PLN_AREA_N\n [7] PLN_AREA_C REGION_N   REGION_C   INC_CRC    FMEL_UPD_D X_ADDR    \n[13] Y_ADDR     SHAPE_Leng SHAPE_Area geometry  \n&lt;0 rows&gt; (or 0-length row.names)\n\n\nIn SG_SF there’s one invalid as well, so we apply the fix.\n\nsg_sf &lt;- st_make_valid(sg_sf)\nsg_validity &lt;- st_is_valid(sg_sf)\nsg_invalid &lt;- which(!sg_validity)\nif (length(sg_invalid) &gt; 0) {\n  print(\"SG Invalid!\")\n  print(mpsz_sf[sg_invalid, ])\n} else {\n  print(\"it's valid!\")\n}\n\n[1] \"it's valid!\"\n\n\n\n\nNotice that childcare is a geojson data and it houses it’s data in the description column, we need to break this up to get more meaningful data.\nWe can do a simple extraction from the Description attribute and map the data better. Assuming that each Table Row (TR) contains a Table Head (TH) and a Table Data (TD), we can map the data accordingly.\n\nchildcare_validity &lt;- st_is_valid(childcare_sf)\nchildcare_invalid &lt;- which(!childcare_validity)\nif (length(childcare_invalid) &gt; 0) {\n  print(\"ChildCare Invalid!\")\n  print(childcare_sf[childcare_invalid, ])\n} else {\n  print(\"it's valid!\")\n}\n\n[1] \"it's valid!\"\n\n# Ensure the geometry column is preserved\ngeometry_column &lt;- st_geometry(childcare_sf)\nparse_description &lt;- function(html_string) {\n  html &lt;- read_html(html_string)\n  html &lt;- html %&gt;% html_nodes(\"tr\") %&gt;% .[!grepl(\"Attributes\", .)]\n  headers &lt;- html %&gt;% html_nodes(\"th\") %&gt;% html_text(trim = TRUE)\n  values &lt;- html %&gt;% html_nodes(\"td\") %&gt;% html_text(trim = TRUE)\n  \n  # Handle cases where the number of headers and values don't match\n  if (length(headers) != length(values)) {\n    max_length &lt;- max(length(headers), length(values))\n    headers &lt;- c(headers, rep(\"ExtraHeader\", max_length - length(headers)))\n    values &lt;- c(values, rep(\"NULL\", max_length - length(values)))\n  }\n  \n  setNames(values, headers)\n}\n\n# Apply parsing function, unnest the description fields, and remove the original 'Description' column\nchildcare_sf &lt;- childcare_sf %&gt;% \n  mutate(Description_parsed = map(Description, parse_description)) %&gt;%\n  unnest_wider(Description_parsed) %&gt;%\n  select(-Description)  # Remove the original 'Description' column\n\n# Overwrite the 'Name' column with the 'LANDYADDRESSPOINT' column values\nchildcare_sf &lt;- childcare_sf %&gt;%\n  mutate(Name = NAME)  # Overwrite 'Name' with 'LANDYADDRESSPOINT'\n\n# Replace empty strings or NA across all columns with \"NULL\"\nchildcare_sf &lt;- childcare_sf %&gt;%\n  mutate(across(!geometry, ~ ifelse(is.na(.) | . == \"\", \"NULL\", .)))\n\n# Reassign the geometry to the dataframe\nst_geometry(childcare_sf) &lt;- geometry_column\n# Ensure it's still an sf object\nclass(childcare_sf)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\""
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#mapping-the-geospatial-datasets.",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#mapping-the-geospatial-datasets.",
    "title": "Spatial Point Patterns Analysis",
    "section": "4.2 Mapping the geospatial datasets.",
    "text": "4.2 Mapping the geospatial datasets.\n\nDIY PLOT MapDIY View Interactivity\n\n\nUsing the mapping methods you learned in Hands-on Exercise 3, prepare a static map\n\n# Suppress the tmap mode message\nsuppressMessages({\n  tmap_mode(\"plot\")  # Use \"view\" for an interactive map or \"plot\" for a static map\n})\n\n# Create the map\ntm &lt;- tm_shape(mpsz_sf) + \n  tm_polygons(col = \"grey\", border.col = \"black\", alpha = 0.5) +  # Base map with subzones\n  tm_shape(childcare_sf) + \n  tm_dots(col = \"black\", size = 0.05) +  # Plot childcare locations as dots\n   tm_layout(\n    main.title = \"Childcare Locations on Singapore Map\",\n    main.title.position = c(\"center\"),  # Center the title at the top\n    outer.margins = c(0.1, 0, 0, 0),  # Adjust outer margins to make space for the title\n    legend.outside = TRUE,  # Keep legend outside the map area\n    legend.outside.position = \"bottom\"  # Position the legend at the bottom\n  )\ntm\n\n\n\n\n\n\n\n\n\n\nwe can also prepare a pin map by using the code chunk below.\n\nsuppressMessages({\n  tmap_mode(\"view\")  # Use \"view\" for an interactive map or \"plot\" for a static map\n})\n\ntm &lt;- tm_shape(mpsz_sf) + \n  tm_polygons(col = \"grey\", border.col = \"black\", alpha = 0.5) +  # Base map with subzones\n  tm_shape(childcare_sf) + \n  tm_dots(col = \"black\", size = 0.05) +  # Plot childcare locations as dots\n   tm_layout(\n    title = \"Childcare Locations on Singapore Map\",\n    title.position = c(\"center\"),  # Center the title at the top\n    outer.margins = c(0.1, 0, 0, 0),  # Adjust outer margins to make space for the title\n    legend.outside = TRUE,  # Keep legend outside the map area\n    legend.outside.position = \"bottom\"  # Position the legend at the bottom\n  )\n\ntm"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#data-frame-to-spatial-class",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#data-frame-to-spatial-class",
    "title": "Spatial Point Patterns Analysis",
    "section": "5.1 Data frame to Spatial Class",
    "text": "5.1 Data frame to Spatial Class\nUse as_Spatial() to convert the data from dataframe to spatial class, we can check so using the class function or simply display it.\n\nChildcareMpszSG\n\n\n\nchildcare &lt;- as_Spatial(childcare_sf)\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 16\nnames       :                    Name, ADDRESSBLOCKHOUSENUMBER, ADDRESSBUILDINGNAME, ADDRESSPOSTALCODE,                                                                       ADDRESSSTREETNAME, ADDRESSTYPE,         DESCRIPTION, HYPERLINK, LANDXADDRESSPOINT, LANDYADDRESSPOINT,                    NAME, PHOTOURL, ADDRESSFLOORNUMBER,          INC_CRC,     FMEL_UPD_D, ... \nmin values  :    3-IN-1 FAMILY CENTRE,                    NULL,                NULL,            018989,                                                  1 & 3, Stratton Road, SINGAPORE 806787,        NULL, Child Care Services,      NULL,                 0,                 0,    3-IN-1 FAMILY CENTRE,     NULL,               NULL, 00A958622500BF89, 20200812221033, ... \nmax values  : ZEE SCHOOLHOUSE PTE LTD,                    NULL,                NULL,            829646, UPPER BASEMENT LEVEL, WEST WING, TERMINAL 1, SINGAPORE CHANGI AIRPORT, SINGAPORE 819642,        NULL,                NULL,      NULL,                 0,                 0, ZEE SCHOOLHOUSE PTE LTD,     NULL,               NULL, FFCFA88A8CE5665A, 20200826094036, ... \n\nclass(childcare)\n\n[1] \"SpatialPointsDataFrame\"\nattr(,\"package\")\n[1] \"sp\"\n\n\n\n\n\nmpsz &lt;- as_Spatial(mpsz_sf)\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\nclass(mpsz)\n\n[1] \"SpatialPolygonsDataFrame\"\nattr(,\"package\")\n[1] \"sp\"\n\n\n\n\n\nsg &lt;- as_Spatial(sg_sf)\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\nclass(sg)\n\n[1] \"SpatialPolygonsDataFrame\"\nattr(,\"package\")\n[1] \"sp\""
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#converting-spatial-class-into-generic-ppp-format",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#converting-spatial-class-into-generic-ppp-format",
    "title": "Spatial Point Patterns Analysis",
    "section": "5.2 Converting Spatial Class into generic PPP Format",
    "text": "5.2 Converting Spatial Class into generic PPP Format\nAs Spatstat requires analytical data in ppp object form. We have to map the data to a PPP object. The following steps breakdown the method to convert a SF to PPP object.\n\nExtract Coordinates (st_coordinates(childcare_sf)):\nThis step extracts the x (longitude) and y (latitude) coordinates from the sf object. The result is a matrix with two columns—one for each coordinate. These coordinates represent the location of each point in our spatial dataset.\n\n\n\nGet Bounding Box (st_bbox(childcare_sf)):\nThis function retrieves the bounding box of the sf object, which is the smallest rectangle that can enclose all the points in the dataset. The bounding box provides the minimum and maximum x and y values (xmin, xmax, ymin, ymax)\nCreate Observation Window (owin()):\nUsing the bounding box values, you create an observation window. This window defines the spatial limits (study area) for the point pattern analysis. It ensures that all points lie within these specified boundaries.\nCreate ppp Object (ppp()):\nFinally, we combine the extracted coordinates and the defined observation window into a ppp object using the ppp() function. The ppp object is the required format for analyzing point patterns in the spatstat package, enabling us to conduct spatial analyses on our data.\n\n\n# Extract coordinates\nchildcare_coords &lt;- st_coordinates(childcare_sf)\n\n# Define the window using the bounding box\nchildcare_bbox &lt;- st_bbox(childcare_sf)\nchildcare_window &lt;- owin(xrange = childcare_bbox[c(\"xmin\", \"xmax\")], yrange = childcare_bbox[c(\"ymin\", \"ymax\")])\n\n# Create the ppp object\nchildcare_ppp &lt;- ppp(x = childcare_coords[, 1], y = childcare_coords[, 2], window = childcare_window)\n\n# Check the ppp object\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\nplot(childcare_ppp)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#checking-for-duplicate-data.",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#checking-for-duplicate-data.",
    "title": "Spatial Point Patterns Analysis",
    "section": "5.3 Checking for duplicate data.",
    "text": "5.3 Checking for duplicate data.\n\n5.3.1 Code to analyse for duplicate data.\n\nCheck For Any DuplicateCount No. of co-indicence pointLocation With &gt; 1 Point Event\n\n\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\n\n\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\n\n\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 128\n\n\n\n\n\n\n\n5.3.2 Spot duplicate points from the map\n\n# Identify duplicates in the ppp object\nchildcare_duplicate_indices &lt;- duplicated(childcare_ppp)\n# Extract the coordinates of duplicate points\nchildcare_duplicate_coords &lt;- childcare_ppp[childcare_duplicate_indices]\n# Plot the original points\nplot(childcare_ppp, main = \"Childcare Locations with Duplicate Points Highlighted\")\n# Overlay duplicate points in a different color\npoints(childcare_duplicate_coords$x, childcare_duplicate_coords$y, col = \"red\", pch = 19, cex = 0.7)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#handling-duplicates-events.",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#handling-duplicates-events.",
    "title": "Spatial Point Patterns Analysis",
    "section": "5.4 Handling Duplicates Events.",
    "text": "5.4 Handling Duplicates Events.\n\n5.4.1 Methods to Handle Duplicates\nThree Methods\n\nDeleting Duplicates (unique_childcare_ppp): Removes duplicate points, resulting in a dataset with only unique events.\n\n\n\nJittering Duplicates (jittered_childcare_ppp): Slightly perturbs duplicate points to distinguish them spatially, preventing them from overlapping completely.\nUnique Marks (marked_childcare_ppp): Attaches a “mark” to each point, especially duplicates, which can be used later in the analysis to account for the fact that these points were originally duplicates.\n\n\nDeleteJitteringUnique Marks\n\n\n\nunique_childcare_ppp &lt;- childcare_ppp[!duplicated(childcare_ppp)]\n\n# Check the ppp object after removing duplicates\nsummary(unique_childcare_ppp)\n\nPlanar point pattern:  1471 points\nAverage intensity 1.819898e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\nplot(unique_childcare_ppp, main = \"Childcare Locations Without Duplicates\")\n\n\n\n\n\n\n\n\n\n\n\n# Jitter the coordinates to handle duplicates\njittered_coords &lt;- childcare_coords\njittered_coords[duplicated(childcare_ppp), ] &lt;- jitter(jittered_coords[duplicated(childcare_ppp), ], amount = 0.01)\n\n# Create a new ppp object with jittered points\njittered_childcare_ppp &lt;- ppp(x = jittered_coords[, 1], y = jittered_coords[, 2], window = childcare_window)\n\n# Check the ppp object after jittering\nsummary(jittered_childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\nplot(jittered_childcare_ppp, main = \"Childcare Locations with Jittered Duplicates\")\n\n\n\n\n\n\n\n\n\n\n\n# Create marks for duplicates\nmarks &lt;- rep(1, npoints(childcare_ppp))\nmarks[duplicated(childcare_ppp)] &lt;- 2\n\n# Create a new ppp object with marks attached to each point\nmarked_childcare_ppp &lt;- ppp(x = childcare_coords[, 1], y = childcare_coords[, 2], window = childcare_window, marks = marks)\n\n# Check the ppp object with unique marks\nsummary(marked_childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   1.000   1.000   1.048   1.000   2.000 \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\nplot(marked_childcare_ppp, main = \"Childcare Locations with Unique Marks\", cols = c(\"black\", \"red\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.4.2 Last check for duplicates\n\nany(duplicated(unique_childcare_ppp))\n\n[1] FALSE\n\nany(duplicated(jittered_childcare_ppp))\n\n[1] FALSE\n\nany(duplicated(marked_childcare_ppp))\n\n[1] TRUE\n\n\nNotice that mark will still make it true, because there are still duplicates but marked differently.\nI would use jittered from here forward"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#creating-owin-object",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#creating-owin-object",
    "title": "Spatial Point Patterns Analysis",
    "section": "5.5 Creating OWIN Object",
    "text": "5.5 Creating OWIN Object\nOWIN is used to represent the polygonal region, and we us the SG_SF to plot the map.\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n51 separate polygons (2 holes)\n                  vertices         area relative.area\npolygon 1 (hole)        30 -7.08118e+03     -9.76e-06\npolygon 2               55  8.25379e+04      1.14e-04\npolygon 3               90  4.15092e+05      5.72e-04\npolygon 4               49  1.66986e+04      2.30e-05\npolygon 5               38  2.42492e+04      3.34e-05\npolygon 6              976  2.33447e+07      3.22e-02\npolygon 7              721  1.92795e+06      2.66e-03\npolygon 8             1989  9.99217e+06      1.38e-02\npolygon 9              330  1.11896e+06      1.54e-03\npolygon 10             175  9.25904e+05      1.28e-03\npolygon 11             115  9.28394e+05      1.28e-03\npolygon 12              24  6.35239e+03      8.76e-06\npolygon 13 (hole)        3 -1.06765e+00     -1.47e-09\npolygon 14             190  2.02489e+05      2.79e-04\npolygon 15              37  1.01705e+04      1.40e-05\npolygon 16              25  1.66227e+04      2.29e-05\npolygon 17              10  2.14507e+03      2.96e-06\npolygon 18              66  1.61841e+04      2.23e-05\npolygon 19            5195  6.36837e+08      8.78e-01\npolygon 20              76  3.12332e+05      4.31e-04\npolygon 21             627  3.18913e+07      4.40e-02\npolygon 22              20  3.28420e+04      4.53e-05\npolygon 23              42  5.58317e+04      7.70e-05\npolygon 24              67  1.31354e+06      1.81e-03\npolygon 25             734  4.69093e+06      6.47e-03\npolygon 26              16  3.19460e+03      4.40e-06\npolygon 27              15  4.87296e+03      6.72e-06\npolygon 28              15  4.46420e+03      6.15e-06\npolygon 29              14  5.46674e+03      7.54e-06\npolygon 30              37  5.26194e+03      7.25e-06\npolygon 31             111  6.62927e+05      9.14e-04\npolygon 32              69  5.63134e+04      7.76e-05\npolygon 33             143  1.45139e+05      2.00e-04\npolygon 34             397  2.48821e+06      3.43e-03\npolygon 35              90  1.15991e+05      1.60e-04\npolygon 36              98  6.26829e+04      8.64e-05\npolygon 37             165  3.38736e+05      4.67e-04\npolygon 38             130  9.40465e+04      1.30e-04\npolygon 39              93  4.30642e+05      5.94e-04\npolygon 40              16  2.01046e+03      2.77e-06\npolygon 41             415  3.25384e+06      4.49e-03\npolygon 42              30  1.08382e+04      1.49e-05\npolygon 43              53  3.44003e+04      4.74e-05\npolygon 44              26  8.34758e+03      1.15e-05\npolygon 45              74  5.82234e+04      8.03e-05\npolygon 46             327  2.16921e+06      2.99e-03\npolygon 47             177  4.67446e+05      6.44e-04\npolygon 48              46  6.99702e+05      9.65e-04\npolygon 49               6  1.68410e+04      2.32e-05\npolygon 50              13  7.00873e+04      9.66e-05\npolygon 51               4  9.45963e+03      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#combining-point-events-object-and-owin-object",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#combining-point-events-object-and-owin-object",
    "title": "Spatial Point Patterns Analysis",
    "section": "5.6 Combining Point events object and owin object",
    "text": "5.6 Combining Point events object and owin object\nExtract and combine the point and polygon feaature in one ppp object.\n\nchildcareSG_ppp = jittered_childcare_ppp[sg_owin]\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nWindow: polygonal boundary\n51 separate polygons (2 holes)\n                  vertices         area relative.area\npolygon 1 (hole)        30 -7.08118e+03     -9.76e-06\npolygon 2               55  8.25379e+04      1.14e-04\npolygon 3               90  4.15092e+05      5.72e-04\npolygon 4               49  1.66986e+04      2.30e-05\npolygon 5               38  2.42492e+04      3.34e-05\npolygon 6              976  2.33447e+07      3.22e-02\npolygon 7              721  1.92795e+06      2.66e-03\npolygon 8             1989  9.99217e+06      1.38e-02\npolygon 9              330  1.11896e+06      1.54e-03\npolygon 10             175  9.25904e+05      1.28e-03\npolygon 11             115  9.28394e+05      1.28e-03\npolygon 12              24  6.35239e+03      8.76e-06\npolygon 13 (hole)        3 -1.06765e+00     -1.47e-09\npolygon 14             190  2.02489e+05      2.79e-04\npolygon 15              37  1.01705e+04      1.40e-05\npolygon 16              25  1.66227e+04      2.29e-05\npolygon 17              10  2.14507e+03      2.96e-06\npolygon 18              66  1.61841e+04      2.23e-05\npolygon 19            5195  6.36837e+08      8.78e-01\npolygon 20              76  3.12332e+05      4.31e-04\npolygon 21             627  3.18913e+07      4.40e-02\npolygon 22              20  3.28420e+04      4.53e-05\npolygon 23              42  5.58317e+04      7.70e-05\npolygon 24              67  1.31354e+06      1.81e-03\npolygon 25             734  4.69093e+06      6.47e-03\npolygon 26              16  3.19460e+03      4.40e-06\npolygon 27              15  4.87296e+03      6.72e-06\npolygon 28              15  4.46420e+03      6.15e-06\npolygon 29              14  5.46674e+03      7.54e-06\npolygon 30              37  5.26194e+03      7.25e-06\npolygon 31             111  6.62927e+05      9.14e-04\npolygon 32              69  5.63134e+04      7.76e-05\npolygon 33             143  1.45139e+05      2.00e-04\npolygon 34             397  2.48821e+06      3.43e-03\npolygon 35              90  1.15991e+05      1.60e-04\npolygon 36              98  6.26829e+04      8.64e-05\npolygon 37             165  3.38736e+05      4.67e-04\npolygon 38             130  9.40465e+04      1.30e-04\npolygon 39              93  4.30642e+05      5.94e-04\npolygon 40              16  2.01046e+03      2.77e-06\npolygon 41             415  3.25384e+06      4.49e-03\npolygon 42              30  1.08382e+04      1.49e-05\npolygon 43              53  3.44003e+04      4.74e-05\npolygon 44              26  8.34758e+03      1.15e-05\npolygon 45              74  5.82234e+04      8.03e-05\npolygon 46             327  2.16921e+06      2.99e-03\npolygon 47             177  4.67446e+05      6.44e-04\npolygon 48              46  6.99702e+05      9.65e-04\npolygon 49               6  1.68410e+04      2.32e-05\npolygon 50              13  7.00873e+04      9.66e-05\npolygon 51               4  9.45963e+03      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nPlot the map as shown below here by:\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#kernel-density-estimation",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#kernel-density-estimation",
    "title": "Spatial Point Patterns Analysis",
    "section": "6.1 Kernel Density Estimation",
    "text": "6.1 Kernel Density Estimation\n\n6.1.1 Understanding KDE\nKernel Density Estimation (KDE) is a non-parametric way to estimate the probability density function of a random variable. In spatial analysis, KDE is used to estimate the intensity of point patterns across a study area, which helps to identify hotspots or areas with high concentrations of events (e.g., childcare locations).\nSteps in KDE:\n\nKernel Function:\n\nThe kernel function is a smooth, symmetric function (often Gaussian) that is used to estimate the density at each point. It determines how much influence each point has on the surrounding area.\nIn the spatial context, each point in your dataset contributes to the density estimate, with its influence decreasing with distance according to the kernel function.\n\nBandwidth (sigma):\n\nThe bandwidth parameter (sigma) controls the width of the kernel function. It determines the scale of smoothing:\n\nSmall bandwidth: Results in a more detailed map with sharper peaks but may be too sensitive to noise.\nLarge bandwidth: Produces a smoother map but may oversmooth the data, losing important details.\n\nBandwidth selection is crucial for accurate density estimation. One common method for selecting bandwidth is Diggle’s bandwidth (bw.diggle), which is specifically designed for spatial point patterns.\n\nEdge Correction:\n\nWhen performing KDE on finite study areas, edge effects can bias the density estimates near the boundaries.\nEdge correction (edge=TRUE) adjusts for this by accounting for the missing density outside the boundaries, leading to more accurate results near the edges.\n\nDensity Calculation:\n\nThe KDE produces a continuous surface (usually a raster or grid) where each cell represents the estimated density of points. Higher values indicate areas with a higher concentration of points.\n\n\n\n\n6.1.2 As Seen in Code\nBreaking Down the Code:\n\ndensity(childcareSG_ppp, ...):\n\nThis function from the spatstat package computes the Kernel Density Estimation (KDE) for the ppp object childcareSG_ppp.\n\nsigma=bw.diggle:\n\nsigma specifies the bandwidth (smoothing parameter). Here, bw.diggle is used to automatically calculate the optimal bandwidth based on Diggle’s method, which balances the trade-off between detail and smoothness.\n\nedge=TRUE:\n\nThis argument enables edge correction, adjusting the density estimate near the boundaries of the study area to avoid underestimation due to the edge effect.\n\nkernel=\"gaussian\":\n\nSpecifies the type of kernel function to use. The Gaussian kernel is the most commonly used, providing a smooth, bell-shaped curve that smoothly decreases in influence as distance from the point increases.\n\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\nst_crs(kde_childcareSG_bw)\n\nCoordinate Reference System: NA\n\n\nRetrieving the bandwidth to compute the kde layer\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n6.1.3 Rescaling KDE Values\n\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nWindow: polygonal boundary\n51 separate polygons (2 holes)\n                  vertices         area relative.area\npolygon 1 (hole)        30 -7.08118e+03     -9.76e-06\npolygon 2               55  8.25379e+04      1.14e-04\npolygon 3               90  4.15092e+05      5.72e-04\npolygon 4               49  1.66986e+04      2.30e-05\npolygon 5               38  2.42492e+04      3.34e-05\npolygon 6              976  2.33447e+07      3.22e-02\npolygon 7              721  1.92795e+06      2.66e-03\npolygon 8             1989  9.99217e+06      1.38e-02\npolygon 9              330  1.11896e+06      1.54e-03\npolygon 10             175  9.25904e+05      1.28e-03\npolygon 11             115  9.28394e+05      1.28e-03\npolygon 12              24  6.35239e+03      8.76e-06\npolygon 13 (hole)        3 -1.06765e+00     -1.47e-09\npolygon 14             190  2.02489e+05      2.79e-04\npolygon 15              37  1.01705e+04      1.40e-05\npolygon 16              25  1.66227e+04      2.29e-05\npolygon 17              10  2.14507e+03      2.96e-06\npolygon 18              66  1.61841e+04      2.23e-05\npolygon 19            5195  6.36837e+08      8.78e-01\npolygon 20              76  3.12332e+05      4.31e-04\npolygon 21             627  3.18913e+07      4.40e-02\npolygon 22              20  3.28420e+04      4.53e-05\npolygon 23              42  5.58317e+04      7.70e-05\npolygon 24              67  1.31354e+06      1.81e-03\npolygon 25             734  4.69093e+06      6.47e-03\npolygon 26              16  3.19460e+03      4.40e-06\npolygon 27              15  4.87296e+03      6.72e-06\npolygon 28              15  4.46420e+03      6.15e-06\npolygon 29              14  5.46674e+03      7.54e-06\npolygon 30              37  5.26194e+03      7.25e-06\npolygon 31             111  6.62927e+05      9.14e-04\npolygon 32              69  5.63134e+04      7.76e-05\npolygon 33             143  1.45139e+05      2.00e-04\npolygon 34             397  2.48821e+06      3.43e-03\npolygon 35              90  1.15991e+05      1.60e-04\npolygon 36              98  6.26829e+04      8.64e-05\npolygon 37             165  3.38736e+05      4.67e-04\npolygon 38             130  9.40465e+04      1.30e-04\npolygon 39              93  4.30642e+05      5.94e-04\npolygon 40              16  2.01046e+03      2.77e-06\npolygon 41             415  3.25384e+06      4.49e-03\npolygon 42              30  1.08382e+04      1.49e-05\npolygon 43              53  3.44003e+04      4.74e-05\npolygon 44              26  8.34758e+03      1.15e-05\npolygon 45              74  5.82234e+04      8.03e-05\npolygon 46             327  2.16921e+06      2.99e-03\npolygon 47             177  4.67446e+05      6.44e-04\npolygon 48              46  6.99702e+05      9.65e-04\npolygon 49               6  1.68410e+04      2.32e-05\npolygon 50              13  7.00873e+04      9.66e-05\npolygon 51               4  9.45963e+03      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\nsummary(childcareSG_ppp.km)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.129929 points per square km\n\nCoordinates are given to 14 decimal places\n\nWindow: polygonal boundary\n51 separate polygons (2 holes)\n                  vertices         area relative.area\npolygon 1 (hole)        30 -7.08118e-03     -9.76e-06\npolygon 2               55  8.25379e-02      1.14e-04\npolygon 3               90  4.15092e-01      5.72e-04\npolygon 4               49  1.66986e-02      2.30e-05\npolygon 5               38  2.42492e-02      3.34e-05\npolygon 6              976  2.33447e+01      3.22e-02\npolygon 7              721  1.92795e+00      2.66e-03\npolygon 8             1989  9.99217e+00      1.38e-02\npolygon 9              330  1.11896e+00      1.54e-03\npolygon 10             175  9.25904e-01      1.28e-03\npolygon 11             115  9.28394e-01      1.28e-03\npolygon 12              24  6.35239e-03      8.76e-06\npolygon 13 (hole)        3 -1.06765e-06     -1.47e-09\npolygon 14             190  2.02489e-01      2.79e-04\npolygon 15              37  1.01705e-02      1.40e-05\npolygon 16              25  1.66227e-02      2.29e-05\npolygon 17              10  2.14507e-03      2.96e-06\npolygon 18              66  1.61841e-02      2.23e-05\npolygon 19            5195  6.36837e+02      8.78e-01\npolygon 20              76  3.12332e-01      4.31e-04\npolygon 21             627  3.18913e+01      4.40e-02\npolygon 22              20  3.28420e-02      4.53e-05\npolygon 23              42  5.58317e-02      7.70e-05\npolygon 24              67  1.31354e+00      1.81e-03\npolygon 25             734  4.69093e+00      6.47e-03\npolygon 26              16  3.19460e-03      4.40e-06\npolygon 27              15  4.87296e-03      6.72e-06\npolygon 28              15  4.46420e-03      6.15e-06\npolygon 29              14  5.46674e-03      7.54e-06\npolygon 30              37  5.26194e-03      7.25e-06\npolygon 31             111  6.62927e-01      9.14e-04\npolygon 32              69  5.63134e-02      7.76e-05\npolygon 33             143  1.45139e-01      2.00e-04\npolygon 34             397  2.48821e+00      3.43e-03\npolygon 35              90  1.15991e-01      1.60e-04\npolygon 36              98  6.26829e-02      8.64e-05\npolygon 37             165  3.38736e-01      4.67e-04\npolygon 38             130  9.40465e-02      1.30e-04\npolygon 39              93  4.30642e-01      5.94e-04\npolygon 40              16  2.01046e-03      2.77e-06\npolygon 41             415  3.25384e+00      4.49e-03\npolygon 42              30  1.08382e-02      1.49e-05\npolygon 43              53  3.44003e-02      4.74e-05\npolygon 44              26  8.34758e-03      1.15e-05\npolygon 45              74  5.82234e-02      8.03e-05\npolygon 46             327  2.16921e+00      2.99e-03\npolygon 47             177  4.67446e-01      6.44e-04\npolygon 48              46  6.99702e-01      9.65e-04\npolygon 49               6  1.68410e-02      2.32e-05\npolygon 50              13  7.00873e-02      9.66e-05\npolygon 51               4  9.45963e-03      1.30e-05\nenclosing rectangle: [2.66393, 56.04779] x [16.35798, 50.24403] km\n                     (53.38 x 33.89 km)\nWindow area = 725.376 square km\nUnit of length: 1 km\nFraction of frame area: 0.401\n\n\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw,main = \"Kernel Density Estimation of Childcare Locations (Rescaled to KM)\")"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#working-with-different-automatic-bandwidth-methods",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#working-with-different-automatic-bandwidth-methods",
    "title": "Spatial Point Patterns Analysis",
    "section": "6.2 working with different automatic bandwidth methods",
    "text": "6.2 working with different automatic bandwidth methods\nBandwidth is a crucial parameter in Kernel Density Estimation (KDE). It controls the degree of smoothing applied to the data. Different methods for selecting the bandwidth lead to different levels of smoothing, which can impact the interpretation of the density estimate.\nIn the spatstat package, several functions are available to determine the optimal bandwidth for KDE:\n\nbw.diggle():\n\nPurpose: Designed for spatial point patterns, it aims to balance the trade-off between bias and variance in the density estimate.\nCharacteristics: Often produces a good balance between under- and over-smoothing, making it suitable for general spatial analysis.\n\nbw.CvL() (Cronie and Van Lieshout):\n\nPurpose: This method minimizes the integrated squared error between the true intensity function and the estimated intensity function.\nCharacteristics: It’s particularly good for minimizing error over the entire study area, but it can be sensitive to the overall distribution of points.\n\nbw.scott() (Scott’s Rule):\n\nPurpose: Based on Scott’s rule of thumb, this method provides a bandwidth that scales with the number of points and the dimension of the data.\nCharacteristics: Often results in a conservative (wider) bandwidth, leading to smoother density estimates that may miss finer details.\n\nbw.ppl() (Likelihood Cross-Validation):\n\nPurpose: This method uses cross-validation to select a bandwidth that maximizes the likelihood of the observed data under the KDE model.\nCharacteristics: It tends to focus on how well the bandwidth explains the data, often leading to a finer, more detailed density estimate.\n\n\n\nCvLScottPPLdiggle\n\n\n\nbw.CvL(childcareSG_ppp.km)\n\n   sigma \n2.594207 \n\n\n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.2347849 \n\n\n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\n\n\n\n\n# Perform Kernel Density Estimation with different bandwidth selection methods\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, sigma=bw.ppl, edge=TRUE, kernel=\"gaussian\")\nkde_childcareSG.scott &lt;- density(childcareSG_ppp.km, sigma=bw.scott, edge=TRUE, kernel=\"gaussian\")\nkde_childcareSG.CvL &lt;- density(childcareSG_ppp.km, sigma=bw.CvL, edge=TRUE, kernel=\"gaussian\")\nkde_childcareSG.diggle &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\n\n\nlayout(matrix(c(1, 2, 3, 4), 2, 2, byrow = TRUE), widths = c(1, 1), heights = c(1, 1))\n# Set margins to the minimum (bottom, left, top, right)\npar(mar = c(2, 2, 2, 2), oma = c(0, 0, 0, 0))\n# Plot the results for comparison\npar(mfrow=c(2,2))  # Arrange plots in a 2x2 grid\nplot(kde_childcareSG.diggle, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\nplot(kde_childcareSG.CvL, main = \"bw.CvL\")\nplot(kde_childcareSG.scott, main = \"bw.scott\")"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#working-with-different-kernel-methods.",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#working-with-different-kernel-methods.",
    "title": "Spatial Point Patterns Analysis",
    "section": "6.3 working with different kernel methods.",
    "text": "6.3 working with different kernel methods.\n\n\n\n\n\n\n\n\nKernel Method\nShape\nCharacterisitics\n\n\n\n\nGaussian\nBell shaped- normal\nVery smooth, widely used, good for most applications, but might oversmooth and miss finer details.\n\n\nEpanechnikov\nParabolic\nEfficient, minimizes estimation error, compact support (affects nearby points), less smooth than Gaussian.\n\n\nQuartic\nBell Shape with flat top\nBalanced smoothness and efficiency, compact support, focuses on nearby points, similar to Epanechnikov.\n\n\nUniform\nRectangle\nSimple and fast, gives equal weight within a certain distance, but produces rougher estimates.\n\n\n\n\nlayout(matrix(c(1, 2, 3, 4), 2, 2, byrow = TRUE), widths = c(1, 1), heights = c(1, 1))\n\n# Set margins to the minimum (bottom, left, top, right)\npar(mar = c(2, 2, 2, 2), oma = c(0, 0, 0, 0))\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#compute-kde-using-adaptive-bandwidth",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#compute-kde-using-adaptive-bandwidth",
    "title": "Spatial Point Patterns Analysis",
    "section": "7.1 Compute KDE using adaptive bandwidth",
    "text": "7.1 Compute KDE using adaptive bandwidth\nderive adaptive kernel density estimation by using density.adaptive() of spatstat. we can adaptively display\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nComparing it side by side\n\nsuppressMessages({\n  tmap_mode(\"plot\")  # Use \"view\" for an interactive map or \"plot\" for a static map\n})\n\npar(mfrow = c(1, 2), mar = c(2, 2, 2, 2), oma = c(0, 0, 0, 0))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#converting-kde-output-into-grid-object",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#converting-kde-output-into-grid-object",
    "title": "Spatial Point Patterns Analysis",
    "section": "7.3 Converting KDE output into GRID Object",
    "text": "7.3 Converting KDE output into GRID Object\n\nkde_df &lt;- as.data.frame(kde_childcareSG.bw)\ncoordinates(kde_df) &lt;- ~x+y\ngridded(kde_df) &lt;- TRUE\n# Now we have a SpatialGridDataFrame\nkde_SpatialGrid &lt;- as(kde_df, \"SpatialGridDataFrame\")\nspplot(kde_SpatialGrid, main = \"Kernel Density Estimation (bw.diggle)\")\n\n\n\n\n\n\n\n\n\n7.3.1 Coverting grid output into raster\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\n\n7.3.2 Assigning Projection Systems\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#visualizing-the-output-map",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#visualizing-the-output-map",
    "title": "Spatial Point Patterns Analysis",
    "section": "7.4 Visualizing the Output Map",
    "text": "7.4 Visualizing the Output Map\n\nsuppressMessages({\n  tmap_mode(\"plot\")  # Use \"view\" for an interactive map or \"plot\" for a static map\n})\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#comparing-spatial-point-patterns-using-kde",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#comparing-spatial-point-patterns-using-kde",
    "title": "Spatial Point Patterns Analysis",
    "section": "7.5 Comparing Spatial Point Patterns Using KDE",
    "text": "7.5 Comparing Spatial Point Patterns Using KDE\nFocused on KDE childcare at ponggol, tampines, chua chu kang and jurong west these are the planning areas we would like to epxlore further\n\n7.5.1 Extracting the study area\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\n\nPunggolTampinesChoa Chu KangJurong West\n\n\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\n\n\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\n\n\n\n\n\n\n\n\n\n\nplot(ck, main.title = \"Choa Chu Kang\")\n\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.5.2 Creating the owin object\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n7.5.3 Combining the childcare points and study area\n\nchildcare_pg_ppp = jittered_childcare_ppp[pg_owin]\nchildcare_tm_ppp = jittered_childcare_ppp[tm_owin]\nchildcare_ck_ppp = jittered_childcare_ppp[ck_owin]\nchildcare_jw_ppp = jittered_childcare_ppp[jw_owin]\n\nNext, rescale.ppp() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nplot the maps\n\n# Adjust margins and layout\nlayout(matrix(c(1, 2, 3, 4), 2, 2, byrow = TRUE), widths = c(1, 1), heights = c(1, 1))\n# Set margins to the minimum (bottom, left, top, right)\npar(mar = c(2, 2, 2, 2), oma = c(0, 0, 0, 0))\n# Plot the point patterns\nplot(childcare_pg_ppp.km, main = \"Punggol\", cex.main = 5)\nplot(childcare_tm_ppp.km, main = \"Tampines\", cex.main = 5)\nplot(childcare_ck_ppp.km, main = \"Choa Chu Kang\", cex.main = 5)\nplot(childcare_jw_ppp.km, main = \"Jurong West\", cex.main = 5)\n\n\n\n\n\n\n\n\n\n\n7.5.4 computing the kde\n\nlayout(matrix(c(1, 2, 3, 4), 2, 2, byrow = TRUE), widths = c(1, 1), heights = c(1, 1))\n# Set margins to the minimum (bottom, left, top, right)\npar(mar = c(2, 2, 2, 2), oma = c(0, 0, 0, 0))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n7.5.5 Computing fixed bandwidth KDE\nFor comparison purposes, we will use 250m as the bandwidth.\n\nlayout(matrix(c(1, 2, 3, 4), 2, 2, byrow = TRUE), widths = c(1, 1), heights = c(1, 1))\n\n# Set margins to the minimum (bottom, left, top, right)\npar(mar = c(2, 2, 2, 2), oma = c(0, 0, 0, 0))\n\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#testing-spatial-point-patterns-using-clark-and-evans-test",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#testing-spatial-point-patterns-using-clark-and-evans-test",
    "title": "Spatial Point Patterns Analysis",
    "section": "8.1 Testing spatial point patterns using Clark and Evans Test",
    "text": "8.1 Testing spatial point patterns using Clark and Evans Test\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\nR = 0.55631: The observed mean nearest-neighbor distance is significantly smaller than the expected distance under CSR, indicating clustering.\np-value &lt; 2.2e-16: The p-value is extremely small, which strongly suggests that the null hypothesis (random distribution) should be rejected.\nConclusion: Based on these results, we reject the null hypothesis and accept the alternative hypothesis that the distribution of childcare services is clustered."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#clark-and-evans-test-choa-chu-kang-planning-area",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#clark-and-evans-test-choa-chu-kang-planning-area",
    "title": "Spatial Point Patterns Analysis",
    "section": "8.2 Clark and Evans Test: Choa Chu Kang planning area",
    "text": "8.2 Clark and Evans Test: Choa Chu Kang planning area\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.91416, p-value = 0.1996\nalternative hypothesis: two-sided\n\n\nHypotheses for the Clark-Evans Test\nNull Hypothesis (Ho):\n\nThe distribution of childcare services in the Choa Chu Kang region (childcare_ck_ppp) is randomly distributed. This means there is no significant clustering or regular spacing in the locations of the childcare services; they follow a pattern consistent with complete spatial randomness (CSR).\n\nAlternative Hypothesis (H1):\n\nThe distribution of childcare services in the Choa Chu Kang region is not randomly distributed. This means there is a significant deviation from randomness, which could be either clustering (points are closer together than expected) or regular spacing (points are further apart than expected).\n\nTest Results\nTest Statistic (R):\n\nR = 0.91416: The ratio of the observed mean nearest-neighbor distance to the expected mean distance under CSR is close to 1. This indicates that the observed distribution of points is fairly similar to what would be expected under a random distribution, with a slight indication of clustering (since R is slightly less than 1), but not strong enough to be statistically significant.\n\np-value:\n\np-value = 0.1996: The p-value is greater than the typical alpha level of 0.05, indicating that the observed pattern could reasonably occur under the null hypothesis (random distribution). In other words, there isn’t enough evidence to reject the null hypothesis.\n\nConclusion\n\nFail to Reject the Null Hypothesis: Since the p-value is 0.1996 (which is greater than 0.05), we do not reject the null hypothesis. This means we do not have sufficient evidence to conclude that the distribution of childcare services in Choa Chu Kang is significantly different from random.\nInterpretation:\n\nR = 0.91416 suggests a slight tendency towards clustering, but this is not statistically significant.\nThe p-value of 0.1996 suggests that any apparent clustering could be due to random variation, and there is no strong evidence of a non-random (clustered or regular) distribution pattern"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#clark-and-evans-test-tampines-planning-area",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#clark-and-evans-test-tampines-planning-area",
    "title": "Spatial Point Patterns Analysis",
    "section": "8.3 Clark and Evans Test: Tampines planning area",
    "text": "8.3 Clark and Evans Test: Tampines planning area\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.77989, p-value = 7.113e-05\nalternative hypothesis: two-sided\n\n\nNull Hypothesis (Ho):\n\nThe distribution of childcare services in the Tampines region is randomly distributed. This means there is no significant clustering or regular spacing in the locations of the childcare services; they follow a pattern consistent with complete spatial randomness (CSR).\n\nAlternative Hypothesis (H1):\n\nThe distribution of childcare services in the Tampines region is not randomly distributed. This means there is a significant deviation from randomness, which could be either clustering (points are closer together than expected) or regular spacing (points are further apart than expected).\n\nInterpreting the Results\nTest Statistic (R):\n\nR = 0.77989: The ratio of the observed mean nearest-neighbor distance to the expected mean distance under CSR is less than 1. This indicates that the points are closer together than they would be under a random distribution, suggesting some level of clustering.\n\np-value:\n\np-value = 7.113e-05: The p-value is very small, significantly less than the typical alpha level of 0.05. This indicates that the probability of observing this pattern of points under the null hypothesis (random distribution) is extremely low.\n\nConclusion:\n\nSince the p-value is much smaller than 0.05, we reject the null hypothesis. The result supports the alternative hypothesis that the distribution of childcare services in the Tampines region is not randomly distributed.\n\nGiven that R &lt; 1, this deviation from randomness is specifically indicative of clustering. The childcare services are more tightly grouped together than would be expected if they were randomly distributed."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#choa-chu-kang-planning-area",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#choa-chu-kang-planning-area",
    "title": "Spatial Point Patterns Analysis",
    "section": "9.1 Choa Chu Kang planning area",
    "text": "9.1 Choa Chu Kang planning area\n\n9.1.1 Computing G-function estimation\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n9.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function\nenvelope(): Generates a comparison between observed and expected patterns under CSR by simulating many possible outcomes and calculating the range of these simulations.\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\n\n\n9.1.3 Analyzing the result\n\n# Calculate the p-value based on the envelope\np_value &lt;- mean(G_CK.csr$obs &lt; G_CK.csr$lo | G_CK.csr$obs &gt; G_CK.csr$hi)\n# Print the P value\nprint(paste(\"P value =\", p_value))\n\n[1] \"P value = 0.0311890838206628\"\n\n\nKey Elements in the Plot:\n\nBlack Line (G_obs(r)): Represents the observed G-function, showing the cumulative distribution of the nearest neighbor distances in your actual data.\nRed Dashed Line (G_theo(r)): Represents the theoretical G-function under CSR, showing what the distribution of nearest neighbor distances would look like if the points were randomly distributed.\nGray Envelope: Represents the range of G-function values generated from simulations under CSR, providing a visual benchmark for assessing the significance of deviations in the observed G-function.\n\nWhat the Plot Tells Us:\n\nObserved G-function Above the Theoretical G-function: In our plot, the black line (G_obs(r)) is mostly above the red dashed line (G_theo(r)), indicating that the observed points are closer together (more clustered) than what would be expected under CSR.\nObserved G-function Outside the CSR Envelope: When the black line moves outside the gray envelope (particularly above it), this suggests that the clustering is statistically significant.\n\nResults\n\nClustering: The observed G-function (G_obs(r)) being above the theoretical G-function (G_theo(r)) and often outside the CSR envelope indicates significant clustering of the childcare services in the Choa Chu Kang area.\nStatistical Significance: The p-value of 0.025 confirms that this clustering is statistically significant, meaning that the spatial distribution of childcare centers in this area is not random but rather clustered."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#tampines-planning-area",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#tampines-planning-area",
    "title": "Spatial Point Patterns Analysis",
    "section": "9.2 Tampines planning area",
    "text": "9.2 Tampines planning area\n\n9.2.1 Computing G-function estimation\nThe \"best\" option allows spatstat to choose the most suitable edge correction method for the specific point pattern you are analyzing. This is particularly useful if you’re unsure which correction method is optimal for your data.\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\n9.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\n\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_tm.csr)\n\n\n\n\n\n\n\n\n\n\n9.2.3 Analyzing the result\n\n# Calculate the p-value based on the envelope \np_value &lt;- mean(G_tm.csr$obs &lt; G_tm.csr$lo | G_tm.csr$obs &gt; G_tm.csr$hi) \n# Print the P value \nprint(paste(\"P value =\", p_value)) \n\n[1] \"P value = 0.0623781676413255\"\n\n\nKey Observations from the Plot:\n\nBlack Line (G_obs(r)) Above Red Dashed Line (G_theo(r)): This indicates that the observed points (childcare services in Tampines) are generally closer to each other than would be expected under CSR, suggesting clustering.\nBlack Line Partially Outside the Gray Envelope: The observed G-function steps outside the CSR envelope at some distances, suggesting that the observed clustering is statistically significant at those distances.\n\np-value:\n\np-value = 0.037: This p-value indicates that there is a 3.7% chance of observing such a distribution (or one more extreme) under the null hypothesis of random distribution. Since this p-value is below the common significance threshold of 0.05, we can conclude that the observed pattern is unlikely to be due to random chance.\n\nConclusion:\n\nReject the Null Hypothesis (Ho): Given the p-value of 0.037, we reject the null hypothesis that the distribution of childcare services in Tampines is randomly distributed.\nAccept the Alternative Hypothesis (H1): The data suggests that the distribution of childcare services in Tampines is not random. Specifically, the observed G-function shows clustering, where the childcare centers are closer to each other than would be expected under a random distribution."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#choa-chu-kang-planning-area-1",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#choa-chu-kang-planning-area-1",
    "title": "Spatial Point Patterns Analysis",
    "section": "10.1 Choa Chu Kang planning area",
    "text": "10.1 Choa Chu Kang planning area\n\n10.1.1 Computing F-function estimation\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\n\n\n10.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-function\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\n10.1.3 Analyzing the result\n\np_value &lt;- mean(F_CK.csr$obs &lt; F_CK.csr$lo | F_CK.csr$obs &gt; F_CK.csr$hi)\n# Print the p-value\nprint(paste(\"P-value =\", p_value))\n\n[1] \"P-value = 0\"\n\n\nKey Observations:\n\nF_obs(r) Below the Envelope:\n\nThe observed F-function (F_obs(r)) lies entirely below the gray CSR envelope across almost all distances r. This suggests that the nearest neighbor distances from random locations to the nearest childcare center are generally larger than expected under CSR.\nIn practical terms, this means that the points (childcare centers) are more dispersed than would be expected if they were randomly distributed, indicating a tendency toward regular spacing.\n\np-value of 0:\n\nA p-value of 0 indicates that in all 999 simulations, the observed F-function fell outside the envelope. This is a strong statistical signal that the observed pattern deviates significantly from randomness.\nSince the observed F-function is consistently below the CSR envelope, it suggests that the observed pattern is significantly more dispersed (regular) than would be expected under a random distribution.\n\n\nConclusion:\n\nReject the Null Hypothesis (Ho):\n\nGiven that the p-value is 0, we reject the null hypothesis that the distribution of childcare services in Choa Chu Kang is randomly distributed.\n\nAccept the Alternative Hypothesis (H1):\n\nThe observed spatial pattern of childcare services in Choa Chu Kang is not random. The F-function analysis suggests that the pattern is significantly more dispersed than expected under CSR, indicating a regular spacing of childcare centers rather than clustering or randomness."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#tampines-planning-area-1",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#tampines-planning-area-1",
    "title": "Spatial Point Patterns Analysis",
    "section": "10.2 Tampines planning area",
    "text": "10.2 Tampines planning area\n\n10.2.1 Computing F-function estimation\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n\n10.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed\n\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-function\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(F_tm.csr)\n\n\n\n\n\n\n\n\n\n\n10.2.3 Analyzing the result\n\np_value &lt;- mean(F_tm.csr$obs &lt; F_tm.csr$lo | F_tm.csr$obs &gt; F_tm.csr$hi) \n# Print the p-value \nprint(paste(\"P-value =\", p_value))\n\n[1] \"P-value = 0.616438356164384\"\n\n\nKey Observations:\n\nF_obs(r) Below the Theoretical Line and Envelope:\n\nThe observed F-function (F_obs(r)) is mostly below the theoretical F-function (F_theo(r)) and falls below the lower bound of the CSR envelope. This suggests that the nearest neighbor distances from random locations to the nearest childcare center are generally larger than expected under CSR, indicating a tendency towards regular spacing.\n\np-value = 0.657:\n\nThe p-value of 0.657 suggests that there is no significant deviation from the null hypothesis of randomness. A p-value this high indicates that the observed spatial distribution is consistent with what would be expected under CSR.\n\n\nConclusion:\n\nFail to Reject the Null Hypothesis (Ho):\n\nGiven the p-value of 0.657, we fail to reject the null hypothesis that the distribution of childcare services in Tampines is randomly distributed.\n\nInterpretation:\n\nThe observed F-function does not show significant deviation from the theoretical F-function under CSR. The high p-value indicates that any observed regularity or dispersion in the spatial distribution of childcare services in Tampines is likely due to random variation, rather than a systematic pattern."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#choa-chu-kang-planning-area-2",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#choa-chu-kang-planning-area-2",
    "title": "Spatial Point Patterns Analysis",
    "section": "11.1 Choa Chu Kang planning area",
    "text": "11.1 Choa Chu Kang planning area\n\n11.1.1 Computing K-function estimation\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n11.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with K-function\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n11.1.3 Analyzing the result\n\np_value &lt;- mean(K_ck.csr$obs &lt; K_ck.csr$lo | K_ck.csr$obs &gt; K_ck.csr$hi) \n# Print the p-value \nprint(paste(\"P-value =\", p_value))\n\n[1] \"P-value = 0.0233918128654971\"\n\n\nKey Observations:\n\nK_obs(r) Above the Theoretical Line:\n\nThe observed K-function (K_obs(r) - r) is slightly above the theoretical K-function (K_theo(r) - r), particularly at larger distances. This suggests that there might be some clustering in the distribution of childcare centers at larger scales, as more pairs of points are found within these distances than expected under CSR.\n\nK_obs(r) Within the CSR Envelope:\n\nThe observed K-function mostly remains within the CSR envelope, although it tends to approach the upper bound of the envelope at larger distances. This indicates that while there is some indication of clustering, the deviation is not statistically significant across all distances.\n\n\np-value = 0.113:\n\np-value of 0.113:\n\nThe p-value of 0.113 indicates that there is an 11.3% chance of observing such a distribution (or one more extreme) under the null hypothesis of random distribution. This p-value is above the common significance threshold of 0.05, meaning that we do not have strong enough evidence to reject the null hypothesis.\n\n\nConclusion:\n\nFail to Reject the Null Hypothesis (Ho):\n\nGiven the p-value of 0.113, we fail to reject the null hypothesis that the distribution of childcare services in Choa Chu Kang is randomly distributed.\n\nInterpretation:\n\nWhile the K-function suggests some mild clustering, especially at larger distances, the observed pattern does not deviate significantly from what would be expected under CSR. The p-value supports this conclusion, indicating that any clustering observed is not statistically significant at the 5% level."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#tampines-planning-area-2",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#tampines-planning-area-2",
    "title": "Spatial Point Patterns Analysis",
    "section": "11.2 Tampines planning area",
    "text": "11.2 Tampines planning area\n\n11.2.1 Computing K-function estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n11.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed\n\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-function\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n11.2.3 Analyzing the result\n\np_value &lt;- mean(K_tm.csr$obs &lt; K_tm.csr$lo | K_tm.csr$obs &gt; K_tm.csr$hi) \n# Print the p-value \nprint(paste(\"P-value =\", p_value))\n\n[1] \"P-value = 0.998050682261209\"\n\n\nKey Observations:\n\nK_obs(r) Significantly Above the Theoretical Line and Envelope:\n\nThe observed K-function (K_obs(r) - r) is consistently above the theoretical K-function (K_theo(r) - r) and lies well above the upper bound of the CSR envelope, especially as distance rrr increases. This strong deviation indicates a significant clustering of points at varying distances, particularly at larger scales.\n\np-value of 0.998:\n\nThe extremely high p-value of 0.998 suggests that the observed pattern is consistent with the null hypothesis of CSR. However, given the context and the K-function being well above the envelope, this might seem counte rintuitive. This high p-value typically indicates that the observed pattern is not significantly different from CSR, but the visual evidence in the plot suggests otherwise.\n\n\nConclusion:\n\nFail to Reject the Null Hypothesis (Ho):\n\nGiven the p-value of 0.998, we would typically fail to reject the null hypothesis that the distribution of childcare services in Tampines is randomly distributed.\n\nInterpretation:\n\nDespite the high p-value, the plot clearly shows that the observed K-function is consistently and significantly above the CSR envelope, indicating clustering. This discrepancy between the p-value and visual interpretation could result from a peculiarity in the data or the way the p-value was calculated. It’s essential to consider both statistical results and visual evidence when drawing conclusions."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#choa-chu-kang-planning-area-3",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#choa-chu-kang-planning-area-3",
    "title": "Spatial Point Patterns Analysis",
    "section": "12.1 Choa Chu Kang planning area",
    "text": "12.1 Choa Chu Kang planning area\n\n12.1.1 Computing L-function estimation\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n12.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with L-function\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\n11.1.3 Analyzing the result\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.91416, p-value = 0.1996\nalternative hypothesis: two-sided\n\np_value &lt;- mean(L_ck.csr$obs &lt; L_ck.csr$lo | L_ck.csr$obs &gt; L_ck.csr$hi)  \n# Print the p-value  \nprint(paste(\"P-value =\", p_value))\n\n[1] \"P-value = 0.0526315789473684\"\n\n\nKey Observations:\n\nL_obs(r) Fluctuations:\n\nThe observed L-function (L_obs(r) - r) fluctuates around the theoretical line (L_theo(r) - r = 0) and within the CSR envelope for most of the distance range.\nIn the early part of the plot (small distances), the observed L-function dips below the envelope briefly, indicating some regularity or dispersion at very small scales.\n\nMostly Within the CSR Envelope:\n\nFor the majority of distances rrr, the observed L-function stays within the CSR envelope, suggesting that the observed pattern does not significantly deviate from randomness at these scales.\n\np-value of 0.051:\n\nThe p-value of 0.051 is very close to the common significance threshold of 0.05. This p-value indicates that there is a 5.1% chance of observing such a distribution (or one more extreme) under the null hypothesis of random distribution.\nAlthough the p-value is slightly above the threshold, it suggests a marginal significance, meaning that the observed pattern might be slightly more regular or dispersed than what would be expected under CSR.\n\n\nConclusion:\n\nMarginal Result:\n\nGiven the p-value of 0.051, we fail to reject the null hypothesis at the 5% significance level, but it’s very close. This suggests that the evidence is not strong enough to confidently assert that the distribution is non-random.\nHowever, the proximity of the p-value to 0.05 indicates that the observed pattern is on the verge of being considered significantly different from CSR, possibly indicating some degree of regularity or dispersion, especially at smaller scales."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#tampines-planning-area-3",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html#tampines-planning-area-3",
    "title": "Spatial Point Patterns Analysis",
    "section": "12.2 Tampines planning area",
    "text": "12.2 Tampines planning area\n\n12.2.1 Computing F-function estimation\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n12.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed\n\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-function\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n12.2.3 Analyzing the result\n\np_value &lt;- mean(L_tm.csr$obs &lt; L_tm.csr$lo | L_tm.csr$obs &gt; L_tm.csr$hi)  \n# Print the p-value  \nprint(paste(\"P-value =\", p_value))\n\n[1] \"P-value = 0.998050682261209\"\n\n\nKey Observations:\n\nL_obs(r) Above the Theoretical Line:\n\nThe observed L-function (L_obs(r) - r) is consistently above the theoretical line (L_theo(r) - r = 0) and outside the CSR envelope across almost all distances rrr. This suggests significant clustering of childcare centers at these scales.\n\np-value of 0.996:\n\nThe extremely high p-value of 0.996 indicates that the observed L-function does not significantly deviate from what would be expected under CSR, according to the simulations.\nGiven alpha level of 0.001, the p-value is much higher than this threshold, meaning that there is no strong evidence to reject the null hypothesis in favor of the alternative.\n\n\nConclusion:\n\nFail to Reject the Null Hypothesis (Ho):\n\nGiven that the p-value of 0.996 is well above the alpha threshold of 0.001, we fail to reject the null hypothesis. This suggests that the observed distribution of childcare services in Tampines does not significantly deviate from a random distribution, according to the statistical test."
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_1/data/geospatial/MPSZ-2019.html",
    "href": "In_Class_Exercises/In_Class_Exercise_1/data/geospatial/MPSZ-2019.html",
    "title": "IS415-GAA: JialeSo",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_1/In_Class_Exercise1.html",
    "href": "In_Class_Exercises/In_Class_Exercise_1/In_Class_Exercise1.html",
    "title": "In Class Exercise1: Geospatial Data Science",
    "section": "",
    "text": "There’s no In Class Exercise 1, so here’s a picture of a cat."
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_2/downloaded Files/MPSZ-2019/MPSZ-2019.html",
    "href": "In_Class_Exercises/In_Class_Exercise_2/downloaded Files/MPSZ-2019/MPSZ-2019.html",
    "title": "IS415-GAA: JialeSo",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Take_Home_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html",
    "href": "Take_Home_Exercises/Hands_On_Exercise_1/Hands_On_Exercise1.html",
    "title": "Hands-On Exercise 1:",
    "section": "",
    "text": "Getting Started\nInstall and launching R Packages\nThe code chunk below uses the p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\n  library(pacman)\n\nWarning: package 'pacman' was built under R version 4.3.3\n\n  pacman::p_load(tidyverse)\n\nImporting the data"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html",
    "href": "Hands_On_Exercises/Hands_On_Exercise_3/Hands_On_Exercise3.html",
    "title": "Spatial Point Patterns Analysis",
    "section": "",
    "text": "Spatial Point Pattern Analysis involves evaluating the pattern or distribution of a set of points on a surface. These points can represent the locations of:\n\nEvents, such as crimes, traffic accidents, or disease outbreaks, or\nBusiness services, like coffee shops and fast food outlets, or facilities such as childcare and eldercare centers.\n\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_3/In_Class_Exercise3.html#import-and-simple-data-transformation",
    "href": "In_Class_Exercises/In_Class_Exercise_3/In_Class_Exercise3.html#import-and-simple-data-transformation",
    "title": "In Class Exercise 3: Spatial Point Patterns Analysis",
    "section": "4.1 Import and Simple Data Transformation",
    "text": "4.1 Import and Simple Data Transformation"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_3/In_Class_Exercise3.html#simply-join-the-data-and-then-map-it-out",
    "href": "In_Class_Exercises/In_Class_Exercise_3/In_Class_Exercise3.html#simply-join-the-data-and-then-map-it-out",
    "title": "In Class Exercise 3: Spatial Point Patterns Analysis",
    "section": "4.2 Simply join the data and then map it out",
    "text": "4.2 Simply join the data and then map it out\n\n4.2.1 Join the data\n\n\n4.2.2 Plot the map"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_3/In_Class_Exercise3.html",
    "href": "In_Class_Exercises/In_Class_Exercise_3/In_Class_Exercise3.html",
    "title": "In Class Exercise 3: Spatial Point Patterns Analysis",
    "section": "",
    "text": "# eval: FALSE"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_3/In_Class_Exercise3.html#sf-costal",
    "href": "In_Class_Exercises/In_Class_Exercise_3/In_Class_Exercise3.html#sf-costal",
    "title": "In Class Exercise 3: Spatial Point Patterns Analysis",
    "section": "4.1 SF Costal",
    "text": "4.1 SF Costal\nWorking with st_union()\n\nWe want to have a coastal outline of Singapore, and we can do so with st_union() to union the outline data with the subzone data.\n\n\nsg_sf &lt;- mpsz_sf %&gt;%\n  st_union()\n\nplot(sg_sf)"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_3/In_Class_Exercise3.html#importing-acled-myanmar-file",
    "href": "In_Class_Exercises/In_Class_Exercise_3/In_Class_Exercise3.html#importing-acled-myanmar-file",
    "title": "In Class Exercise 3: Spatial Point Patterns Analysis",
    "section": "4.2 Importing ACLED Myanmar File",
    "text": "4.2 Importing ACLED Myanmar File\n\nacled_sf &lt;- read_csv(\"data/ACLED_Myanmar.csv\") %&gt;%\n  st_as_sf(coords = c(\"longitude\",\"latitude\"),\n  crs=4326) %&gt;%\n  st_transform(crs = 32647) %&gt;%\n  mutate(event_date = dmy(event_date))\n\n\nglimpse(acled_sf)\n\nRows: 55,574\nColumns: 30\n$ event_id_cnty      &lt;chr&gt; \"MMR56099\", \"MMR56222\", \"MMR56370\", \"MMR56376\", \"MM…\n$ event_date         &lt;date&gt; 2023-12-31, 2023-12-31, 2023-12-31, 2023-12-31, 20…\n$ year               &lt;dbl&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 202…\n$ time_precision     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ disorder_type      &lt;chr&gt; \"Political violence\", \"Political violence\", \"Politi…\n$ event_type         &lt;chr&gt; \"Explosions/Remote violence\", \"Explosions/Remote vi…\n$ sub_event_type     &lt;chr&gt; \"Shelling/artillery/missile attack\", \"Shelling/arti…\n$ actor1             &lt;chr&gt; \"Military Forces of Myanmar (2021-)\", \"Military For…\n$ assoc_actor_1      &lt;chr&gt; NA, NA, NA, NA, NA, NA, \"Daw Na Column; YGF: Ye Gue…\n$ inter1             &lt;dbl&gt; 1, 1, 3, 6, 1, 1, 3, 1, 2, 1, 1, 2, 2, 1, 1, 3, 3, …\n$ actor2             &lt;chr&gt; NA, \"Civilians (Myanmar)\", \"Military Forces of Myan…\n$ assoc_actor_2      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ inter2             &lt;dbl&gt; 0, 7, 1, 0, 7, 0, 1, 0, 1, 7, 7, 1, 1, 0, 0, 1, 1, …\n$ interaction        &lt;dbl&gt; 10, 17, 13, 60, 17, 10, 13, 10, 12, 17, 17, 12, 12,…\n$ civilian_targeting &lt;chr&gt; NA, \"Civilian targeting\", NA, NA, NA, NA, NA, NA, N…\n$ iso                &lt;dbl&gt; 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 1…\n$ region             &lt;chr&gt; \"Southeast Asia\", \"Southeast Asia\", \"Southeast Asia…\n$ country            &lt;chr&gt; \"Myanmar\", \"Myanmar\", \"Myanmar\", \"Myanmar\", \"Myanma…\n$ admin1             &lt;chr&gt; \"Mon\", \"Rakhine\", \"Bago-West\", \"Sagaing\", \"Bago-Wes…\n$ admin2             &lt;chr&gt; \"Mawlamyine\", \"Maungdaw\", \"Thayarwady\", \"Yinmarbin\"…\n$ admin3             &lt;chr&gt; \"Ye\", \"Maungdaw\", \"Nattalin\", \"Salingyi\", \"Nattalin…\n$ location           &lt;chr&gt; \"Aing Shey\", \"Kaing Gyi (NaTaLa)\", \"Kyauk Pyoke\", \"…\n$ geo_precision      &lt;dbl&gt; 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, …\n$ source             &lt;chr&gt; \"Democratic Voice of Burma\", \"Development Media Gro…\n$ source_scale       &lt;chr&gt; \"National\", \"Subnational\", \"National\", \"National\", …\n$ notes              &lt;chr&gt; \"On 31 December 2023, in Aing Shey village (Ye town…\n$ fatalities         &lt;dbl&gt; 0, 0, 4, 0, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2, …\n$ tags               &lt;chr&gt; NA, NA, NA, \"crowd size=no report\", NA, NA, NA, NA,…\n$ timestamp          &lt;dbl&gt; 1704831212, 1704831213, 1704831214, 1704831214, 170…\n$ geometry           &lt;POINT [m]&gt; POINT (393190.2 1690159), POINT (-183852.6 23…\n\nclass(acled_sf)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\ntmap_mode('plot')\n\nacled_sf %&gt;%\n  filter(year == 2023 | event_type == 'Political violence') %&gt;%\n  tm_shape() +\n  tm_dots()\n\n\n\n\n\n\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html",
    "href": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html",
    "title": "Hands On Exercise 4: Spatio-Temporal & Network Constrainted Spatial Point Pattern Analysis",
    "section": "",
    "text": "A spatio-temporal point process (also called space-time or spatial-temporal point process) is a random collection of points, where each point represents the time and location of an event. Examples of events include incidence of disease, sightings or births of a species, or the occurrences of fires, earthquakes, lightning strikes, tsunamis, or volcanic eruptions.\nThe analysis of spatio-temporal point patterns is becoming increasingly necessary, given the rapid emergence of geographically and temporally indexed data in a wide range of fields. Several spatio-temporal point patterns analysis methods have been introduced and implemented in R in the last ten years. This chapter shows how various R packages can be combined to run a set of spatio-temporal point pattern analyses in a guided and intuitive way. A real world forest fire events in Kepulauan Bangka Belitung, Indonesia from 1st January 2023 to 31st December 2023 is used to illustrate the methods, procedures and interpretations.\n\n\nThe specific question we would like to answer is:\n\nare the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nif the answer is NO, where and when the observed forest fire locations tend to cluster?"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html#importing-spatial-data",
    "href": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html#importing-spatial-data",
    "title": "Spatial Point Patterns Analysis",
    "section": "4.1 Importing Spatial Data",
    "text": "4.1 Importing Spatial Data\n\nChildcare dataCostal Outlinemp14_subzone\n\n\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_4\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_4\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_4\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\n4.1.1 DIY:Use the appropriate SF function to retrieve the referencing system information of these geospatial data.\nSimple, use the st_crs function from SF to check and print the crs information\n\n# Retrieve CRS information\nchildcare_crs &lt;- st_crs(childcare_sf)\nsg_crs &lt;- st_crs(sg_sf)\nmpsz_crs &lt;- st_crs(mpsz_sf)\n\n# Print CRS information\nprint(childcare_crs)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\nprint(sg_crs)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\nprint(mpsz_crs)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\n\n4.1.2 DIY: Assign the correct CRS to MPSZ_SF and SG_SF Simple Feature Data frames.\nnotice that the MPSZ_SF and SG_SF is in World Geodetic System 1984 format, we need set the correct crs to these data and we can do so using the st transform. We can do so using the transform method\n\nChanging to CRSCheck if its the right CRS\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", layer = \"MP14_SUBZONE_WEB_PL\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_4\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nsg_sf &lt;- st_read(dsn = \"data\", layer = \"CostalOutline\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `CostalOutline' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_4\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\n\n\nprint(st_crs(mpsz_sf))\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\nprint(st_crs(sg_sf))\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\n\n\n4.1.3 Change the referencing System to Singapore National Projected Coordinate System\n\n\n\n\n\n\nNote\n\n\n\nUnderstanding the CRS in Our Data:\n\nMPZ and Coastal Data:\n\nCRS: SVY21, which is the Singapore National Projected Coordinate System based on WGS84.\nDescription: This is a common projected coordinate system used in Singapore for accurate mapping.\n\nChildcare Data:\n\nCRS: SVY21 / Singapore TM (Transverse Mercator projection).\nDescription: This is also a projection based on SVY21, specifically using the Transverse Mercator projection. It is very close to the SVY21 system, with minor differences in how the projection is handled.\n\n\nGiven that the map file serves as the base, we want all spatial data to overlay correctly, we should:\n\nTransform the GeoJSON Data to Match the Map File’s CRS:\n\nSince our MPZ and Coastal data are already in SVY21 (EPSG:3414), transform the GeoJSON data to EPSG:3414 as well.\n\nRationale:\n\nThis approach ensures that the childcare locations from the GeoJSON data will be accurately plotted within the boundaries and context provided by the map file (MPZ and Coastal data).\nIt avoids potential issues with misalignment, especially since oour base map data is already set up in a local projection suitable for Singapore.\n\n\n\n\n\n# Transform Childcare data to match the base map's CRS (EPSG:3414)\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_4\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n# Now, all datasets should be aligned in the same CRS\n\n\n\n4.1.4 Checking for validity of maps\nWhen working with spatial data, it’s crucial to ensure that all geometries are valid. Invalid geometries can cause errors in analysis and visualization.\n\nChecking Validity with st_is_valid():\nIdentifying Invalid Geometries:\nFixing Invalid Geometries with st_make_valid()\n\n\nMPZSGChildcare\n\n\n\nmpsz_validity &lt;- st_is_valid(mpsz_sf)\nmpsz_invalid &lt;- which(!mpsz_validity)\nif (length(mpsz_invalid) &gt; 0) {\n  print(\"MPZ Invalid!\")\n  print(mpsz_sf[mpsz_invalid, ])\n} else {\n  print(\"it's valid!\")\n}\n\n[1] \"MPZ Invalid!\"\nSimple feature collection with 9 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 12535.88 ymin: 21678.35 xmax: 56396.44 ymax: 49291.03\nProjected CRS: SVY21 / Singapore TM\n    OBJECTID SUBZONE_NO             SUBZONE_N SUBZONE_C CA_IND\n19        19          2        SOUTHERN GROUP    SISZ02      N\n20        20          1               SENTOSA    SISZ01      N\n24        24          1       MARITIME SQUARE    BMSZ01      N\n122      122          9           JURONG PORT    JESZ09      N\n123      123          3               SAMULUN    BLSZ03      N\n128      128          9                PANDAN    CLSZ09      N\n258      258          4        PASIR RIS PARK    PRSZ04      N\n302      302          1 NORTH-EASTERN ISLANDS    NESZ01      N\n320      320          9           NORTH COAST    WDSZ09      N\n               PLN_AREA_N PLN_AREA_C          REGION_N REGION_C\n19       SOUTHERN ISLANDS         SI    CENTRAL REGION       CR\n20       SOUTHERN ISLANDS         SI    CENTRAL REGION       CR\n24            BUKIT MERAH         BM    CENTRAL REGION       CR\n122           JURONG EAST         JE       WEST REGION       WR\n123              BOON LAY         BL       WEST REGION       WR\n128              CLEMENTI         CL       WEST REGION       WR\n258             PASIR RIS         PR       EAST REGION       ER\n302 NORTH-EASTERN ISLANDS         NE NORTH-EAST REGION      NER\n320             WOODLANDS         WD      NORTH REGION       NR\n             INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng SHAPE_Area\n19  5809FC547293EA2D 2014-12-05 29815.09 23412.59  25626.977    2206319\n20  A6FCDC9C447952CB 2014-12-05 27593.94 25813.35  17496.194    4919132\n24  C1AC31ABF9978DDB 2014-12-05 25805.79 27911.42  13737.116    2701634\n122 0664CA7EF6504AE5 2014-12-05 15250.74 32183.92  11355.002    2464857\n123 F78E0287D3F24214 2014-12-05 13418.49 32264.59   8738.679    1940693\n128 A6EE4A49376B69C4 2014-12-05 19228.60 32265.40   5689.647    1312923\n258 9856E3CDCF57AD96 2014-12-05 41529.80 40218.94   8533.964    1719705\n302 92BC3E09C68F3B52 2014-12-05 50424.79 42612.88  62436.235   67250563\n320 898B2436858382A1 2014-12-05 22147.04 48031.55  10847.882    2450784\n                          geometry\n19  MULTIPOLYGON (((29712.51 23...\n20  MULTIPOLYGON (((26858.1 266...\n24  MULTIPOLYGON (((26514.58 28...\n122 MULTIPOLYGON (((14483.48 31...\n123 MULTIPOLYGON (((12861.38 32...\n128 MULTIPOLYGON (((19680.06 31...\n258 MULTIPOLYGON (((41343.11 40...\n302 MULTIPOLYGON (((52567.43 46...\n320 MULTIPOLYGON (((21693.06 48...\n\n\nNotice that MPZ has 9 invalidity of sub zones here, so we have to make it valid through the function make valid. Once it’s valid we then check again\n\nmpsz_sf &lt;- st_make_valid(mpsz_sf)\nmpsz_validity &lt;- st_is_valid(mpsz_sf)\nmpsz_invalid &lt;- which(!mpsz_validity)\nif (length(mpsz_invalid) &gt; 0) {\n  print(\"MPZ Invalid!\")\n  print(mpsz_sf[mpsz_invalid, ])\n} else {\n  print(\"it's valid!\")\n}\n\n[1] \"it's valid!\"\n\n\n\n\n\nsg_validity &lt;- st_is_valid(sg_sf)\nsg_invalid &lt;- which(!sg_validity)\nif (length(sg_invalid) &gt; 0) {\n  print(\"SG Invalid!\")\n  print(mpsz_sf[mpsz_invalid, ])\n} else {\n  print(\"it's valid!\")\n}\n\n[1] \"SG Invalid!\"\nSimple feature collection with 0 features and 15 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n [1] OBJECTID   SUBZONE_NO SUBZONE_N  SUBZONE_C  CA_IND     PLN_AREA_N\n [7] PLN_AREA_C REGION_N   REGION_C   INC_CRC    FMEL_UPD_D X_ADDR    \n[13] Y_ADDR     SHAPE_Leng SHAPE_Area geometry  \n&lt;0 rows&gt; (or 0-length row.names)\n\n\nIn SG_SF there’s one invalid as well, so we apply the fix.\n\nsg_sf &lt;- st_make_valid(sg_sf)\nsg_validity &lt;- st_is_valid(sg_sf)\nsg_invalid &lt;- which(!sg_validity)\nif (length(sg_invalid) &gt; 0) {\n  print(\"SG Invalid!\")\n  print(mpsz_sf[sg_invalid, ])\n} else {\n  print(\"it's valid!\")\n}\n\n[1] \"it's valid!\"\n\n\n\n\nNotice that childcare is a geojson data and it houses it’s data in the description column, we need to break this up to get more meaningful data.\nWe can do a simple extraction from the Description attribute and map the data better. Assuming that each Table Row (TR) contains a Table Head (TH) and a Table Data (TD), we can map the data accordingly.\n\nchildcare_validity &lt;- st_is_valid(childcare_sf)\nchildcare_invalid &lt;- which(!childcare_validity)\nif (length(childcare_invalid) &gt; 0) {\n  print(\"ChildCare Invalid!\")\n  print(childcare_sf[childcare_invalid, ])\n} else {\n  print(\"it's valid!\")\n}\n\n[1] \"it's valid!\"\n\n# Ensure the geometry column is preserved\ngeometry_column &lt;- st_geometry(childcare_sf)\nparse_description &lt;- function(html_string) {\n  html &lt;- read_html(html_string)\n  html &lt;- html %&gt;% html_nodes(\"tr\") %&gt;% .[!grepl(\"Attributes\", .)]\n  headers &lt;- html %&gt;% html_nodes(\"th\") %&gt;% html_text(trim = TRUE)\n  values &lt;- html %&gt;% html_nodes(\"td\") %&gt;% html_text(trim = TRUE)\n  \n  # Handle cases where the number of headers and values don't match\n  if (length(headers) != length(values)) {\n    max_length &lt;- max(length(headers), length(values))\n    headers &lt;- c(headers, rep(\"ExtraHeader\", max_length - length(headers)))\n    values &lt;- c(values, rep(\"NULL\", max_length - length(values)))\n  }\n  \n  setNames(values, headers)\n}\n\n# Apply parsing function, unnest the description fields, and remove the original 'Description' column\nchildcare_sf &lt;- childcare_sf %&gt;% \n  mutate(Description_parsed = map(Description, parse_description)) %&gt;%\n  unnest_wider(Description_parsed) %&gt;%\n  select(-Description)  # Remove the original 'Description' column\n\n# Overwrite the 'Name' column with the 'LANDYADDRESSPOINT' column values\nchildcare_sf &lt;- childcare_sf %&gt;%\n  mutate(Name = NAME)  # Overwrite 'Name' with 'LANDYADDRESSPOINT'\n\n# Replace empty strings or NA across all columns with \"NULL\"\nchildcare_sf &lt;- childcare_sf %&gt;%\n  mutate(across(!geometry, ~ ifelse(is.na(.) | . == \"\", \"NULL\", .)))\n\n# Reassign the geometry to the dataframe\nst_geometry(childcare_sf) &lt;- geometry_column\n# Ensure it's still an sf object\nclass(childcare_sf)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\""
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html#mapping-the-geospatial-datasets.",
    "href": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html#mapping-the-geospatial-datasets.",
    "title": "Spatial Point Patterns Analysis",
    "section": "4.2 Mapping the geospatial datasets.",
    "text": "4.2 Mapping the geospatial datasets.\n\nDIY PLOT MapDIY View Interactivity\n\n\nUsing the mapping methods you learned in Hands-on Exercise 3, prepare a static map\n\n# Suppress the tmap mode message\nsuppressMessages({\n  tmap_mode(\"plot\")  # Use \"view\" for an interactive map or \"plot\" for a static map\n})\n\n# Create the map\ntm &lt;- tm_shape(mpsz_sf) + \n  tm_polygons(col = \"grey\", border.col = \"black\", alpha = 0.5) +  # Base map with subzones\n  tm_shape(childcare_sf) + \n  tm_dots(col = \"black\", size = 0.05) +  # Plot childcare locations as dots\n   tm_layout(\n    main.title = \"Childcare Locations on Singapore Map\",\n    main.title.position = c(\"center\"),  # Center the title at the top\n    outer.margins = c(0.1, 0, 0, 0),  # Adjust outer margins to make space for the title\n    legend.outside = TRUE,  # Keep legend outside the map area\n    legend.outside.position = \"bottom\"  # Position the legend at the bottom\n  )\ntm\n\n\n\n\n\n\n\n\n\n\nwe can also prepare a pin map by using the code chunk below.\n\nsuppressMessages({\n  tmap_mode(\"view\")  # Use \"view\" for an interactive map or \"plot\" for a static map\n})\n\ntm &lt;- tm_shape(mpsz_sf) + \n  tm_polygons(col = \"grey\", border.col = \"black\", alpha = 0.5) +  # Base map with subzones\n  tm_shape(childcare_sf) + \n  tm_dots(col = \"black\", size = 0.05) +  # Plot childcare locations as dots\n   tm_layout(\n    title = \"Childcare Locations on Singapore Map\",\n    title.position = c(\"center\"),  # Center the title at the top\n    outer.margins = c(0.1, 0, 0, 0),  # Adjust outer margins to make space for the title\n    legend.outside = TRUE,  # Keep legend outside the map area\n    legend.outside.position = \"bottom\"  # Position the legend at the bottom\n  )\n\ntm"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "",
    "text": "The study of armed conflicts in Myanmar has gained critical importance in understanding the geographical distribution and intensity of violence across different regions. Myanmar’s complex ethnic composition and ongoing civil strife make it a unique case for geospatial analysis. This project aims to apply spatial and spatio-temporal point pattern analysis methods to uncover the patterns of armed conflict between January 2021 and June 2024.\nBy leveraging conflict data from the Armed Conflict Location & Event Data (ACLED) and geospatial tools, we will focus on visualizing and interpreting conflict density through heat maps, Kernel Density Estimation (KDE), and advanced spatio-temporal analysis.\n\nOur analysis will focus on four types of conflict events:\n\nBattles,\nExplosion/Remote violence,\nStrategic developments,\nViolence against civilians,\n\nwith particular attention paid to quarterly patterns in conflict occurrence."
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html",
    "href": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html",
    "title": "In Class Exercise 4: Spatio-Temporal Point Patterns Analysis",
    "section": "",
    "text": "A spatio-temporal point process (also called space-time or spatial-temporal point process) is a random collection of points, where each point represents the time and location of an event. Examples of events include incidence of disease, sightings or births of a species, or the occurrences of fires, earthquakes, lightning strikes, tsunamis, or volcanic eruptions.\nThe analysis of spatio-temporal point patterns is becoming increasingly necessary, given the rapid emergence of geographically and temporally indexed data in a wide range of fields. Several spatio-temporal point patterns analysis methods have been introduced and implemented in R in the last ten years. This chapter shows how various R packages can be combined to run a set of spatio-temporal point pattern analyses in a guided and intuitive way. A real world forest fire events in Kepulauan Bangka Belitung, Indonesia from 1st January 2023 to 31st December 2023 is used to illustrate the methods, procedures and interpretations.\n\n\nThe specific question we would like to answer is:\n\nare the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nif the answer is NO, where and when the observed forest fire locations tend to cluster?"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#research-questions",
    "href": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#research-questions",
    "title": "In Class Exercise 4: Spatio-Temporal Point Patterns Analysis",
    "section": "",
    "text": "The specific question we would like to answer is:\n\nare the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nif the answer is NO, where and when the observed forest fire locations tend to cluster?"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#extracting-forest-fire-by-months",
    "href": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#extracting-forest-fire-by-months",
    "title": "In Class Exercise 4: Spatio-Temporal Point Patterns Analysis",
    "section": "5.1 Extracting forest fire by months",
    "text": "5.1 Extracting forest fire by months\n\nfire_month &lt;- forestFire_sf %&gt;%\n  dplyr::select(Month_num)"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#creating-the-ppp",
    "href": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#creating-the-ppp",
    "title": "In Class Exercise 4: Spatio-Temporal Point Patterns Analysis",
    "section": "5.2 Creating the PPP",
    "text": "5.2 Creating the PPP\n\nfire_month_ppp &lt;- as.ppp(fire_month)\nfire_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#including-owin-object",
    "href": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#including-owin-object",
    "title": "In Class Exercise 4: Spatio-Temporal Point Patterns Analysis",
    "section": "5.3 Including Owin Object",
    "text": "5.3 Including Owin Object\n\nfire_month_owin &lt;- fire_month_ppp[kbb_owin]\nhead(fire_month_owin)\n\nMarked planar point pattern: 6 points\nmarks are numeric, of storage type  'double'\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\nglimpse(fire_month_owin)\n\nList of 6\n $ window    :List of 5\n  ..$ type  : chr \"polygonal\"\n  ..$ xrange: num [1:2] 512067 705559\n  ..$ yrange: num [1:2] 9655398 9834006\n  ..$ bdry  :List of 2\n  .. ..$ :List of 2\n  .. ..$ :List of 2\n  ..$ units :List of 3\n  .. ..$ singular  : chr \"unit\"\n  .. ..$ plural    : chr \"units\"\n  .. ..$ multiplier: num 1\n  .. ..- attr(*, \"class\")= chr \"unitname\"\n  ..- attr(*, \"class\")= chr \"owin\"\n $ n         : int 741\n $ x         : num [1:741] 606179 661411 637809 654882 669934 ...\n $ y         : num [1:741] 9703062 9683536 9682757 9690665 9697468 ...\n $ markformat: chr \"vector\"\n $ marks     : num [1:741] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"ppp\"\n\nskim(fire_month_owin)\n\n\nData summary\n\n\nName\nfire_month_owin\n\n\nNumber of rows\n741\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nx\n0\n1\n620811.99\n39443.39\n521564.1\n595009.7\n624170.1\n653519.9\n695791\n▂▅▇▇▅\n\n\ny\n0\n1\n9733857.60\n44333.24\n9658137.5\n9696276.9\n9722669.8\n9774209.8\n9828767\n▆▇▃▆▃\n\n\nmarks\n0\n1\n8.58\n2.04\n1.0\n8.0\n9.0\n10.0\n12\n▁▁▃▇▇"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#computing-spatio-temporal-kde",
    "href": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#computing-spatio-temporal-kde",
    "title": "In Class Exercise 4: Spatio-Temporal Point Patterns Analysis",
    "section": "5.4 Computing Spatio-temporal KDE",
    "text": "5.4 Computing Spatio-temporal KDE\nSpattemp.density() of sparr package is used to compute the STYKDE.\n\nst_kde &lt;- spattemp.density(fire_month_owin)\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#plotting-the-spatio-temporal-kde-object",
    "href": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#plotting-the-spatio-temporal-kde-object",
    "title": "In Class Exercise 4: Spatio-Temporal Point Patterns Analysis",
    "section": "5.5 Plotting the spatio-temporal KDE Object",
    "text": "5.5 Plotting the spatio-temporal KDE Object\nplot for the KDE between july 2023 = december 2023.\n\ntims &lt;- c(7,8,9,10,11,12)\n par(mfcol = c(2,3))\n for(i in tims) {\n   plot(st_kde, i,\n        override.par=FALSE,\n        fix.range = TRUE,\n        main = paste(\"KDE at month\", i)\n        )\n }"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_4/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "href": "In_Class_Exercises/In_Class_Exercise_4/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "title": "IS415-GAA: JialeSo",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_4/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "href": "Hands_On_Exercises/Hands_On_Exercise_4/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "title": "IS415-GAA: JialeSo",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html",
    "href": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html",
    "title": "Spatial Weights and Applications",
    "section": "",
    "text": "How to compute spatial weights using R. By the end to this hands-on exercise, you will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html#computing-queen-contiguity-based-neighbours",
    "href": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html#computing-queen-contiguity-based-neighbours",
    "title": "Spatial Weights and Applications",
    "section": "4.1 Computing (QUEEN) contiguity based neighbours",
    "text": "4.1 Computing (QUEEN) contiguity based neighbours\n\nComputing Queen Contiguity Weight Matrix\n\n\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE):\n\npoly2nb creates a neighborhood list based on polygon boundaries.\nhunan is the spatial polygon data (likely a SpatialPolygonsDataFrame or sf object).\nqueen=TRUE specifies that the Queen contiguity rule should be used. This means that two polygons are considered neighbors if they share at least one point (either a boundary or a corner).\nwm_q stores the neighborhood structure as an object.\n\nsummary(wm_q):\n\nThis provides a summary of the neighborhood list, showing how many neighbors each polygon has and other summary statistics.\n\n\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours.\n\n\n\n\nNeighboursGet Their NamesNeighbour NamesRetrieve the GDPPC of Neighbour countries With NamesList Each Country’s Neighbour\n\n\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, we use the following code chunk, to which we see they have 5 neighbours\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\n\n\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\n\n\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\n\n# Retrieve the GDPPC values for the neighbors and the first polygon\ngdp_values &lt;- c(hunan$GDPPC[1], hunan$GDPPC[nb1])\n\n# Retrieve the county names for the first polygon and its neighbors\ncounty_names &lt;- c(hunan$NAME_3[1], hunan$NAME_3[nb1])\n\n# Assign the county names as names of the GDPPC values\nnames(gdp_values) &lt;- county_names\n\n# Display the GDPPC values with county names\ngdp_values\n\nAnxiang Hanshou  Jinshi      Li     Nan Taoyuan \n  23667   20981   34592   24473   21311   22879 \n\n\n\n\n\n# Initialize a list to store the data for all polygons\ngdp_data &lt;- lapply(seq_along(wm_q), function(i) {\n  # Get the neighbors of polygon i\n  neighbors &lt;- wm_q[[i]]\n  \n  # Get the GDPPC values for the polygon and its neighbors\n  gdp_values &lt;- c(hunan$GDPPC[i], hunan$GDPPC[neighbors])\n  \n  # Get the county names for the polygon and its neighbors\n  county_names &lt;- c(hunan$NAME_3[i], hunan$NAME_3[neighbors])\n  \n  # Create a tibble for each polygon with neighbors\n  data &lt;- tibble(\n    Polygon = county_names[1],  # Main polygon name\n    Neighbor = county_names[-1],  # Neighbor names\n    GDPPC = gdp_values[-1],  # Neighbor GDPPC values\n    Neighbour_GDPPC = gdp_values[1]  # Main polygon GDPPC\n  )\n  \n  return(data)\n})\n\n# Combine all rows into a single data frame\ngdp_df &lt;- bind_rows(gdp_data)\n\n# View the combined data in a cleaner format\ngdp_df\n\n# A tibble: 448 × 4\n   Polygon Neighbor  GDPPC Neighbour_GDPPC\n   &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;           &lt;dbl&gt;\n 1 Anxiang Hanshou   20981           23667\n 2 Anxiang Jinshi    34592           23667\n 3 Anxiang Li        24473           23667\n 4 Anxiang Nan       21311           23667\n 5 Anxiang Taoyuan   22879           23667\n 6 Hanshou Anxiang   23667           20981\n 7 Hanshou Nan       21311           20981\n 8 Hanshou Yuanjiang 26258           20981\n 9 Hanshou Taojiang  19509           20981\n10 Hanshou Taoyuan   22879           20981\n# ℹ 438 more rows"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html#creating-rook-contiguity-based-neighbours",
    "href": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html#creating-rook-contiguity-based-neighbours",
    "title": "Spatial Weights and Applications",
    "section": "4.2 Creating (ROOK) contiguity based neighbours",
    "text": "4.2 Creating (ROOK) contiguity based neighbours\n\nComputing Root Contiguity Weight Matrix\n\n\nInstead of queen true, we use False here\n\nwm_r  &lt;- poly2nb(hunan, queen= FALSE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan using the rook. The most connected area unit has 10 neighbours. There are two area units with only one heighbours.\n\n\n\n\nNeighboursGet Their NamesNeighbour NamesRetrieve the GDPPC of Neighbour countries With NamesList Each Country’s Neighbour\n\n\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, we use the following code chunk, to which we see they have 4 neighbours\n\nwm_r[[1]]\n\n[1]  3  4 57 85\n\n\n\n\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\n\n\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(3,4,57,85)]\n\n[1] \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_r[[1]]\n\n# Retrieve the GDPPC values for the neighbors and the first polygon\ngdp_values &lt;- c(hunan$GDPPC[1], hunan$GDPPC[nb1])\n\n# Retrieve the county names for the first polygon and its neighbors\ncounty_names &lt;- c(hunan$NAME_3[1], hunan$NAME_3[nb1])\n\n# Assign the county names as names of the GDPPC values\nnames(gdp_values) &lt;- county_names\n\n# Display the GDPPC values with county names\ngdp_values\n\nAnxiang  Jinshi      Li     Nan Taoyuan \n  23667   34592   24473   21311   22879 \n\n\n\n\n\n# Initialize a list to store the data for all polygons\ngdp_data &lt;- lapply(seq_along(wm_q), function(i) {\n  # Get the neighbors of polygon i\n  neighbors &lt;- wm_r[[i]]\n  \n  # Get the GDPPC values for the polygon and its neighbors\n  gdp_values &lt;- c(hunan$GDPPC[i], hunan$GDPPC[neighbors])\n  \n  # Get the county names for the polygon and its neighbors\n  county_names &lt;- c(hunan$NAME_3[i], hunan$NAME_3[neighbors])\n  \n  # Create a tibble for each polygon with neighbors\n  data &lt;- tibble(\n    Polygon = county_names[1],  # Main polygon name\n    Neighbor = county_names[-1],  # Neighbor names\n    GDPPC = gdp_values[-1],  # Neighbor GDPPC values\n    Neighbour_GDPPC = gdp_values[1]  # Main polygon GDPPC\n  )\n  \n  return(data)\n})\n\n# Combine all rows into a single data frame\ngdp_df &lt;- bind_rows(gdp_data)\n\n# View the combined data in a cleaner format\ngdp_df\n\n# A tibble: 440 × 4\n   Polygon Neighbor  GDPPC Neighbour_GDPPC\n   &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;           &lt;dbl&gt;\n 1 Anxiang Jinshi    34592           23667\n 2 Anxiang Li        24473           23667\n 3 Anxiang Nan       21311           23667\n 4 Anxiang Taoyuan   22879           23667\n 5 Hanshou Nan       21311           20981\n 6 Hanshou Yuanjiang 26258           20981\n 7 Hanshou Taojiang  19509           20981\n 8 Hanshou Taoyuan   22879           20981\n 9 Jinshi  Anxiang   23667           34592\n10 Jinshi  Li        24473           34592\n# ℹ 430 more rows"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html#visualizing-contiguity-weights",
    "href": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html#visualizing-contiguity-weights",
    "title": "Spatial Weights and Applications",
    "section": "4.3 Visualizing Contiguity Weights",
    "text": "4.3 Visualizing Contiguity Weights\nTo create a connectivity graph for polygons, we first need to obtain points for each polygon, which can be done using their centroids. The centroids will serve as the points for the graph.\nThe process involves calculating the centroids using the sf package. Instead of directly using st_centroid on the spatial data object, we need to extract the centroid coordinates into a separate data frame. This is done by applying the st_centroid function to the geometry column of the spatial data using a mapping function (map_dbl from the purrr package).\nBy mapping st_centroid over the geometry column, we can extract the longitude (the first value in each centroid) using double bracket notation [[1]]. This prepares the longitude values for further use in creating the connectivity graph.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]]) #This allows us to get only the longitude, which is the first value in each centroid.\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]]) #We do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\ncoords &lt;- cbind(longitude, latitude) # Now that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\nhead(coords) #We check the first few observations to see if things are formatted correctly.\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n4.3.1 Plotting Contiguity based Neighbours Map\n\nQueen’sKing’sSide By Side Comparison\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html#determine-cut-off-distance",
    "href": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html#determine-cut-off-distance",
    "title": "Spatial Weights and Applications",
    "section": "5.1 Determine Cut-Off Distance",
    "text": "5.1 Determine Cut-Off Distance\n\n# Extract the coordinates of the regions\n#coords &lt;- coordinates(hunan)\n\n# Find the k-nearest neighbors\nk1 &lt;- knn2nb(knearneigh(coords))\n# Calculate the distances between the neighbors\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\n# Display a summary of the distances\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html#computing-fixed-and-adaptive-distance-weight-matrix",
    "href": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html#computing-fixed-and-adaptive-distance-weight-matrix",
    "title": "Spatial Weights and Applications",
    "section": "5.2 Computing Fixed and Adaptive Distance Weight Matrix",
    "text": "5.2 Computing Fixed and Adaptive Distance Weight Matrix\n\n\n\n\n\n\nNote\n\n\n\nWhen to use fixed or adaptive?\n\nFixed Distance Weighting: Use when spatial points are distributed evenly and when you want a constant radius of influence for all regions.\nAdaptive Distance Weighting: Use when spatial points are unevenly distributed and when you want each region to have a comparable number of neighbors, regardless of their physical distance.\n\n\n\n\nFixed DistanceAdaptive Distance\n\n\nCompute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\n\n\n\n\n\nNote\n\n\n\nQuiz: What is the meaning of “Average number of links: 3.681818” shown above?\n“Average number of links: 3.681818” refers to the average number of neighboring regions each region in the dataset has, based on the distance threshold defined earlier 62km.\n“Average number of links: 3.681818” means that, on average, each region has around 3.68 neighbors within a 62-kilometer radius.\n\n\nVisualizing the weight matrix\n\nneighbor_counts &lt;- data.frame(\n  County = hunan$County,\n  Neighbors = card(wm_d62)  # card() gives the number of neighbors for each region\n)\n\n# View the data frame\nprint(neighbor_counts)\n\n          County Neighbors\n1        Anxiang         5\n2        Hanshou         4\n3         Jinshi         4\n4             Li         3\n5          Linli         4\n6         Shimen         1\n7        Liuyang         2\n8      Ningxiang         4\n9      Wangcheng         4\n10         Anren         4\n11       Guidong         3\n12         Jiahe         5\n13         Linwu         4\n14       Rucheng         2\n15       Yizhang         1\n16      Yongxing         4\n17        Zixing         3\n18     Changning         3\n19      Hengdong         5\n20       Hengnan         5\n21      Hengshan         6\n22       Leiyang         4\n23        Qidong         3\n24        Chenxi         4\n25     Zhongfang         4\n26       Huitong         4\n27      Jingzhou         2\n28        Mayang         6\n29       Tongdao         2\n30      Xinhuang         1\n31          Xupu         2\n32      Yuanling         1\n33      Zhijiang         5\n34 Lengshuijiang         3\n35    Shuangfeng         6\n36        Xinhua         5\n37       Chengbu         2\n38        Dongan         3\n39       Dongkou         4\n40       Longhui         3\n41      Shaodong         5\n42       Suining         5\n43        Wugang         3\n44       Xinning         2\n45       Xinshao         6\n46      Shaoshan         5\n47    Xiangxiang         5\n48       Baojing         5\n49     Fenghuang         4\n50       Guzhang         6\n51       Huayuan         4\n52        Jishou         6\n53      Longshan         2\n54          Luxi         5\n55      Yongshun         4\n56         Anhua         1\n57           Nan         5\n58     Yuanjiang         5\n59      Jianghua         3\n60       Lanshan         4\n61      Ningyuan         5\n62     Shuangpai         4\n63       Xintian         5\n64       Huarong         4\n65      Linxiang         1\n66         Miluo         5\n67     Pingjiang         2\n68      Xiangyin         4\n69          Cili         2\n70       Chaling         3\n71        Liling         2\n72       Yanling         3\n73           You         4\n74       Zhuzhou         5\n75       Sangzhi         2\n76       Yueyang         3\n77        Qiyang         3\n78      Taojiang         2\n79      Shaoyang         4\n80      Lianyuan         5\n81     Hongjiang         5\n82      Hengyang         6\n83       Guiyang         4\n84      Changsha         4\n85       Taoyuan         2\n86      Xiangtan         4\n87           Dao         4\n88     Jiangyong         2\n\n# Or use View() in RStudio for an interactive table view\n\nPlotting It\n\nFirst Plot: The base map of the regions (Hunan) is drawn using their geographic boundaries.\nSecond Plot: The distance-based neighbor links are added, connecting regions that are within 62 km of each other.\nThird Plot: The k-nearest neighbor links are added as red arrows, showing the regions’ closest neighbors.\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\nComparing it against 1st nearest and distance link.\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, we can display the content of the matrix by using str().\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\nPlotting it and against 1st nearest and distance link\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(knn6, coords, add=TRUE, pch = 19, cex = 0.6)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html#spatial-lag-with-row-standardized-weights",
    "href": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html#spatial-lag-with-row-standardized-weights",
    "title": "Spatial Weights and Applications",
    "section": "8.1 spatial lag with row-standardized weights",
    "text": "8.1 spatial lag with row-standardized weights\ncompute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\nlag.listw(rswm_q, hunan$GDPPC):\n\nThis calculates the spatial lag of GDP per capita (GDPPC) for each region using the row-standardized weights (rswm_q).\nFor each region, the function computes the weighted average of the GDPPC values of its neighboring regions.\nSince we are using row-standardized weights, the influence of each neighboring region is scaled based on the number of neighbors. If a region has 4 neighbors, each neighbor’s influence will be 1441​.\n\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nIn the earlier section, we retrieved the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: Can you see the meaning of Spatial lag with row-standardized weights now?\nThe spatial lag with row-standardized weights helps quantify the average impact of neighboring regions on a specific variable (e.g., GDP per capita). It shows how a region’s characteristics, such as economic performance, are influenced by its neighbors, with the weights for each region’s neighbors summing to 1 for consistency across regions.\n\nSpatial Lag: Represents the weighted average of a region’s neighbors’ values, with equal weight assigned to each neighbor in the row-standardized approach.\nRow-Standardized Weights: Since the sum of the weights for each region’s neighbors equals 1, the spatial lag becomes the arithmetic mean of its neighbors’ values. More neighbors dilute the influence of any single one.\nPractical Use: Spatial lag reflects how the GDP of neighboring regions affects a region’s own GDP. If there is a mismatch between a region’s GDP and that of its neighbors, this will be evident in the spatial lag, making it a valuable tool in spatial econometrics for understanding regional dynamics.\n\n\n\nAppend the spatially lag GDPPC Values\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\nhead(hunan)\n\nSimple feature collection with 6 features and 36 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3 Shape_Leng Shape_Area  County    City\n1 Changde 21098 Anxiang      County   1.869074 0.10056190 Anxiang Changde\n2 Changde 21100 Hanshou      County   2.360691 0.19978745 Hanshou Changde\n3 Changde 21101  Jinshi County City   1.425620 0.05302413  Jinshi Changde\n4 Changde 21102      Li      County   3.474325 0.18908121      Li Changde\n5 Changde 21103   Linli      County   2.289506 0.11450357   Linli Changde\n6 Changde 21104  Shimen      County   4.171918 0.37194707  Shimen Changde\n  avg_wage deposite     FAI Gov_Rev Gov_Exp     GDP GDPPC     GIO   Loan  NIPCR\n1    31935   5517.2  3541.0  243.64  1779.5 12482.0 23667  5108.9 2806.9 7693.7\n2    32265   7979.0  8665.0  386.13  2062.4 15788.0 20981 13491.0 4550.0 8269.9\n3    28692   4581.7  4777.0  373.31  1148.4  8706.9 34592 10935.0 2242.0 8169.9\n4    32541  13487.0 16066.0  709.61  2459.5 20322.0 24473 18402.0 6748.0 8377.0\n5    32667    564.1  7781.2  336.86  1538.7 10355.0 25554  8214.0  358.0 8143.1\n6    33261   8334.4 10531.0  548.33  2178.8 16293.0 27137 17795.0 6026.5 6156.0\n   Bed    Emp  EmpR EmpRT Pri_Stu Sec_Stu Household Household_R NOIP Pop_R\n1 1931 336.39 270.5 205.9  19.584  17.819     148.1       135.4   53 346.0\n2 2560 456.78 388.8 246.7  42.097  33.029     240.2       208.7   95 553.2\n3  848 122.78  82.1  61.7   8.723   7.592      81.9        43.7   77  92.4\n4 2038 513.44 426.8 227.1  38.975  33.938     268.5       256.0   96 539.7\n5 1440 307.36 272.2 100.8  23.286  18.943     129.1       157.2   99 246.6\n6 2502 392.05 329.6 193.8  29.245  26.104     190.6       184.7  122 399.2\n    RSCG Pop_T    Agri Service Disp_Inc      RORP    ROREmp lag GDPPC\n1 3957.9 528.3 4524.41   14100    16610 0.6549309 0.8041262  24847.20\n2 4460.5 804.6 6545.35   17727    18925 0.6875466 0.8511756  22724.80\n3 3683.0 251.8 2562.46    7525    19498 0.3669579 0.6686757  24143.25\n4 7110.2 832.5 7562.34   53160    18985 0.6482883 0.8312558  27737.50\n5 3604.9 409.3 3583.91    7031    18604 0.6024921 0.8856065  27270.25\n6 6490.7 600.5 5266.51    6981    19275 0.6647794 0.8407091  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nPlot both GDPPC and spatial Lag GDPPC for comparison.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html#spatial-lag-as-a-sum-of-neighbouring-values",
    "href": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html#spatial-lag-as-a-sum-of-neighbouring-values",
    "title": "Spatial Weights and Applications",
    "section": "8.2 spatial lag as a sum of neighbouring values",
    "text": "8.2 spatial lag as a sum of neighbouring values\nCalculating the spatial lag by summing the GDP per capita (GDPPC) values of neighboring regions. Unlike row-standardized weights, where each neighbor’s value is averaged, here each neighbor’s GDPPC is simply added up without adjusting for the number of neighbors (since style = \"B\" is used, indicating binary weights). This approach gives an unweighted sum of neighboring values.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\n\nb_weights: A binary weight matrix where each neighbor is assigned a weight of 1. The function 0*x + 1 ensures that for each neighbor, the weight is 1, no matter the distance or number of neighbors.\nb_weights2: Converts the neighbor list wm_q to a binary weight matrix, meaning all neighboring polygons are equally weighted with no standardization.\n\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\n\nlag.listw(b_weights2, hunan$GDPPC): This function calculates the spatial lag as the sum of GDPPC values of neighboring regions based on the binary weights. It returns a vector of summed GDPPC values for each region.\nlag_sum: Combines the region names (hunan$NAME_3) with the spatial lag values (summed GDPPC) into a list.\nlag.res: Converts this list into a data frame and assigns appropriate column names (“NAME_3” and “lag_sum GDPPC”).\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: Can you understand the meaning of Spatial lag as a sum of neighboring values now?\nThis method of calculating spatial lag highlights the cumulative economic influence of neighboring regions. Regions with more neighbors will tend to have larger summed values, whereas regions with fewer neighbors may have lower sums, which can be important when considering spatial spillover effects.\n\nSpatial Lag as a Sum: In this approach, the spatial lag is the sum of the GDPPC values of a region’s neighbors. Unlike row-standardized weights where values are averaged, here each neighbor’s GDPPC is simply added up, emphasizing the total contribution from neighboring regions.\nExample: If a region has three neighbors with GDPPC values of 20000, 25000, and 30000, the spatial lag would be the sum of these values: 20000+25000+30000=7500020000 + 25000 + 30000 = 7500020000+25000+30000=75000.\n\n\n\n\nhunan &lt;- left_join(hunan, lag.res)\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html#spatial-window-average",
    "href": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html#spatial-window-average",
    "title": "Spatial Weights and Applications",
    "section": "8.3 spatial window average",
    "text": "8.3 spatial window average\nmodifying the neighbor structure to include each polygon itself as its own neighbor (i.e., adding a diagonal element), followed by computing the spatial lag of the GDPPC (Gross Domestic Product Per Capita) for each region, and finally visualizing and comparing the results.\n\n8.3.1. Include Self in Neighbor List:\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\n\ninclude.self(wm_q): This function adds the diagonal element to the neighbor list, meaning that each region is now considered its own neighbor, in addition to its original neighbors.\n\nFor example, if region 1 originally had neighbors 2 and 3, after using include.self(), region 1 will now also be its own neighbor.\n\nwm_qs[[1]]: Displays the neighbors of region 1, which now includes itself.\n\n\n\n8.3.2. Convert to Weights List:\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\n\nnb2listw(wm_qs): Converts the updated neighbor list (with diagonal elements) into a weights list. This weights list will now include self-influence (i.e., each region is also its own neighbor with a certain weight).\nWeights List: The resulting object stores the spatial weights for each region based on its new neighbor structure (including itself).\n\n\n\n8.3.3 Calculate Spatial Lag (with Self):\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nlag.listw(wm_qs, hunan$GDPPC): Computes the spatial lag of the GDPPC values using the updated weights list (wm_qs). The spatial lag now includes the influence of the region itself, in addition to its neighbors.\n\nThis means that when calculating the spatial lag for a region, its own GDPPC value is considered in the weighted average along with its neighbors’ values.\n\n\n\n8.3.4. Store Results and Modify Data:\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\nhunan %&gt;%\n  select(\"County\", \"lag GDPPC\", \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\n\nStore Lag Results: A new list, lag.list.wm_qs, is created to store the names of the regions (hunan$NAME_3) and their corresponding spatial lag values.\nConvert to Data Frame: The list is converted into a data frame (lag_wm_qs.res), where each row contains a region’s name and its calculated spatial lag (including self).\nColumn Names: The columns are renamed for clarity, with lag_window_avg GDPPC indicating the spatial lag values, including the diagonal elements (self).\n\n\n\n8.3.5 Visualize the Results: and Interpret\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nAdding Self as a Neighbor: The code includes each region as its own neighbor, which means when calculating the spatial lag (the weighted average of neighboring values), the region’s own value is now part of the calculation.\nSpatial Lag Comparison: Two versions of the spatial lag are created:\n\nWithout self: The original spatial lag where only neighboring regions influence the lagged value.\nWith self: The spatial lag that includes the region’s own value in the weighted average."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html#spatial-window-sum",
    "href": "Hands_On_Exercises/Hands_On_Exercise_5/Hands_On_Exercise5.html#spatial-window-sum",
    "title": "Spatial Weights and Applications",
    "section": "8.4 spatial window sum",
    "text": "8.4 spatial window sum\nThe spatial window sum calculates the sum of neighboring values for each region without using row-standardized weights. Unlike row-standardized weights, where each neighbor’s influence is normalized to ensure that the weights sum to 1, the spatial window sum uses binary weights (equal weight for each neighbor) but directly sums the values of the neighboring regions, including the region itself as its own neighbor (with the help of include.self()).\n\n8.4.1 Add Diagonal Element (Include Self as Neighbor):\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\ninclude.self(wm_q): This function modifies the neighbor list (wm_q) so that each region now considers itself as one of its neighbors. This allows the region’s own GDPPC value to be included when calculating the spatial sum\n\n\n8.4.2 Create Binary Weights: & Convert Neighbor to weight matrix\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\nb_weights2 &lt;- nb2listw(wm_qs, glist = b_weights, style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\n\nlapply(wm_qs, function(x) 0*x + 1): This creates binary weights, where each neighbor, including the region itself, is given a weight of 1. This means that when calculating the spatial sum, each neighboring region’s GDPPC is added without adjusting for the number of neighbors.\nExample of b_weights[1]: For the first region, this shows the binary weights assigned to its neighbors, which will all be 1 (since 0*x + 1 results in 1 for each neighbor).\nnb2listw(wm_qs, glist = b_weights, style = \"B\"): Converts the neighbor list with binary weights (b_weights) into a spatial weight matrix.\n\nstyle = \"B\" means the matrix is binary (each neighbor gets an equal weight of 1).\nThis weight matrix is used to calculate the spatial window sum, where each neighboring region’s value is simply summed up.\n\n\n\n\n8.4.3 Calculate Spatial Window Sum for GDPPC:\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\n\nlag.listw(b_weights2, hunan$GDPPC): This calculates the spatial window sum of the GDPPC values using the binary weights matrix (b_weights2). Each region’s GDPPC value and its neighbors’ GDPPC values are summed up directly.\nw_sum_gdppc: Stores the list of region names (hunan$NAME_3) along with the spatial window sum of GDPPC values for each region.\n\n\n\n8.4.4 visualise and interpret the results\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nSpatial Window Sum: This method calculates the sum of neighboring values without normalizing by the number of neighbors (i.e., without row-standardization). Each region’s value is added together with its neighbors’ values, including itself.\nCode Breakdown:\n\nFirst, the diagonal (self) element is added to the neighbor list using include.self().\nBinary weights (1 for each neighbor, including self) are applied to compute the spatial window sum using the lag.listw() function.\nThe spatial window sum is then visualized alongside the row-standardized spatial lag to compare the two approaches.\n\nComparison: The spatial window sum gives a total influence of neighbors, whereas row-standardized weights give an average influence. Both approaches offer different insights into the spatial relationships between regions."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html#research-questions",
    "href": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html#research-questions",
    "title": "Hands On Exercise 4: Spatio-Temporal & Network Constrainted Spatial Point Pattern Analysis",
    "section": "",
    "text": "The specific question we would like to answer is:\n\nare the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nif the answer is NO, where and when the observed forest fire locations tend to cluster?"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html#extracting-forest-fire-by-months",
    "href": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html#extracting-forest-fire-by-months",
    "title": "Hands On Exercise 4: Spatio-Temporal & Network Constrainted Spatial Point Pattern Analysis",
    "section": "5.1 Extracting forest fire by months",
    "text": "5.1 Extracting forest fire by months\n\nfire_month &lt;- forestFire_sf %&gt;%\n  dplyr::select(Month_num)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html#creating-the-ppp",
    "href": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html#creating-the-ppp",
    "title": "Hands On Exercise 4: Spatio-Temporal & Network Constrainted Spatial Point Pattern Analysis",
    "section": "5.2 Creating the PPP",
    "text": "5.2 Creating the PPP\n\nfire_month_ppp &lt;- as.ppp(fire_month)\nfire_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html#including-owin-object",
    "href": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html#including-owin-object",
    "title": "Hands On Exercise 4: Spatio-Temporal & Network Constrainted Spatial Point Pattern Analysis",
    "section": "5.3 Including Owin Object",
    "text": "5.3 Including Owin Object\nThe code chunk below is used to combine origin_am_ppp and am_owin objects into one.\n\nfire_month_owin &lt;- fire_month_ppp[kbb_owin]\nhead(fire_month_owin)\n\nMarked planar point pattern: 6 points\nmarks are numeric, of storage type  'double'\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\nglimpse(fire_month_owin)\n\nList of 6\n $ window    :List of 5\n  ..$ type  : chr \"polygonal\"\n  ..$ xrange: num [1:2] 512067 705559\n  ..$ yrange: num [1:2] 9655398 9834006\n  ..$ bdry  :List of 2\n  .. ..$ :List of 2\n  .. ..$ :List of 2\n  ..$ units :List of 3\n  .. ..$ singular  : chr \"unit\"\n  .. ..$ plural    : chr \"units\"\n  .. ..$ multiplier: num 1\n  .. ..- attr(*, \"class\")= chr \"unitname\"\n  ..- attr(*, \"class\")= chr \"owin\"\n $ n         : int 741\n $ x         : num [1:741] 606179 661411 637809 654882 669934 ...\n $ y         : num [1:741] 9703062 9683536 9682757 9690665 9697468 ...\n $ markformat: chr \"vector\"\n $ marks     : num [1:741] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"ppp\"\n\nskim(fire_month_owin)\n\n\nData summary\n\n\nName\nfire_month_owin\n\n\nNumber of rows\n741\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nx\n0\n1\n620811.99\n39443.39\n521564.1\n595009.7\n624170.1\n653519.9\n695791\n▂▅▇▇▅\n\n\ny\n0\n1\n9733857.60\n44333.24\n9658137.5\n9696276.9\n9722669.8\n9774209.8\n9828767\n▆▇▃▆▃\n\n\nmarks\n0\n1\n8.58\n2.04\n1.0\n8.0\n9.0\n10.0\n12\n▁▁▃▇▇"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html#computing-spatio-temporal-kde",
    "href": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html#computing-spatio-temporal-kde",
    "title": "Hands On Exercise 4: Spatio-Temporal & Network Constrainted Spatial Point Pattern Analysis",
    "section": "5.4 Computing Spatio-temporal KDE",
    "text": "5.4 Computing Spatio-temporal KDE\nSpattemp.density() of sparr package is used to compute the STYKDE.\n\nst_kde &lt;- spattemp.density(fire_month_owin)\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html#plotting-the-stkde-object-by-month",
    "href": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html#plotting-the-stkde-object-by-month",
    "title": "Hands On Exercise 4: Spatio-Temporal & Network Constrainted Spatial Point Pattern Analysis",
    "section": "5.5 Plotting the STKDE Object By Month",
    "text": "5.5 Plotting the STKDE Object By Month\nplot for the KDE between july 2023 = december 2023.\n\ntims &lt;- c(7,8,9,10,11,12)\n par(mfcol = c(2,3))\n for(i in tims) {\n   plot(st_kde, i,\n        override.par=FALSE,\n        fix.range = TRUE,\n        main = paste(\"KDE at month\", i)\n        )\n }"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html#plotting-the-stkde-object-by-day-of-year-improved",
    "href": "Hands_On_Exercises/Hands_On_Exercise_4/Hands_On_Exercise4.html#plotting-the-stkde-object-by-day-of-year-improved",
    "title": "Hands On Exercise 4: Spatio-Temporal & Network Constrainted Spatial Point Pattern Analysis",
    "section": "5.6 Plotting the STKDE Object By Day Of Year & Improved",
    "text": "5.6 Plotting the STKDE Object By Day Of Year & Improved\n\nfire_yday_ppp &lt;- forestFire_sf %&gt;% \n  dplyr::select(DayofYear) %&gt;%\n  as.ppp()\n\nfire_yday_owin &lt;- fire_yday_ppp[kbb_owin]\n\n\nset.seed(1234)\nBOOT.spattemp(fire_yday_owin) \n\nInitialising...Done.\nOptimising...\nh = 15102.47 \b; lambda = 16.84806 \nh = 16612.72 \b; lambda = 16.84806 \nh = 15102.47 \b; lambda = 1527.095 \nh = 15480.03 \b; lambda = 771.9715 \nh = 15668.81 \b; lambda = 394.4098 \nh = 15763.2 \b; lambda = 205.6289 \nh = 15810.4 \b; lambda = 111.2385 \nh = 15833.99 \b; lambda = 64.04328 \nh = 15845.79 \b; lambda = 40.44567 \nh = 15851.69 \b; lambda = 28.64687 \nh = 15863.49 \b; lambda = 5.049258 \nh = 15854.64 \b; lambda = 22.74746 \nh = 15860.54 \b; lambda = 10.94866 \nh = 15859.07 \b; lambda = 13.89836 \nh = 14348.82 \b; lambda = 13.89836 \nh = 13216.87 \b; lambda = 12.42351 \nh = 12460.27 \b; lambda = 15.37321 \nh = 10760.88 \b; lambda = 16.11064 \nh = 8875.282 \b; lambda = 11.68608 \nh = 10432.08 \b; lambda = 12.97658 \nh = 7976.084 \b; lambda = 16.66371 \nh = 9286.281 \b; lambda = 15.60366 \nh = 9615.08 \b; lambda = 18.73771 \nh = 9206.581 \b; lambda = 21.61828 \nh = 8140.483 \b; lambda = 18.23073 \nh = 8795.582 \b; lambda = 17.70071 \nh = 9124.381 \b; lambda = 20.83477 \nh = 9164.856 \b; lambda = 19.52699 \nh = 8345.358 \b; lambda = 18.48998 \nh = 9297.65 \b; lambda = 18.67578 \nh = 8928.375 \b; lambda = 16.8495 \nh = 9105.736 \b; lambda = 18.85762 \nDone.\n\n\n         h     lambda \n9105.73611   18.85762 \n\nkde_yday &lt;- spattemp.density(\n  fire_yday_owin,\n  h = 9000,\n  lambda = 19)\nsummary(kde_yday)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 9000 (spatial)\n  lambda = 19 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [10, 352]\n\nEvaluation\n  128 x 128 x 343 trivariate lattice\n  Density range: [2.001642e-19, 2.445724e-12]\n\n\n\n5.6.1 Making An Animated Time Series Gif Across Days\nFirst Make the data Streamlined into a Dataframe object\n\n# Assuming kde_yday$z.cond contains 343 frames (one for each day)\ndays &lt;- 1:343  # Adjust to match the number of days\n\n# Initialize an empty list to hold the data for each day\nkde_data_list &lt;- lapply(days, function(day) {\n  # Extract the kernel density image for each day from z.cond\n  kde_day &lt;- as.data.frame(kde_yday$z.cond[[day]])  # Convert to a data frame (adjust if necessary)\n  \n  # Rename the columns appropriately (adjust based on the actual structure)\n  colnames(kde_day) &lt;- c(\"x\", \"y\", \"value\")  # Ensure the correct column names for spatial data\n  \n  # Add a DayofYear column for animation\n  kde_day$DayofYear &lt;- day\n  \n  return(kde_day)\n})\n\n# Combine all days' data into a single data frame\nkde_data &lt;- do.call(rbind, kde_data_list)\n\n# Check the structure of the combined data\nstr(kde_data)  # Ensure it contains x, y, value, and DayofYear columns\n\n'data.frame':   1875867 obs. of  4 variables:\n $ x        : num  512823 512823 514334 514334 514334 ...\n $ y        : num  9776098 9777493 9770517 9771912 9773307 ...\n $ value    : num  2.11e-12 2.42e-12 1.19e-12 1.40e-12 1.64e-12 ...\n $ DayofYear: int  1 1 1 1 1 1 1 1 1 1 ...\n\n\nThen get plot data into gif.\n\nlibrary(ggplot2)\nlibrary(gganimate)\n\n# Create an animated plot using ggplot2\np &lt;- ggplot(kde_data, aes(x = x, y = y, fill = value)) +\n  geom_raster() +\n  scale_fill_viridis_c() +  # Use a color scale for density values\n  labs(title = \"Kernel Density Estimation for Day {frame_time}\",\n       x = \"Longitude\", y = \"Latitude\") +\n  coord_equal() +\n  transition_time(DayofYear) +  # Animate by DayofYear (1 to 343)\n  ease_aes('linear')\n\n# Animate the plot and save as a GIF\nanimate(p, nframes = 343, fps = 10, width = 800, height = 600, renderer = gifski_renderer(\"kde_animation_343_days.gif\"))\n\nResults!"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#plotting-the-stkde-object-by-day-of-year-improved",
    "href": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#plotting-the-stkde-object-by-day-of-year-improved",
    "title": "In Class Exercise 4: Spatio-Temporal Point Patterns Analysis",
    "section": "5.6 Plotting the STKDE Object By Day Of Year & Improved",
    "text": "5.6 Plotting the STKDE Object By Day Of Year & Improved\n\nfire_yday_ppp &lt;- forestFire_sf %&gt;% \n  dplyr::select(DayofYear) %&gt;%\n  as.ppp()\n\nfire_yday_owin &lt;- fire_yday_ppp[kbb_owin]\n\n\nset.seed(1234)\nBOOT.spattemp(fire_yday_owin) \n\nInitialising...Done.\nOptimising...\nh = 15102.47 \b; lambda = 16.84806 \nh = 16612.72 \b; lambda = 16.84806 \nh = 15102.47 \b; lambda = 1527.095 \nh = 15480.03 \b; lambda = 771.9715 \nh = 15668.81 \b; lambda = 394.4098 \nh = 15763.2 \b; lambda = 205.6289 \nh = 15810.4 \b; lambda = 111.2385 \nh = 15833.99 \b; lambda = 64.04328 \nh = 15845.79 \b; lambda = 40.44567 \nh = 15851.69 \b; lambda = 28.64687 \nh = 15863.49 \b; lambda = 5.049258 \nh = 15854.64 \b; lambda = 22.74746 \nh = 15860.54 \b; lambda = 10.94866 \nh = 15859.07 \b; lambda = 13.89836 \nh = 14348.82 \b; lambda = 13.89836 \nh = 13216.87 \b; lambda = 12.42351 \nh = 12460.27 \b; lambda = 15.37321 \nh = 10760.88 \b; lambda = 16.11064 \nh = 8875.282 \b; lambda = 11.68608 \nh = 10432.08 \b; lambda = 12.97658 \nh = 7976.084 \b; lambda = 16.66371 \nh = 9286.281 \b; lambda = 15.60366 \nh = 9615.08 \b; lambda = 18.73771 \nh = 9206.581 \b; lambda = 21.61828 \nh = 8140.483 \b; lambda = 18.23073 \nh = 8795.582 \b; lambda = 17.70071 \nh = 9124.381 \b; lambda = 20.83477 \nh = 9164.856 \b; lambda = 19.52699 \nh = 8345.358 \b; lambda = 18.48998 \nh = 9297.65 \b; lambda = 18.67578 \nh = 8928.375 \b; lambda = 16.8495 \nh = 9105.736 \b; lambda = 18.85762 \nDone.\n\n\n         h     lambda \n9105.73611   18.85762 \n\nkde_yday &lt;- spattemp.density(\n  fire_yday_owin,\n  h = 9000,\n  lambda = 19)\nsummary(kde_yday)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 9000 (spatial)\n  lambda = 19 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [10, 352]\n\nEvaluation\n  128 x 128 x 343 trivariate lattice\n  Density range: [2.001642e-19, 2.445724e-12]\n\n\n\n5.6.1 Making An Animated Time Series Gif Across Days\nFirst Make the data Streamlined into a Dataframe object\n\n# Assuming kde_yday$z.cond contains 343 frames (one for each day)\ndays &lt;- 1:343  # Adjust to match the number of days\n\n# Initialize an empty list to hold the data for each day\nkde_data_list &lt;- lapply(days, function(day) {\n  # Extract the kernel density image for each day from z.cond\n  kde_day &lt;- as.data.frame(kde_yday$z.cond[[day]])  # Convert to a data frame (adjust if necessary)\n  \n  # Rename the columns appropriately (adjust based on the actual structure)\n  colnames(kde_day) &lt;- c(\"x\", \"y\", \"value\")  # Ensure the correct column names for spatial data\n  \n  # Add a DayofYear column for animation\n  kde_day$DayofYear &lt;- day\n  \n  return(kde_day)\n})\n\n# Combine all days' data into a single data frame\nkde_data &lt;- do.call(rbind, kde_data_list)\n\n# Check the structure of the combined data\nstr(kde_data)  # Ensure it contains x, y, value, and DayofYear columns\n\n'data.frame':   1875867 obs. of  4 variables:\n $ x        : num  512823 512823 514334 514334 514334 ...\n $ y        : num  9776098 9777493 9770517 9771912 9773307 ...\n $ value    : num  2.11e-12 2.42e-12 1.19e-12 1.40e-12 1.64e-12 ...\n $ DayofYear: int  1 1 1 1 1 1 1 1 1 1 ...\n\n\nThen get plot data into gif.\n\nlibrary(ggplot2)\nlibrary(gganimate)\n\n# Create an animated plot using ggplot2\np &lt;- ggplot(kde_data, aes(x = x, y = y, fill = value)) +\n  geom_raster() +\n  scale_fill_viridis_c() +  # Use a color scale for density values\n  labs(title = \"Kernel Density Estimation for Day {frame_time}\",\n       x = \"Longitude\", y = \"Latitude\") +\n  coord_equal() +\n  transition_time(DayofYear) +  # Animate by DayofYear (1 to 343)\n  ease_aes('linear')\n\n# Animate the plot and save as a GIF\nanimate(p, nframes = 343, fps = 10, width = 800, height = 600, renderer = gifski_renderer(\"kde_animation_343_days.gif\"))\n\nResults!"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#installing-the-required-packages",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#installing-the-required-packages",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "2.1 Installing the required Packages",
    "text": "2.1 Installing the required Packages\nKey Packages Used in the Project:\n\nsf: Handles simple features in R, allowing for spatial data manipulation and analysis. It is crucial for reading and managing geospatial data like shapefiles (e.g., Myanmar’s administrative boundaries).\nraster: Used for raster-based spatial data manipulation, especially for working with raster maps, such as Kernel Density Estimation (KDE) results.\nspatstat: A powerful package for spatial point pattern analysis. It helps to analyze and visualize spatial point data, particularly for identifying clusters or patterns in armed conflict events.\nsparr: Builds on spatstat and focuses on performing spatial and spatio-temporal kernel smoothing, which will be crucial for KDE and heatmap creation.\ntmap: A thematic mapping package that will allow us to create maps, including KDE visualizations on an OpenStreetMap base.\ntidyverse: A collection of data manipulation packages like dplyr, ggplot2, and purrr. It’s essential for data cleaning, manipulation, and visualization tasks.\nstpp: Used for spatio-temporal point pattern analysis, crucial for analyzing how conflict events evolve in both space and time.\nskimr: A quick and comprehensive tool to provide summaries and descriptive statistics for datasets, helping in the initial exploration.\ngganimate: Extends ggplot2 to create animated visualizations. We can use this for animated time-series or evolving conflict maps.\nggplot2: The core plotting package in R, essential for creating visualizations like time series plots and KDE heatmaps.\nplotly: Useful for creating interactive visualizations, allowing users to explore spatial data interactively (e.g., hover over points to see conflict details).\npacman: is a package management tool in R designed to streamline the process of loading and installing packages.\n\n\npacman::p_load(sf, raster, spatstat, sparr, tmap, tidyverse, stpp, skimr, gganimate, ggplot2, plotly, flexdashboard, DT,gridExtra, rlist, grid, animation)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#data-set-involved-in-this-topic",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#data-set-involved-in-this-topic",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "2.2 Data-set involved in this topic",
    "text": "2.2 Data-set involved in this topic\nFor this analysis, we use two key datasets:\n\n2.2.1 ACLED Armed Conflict Data\nLocation & Event Data (ACLED)platform, which maintains an extensive record of conflict events globally. For this specific analysis, we will limit the dataset by filtering based on the following parameters to streamline data preparation and minimize the need for extensive data cleaning:\n\n\n\n\n\n\n\nData Parameter\nFilter Category\n\n\n\n\nDate Range\nFrom 01/01/2021 to 30/06/2024.\n\n\nEvent Type\n1. Battles\n2. Violence Against Civilians\n3. Explosions/Remote Violence\n4. Strategic Developments\n\n\nCountry\nMyanmar\n\n\n\n\n\nACLED Configuration Image\n\n\n\n\n\nCode to Import ACLED Dataset\n\n\nACLEDData &lt;- read_csv(\"data/raw/aspatial/2021-01-01-2024-06-30-Myanmar.csv\")\n\n\n\n2.2.1.1 Understanding the data set fields.\nReferencing this ACLED Official codebook, this is the dataset that we are working with, not to bore you with the details are mainly interested in the following fields,\n\nEvent ID: Unique identifier for each conflict event.\nEvent Date: Date of occurrence.\nEvent Type: Type of conflict event (e.g., Battles, Remote Violence).\nLatitude/Longitude: Coordinates of the event.\nFatalities: Number of fatalities resulting from the event.\nActors: The groups or individuals involved in the conflict (e.g., state actors, ethnic armed groups).\nAdmin Levels: Administrative region, district, and township where the event took place.\n\nIf you’re interested in the data set fields to explore more, here’s the full fields!\n\n\nACLED Full Table Fields Summary\n\n\n\n\nFields name\nFields Description\nValues\n\n\nevent_id_cnty\nA unique alphanumeric event identifier by number and country acronym. This identifier remains constant even when the event details are updated.\nE.g. ETH9766\n\n\nevent_date\nThe date on which the event took place. Recorded as Year-Month-Day.\nE.g. 2023-02-16\n\n\nyear\nThe year in which the event took place.\nE.g. 2018\n\n\ntime_precision\nA numeric code between 1 and 3 indicating the level of precision of the date recorded for the event. The higher the number, the lower the precision.\n1, 2, or 3; with 1 being the most precise.\n\n\ndisorder_type\nThe disorder category an event belongs to.\nPolitical violence, Demonstrations, or Strategic developments.\n\n\nevent_type\nThe type of event; further specifies the nature of the event.\nE.g. BattlesFor the full list of ACLED event types, see the ACLED Event Types table.\n\n\nsub_event_type\nA subcategory of the event type.\nE.g. Armed clashFor the full list of ACLED sub-event types, see the ACLED Event Types table.\n\n\nactor1\nOne of two main actors involved in the event (does not necessarily indicate the aggressor).\nE.g. Rioters (Papua New Guinea)\n\n\nassoc_actor_1\nActor(s) involved in the event alongside ‘Actor 1’ or actor designations that further identify ‘Actor 1’.\nE.g. Labor Group (Spain); Women (Spain)Can have multiple actors separated by a semicolon, or can be blank.\n\n\ninter1\nA numeric code between 0 and 8 indicating the type of ‘Actor 1’ (for more, see the section Actor Names, Types, and ‘Inter’ Codes).\n1, 2, 3, 4, 5, 6, 7, or 8.\n\n\nactor2\nOne of two main actors involved in the event (does not necessarily indicate the target or victim).\nE.g. Civilians (Kenya)Can be blank.\n\n\nassoc_actor_2\nActor(s) involved in the event alongside ‘Actor 2’ or actor designation further identifying ‘Actor 2’.\nE.g. Labor Group (Spain); Women (Spain)Can have multiple actors separated by a semicolon, or can be blank.\n\n\ninter2\nA numeric code between 0 to 8 indicating the type of ‘Actor 2’ (for more, see the section Actor Names, Types, and ‘Inter’ Codes).\n0, 1, 2, 3, 4, 5, 6, 7, or 8.\n\n\ninteraction\nA two-digit numeric code (combination of ‘Inter 1’ and ‘Inter 2’) indicating the two actor types interacting in the event (for more, see the section Actor Names, Types, and ‘Inter’ Codes).\nE.g.3, 58\n\n\ncivilian_targeting\nThis column indicates whether the event involved civilian targeting.\nEither ‘Civilians targeted’ or blank.\n\n\niso\nA unique three-digit numeric code assigned to each country or territory according to ISO 3166.\nE.g. 231 for Ethiopia\n\n\nregion\nThe region of the world where the event took place.\nE.g. Eastern Africa\n\n\ncountry\nThe country or territory in which the event took place.\nE.g. Ethiopia\n\n\nadmin1\nThe largest sub-national administrative region in which the event took place.\nE.g. Oromia\n\n\nadmin2\nThe second largest sub-national administrative region in which the event took place.\nE.g. ArsiCan be blank.\n\n\nadmin3\nThe third largest sub-national administrative region in which the event took place.\nE.g. MertiCan be blank.\n\n\nlocation\nThe name of the location at which the event took place.\nE.g. Abomsa\n\n\nlatitude\nThe latitude of the location in four decimal degrees notation (EPSG:32647).\nE.g. 8.5907\n\n\nlongitude\nThe longitude of the location in four decimal degrees notation (EPSG:32647).\nE.g. 39.8588\n\n\ngeo_precision\nA numeric code between 1 and 3 indicating the level of certainty of the location recorded for the event. The higher the number, the lower the precision.\n1, 2, or 3; with 1 being the most precise.\n\n\nsource\nThe sources used to record the event. Separated by a semicolon.\nE.g. Ansar Allah; Yemen Data Project\n\n\nsource_ scale\nAn indication of the geographic closeness of the used sources to the event (for more, see the section Source Scale).\nE.g. Local partner-National\n\n\nnotes\nA short description of the event.\nE.g. On 16 February 2023, OLF-Shane abducted an unidentified number of civilians after stopping a vehicle in an area near Abomsa (Merti, Arsi, Oromia). The abductees were traveling from Adama to Abomsa, Arsi.\n\n\nfatalities\nThe number of reported fatalities arising from an event. When there are conflicting reports, the most conservative estimate is recorded.\nE.g. 3No information on fatalities is recorded as 0 reported fatalities.\n\n\ntags\nAdditional structured information about the event. Separated by a semicolon.\nE.g. women targeted: politicians; sexual violence\n\n\ntimestamp\nAn automatically generated Unix timestamp that represents the exact date and time an event was uploaded to the ACLED API.\nE.g. 1676909320\n\n\n\n\n\n\n\n2.2.2 Myanmar Administrative Boundaries (Shapefiles):\nObtained through Geonode Mimu, this shapefile helps us to build the map and set the boundary zone of each district of myanmar. This dataset provides the geographical boundaries of Myanmar’s administrative divisions, from the national level down to the township level. It is essential for mapping conflict events to specific regions.\n\n\nCode to Import Shapefile Dataset\n\n\nStateDistrict\n\n\n\nM_State_Sf &lt;- st_read(dsn=\"data/raw/geospatial/stateLevel\", layer = \"mmr_polbnda_adm1_250k_mimu_1\") \n\nReading layer `mmr_polbnda_adm1_250k_mimu_1' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Take_Home_Exercises\\Take_Home_Exercise_1\\data\\raw\\geospatial\\stateLevel' \n  using driver `ESRI Shapefile'\nSimple feature collection with 15 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\nM_State_Sf\n\nSimple feature collection with 15 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   OBJECTID          ST ST_PCODE           ST_RG          ST_MMR PCode_V\n1         1  Ayeyarwady   MMR017          Region  ဧရာဝတီတိုင်းဒေသကြီး     9.4\n2         2        Bago   MMR111          Region    ပဲခူးတိုင်းဒေသကြီး     9.4\n3         4        Chin   MMR004           State       ချင်းပြည်နယ်     9.4\n4         5      Kachin   MMR001           State       ကချင်ပြည်နယ်     9.4\n5         6       Kayah   MMR002           State       ကယားပြည်နယ်     9.4\n6         7       Kayin   MMR003           State        ကရင်ပြည်နယ်     9.4\n7         8      Magway   MMR009          Region   မကွေးတိုင်းဒေသကြီး     9.4\n8         9    Mandalay   MMR010          Region မန္တလေးတိုင်းဒေသကြီး     9.4\n9        10         Mon   MMR011           State         မွန်ပြည်နယ်     9.4\n10       11 Nay Pyi Taw   MMR018 Union Territory        နေပြည်တော်     9.4\n                         geometry\n1  MULTIPOLYGON (((95.20798 15...\n2  MULTIPOLYGON (((96.17964 19...\n3  MULTIPOLYGON (((93.36931 24...\n4  MULTIPOLYGON (((97.59674 28...\n5  MULTIPOLYGON (((97.1759 19....\n6  MULTIPOLYGON (((97.81508 16...\n7  MULTIPOLYGON (((94.11699 22...\n8  MULTIPOLYGON (((96.14023 23...\n9  MULTIPOLYGON (((97.73689 15...\n10 MULTIPOLYGON (((96.32013 20...\n\n\n\n\n\nM_District_Sf &lt;- st_read(dsn=\"data/raw/geospatial\", layer = \"mmr_polbnda_adm2_250k_mimu\") \n\nReading layer `mmr_polbnda_adm2_250k_mimu' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Take_Home_Exercises\\Take_Home_Exercise_1\\data\\raw\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 80 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\nM_District_Sf\n\nSimple feature collection with 80 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   OBJECTID          ST ST_PCODE         DT   DT_PCODE      DT_MMR PCode_V\n1         1  Ayeyarwady   MMR017   Hinthada MMR017D002    ဟင်္သာတခရိုင်     9.4\n2         2  Ayeyarwady   MMR017    Labutta MMR017D004    လပွတ္တာခရိုင်     9.4\n3         3  Ayeyarwady   MMR017     Maubin MMR017D005     မအူပင်ခရိုင်     9.4\n4         4  Ayeyarwady   MMR017  Myaungmya MMR017D003 မြောင်းမြခရိုင်     9.4\n5         5  Ayeyarwady   MMR017    Pathein MMR017D001      ပုသိမ်ခရိုင်     9.4\n6         6  Ayeyarwady   MMR017     Pyapon MMR017D006     ဖျာပုံခရိုင်     9.4\n7         7 Bago (East)   MMR007       Bago MMR007D001      ပဲခူးခရိုင်     9.4\n8         8 Bago (East)   MMR007    Taungoo MMR007D002    တောင်ငူခရိုင်     9.4\n9         9 Bago (West)   MMR008       Pyay MMR008D001      ပြည်ခရိုင်     9.4\n10       10 Bago (West)   MMR008 Thayarwady MMR008D002   သာယာဝတီခရိုင်     9.4\n                         geometry\n1  MULTIPOLYGON (((95.12637 18...\n2  MULTIPOLYGON (((95.04462 15...\n3  MULTIPOLYGON (((95.38231 17...\n4  MULTIPOLYGON (((94.6942 16....\n5  MULTIPOLYGON (((94.27572 15...\n6  MULTIPOLYGON (((95.20798 15...\n7  MULTIPOLYGON (((95.90674 18...\n8  MULTIPOLYGON (((96.17964 19...\n9  MULTIPOLYGON (((95.70458 19...\n10 MULTIPOLYGON (((95.85173 18...\n\n\n\n\n\n\n\n2.2.2.1 Understanding the data set fields.\n\n\n\n\n\n\n\nField Name\nDescription\n\n\nOBJECTID\nThis is a unique identifier for each feature in the dataset, typically used to identify individual records or polygons in the shapefile.\n\n\nST\nThis represents the State or Region in Myanmar. For example, in your dataset, “Ayeyarwady” refers to a state/region.\n\n\nST_PCODE\nThis stands for State Postal Code. It is a standardized code that represents each state or region in Myanmar, such as “MMR017” for Ayeyarwady.\n\n\nDT\nThis stands for District or Township within the respective state/region. For example, “Hinthada” is a district or township within Ayeyarwady.\n\n\nDT_PCODE\nThis stands for District/Township Postal Code. It is a standardized postal code for each district or township, such as “MMR017D002” for the Hinthada district/township in Ayeyarwady.\n\n\nDT_MMR\nThis field could be the District/Township name in Myanmar script, written in the local language. It may be an alternative representation of the “DT” field, showing the name of the district/township in Myanmar’s native language.\n\n\nPCODE_V\nThis could be a Version of the Postal Code or a verification value used internally in the dataset. In this case, the value is “9.4”, possibly indicating a specific version of postal codes or an accuracy measure.\n\n\ngeometry\nThis column represents the spatial data for each district/township. It contains the geometrical shape (MULTIPOLYGON) defining the boundaries of the state or district/township, with coordinates provided in longitude and latitude."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.knit.html",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.knit.html",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "",
    "text": "dxIsk4EIsia10WN3u9Vj\n\n\n#Rural Vs Urban Divide\n#Population?\n#State level\n#Division Level\n#Region?\n#Ethinicity?\n#Government? \n#Type of Acceident\n#Death rate? \n#conflict rate?"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.knit.html#installing-the-required-packages",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.knit.html#installing-the-required-packages",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "2.1 Installing the required Packages",
    "text": "2.1 Installing the required Packages\nKey Packages Used in the Project:\n\nsf: Handles simple features in R, allowing for spatial data manipulation and analysis. It is crucial for reading and managing geospatial data like shapefiles (e.g., Myanmar’s administrative boundaries).\nraster: Used for raster-based spatial data manipulation, especially for working with raster maps, such as Kernel Density Estimation (KDE) results.\nspatstat: A powerful package for spatial point pattern analysis. It helps to analyze and visualize spatial point data, particularly for identifying clusters or patterns in armed conflict events.\nsparr: Builds on spatstat and focuses on performing spatial and spatio-temporal kernel smoothing, which will be crucial for KDE and heatmap creation.\ntmap: A thematic mapping package that will allow us to create maps, including KDE visualizations on an OpenStreetMap base.\ntidyverse: A collection of data manipulation packages like dplyr, ggplot2, and purrr. It’s essential for data cleaning, manipulation, and visualization tasks.\nstpp: Used for spatio-temporal point pattern analysis, crucial for analyzing how conflict events evolve in both space and time.\nskimr: A quick and comprehensive tool to provide summaries and descriptive statistics for datasets, helping in the initial exploration.\ngganimate: Extends ggplot2 to create animated visualizations. We can use this for animated time-series or evolving conflict maps.\nggplot2: The core plotting package in R, essential for creating visualizations like time series plots and KDE heatmaps.\nplotly: Useful for creating interactive visualizations, allowing users to explore spatial data interactively (e.g., hover over points to see conflict details).\npacman: is a package management tool in R designed to streamline the process of loading and installing packages.\n\n\npacman::p_load(sf, raster, spatstat, sparr, tmap, tidyverse, stpp, skimr, gganimate, ggplot2, plotly)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.knit.html#data-set-involved-in-this-topic",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.knit.html#data-set-involved-in-this-topic",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "2.2 Data-set involved in this topic",
    "text": "2.2 Data-set involved in this topic\nFor this analysis, we use two key datasets:\n\n2.2.1 ACLED Armed Conflict Data\nLocation & Event Data (ACLED)platform, which maintains an extensive record of conflict events globally. For this specific analysis, we will limit the dataset by filtering based on the following parameters to streamline data preparation and minimize the need for extensive data cleaning:\n\n\n\n\n\n\n\nData Parameter\nFilter Category\n\n\n\n\nDate Range\nFrom 01/01/2021 to 30/06/2024.\n\n\nEvent Type\n1. Battles\n2. Violence Against Civilians\n3. Explosions/Remote Violence\n4. Strategic Developments\n\n\nCountry\nMyanmar\n\n\n\n\n\nACLED Configuration\n\n\n\n\nConfiguration Shown\n\n\n\n2.2.2 Myanmar Administrative Boundaries (Shapefiles):\nThis dataset provides the geographical boundaries of Myanmar’s administrative divisions, from the national level down to the township level. It is essential for mapping conflict events to specific regions.\n\n\n\n\n\n\nNote\n\n\n\nWhy use District and regions?"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#acled-data",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#acled-data",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "3.2 ACLED Data",
    "text": "3.2 ACLED Data\n\n3.2.1 Changing the Column Names\nSince Myanmar’s regional hierarchy follows State, District, and Township levels, we will rename the columns accordingly:\n\nadmin1 → State\nadmin2 → District\nadmin3 → Township\n\nThis is important because different countries use different administrative hierarchies. For example, in Singapore, the hierarchy is organized by Region and Subzones. Adjusting these names ensures that our dataset aligns with Myanmar’s specific regional structure for accurate analysis.\n\nACLEDData_Cleanse &lt;- ACLEDData %&gt;%\n  select(event_id_cnty, event_date, year, disorder_type, event_type, actor1, inter1, \n         actor2, inter2, interaction, admin1, admin2, admin3, location, latitude, \n         longitude, fatalities) %&gt;%\n  rename(state = admin1, district = admin2, township = admin3) %&gt;%\n  mutate(across(where(is.character), ~ replace_na(.x, \"NA\")),  # Replace NA in character columns with \"NA\"\n         across(where(is.numeric), ~ replace_na(.x, 0)))  # Replace NA in numeric columns with 0\n\n\n\n3.2.2 Adding a “Quarter-Year” Column\nTo facilitate our temporal analysis, we need to add a “quarter-year” column based on the event_date field. This can be done by adjusting the date format to represent the quarter and year, ensuring that each event is categorized by the specific quarter it occurred in (e.g., Q1-2021, Q2-2022). This will allow for easier analysis of conflict trends over time.\n\n# Convert event_date to Date format (if it's not already a date)\nACLEDData_Cleanse$event_date &lt;- as.Date(ACLEDData_Cleanse$event_date, format=\"%d-%b-%y\")  # Adjust the format if needed\n# Add a new column that shows the quarter and year\nACLEDData_Cleanse &lt;- ACLEDData_Cleanse %&gt;%\n  mutate(quarter_year = paste0(\"Q\", quarter(event_date), \"-\", year(event_date)))\n\nhead(ACLEDData_Cleanse)\n\n# A tibble: 6 × 18\n  event_id_cnty event_date  year disorder_type   event_type actor1 inter1 actor2\n  &lt;chr&gt;         &lt;date&gt;     &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;      &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; \n1 MMR64313      2024-06-30  2024 Political viol… Battles    Peopl…      3 Milit…\n2 MMR64320      2024-06-30  2024 Political viol… Battles    Peopl…      3 Milit…\n3 MMR64321      2024-06-30  2024 Political viol… Battles    Peopl…      3 Milit…\n4 MMR64322      2024-06-30  2024 Strategic deve… Strategic… Milit…      1 NA    \n5 MMR64323      2024-06-30  2024 Political viol… Battles    PKDF …      3 Milit…\n6 MMR64324      2024-06-30  2024 Strategic deve… Strategic… Milit…      1 NA    \n# ℹ 10 more variables: inter2 &lt;dbl&gt;, interaction &lt;dbl&gt;, state &lt;chr&gt;,\n#   district &lt;chr&gt;, township &lt;chr&gt;, location &lt;chr&gt;, latitude &lt;dbl&gt;,\n#   longitude &lt;dbl&gt;, fatalities &lt;dbl&gt;, quarter_year &lt;chr&gt;\n\n\n\n\n3.2.3 Joining ACLED’s Codebook Description\nACLED’s stores their data for the column “interaction” and “inter1” and “inter2” in codes, using their code book, let’s reorganise their data for simplier view, we can reference the code book here to know what each code represent. Map it out as a csv file read it in and change accordingly.\n\n3.2.3.1 Left joining inter1 and inter’s description.\nFor more details about each inter code read here.\n\nACLEDActorInterCode &lt;- read_csv(\"data/raw/aspatial/ActorTypesInterCode.csv\")\nACLEDData_Cleanse &lt;- ACLEDData_Cleanse %&gt;%\n  left_join(ACLEDActorInterCode, by = c(\"inter1\" = \"code\")) %&gt;%\n  rename(inter1_description = Description)\n# Left join again for inter2\nACLEDData_Cleanse &lt;- ACLEDData_Cleanse %&gt;%\n  left_join(ACLEDActorInterCode, by = c(\"inter2\" = \"code\")) %&gt;%\n  rename(inter2_description = Description)\n\nhead(ACLEDData_Cleanse)\n\n# A tibble: 6 × 20\n  event_id_cnty event_date  year disorder_type   event_type actor1 inter1 actor2\n  &lt;chr&gt;         &lt;date&gt;     &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;      &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; \n1 MMR64313      2024-06-30  2024 Political viol… Battles    Peopl…      3 Milit…\n2 MMR64320      2024-06-30  2024 Political viol… Battles    Peopl…      3 Milit…\n3 MMR64321      2024-06-30  2024 Political viol… Battles    Peopl…      3 Milit…\n4 MMR64322      2024-06-30  2024 Strategic deve… Strategic… Milit…      1 NA    \n5 MMR64323      2024-06-30  2024 Political viol… Battles    PKDF …      3 Milit…\n6 MMR64324      2024-06-30  2024 Strategic deve… Strategic… Milit…      1 NA    \n# ℹ 12 more variables: inter2 &lt;dbl&gt;, interaction &lt;dbl&gt;, state &lt;chr&gt;,\n#   district &lt;chr&gt;, township &lt;chr&gt;, location &lt;chr&gt;, latitude &lt;dbl&gt;,\n#   longitude &lt;dbl&gt;, fatalities &lt;dbl&gt;, quarter_year &lt;chr&gt;,\n#   inter1_description &lt;chr&gt;, inter2_description &lt;chr&gt;\n\n\n\n\n3.2.3.2 Left joining interaction description.\nFor more details about each interaction code read here.\n\nACLEDInteractionCode &lt;- read_csv(\"data/raw/aspatial/AcledInteractionCodes.csv\")\nACLEDData_Cleanse &lt;- ACLEDData_Cleanse %&gt;%\n  left_join(ACLEDInteractionCode, by = c(\"interaction\" = \"code\")) %&gt;%\n  rename(interaction_description = Description)\nhead(ACLEDData_Cleanse)\n\n# A tibble: 6 × 21\n  event_id_cnty event_date  year disorder_type   event_type actor1 inter1 actor2\n  &lt;chr&gt;         &lt;date&gt;     &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;      &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; \n1 MMR64313      2024-06-30  2024 Political viol… Battles    Peopl…      3 Milit…\n2 MMR64320      2024-06-30  2024 Political viol… Battles    Peopl…      3 Milit…\n3 MMR64321      2024-06-30  2024 Political viol… Battles    Peopl…      3 Milit…\n4 MMR64322      2024-06-30  2024 Strategic deve… Strategic… Milit…      1 NA    \n5 MMR64323      2024-06-30  2024 Political viol… Battles    PKDF …      3 Milit…\n6 MMR64324      2024-06-30  2024 Strategic deve… Strategic… Milit…      1 NA    \n# ℹ 13 more variables: inter2 &lt;dbl&gt;, interaction &lt;dbl&gt;, state &lt;chr&gt;,\n#   district &lt;chr&gt;, township &lt;chr&gt;, location &lt;chr&gt;, latitude &lt;dbl&gt;,\n#   longitude &lt;dbl&gt;, fatalities &lt;dbl&gt;, quarter_year &lt;chr&gt;,\n#   inter1_description &lt;chr&gt;, inter2_description &lt;chr&gt;,\n#   interaction_description &lt;chr&gt;\n\n\n\n\n\n3.2.3 Making it a SF Object and reverse geolocate state and district\nSince ACLED provides longitude and latitude data, I prefer to reverse geolocate the points to match Myanmar’s official state and district boundaries. We are uncertain how ACLED assigns these regions, so to ensure consistency, we remove the original state and district columns from the ACLED data and replace them with the geolocated values.\nSteps:\n\nConvert ACLED Data to an SF Object: Using longitude and latitude coordinates, transform the ACLED dataset into a spatial object. Remember thatt we have to set CRS 32647 here as well.\nPerform a Spatial Join: Match the points from ACLED with the corresponding state and district boundaries from the m_sf shapefile, selecting only those columns.\nRemove Original Columns: After the spatial join, drop the original state, district, and township columns from the ACLED dataset.\nRename the Joined Columns: Rename the newly joined state.y and district.y to state and district, effectively replacing the original columns with the reverse-geolocated values.\n\n\n# Step 1: Convert ACLEDDataCleanse to an sf object using longitude and latitude\nACLEDData_Cleanse_Sf &lt;- st_as_sf(ACLEDData_Cleanse, coords = c(\"longitude\", \"latitude\"), crs = 4326, remove = FALSE)\n\n# Step 2: Transform ACLEDDataCleanse_sf to the same CRS as m_sf (EPSG: 32647)\nACLEDData_Cleanse_Sf &lt;- st_transform(ACLEDData_Cleanse_Sf, crs = 32647)\n\n# Step 3: Perform a spatial join, selecting only the state and district from m_sf\nreverse_geolocated_state &lt;- st_join(ACLEDData_Cleanse_Sf, M_State_Sf_Cleansed[, c(\"state\")], join = st_intersects)\n\n# Step 2: Spatial join to add 'district' from M_District_Sf_Cleansed\nreverse_geolocated_district &lt;- st_join(reverse_geolocated_state, M_District_Sf_Cleansed[, c(\"district\")], join = st_intersects)\n\n# Step 3: Remove original 'state', 'district', and 'township' columns from ACLEDData_Cleanse (if they exist)\n# This step removes the original columns, and then renames the newly joined columns\nACLEDData_Cleanse_Sf &lt;- reverse_geolocated_district %&gt;%\n  select(-contains(\"state.x\"), -contains(\"district.x\"), -contains(\"township\")) %&gt;%  # Remove old state, district, township columns\n  rename(state = state.y, district = district.y)  # Rename newly joined columns\n\nACLEDData_Cleanse &lt;- st_drop_geometry(ACLEDData_Cleanse_Sf)\n\n# View the updated data\nprint(ACLEDData_Cleanse_Sf)\n\nSimple feature collection with 42608 features and 20 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -208804.4 ymin: 1103500 xmax: 640934.5 ymax: 3042960\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 42,608 × 21\n   event_id_cnty event_date  year disorder_type  event_type actor1 inter1 actor2\n   &lt;chr&gt;         &lt;date&gt;     &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; \n 1 MMR64313      2024-06-30  2024 Political vio… Battles    Peopl…      3 Milit…\n 2 MMR64320      2024-06-30  2024 Political vio… Battles    Peopl…      3 Milit…\n 3 MMR64321      2024-06-30  2024 Political vio… Battles    Peopl…      3 Milit…\n 4 MMR64322      2024-06-30  2024 Strategic dev… Strategic… Milit…      1 NA    \n 5 MMR64323      2024-06-30  2024 Political vio… Battles    PKDF …      3 Milit…\n 6 MMR64324      2024-06-30  2024 Strategic dev… Strategic… Milit…      1 NA    \n 7 MMR64325      2024-06-30  2024 Political vio… Battles    Milit…      1 PSLF/…\n 8 MMR64326      2024-06-30  2024 Political vio… Battles    PSLF/…      2 Milit…\n 9 MMR64328      2024-06-30  2024 Political vio… Battles    Milit…      1 PSLF/…\n10 MMR64330      2024-06-30  2024 Political vio… Battles    Milit…      1 PSLF/…\n# ℹ 42,598 more rows\n# ℹ 13 more variables: inter2 &lt;dbl&gt;, interaction &lt;dbl&gt;, location &lt;chr&gt;,\n#   latitude &lt;dbl&gt;, longitude &lt;dbl&gt;, fatalities &lt;dbl&gt;, quarter_year &lt;chr&gt;,\n#   inter1_description &lt;chr&gt;, inter2_description &lt;chr&gt;,\n#   interaction_description &lt;chr&gt;, geometry &lt;POINT [m]&gt;, state &lt;chr&gt;,\n#   district &lt;chr&gt;\n\n\n\n\n3.2.5 Visualizing it by Event Type\n\n# Set tmap mode to plot for static maps\ntmap_mode(\"view\")\n\n# Create the tmap object with the base map and event markers\ntm_basemap(server = \"OpenStreetMap\") +  # Add OpenStreetMap as the base map\n  \n  # Add Myanmar state boundaries with transparency\n  tm_shape(M_State_Sf_Cleansed) + \n  tm_polygons(\"state\", alpha = 0.3, border.col = \"gray\", \n              title = \"State Boundaries\", legend.show = TRUE) +  # Add a legend for state boundaries\n  \n  # Add event markers (bubbles) with size based on fatalities\n  tm_shape(ACLEDData_Cleanse_Sf) + \n  tm_bubbles(size = \"fatalities\",  # Marker size based on fatalities\n             col = \"event_type\",  # Color markers by event type\n             palette = \"Set1\",  # Use Set1 color palette for event types\n             border.col = \"black\",  # Border color for bubbles\n             border.alpha = 0.5,  # Semi-transparent border\n             title.size = \"Number of Fatalities\",  # Title for bubble size legend\n             title.col = \"Event Types\",  # Title for event type legend\n             legend.size.show = TRUE,  # Show legend for bubble size\n             legend.col.show = TRUE) +  # Show legend for event types\n  \n  # Layout settings for the map, including title and legend positioning\n  tm_layout(main.title = \"Myanmar's State Conflicts by Fatalities\",  # Main map title\n            main.title.size = 1.5,  # Title font size\n            legend.outside = TRUE,  # Position legend outside the map\n            legend.outside.size = 0.5,  # Adjust size of outside legend\n            legend.position = c(\"left\", \"top\"),  # Position for the event type legend\n            legend.title.size = 1.2,  # Size of the legend title\n            legend.text.size = 1,  # Size of the legend text\n            legend.bg.color = \"white\",  # Background color for the legend\n            legend.bg.alpha = 0.5,  # Transparency for the legend background\n            inner.margins = c(0.05, 0.05, 0.05, 0.05))  # Inner margins for the map"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#shapefile",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#shapefile",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "3.2 Shapefile",
    "text": "3.2 Shapefile"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#myanmar-shapefile",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#myanmar-shapefile",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "3.1 Myanmar Shapefile",
    "text": "3.1 Myanmar Shapefile\n\n3.1.1 Setting the CRS for the\nSince Myanmar uses CRS of 32647 and when we download the map it’s in WGS84, we should change it to 32647 .\n\nStateDistrict\n\n\n\nst_crs(M_State_Sf)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n# Set the CRS for m_sf, assuming the appropriate CRS is WGS 84 (EPSG:32647)\nM_State_Sf &lt;- st_transform(M_State_Sf, crs = 32647)\n# Verify that the CRS has been correctly set\nprint(st_crs(M_State_Sf))\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\n\n\nst_crs(M_District_Sf)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n# Set the CRS for m_sf, assuming the appropriate CRS is WGS 84 (EPSG:32647)\nM_District_Sf &lt;- st_transform(M_District_Sf, crs = 32647)\n# Verify that the CRS has been correctly set\nprint(st_crs(M_District_Sf))\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\n\n\n\n\n3.1.2 Renaming and removal of column names\n\nStateDistrict\n\n\n\ncolnames(M_State_Sf) &lt;- c(\"OBJECTID\", \"state\",\"state_code\",\"type\", \"state_myr\", \"mimi_version\", \"geometry\")\n\nM_State_Sf_Cleansed &lt;- M_State_Sf %&gt;% select(state, type, state_myr ,geometry)\n\n\n\n\ncolnames(M_District_Sf) &lt;- c(\"OBJECTID\", \"state\", \"state_code\", \"district\", \"district_code\", \"district_mmr\", \"mimi_version\", \"geometry\")\n\nM_District_Sf_Cleansed &lt;- M_District_Sf %&gt;% select(state, district, district_mmr, geometry)\n\n\n\n\n\n\n3.1.3 Checking for validity of data\nWhen working with spatial data, it’s crucial to ensure that all geometries are valid. Invalid geometries can cause errors in analysis and visualization.\n\nChecking Validity with st_is_valid():\nIdentifying Invalid Geometries:\nFixing Invalid Geometries with st_make_valid()\n\n\nStateDistrict\n\n\n\n#checking if it's valid\nM_State_Sf_Validity &lt;- st_is_valid(M_State_Sf_Cleansed)\nM_State_Sf_Invalid &lt;- which(!M_State_Sf_Validity)\nif (length(M_State_Sf_Invalid) &gt; 0) {\n  print(\"MPZ Invalid!\")\n  print(M_State_Sf_cleansed[M_State_Sf_Invalid, ])\n} else {\n  print(\"it's valid!\")\n}\n\n[1] \"it's valid!\"\n\n\n\n\n\n#checking if it's valid\nM_District_Sf_Validity &lt;- st_is_valid(M_District_Sf_Cleansed)\nM_District_Sf_Invalid &lt;- which(!M_District_Sf_Validity)\nif (length(M_District_Sf_Invalid) &gt; 0) {\n  print(\"MPZ Invalid!\")\n  print(M_District_Sf_cleansed[M_District_Sf_Invalid, ])\n} else {\n  print(\"it's valid!\")\n}\n\n[1] \"it's valid!\"\n\n\n\n\n\n\n\n3.1.4 Visualizing the mynamar map\nOn the top right, you can toggle between the district level and also the state level to understand more about the boundaries of Myanmar.\n\nStateDistrict\n\n\n\ntm_shape(M_State_Sf_Cleansed) +  # Base map (Myanmar boundaries)\n  tm_basemap(server = \"OpenStreetMap.HOT\") +  # Add OpenStreetMap as the basemap\n  tm_polygons(\"state\",  # Color the base map by state\n              palette = \"Set3\",  # Use Set3 color palette for states\n              border.col = \"gray\",  # Border color for the states\n              alpha = 0.5,  # Semi-transparent polygons\n              title = \"State\",  # Legend title for states\n              legend.show = TRUE  # Show legend for state colors\n             ) +\n  tm_layout(main.title = \"States of Myanmar\",  # Main map title\n            legend.outside = TRUE)  # Position the legend outside the map\n\n\n\n\n\n\n\n\n\n\nThere is more than 80 district here, so it only showcases 30 :)\n\ntm_shape(M_District_Sf_Cleansed) +  # Base map (Myanmar boundaries)\n  tm_basemap(server = \"OpenStreetMap.HOT\") +  # Add OpenStreetMap as the basemap\n  tm_polygons(\"district\",  # Color the base map by state\n              palette = \"Set3\",  # Use Set3 color palette for states\n              border.col = \"gray\",  # Border color for the states\n              alpha = 0.5,  # Semi-transparent polygons\n              title = \"District\",  # Legend title for states\n              legend.show = TRUE  # Show legend for state colors\n             ) +\n  tm_layout(main.title = \"District of Myanmar\",  # Main map title\n            legend.outside = TRUE)  # Position the legend outside the map"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#joining-the-aspatial-data-and-geospatial-data.",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#joining-the-aspatial-data-and-geospatial-data.",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "3.3 Joining the ASpatial data and GeoSpatial Data.",
    "text": "3.3 Joining the ASpatial data and GeoSpatial Data.\nInstead of left joining base on state, i chose to join base on the long lat of the event for better accuracy as we do not know how does acled prep their data, so using the event’s long lat, we will join base on the intersect\n\n# Step 1: Convert ACLEDData_cleanse to an sf object using latitude and longitude\nACLEDDataCleanse_sf &lt;- st_as_sf(ACLEDDataCleanse, coords = c(\"longitude\", \"latitude\"), crs = 4326, remove = FALSE)\n\n# Step 3: Perform a spatial join to get reverse-geolocated state and district from m_sf\nreverse_geolocated &lt;- st_join(ACLEDDataCleanse_sf, m_sf, join = st_intersects)\n\nreverse_geolocated &lt;- reverse_geolocated %&gt;%\n  rename(reverse_state = state.y, reverse_district = district.y, state = state.x, district = district.x)\n\n# Step 4: Add the reverse-geolocated state and district along with accuracy checks\nACLEDDataCleanse &lt;- reverse_geolocated %&gt;%\n  mutate(\n    state_accuracy = ifelse(state == reverse_state, \"Accurate\", \"Not Accurate\"),       # Check if reverse_state matches existing state\n    district_accuracy = ifelse(district == reverse_district, \"Accurate\", \"Not Accurate\") # Check if reverse_district matches existing district\n  )"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#aggregation-of-data",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#aggregation-of-data",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "3.4 Aggregation of Data",
    "text": "3.4 Aggregation of Data\n\n# Fixing the expand.grid function to use consistent column names\nall_combinations &lt;- expand.grid(\n  district = unique(m_sf$district),                # Unique districts from shapefile\n  event_type = unique(ACLEDDataCleanse$event_type), # Unique event types\n  quarter_year = unique(ACLEDDataCleanse$quarter_year), # Unique quarters\n  interaction_description = unique(ACLEDDataCleanse$interaction_description),  # Unique interactions\n  inter1_description = unique(ACLEDDataCleanse$inter1_description),  # Actor 1 descriptions\n  inter2_description = unique(ACLEDDataCleanse$inter2_description)   # Actor 2 descriptions\n)\n\n# Aggregate the data by quarter_year, district, event_type, interaction_description, inter1_description, inter2_description\nagg_data &lt;- ACLEDDataCleanse %&gt;%\n  group_by(quarter_year, district, event_type, interaction_description, inter1_description, inter2_description) %&gt;%\n  summarise(count = n(),                       # Count the number of events\n            fatalities = sum(fatalities, na.rm = TRUE),  # Sum the fatalities\n            .groups = \"drop\")\n\n# Perform a full join with all_combinations to keep all districts, event types, interactions, etc.\nfull_data &lt;- all_combinations %&gt;%\n  left_join(agg_data, by = c(\"district\", \"event_type\", \"quarter_year\", \"interaction_description\", \"inter1_description\", \"inter2_description\")) %&gt;%\n  mutate(count = ifelse(is.na(count), 0, count),        # Replace NAs in count with 0\n         fatalities = ifelse(is.na(fatalities), 0, fatalities))  # Replace NAs in fatalities with 0"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#summary-of-data-sets",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#summary-of-data-sets",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "5.5 Summary of Data sets",
    "text": "5.5 Summary of Data sets\nWe have created a total of five datasets, each serving a distinct purpose in our spatial analysis:\n\nACLEDData_SF: This is the cleaned and formatted ACLED dataset, stored as an sf (simple feature) object. It contains the key event data, including attributes like location, event type, and time period, and will be used for further spatial analysis.\nM_SF: This dataset represents the Myanmar boundary as an sf object. It will be used as the base layer in the analysis, defining the spatial extent and providing a reference map for the region.\nAggregated Level: This dataset is used for exploratory analysis and contains aggregated data for different event types, quarters, or other relevant categories. It allows for a broader overview before diving into more detailed spatial point pattern analyses.\nACLED_ppp_corrected: This is the point pattern dataset created from the ACLED data. It includes the corrected coordinates (with jittering applied) and is stored as a ppp object (planar point pattern) for use in spatstat. This object will be used for more in-depth spatial analyses, such as density estimation or clustering.\nmyanmar_owin: This is the spatial window object representing the boundary of Myanmar. It defines the geographic limits for our spatial point pattern analysis and ensures that all event data is analyzed within this boundary."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#changing",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#changing",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "3.3 Changing",
    "text": "3.3 Changing\n\nSpatial Join: We only join the state and district from m_sf and ignore other columns from the shapefile.\nRemove Original Columns: After the join, we remove the original state, district, and township columns from the ACLEDDataCleanse dataset using select(-state, -district, -township).\nRename the Joined Columns: We rename the newly joined state.y and district.y to simply state and district, effectively replacing the original columns with the reverse-geolocated ones.\n\n\n# Step 1: Convert ACLEDDataCleanse to an sf object using longitude and latitude\nACLEDDataCleanse_sf &lt;- st_as_sf(ACLEDDataCleanse, coords = c(\"longitude\", \"latitude\"), crs = 4326, remove = FALSE)\n\n# Step 2: Perform a spatial join, selecting only the state and district from m_sf\nreverse_geolocated &lt;- st_join(ACLEDDataCleanse_sf, m_sf[, c(\"state\", \"district\")], join = st_intersects)\n\n# Step 3: Remove original 'state', 'district', and 'township' columns from ACLEDDataCleanse\nACLEDDataCleanse_sf &lt;- reverse_geolocated %&gt;%\n  select(-state, -district, -township) %&gt;%\n  rename(state = state.y, district = district.y)  # Rename the joined columns to be the new state and district\n\n# Step 4: View the cleaned ACLEDDataCleanse dataset\nhead(ACLEDDataCleanse_sf)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#aggregation-of-data-for-explanatory-purposes",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#aggregation-of-data-for-explanatory-purposes",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "3.3 Aggregation of Data For Explanatory Purposes",
    "text": "3.3 Aggregation of Data For Explanatory Purposes\n\n# Fixing the expand.grid function to use consistent column names\nall_combinations &lt;- expand.grid(\n  district = unique(m_sf$district),                # Unique districts from shapefile\n  event_type = unique(ACLEDDataCleanse$event_type), # Unique event types\n  quarter_year = unique(ACLEDDataCleanse$quarter_year), # Unique quarters\n  interaction_description = unique(ACLEDDataCleanse$interaction_description),  # Unique interactions\n  inter1_description = unique(ACLEDDataCleanse$inter1_description),  # Actor 1 descriptions\n  inter2_description = unique(ACLEDDataCleanse$inter2_description)   # Actor 2 descriptions\n)\n\n# Aggregate the data by quarter_year, district, event_type, interaction_description, inter1_description, inter2_description\nagg_data &lt;- ACLEDDataCleanse %&gt;%\n  group_by(quarter_year, district, event_type, interaction_description, inter1_description, inter2_description) %&gt;%\n  summarise(count = n(),                       # Count the number of events\n            fatalities = sum(fatalities, na.rm = TRUE),  # Sum the fatalities\n            .groups = \"drop\")\n\n# Perform a full join with all_combinations to keep all districts, event types, interactions, etc.\nfull_data &lt;- all_combinations %&gt;%\n  left_join(agg_data, by = c(\"district\", \"event_type\", \"quarter_year\", \"interaction_description\", \"inter1_description\", \"inter2_description\")) %&gt;%\n  mutate(count = ifelse(is.na(count), 0, count),        # Replace NAs in count with 0\n         fatalities = ifelse(is.na(fatalities), 0, fatalities))  # Replace NAs in fatalities with 0"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_5/In_Class_Exercise5.html",
    "href": "In_Class_Exercises/In_Class_Exercise_5/In_Class_Exercise5.html",
    "title": "In Class Exercise 5: Spatio-Temporal Point Patterns Analysis",
    "section": "",
    "text": "A spatio-temporal point process (also called space-time or spatial-temporal point process) is a random collection of points, where each point represents the time and location of an event. Examples of events include incidence of disease, sightings or births of a species, or the occurrences of fires, earthquakes, lightning strikes, tsunamis, or volcanic eruptions.\nThe analysis of spatio-temporal point patterns is becoming increasingly necessary, given the rapid emergence of geographically and temporally indexed data in a wide range of fields. Several spatio-temporal point patterns analysis methods have been introduced and implemented in R in the last ten years. This chapter shows how various R packages can be combined to run a set of spatio-temporal point pattern analyses in a guided and intuitive way. A real world forest fire events in Kepulauan Bangka Belitung, Indonesia from 1st January 2023 to 31st December 2023 is used to illustrate the methods, procedures and interpretations.\n\n\nThe specific question we would like to answer is:\n\nare the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nif the answer is NO, where and when the observed forest fire locations tend to cluster?"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_5/In_Class_Exercise5.html#research-questions",
    "href": "In_Class_Exercises/In_Class_Exercise_5/In_Class_Exercise5.html#research-questions",
    "title": "In Class Exercise 5: Spatio-Temporal Point Patterns Analysis",
    "section": "",
    "text": "The specific question we would like to answer is:\n\nare the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nif the answer is NO, where and when the observed forest fire locations tend to cluster?"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_5/In_Class_Exercise5.html#determine-adaptive-bandwidth",
    "href": "In_Class_Exercises/In_Class_Exercise_5/In_Class_Exercise5.html#determine-adaptive-bandwidth",
    "title": "In Class Exercise 5: Spatio-Temporal Point Patterns Analysis",
    "section": "3.1 Determine adaptive bandwidth",
    "text": "3.1 Determine adaptive bandwidth\n\nCross-ValidationAIC\n\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n            data = hunan_sp,\n            approach = \"CV f\",\n            adaptive = TRUE,\n            kernel = 'bisquare',\n            longlat = T\n                 )\n\nAdaptive bandwidth: 62 CV score: 18372757104 \nAdaptive bandwidth: 46 CV score: 18580353939 \nAdaptive bandwidth: 72 CV score: 18261945072 \nAdaptive bandwidth: 78 CV score: 18284736555 \nAdaptive bandwidth: 68 CV score: 18289290196 \nAdaptive bandwidth: 74 CV score: 18279018755 \nAdaptive bandwidth: 70 CV score: 18279860873 \nAdaptive bandwidth: 72 CV score: 18261945072 \n\n\n\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n            data = hunan_sp,\n            approach = \"AIC\",\n            adaptive = TRUE,\n            kernel = 'bisquare',\n            longlat = T\n                 )\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1938.23 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1939.809 \nAdaptive bandwidth (number of nearest neighbours): 72 AICc value: 1937.17 \nAdaptive bandwidth (number of nearest neighbours): 78 AICc value: 1937.175 \nAdaptive bandwidth (number of nearest neighbours): 68 AICc value: 1937.494 \nAdaptive bandwidth (number of nearest neighbours): 74 AICc value: 1937.232 \nAdaptive bandwidth (number of nearest neighbours): 70 AICc value: 1937.334 \nAdaptive bandwidth (number of nearest neighbours): 72 AICc value: 1937.17"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_5/In_Class_Exercise5.html#fixed-distance",
    "href": "In_Class_Exercises/In_Class_Exercise_5/In_Class_Exercise5.html#fixed-distance",
    "title": "In Class Exercise 5: Spatio-Temporal Point Patterns Analysis",
    "section": "3.2 Fixed Distance",
    "text": "3.2 Fixed Distance\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n            data = hunan_sp,\n            approach = \"CV f\",\n            adaptive = FALSE,\n            kernel = 'bisquare',\n            longlat = T\n                 )\n\nFixed bandwidth: 12310.25 CV score: 18273921746 \nFixed bandwidth: 7609.674 CV score: 18103867978 \nFixed bandwidth: 4704.558 CV score: 16845755087 \nFixed bandwidth: 2909.098 CV score: Inf \nFixed bandwidth: 5814.214 CV score: 17412467531 \nFixed bandwidth: 4018.754 CV score: 17199641530 \nFixed bandwidth: 5128.409 CV score: 17049024078 \nFixed bandwidth: 4442.604 CV score: 16843054303 \nFixed bandwidth: 4280.708 CV score: 16938431975 \nFixed bandwidth: 4542.662 CV score: 16824565479 \nFixed bandwidth: 4604.501 CV score: 16826274857 \nFixed bandwidth: 4504.443 CV score: 16828132125 \nFixed bandwidth: 4566.282 CV score: 16824224135 \nFixed bandwidth: 4580.881 CV score: 16824638274 \nFixed bandwidth: 4557.26 CV score: 16824204920 \nFixed bandwidth: 4551.684 CV score: 16824284931 \nFixed bandwidth: 4560.706 CV score: 16824190674 \nFixed bandwidth: 4562.836 CV score: 16824195234 \nFixed bandwidth: 4559.39 CV score: 16824192954 \nFixed bandwidth: 4561.52 CV score: 16824191213 \nFixed bandwidth: 4560.204 CV score: 16824191084 \nFixed bandwidth: 4561.017 CV score: 16824190704 \nFixed bandwidth: 4560.514 CV score: 16824190763 \nFixed bandwidth: 4560.825 CV score: 16824190660 \nFixed bandwidth: 4560.898 CV score: 16824190667 \nFixed bandwidth: 4560.78 CV score: 16824190661 \nFixed bandwidth: 4560.853 CV score: 16824190661 \nFixed bandwidth: 4560.808 CV score: 16824190660 \nFixed bandwidth: 4560.836 CV score: 16824190660 \nFixed bandwidth: 4560.818 CV score: 16824190660 \nFixed bandwidth: 4560.814 CV score: 16824190660 \nFixed bandwidth: 4560.821 CV score: 16824190660 \nFixed bandwidth: 4560.817 CV score: 16824190660 \nFixed bandwidth: 4560.819 CV score: 16824190660 \nFixed bandwidth: 4560.818 CV score: 16824190660 \nFixed bandwidth: 4560.817 CV score: 16824190660 \nFixed bandwidth: 4560.818 CV score: 16824190660 \n\n\nComputing Geographically weighted summary statistics\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T\n               )\n\nPreparing the output data.\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\n\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_5/In_Class_Exercise5.html#the-geographically-weighted-mean",
    "href": "In_Class_Exercises/In_Class_Exercise_5/In_Class_Exercise5.html#the-geographically-weighted-mean",
    "title": "In Class Exercise 5: Spatio-Temporal Point Patterns Analysis",
    "section": "The Geographically Weighted Mean",
    "text": "The Geographically Weighted Mean\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\", \n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Dsitribution of geographically weighted mean\",\n            main.title.position = \"center\",\n            main.title.size = 2.0,\n            legend.text.size = 1.2,\n            legend.height = 1.50,\n            legend.width = 1.50,\n            frame = TRUE)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#aggregation-of-data-for-exploratory-purposes",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#aggregation-of-data-for-exploratory-purposes",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "4.1 Aggregation of Data for exploratory purposes",
    "text": "4.1 Aggregation of Data for exploratory purposes\nStep 1: Filter Data for Civilians\nIn this first step, the data (ACLEDData_Cleanse) is filtered so that only rows where either “Civilians” are involved in the conflict (inter1_description or inter2_description) are kept. Additionally, rows where the state information is missing (NA) are removed because these conflicts can’t be assigned to a specific geographical area.\n\nfiltered_data &lt;- ACLEDData_Cleanse %&gt;%\n  filter((inter1_description == \"Civilians\" | inter2_description == \"Civilians\") & !is.na(state))\n\nStep 2: Calculate State Area in Square Kilometers\nNext, the code calculates the area for each state from the M_State_Sf_Cleansed spatial dataset. The st_area function retrieves the area in square meters, and dividing by 1 million (1e6) converts it into square kilometers. This information will be used later to calculate conflict and fatality density.\n\nstate_area_km2 &lt;- st_area(M_State_Sf_Cleansed) / 1e6\nstate_area_df &lt;- data.frame(state = M_State_Sf_Cleansed$state, area_km2 = as.numeric(state_area_km2))\n\nStep 3: Aggregate Total Conflicts and Fatalities by State\nThe next step is to group the filtered data by state and calculate two key metrics: the total number of conflicts and the total number of fatalities for each state. This is done using group_by and summarise.\n\nagg_data_by_state &lt;- filtered_data %&gt;%\n  group_by(state) %&gt;%\n  summarise(\n    total_conflicts = n(), \n    total_fatalities = sum(fatalities, na.rm = TRUE), \n    .groups = \"drop\"\n  )\n\nStep 4: Convert to Non-Spatial Data Frame\nHere, the spatial data is converted into a regular data frame by dropping the geometry information. This allows easier manipulation of the non-spatial data for further processing.\n\nfiltered_data_df &lt;- st_drop_geometry(filtered_data)\n\nStep 5: Prepare Data Frame for Yearly Data\nTo store yearly conflict and fatality data for each state, an empty data frame is initialized by selecting distinct states from the filtered data\n\nfinal_result &lt;- filtered_data_df %&gt;% select(state) %&gt;% distinct()\n\nStep 6: Loop Through Each Year and Calculate Yearly Conflicts/Fatalities\nIn this step, the code iterates over each unique year in the dataset. For each year, it calculates the total conflicts and fatalities for each state. The results are merged back into the final_result data frame, with columns named according to the year (e.g., conflicts_2021, fatalities_2021).\n\nunique_years &lt;- unique(filtered_data_df$year)\n\nfor (yr in unique_years) {\n  yearly_data &lt;- filtered_data_df %&gt;%\n    filter(year == yr) %&gt;%\n    group_by(state) %&gt;%\n    summarise(\n      conflicts = n(), \n      fatalities = sum(fatalities, na.rm = TRUE)\n    ) %&gt;%\n    rename_at(vars(conflicts, fatalities), ~ paste0(., \"_\", yr))  # Rename with year\n  \n  final_result &lt;- left_join(final_result, yearly_data, by = \"state\")\n}\n\nStep 7: Replace NAs with 0\nAny missing data for a state-year combination (e.g., a state with no conflicts in a particular year) is replaced with 0 to avoid leaving gaps in the analysis.\n\nfinal_result &lt;- final_result %&gt;%\n  mutate(across(everything(), ~ ifelse(is.na(.), 0, .)))\n\nStep 8: Calculate Conflict and Fatality Density\nNow, the code calculates the density of conflicts and fatalities per square kilometer for each state. The results from Step 3 (agg_data_by_state) are joined with the state area data from Step 2. The density is simply the number of conflicts or fatalities divided by the area in square kilometers.\n\nagg_data_with_density &lt;- agg_data_by_state %&gt;%\n  left_join(state_area_df, by = \"state\") %&gt;%\n  mutate(\n    conflict_density = total_conflicts / area_km2,\n    fatality_density = total_fatalities / area_km2\n  )\n\nStep 9: Merge Yearly Data and Density with Spatial Data\nFinally, the spatial data (M_State_Sf_Cleansed) is merged with the yearly conflict/fatality data (final_result) and the density data (agg_data_with_density). Additional calculations are made to find the fatality-per-conflict ratio which are then added to the final spatial dataset.\n\nfinalized_map &lt;- M_State_Sf_Cleansed %&gt;%\n  left_join(final_result, by = \"state\") %&gt;%\n  left_join(agg_data_with_density, by = \"state\")\n\nfinalized_map &lt;- finalized_map %&gt;%\n  mutate(conflict_fatality_ratio = ifelse(total_fatalities == 0, NA, total_fatalities / total_conflicts))\n\nfinalized_map &lt;- finalized_map %&gt;%\n  mutate(\n    fatality_per_conflict = ifelse(total_conflicts == 0, NA, total_fatalities / total_conflicts),\n  )\n\nfinalized_map &lt;- finalized_map %&gt;%\n  mutate(\n    rank_total_conflicts = rank(-total_conflicts, ties.method = \"min\"),  # Rank total_conflicts (largest to smallest)\n    rank_total_fatalities = rank(-total_fatalities, ties.method = \"min\"),  # Rank total_fatalities (largest to smallest)\n    rank_conflict_density = rank(-conflict_density, ties.method = \"min\"),  # Rank conflict_density (largest to smallest)\n    rank_fatality_density = rank(-fatality_density, ties.method = \"min\"),  # Rank fatality_density (largest to smallest)\n    rank_fatality_per_conflict = rank(-fatality_per_conflict, ties.method = \"min\")  # Rank fatality_per_conflict (largest to smallest)\n  )\n\nFinal Output: Display the Data\nThe finalized_map contains all the processed information, including conflict/fatality counts, densities, and state geometry, which can now be visualized or further analyzed.\n\nhead(finalized_map)\n\nSimple feature collection with 6 features and 23 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -162806.6 ymin: 1682875 xmax: 491639.1 ymax: 3158467\nProjected CRS: WGS 84 / UTM zone 47N\n       state   type      state_myr conflicts_2024 fatalities_2024\n1 Ayeyarwady Region ဧရာဝတီတိုင်းဒေသကြီး             64               9\n2       Bago Region   ပဲခူးတိုင်းဒေသကြီး            194             128\n3       Chin  State      ချင်းပြည်နယ်             72              52\n4     Kachin  State      ကချင်ပြည်နယ်            160              95\n5      Kayah  State      ကယားပြည်နယ်             21              38\n6      Kayin  State       ကရင်ပြည်နယ်             52              59\n  conflicts_2023 fatalities_2023 conflicts_2022 fatalities_2022 conflicts_2021\n1             83               7            177              29            233\n2            339             220            172              61            191\n3            101              76            204              80            160\n4            316             133            226             140            221\n5            113              74            149              87            114\n6            165              83            165              86            116\n  fatalities_2021 total_conflicts total_fatalities area_km2 conflict_density\n1              34             557               79 33738.82       0.01650917\n2              87             896              496 38556.99       0.02323833\n3              32             537              240 36276.56       0.01480295\n4              71             923              439 88977.32       0.01037343\n5             108             397              307 11763.10       0.03374961\n6              57             498              285 30337.59       0.01641528\n  fatality_density                       geometry conflict_fatality_ratio\n1      0.002341516 MULTIPOLYGON (((93411.72 17...               0.1418312\n2      0.012864076 MULTIPOLYGON (((203949.9 21...               0.5535714\n3      0.006615843 MULTIPOLYGON (((-72918.03 2...               0.4469274\n4      0.004933841 MULTIPOLYGON (((362696.3 31...               0.4756230\n5      0.026098563 MULTIPOLYGON (((309155.7 22...               0.7732997\n6      0.009394287 MULTIPOLYGON (((373551.3 18...               0.5722892\n  fatality_per_conflict rank_total_conflicts rank_total_fatalities\n1             0.1418312                   11                    14\n2             0.5535714                    9                     6\n3             0.4469274                   12                    13\n4             0.4756230                    8                     7\n5             0.7732997                   14                    10\n6             0.5722892                   13                    12\n  rank_conflict_density rank_fatality_density rank_fatality_per_conflict\n1                    10                    15                         15\n2                     9                     8                          4\n3                    12                    11                          9\n4                    15                    13                          6\n5                     6                     4                          1\n6                    11                    10                          3\n\n\n\n4.2 Visualizing the aggregated data.\nFor each column that we created earlier, we can now showcase it in a choropleth map to highlight the states with the highest values in each category. These maps will help visually identify which state has the highest value for each column. You can navigate through the tabset to explore the different metrics and easily view the data on a map!\n\nTotal Civilian ConflictsTotal Fatalities for civilians related conflicts.Civilian Conflict DensityFatality DensityFatality Per Civilian Conflict\n\n\n\n# Create the tmap object for total civilian conflicts\ntm_total_conflicts &lt;- \n  # Layer for total civilian conflicts\n  tm_shape(finalized_map) +\n  tm_polygons(\"total_conflicts\", \n              title = \"Total Civilian Related Conflicts\",\n              palette = \"Reds\", \n              border.col = \"black\", \n              alpha = 0.8,  # Transparency for polygons\n              border.alpha = 0.5,  # Semi-transparent border\n              id = \"state\") +  # Set state as identifier for the polygons\n\n  # Layout settings matching your style\n  tm_layout(\n    main.title = \"Myanmar's State by Total Civilian Related Conflicts\",  # Main map title\n    main.title.size = 1.0,  # Title font size\n    legend.outside = TRUE,  # Position legend outside the map\n    legend.outside.size = 0.5,  # Adjust size of outside legend\n    legend.position = c(\"left\", \"top\"),  # Position for the event type legend\n    legend.title.size = 1.2,  # Size of the legend title\n    legend.text.size = 1,  # Size of the legend text\n    legend.bg.color = \"white\",  # Background color for the legend\n    legend.bg.alpha = 0.5,  # Transparency for the legend background\n    inner.margins = c(0.05, 0.05, 0.05, 0.05)  # Set inner margins for better spacing\n  )\ntm_total_conflicts\n\n\n\n\n\n\n\n\n\n\n\n# Create the tmap object for total civilian conflicts\ntm_total_fatalities &lt;- tm_basemap(server = c(\"Esri.WorldGrayCanvas\", \"OpenStreetMap\", \"Esri.WorldTopoMap\")) +\n  # Layer for total civilian conflicts\n  tm_shape(finalized_map) +\n  tm_polygons(\"total_fatalities\", \n              title = \"Total Fatalities by Civilian Related Conflicts\",\n              palette = \"Blues\", \n              border.col = \"black\", \n              alpha = 0.8,  # Transparency for polygons\n              border.alpha = 0.5,  # Semi-transparent border\n              id = \"state\") +  # Set state as identifier for the polygons\n\n  # Layout settings matching your style\n  tm_layout(\n    main.title = \"Myanmar's State by Total Fatatlies For Civilian Related Conflicts\",  # Main map title\n    main.title.size = 1.0,  # Title font size\n    legend.outside = TRUE,  # Position legend outside the map\n    legend.outside.size = 0.5,  # Adjust size of outside legend\n    legend.position = c(\"left\", \"top\"),  # Position for the event type legend\n    legend.title.size = 1.2,  # Size of the legend title\n    legend.text.size = 1,  # Size of the legend text\n    legend.bg.color = \"white\",  # Background color for the legend\n    legend.bg.alpha = 0.5,  # Transparency for the legend background\n    inner.margins = c(0.05, 0.05, 0.05, 0.05)  # Set inner margins for better spacing\n  )\n\ntm_total_fatalities\n\n\n\n\n\n\n\n\n\n\n\ntm_conflict_density &lt;-\n  # Layer for total civilian conflicts\n  tm_shape(finalized_map) +\n  tm_polygons(\"conflict_density\", \n              title = \"Myanmar State by Civilian Related Conflicts Density\",\n              palette = \"Blues\", \n              border.col = \"black\", \n              alpha = 0.8,  # Transparency for polygons\n              border.alpha = 0.5,  # Semi-transparent border\n              id = \"state\") +  # Set state as identifier for the polygons\n\n  # Layout settings matching your style\n  tm_layout(\n    main.title = \"Myanmar State by Civilian Related Conflicts Density\",  # Main map title\n    main.title.size = 1.0,  # Title font size\n    legend.outside = TRUE,  # Position legend outside the map\n    legend.outside.size = 0.5,  # Adjust size of outside legend\n    legend.position = c(\"left\", \"top\"),  # Position for the event type legend\n    legend.title.size = 1.2,  # Size of the legend title\n    legend.text.size = 1,  # Size of the legend text\n    legend.bg.color = \"white\",  # Background color for the legend\n    legend.bg.alpha = 0.5,  # Transparency for the legend background\n    inner.margins = c(0.05, 0.05, 0.05, 0.05)  # Set inner margins for better spacing\n  )\n\ntm_conflict_density\n\n\n\n\n\n\n\n\n\n\n\ntm_fatalities_conflict &lt;- \n  # Layer for total civilian conflicts\n  tm_shape(finalized_map) +\n  tm_polygons(\"fatality_density\", \n              title = \"Myanmar State by Fatalies For Civilians Related Conflicts Density Per Km^2\",\n              palette = \"Blues\", \n              border.col = \"black\", \n              alpha = 0.8,  # Transparency for polygons\n              border.alpha = 0.5,  # Semi-transparent border\n              id = \"state\") +  # Set state as identifier for the polygons\n\n  # Layout settings matching your style\n  tm_layout(\n    main.title = \"Myanmar State by Fatalies For Civilians Related Conflicts Density Per Km^2\",  # Main map title\n    main.title.size = 1.0,  # Title font size\n    legend.outside = TRUE,  # Position legend outside the map\n    legend.outside.size = 0.5,  # Adjust size of outside legend\n    legend.position = c(\"left\", \"top\"),  # Position for the event type legend\n    legend.title.size = 1.0,  # Size of the legend title\n    legend.text.size = 0.8,  # Size of the legend text\n    legend.bg.color = \"white\",  # Background color for the legend\n    legend.bg.alpha = 0.5,  # Transparency for the legend background\n    inner.margins = c(0.05, 0.05, 0.05, 0.05)  # Set inner margins for better spacing\n  )\n\ntm_fatalities_conflict\n\n\n\n\n\n\n\n\n\n\n\ntm_fatalities_density &lt;-\n  # Layer for total civilian conflicts\n  tm_shape(finalized_map) +\n  tm_polygons(\"fatality_per_conflict\", \n              title = \"Myanmar State by Fatalies for Civilian Related Conflicts\",\n              palette = \"Blues\", \n              border.col = \"black\", \n              alpha = 0.8,  # Transparency for polygons\n              border.alpha = 0.5,  # Semi-transparent border\n              id = \"state\") +  # Set state as identifier for the polygons\n\n  # Layout settings matching your style\n  tm_layout(\n    main.title = \"Myanmar State by Fatalies for Civilian Related Conflicts\",  # Main map title\n    main.title.size = 1.0,  # Title font size\n    legend.outside = TRUE,  # Position legend outside the map\n    legend.outside.size = 0.5,  # Adjust size of outside legend\n    legend.position = c(\"left\", \"top\"),  # Position for the event type legend\n    legend.title.size = 1.0,  # Size of the legend title\n    legend.text.size = 0.8,  # Size of the legend text\n    legend.bg.color = \"white\",  # Background color for the legend\n    legend.bg.alpha = 0.5,  # Transparency for the legend background\n    inner.margins = c(0.05, 0.05, 0.05, 0.05)  # Set inner margins for better spacing\n  )\n\ntm_fatalities_density"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#analysis-on-the-aggregated-data-to-find-top-3-state-to-analyse",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#analysis-on-the-aggregated-data-to-find-top-3-state-to-analyse",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "4.3 Analysis on the aggregated data to find top 3 state to analyse",
    "text": "4.3 Analysis on the aggregated data to find top 3 state to analyse\n\n4.3.1 Choose which States to analyse?\nWith the maps above, everyone can choose what they would like to analyze, whether it’s total civilian conflicts or fatalities by state. However, I would like to focus on the central question:\nWhich state has the highest amount of conflict and fatality density?\nBy using density, I’ve aimed to assess fatalities in relation to conflicts and ensure a fair comparison by adjusting for density.\n\n\n\n\n\n\nNote\n\n\n\nKeep in mind, this is not the most precise analysis, as other factors—such as ethnicity, population demographics, and gender—could also be considered. However, for the purpose of this study, I have chosen to focus on solely on the state’s conflict and fatality density.\n\n\nConflict Density: This is the number of conflicts per square kilometer in a state.\n\nConflict Density=Total ConflictsArea of State (km²) = Conflict Density=Area of State (km²)Total Conflicts​\nThis tells you how many conflicts occur per unit of area (1 km²) in each state.\nFatality Density: This is the number of fatalities per square kilometer.\nFatality Density=Total FatalitiesArea of State (km²) = Fatality Density=Area of State (km²)Total Fatalities​\n\n\n\n4.3.2 Viewing the top 3 states across\nUsing the map below, you can interactively explore the Conflict and Fatality Density. We observe that the top three states are as follows, and here’s how they compare across the data set.\nYou can use the layer toggle to switch between fatalities and conflicts, or click on the map layers to view detailed, aggregated data for each state.\n\n# Step 1: Set tmap mode to view for interactive maps\n\n# Step 2: Define popup variables to show all relevant columns when clicking on a state\npopup_variables &lt;- c( \n                     \"Total Civilian Conflicts\" = \"total_conflicts\",\n                     \"Fatalities\" = \"total_fatalities\",\n                     \"Civilian Conflict Density\" = \"conflict_density\",\n                     \"Fatality Density\" = \"fatality_density\",\n                     \"Fatality Per Civilian Conflict\" = \"fatality_per_conflict\",\n                     \"Ranked For Total Conflict By State (Out of 15)\" = \"rank_total_conflicts\",\n                     \"Ranked For Total Fatalities By State (Out of 15)\" = \"rank_total_fatalities\",\n                     \"Ranked For Conflict Density By State (Out of 15)\" = \"rank_conflict_density\",\n                     \"Ranked For Fatalities Density By State (Out of 15)\" = \"rank_fatality_density\",\n                     \"Ranked For Fatalies/Conflict By State (Out of 15)\" = \"rank_fatality_per_conflict\"\n                     )\n\n# Step 3: Create the map with 6 layers for toggling\ntm &lt;- tm_basemap(server = \"OpenStreetMap\") +\n  tm_shape(finalized_map) +\n  tm_polygons(\"conflict_density\", \n              title = \"Civilian Conflict Density\",\n              palette = \"Oranges\", \n              border.col = \"black\",\n              popup.vars = popup_variables,\n              id = \"state\", \n              group = \"Civilian Conflict Density\") +\n  tm_shape(finalized_map) +\n  tm_polygons(\"fatality_density\", \n              title = \"Fatality Density\",\n              palette = \"Purples\", \n              border.col = \"black\",\n              popup.vars = popup_variables,\n              id = \"state\", \n              group = \"Fatality Density\") +\n  tm_layout(\n    legend.outside = TRUE,\n    legend.outside.size = 0.5,  # Adjust the size of the legend\n    legend.position = c(\"left\", \"top\")  # Position the legend\n  )\n# Step 5: Display the interactive map\ntm\n\n\n\n\n\nHere we build the bar chart to view rank the states base on the variables.\n\nfinalized_data_df &lt;- as.data.frame(st_drop_geometry(finalized_map))\n# Sort the data by conflict_density and fatality_density in descending order\nfinalized_data_df &lt;- finalized_data_df %&gt;%\n  arrange(desc(conflict_density), desc(fatality_density))\n\n# Format the densities to show \"per km²\"\nfinalized_data_df$conflict_density_label &lt;- paste0(round(finalized_data_df$conflict_density, 2), \" per km²\")\nfinalized_data_df$fatality_density_label &lt;- paste0(round(finalized_data_df$fatality_density, 2), \" per km²\")\n\n# Create bar chart for Conflict Density (sorted by conflict_density)\nconflict_density_plot &lt;- ggplot(finalized_data_df, aes(x = reorder(state, -conflict_density), y = conflict_density)) +\n  geom_bar(stat = \"identity\", fill = \"orange\") +\n  geom_text(aes(label = conflict_density_label), vjust = 1.8, size = 2.0, color = \"black\", position = position_stack(vjust = 0.5)) +  # Place text at bottom of bar\n  ggtitle(\"Top States by Conflict Density (per km²)\") +\n  xlab(\"State\") +\n  ylab(\"Conflict Density (per km²)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# Create bar chart for Fatality Density (sorted by fatality_density)\nfatality_density_plot &lt;- ggplot(finalized_data_df, aes(x = reorder(state, -fatality_density), y = fatality_density)) +\n  geom_bar(stat = \"identity\", fill = \"purple\") +\n  geom_text(aes(label = fatality_density_label), vjust = 1.8, size = 2.0, color = \"black\", position = position_stack(vjust = 0.5)) +  # Place text at bottom of bar\n  ggtitle(\"Top States by Fatality Density (per km²)\") +\n  xlab(\"State\") +\n  ylab(\"Fatality Density (per km²)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# Display both charts side by side\ngrid.arrange(conflict_density_plot, fatality_density_plot, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n4.3.3 Top 3 Chosen state for further analysis\n\n4.3.3.1 Yangon\n\n\n\nYangon, Myanmar’s largest city and former capital, remains the country’s economic and cultural hub. Although it is no longer the political capital, Yangon holds the highest population density in the country, making it a vital urban center with significant influence.\nAccording to the data, Yangon ranks 5th for total conflicts, with 1,489 civilian conflicts reported, and 8th in fatalities, with 431 deaths. However, it stands out with the highest civilian conflict density (0.0531) and fatality density (0.01536) among Myanmar’s 15 states. This means that while the overall number of conflicts may not be the highest, they are more concentrated within Yangon’s urban area, resulting in the highest per-unit area conflict rate.\nYangon’s urbanization and strategic economic importance likely make it a hotspot for civilian unrest. Social tensions in a densely populated city lead to frequent conflicts, reflected in its rank of 1st for conflict density and fatality density. Despite fewer total conflicts compared to other states, Yangon’s density of unrest highlights its vulnerability to civil tensions.\n\n\n4.3.3.2 Mandalay\n\nMandalay, the second-largest city in Myanmar, is known for its cultural significance and central location in the country. It holds a key strategic position in the economy and transportation networks, making it vulnerable to unrest.\nThe data shows Mandalay ranks 2nd for total civilian conflicts with 2,021 conflicts and 950 fatalities. Its civilian conflict density is 0.0255, placing it 3rd in density, while its fatality density is 0.0120, ranked 2nd. Despite being second in conflict counts, the concentration of conflicts and fatalities suggests that civil unrest is deeply rooted in the region, but not as dense as in Yangon.\nMandalay’s high fatality-to-conflict ratio (0.4701 fatalities per conflict) highlights the deadly nature of conflicts, ranking 7th in fatalities per conflict. This reflects a region where conflicts, though frequent, lead to significant loss of life compared to other states.\n\n\n4.3.3.3 Sagaling.\n\nSagaing, located in northern Myanmar, is one of the country’s most conflict-ridden regions, often affected by armed insurgencies and ethnic clashes due to its proximity to volatile borders.\nThe data reveals that Sagaing ranks 1st in total civilian conflicts with 5,346 conflicts and 3,319 fatalities, giving it the highest fatality count as well. However, its civilian conflict density is 0.0241 (ranked 3rd) and its fatality density is 0.01497 (ranked 3rd), indicating a widespread yet slightly less concentrated conflict zone compared to Yangon and Mandalay.\nSagaing’s fatality per civilian conflict ratio of 0.6208 ranks 2nd, emphasizing the high lethality of conflicts in the region. With both the largest number of conflicts and a high fatality rate, Sagaing represents one of the most dangerous and unstable areas in Myanmar for civilians/"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#final-round-of-cleansing-acled-data",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#final-round-of-cleansing-acled-data",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "4.4 Final Round of Cleansing ACLED Data",
    "text": "4.4 Final Round of Cleansing ACLED Data\nIn this final stage of the data cleansing process, we focus on preparing the ACLED (Armed Conflict Location & Event Data) for the different states. The key steps include:\n\nFiltering: We first filter the dataset to focus on data specific to Yangon.\nConverting to Spatial Format: Using the st_as_sf() function, we transform the filtered data into a simple features (sf) object, a format commonly used for spatial data in R. This involves specifying longitude and latitude as the coordinates and setting the correct WGS84 (CRS 4326) coordinate system for global geographic data.\nCoordinate System Transformation: We apply the st_transform() function to project the spatial data from WGS84 (CRS 4326) to UTM Zone 47N (CRS 32647), which is more appropriate for spatial analysis in Myanmar. This step ensures accurate distance and area calculations.\nValidity Check: Using st_is_valid(), we validate the geometries in the spatial data to ensure there are no invalid shapes, such as self-intersecting polygons, which could cause errors during analysis.\nConversion to Spatial Data Frame: Finally, we convert the sf object into a Spatial Data Frame (as_Spatial()) for compatibility with specific spatial analysis functions that require this format.\n\nThis process ensures that the States data is accurately represented in a geospatial format, with proper coordinate transformation and validity checks applied. It prepares the data for further geospatial operations, such as mapping and spatial pattern analysis, with the confidence that the dataset is clean and valid for use.\n\nYangonMandalaySagaing\n\n\n\n# Filter data for Yangon state from the entire ACLED dataset\nYangon_ACLED_Data &lt;- filtered_data %&gt;% \n  filter(state %in% c(\"Yangon\"))\n\n# Check the class of the data to confirm it's a dataframe\nclass(Yangon_ACLED_Data)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n# Convert the filtered data into a spatial format (simple features object)\n# Use longitude and latitude columns as coordinates, with WGS84 (CRS 4326) as the coordinate system\nYangon_ACLED_Data_Sf &lt;- st_as_sf(Yangon_ACLED_Data, coords = c(\"longitude\", \"latitude\"), crs = 4326, remove = FALSE)\n\n# Transform the coordinate system to UTM Zone 47N (CRS 32647) for better spatial precision in Myanmar\nYangon_ACLED_Data_Sf &lt;- st_transform(Yangon_ACLED_Data_Sf, crs = 32647)\n\n# Check the class of the spatial object to confirm conversion\nclass(Yangon_ACLED_Data_Sf)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n# Validate the spatial object to ensure all geometries are valid (no broken or self-intersecting geometries)\nYangon_ACLED_Validity &lt;- st_is_valid(Yangon_ACLED_Data_Sf)\n\n# Identify any invalid geometries and print them if they exist\nYangon_invalid &lt;- which(!Yangon_ACLED_Validity)\nif (length(Yangon_invalid) &gt; 0) {\n  print(\"Yangon is Invalid!\")\n  print(Yangon_ACLED_Data_Sf[Yangon_invalid, ])\n} else {\n  print(\"Yangon_ACLED_Data_Sf is valid!\")\n}\n\n[1] \"Yangon_ACLED_Data_Sf is valid!\"\n\n# Convert the sf object into a Spatial Data Frame (for compatibility with certain spatial analysis functions)\nYangon_ACLED_SFDF &lt;- as_Spatial(Yangon_ACLED_Data_Sf)\n\n# Final output - Yangon ACLED data in spatial data frame format, ready for analysis\nYangon_ACLED_SFDF\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1489 \nextent      : 148595, 259745.5, 1819680, 1944325  (xmin, xmax, ymin, ymax)\ncrs         : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nvariables   : 20\nnames       : event_id_cnty, event_date, year,          disorder_type,                 event_type,                       actor1, inter1,                actor2, inter2, interaction,      location, latitude, longitude, fatalities, quarter_year, ... \nmin values  :      MMR10949,      18633, 2021,     Political violence, Explosions/Remote violence,           5 Brothers Younger,      1, Civilians (Australia),      0,          17,     Ah Hpyauk,  16.4389,   95.6934,          0,      Q1-2021, ... \nmax values  :      MMR64089,      19895, 2024, Strategic developments, Violence against civilians, YUG: Yangon Urban Guerrillas,      7,                    NA,      7,          70, Zee Hpyu Kone,  17.5612,   96.7448,         13,      Q4-2023, ... \n\n\n\n\n\n# Filter data for Mandalay state from the entire ACLED dataset\nMandalay_ACLED_Data &lt;- filtered_data %&gt;% \n  filter(state %in% c(\"Mandalay\"))\n# Check the class of the filtered data to confirm it's still a dataframe\nclass(Mandalay_ACLED_Data)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n# Convert the filtered data into a spatial format (simple features object)\n# Longitude and latitude are used as coordinates, and WGS84 (CRS 4326) is set as the coordinate system\nMandalay_ACLED_Data_Sf &lt;- st_as_sf(Mandalay_ACLED_Data, coords = c(\"longitude\", \"latitude\"), crs = 4326, remove = FALSE)\n\n# Transform the coordinate system to UTM Zone 47N (CRS 32647) for better accuracy in the Myanmar region\nMandalay_ACLED_Data_Sf &lt;- st_transform(Mandalay_ACLED_Data_Sf, crs = 32647)\n\n# Verify that the data has been successfully converted into a spatial object\nclass(Mandalay_ACLED_Data_Sf)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n# Validate the spatial data to check for any invalid geometries (e.g., self-intersections, broken polygons)\nMandalay_ACLED_Validity &lt;- st_is_valid(Mandalay_ACLED_Data_Sf)\n\n# Identify any invalid geometries and print them for inspection, if found\nMandalay_invalid &lt;- which(!Mandalay_ACLED_Validity)\nif (length(Mandalay_invalid) &gt; 0) {\n  print(\"Mandalay is Invalid!\")\n  print(Mandalay_ACLED_Data_Sf[Mandalay_invalid, ])\n} else {\n  # If all geometries are valid, print confirmation\n  print(\"Mandalay_ACLED_Data_Sf is valid!\")\n}\n\n[1] \"Mandalay_ACLED_Data_Sf is valid!\"\n\n# Convert the simple features object to a Spatial Data Frame for compatibility with spatial functions\nMandalay_ACLED_SFDF &lt;- as_Spatial(Mandalay_ACLED_Data_Sf)\n\n# Final output - Mandalay ACLED data in spatial data frame format, ready for analysis\nMandalay_ACLED_SFDF\n\nclass       : SpatialPointsDataFrame \nfeatures    : 2021 \nextent      : 68129.21, 255317.2, 2261881, 2620357  (xmin, xmax, ymin, ymax)\ncrs         : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nvariables   : 20\nnames       : event_id_cnty, event_date, year,          disorder_type,                 event_type,                                   actor1, inter1,              actor2, inter2, interaction,         location, latitude, longitude, fatalities, quarter_year, ... \nmin values  :      MMR10960,      18640, 2021,     Political violence, Explosions/Remote violence, 21KPG: 21 Guerrilla Force - Kyaukpadaung,      1, Civilians (Myanmar),      0,          17, 4 Maing Kan Thar,  20.4319,    94.849,          0,      Q1-2021, ... \nmax values  :      MMR64318,      19904, 2024, Strategic developments, Violence against civilians,          Zero Guerrilla Force - Myingyan,      7,                  NA,      7,          70,       Zin Chaung,   23.667,   96.6148,         10,      Q4-2023, ... \n\n\n\n\n\nSagaing_ACLED_Data &lt;- filtered_data %&gt;% \n  filter(state %in% c(\"Sagaing\"))\n\n# Check the class of the filtered data to confirm it's still a dataframe\nclass(Sagaing_ACLED_Data)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n# Convert the filtered data into a spatial format (simple features object)\n# Longitude and latitude are used as coordinates, and WGS84 (CRS 4326) is set as the coordinate system\nSagaing_ACLED_Data_Sf &lt;- st_as_sf(Sagaing_ACLED_Data, coords = c(\"longitude\", \"latitude\"), crs = 4326, remove = FALSE)\n\n# Transform the coordinate system to UTM Zone 47N (CRS 32647) for better accuracy in the Myanmar region\nSagaing_ACLED_Data_Sf &lt;- st_transform(Sagaing_ACLED_Data_Sf, crs = 32647)\n\n# Verify that the data has been successfully converted into a spatial object\nclass(Sagaing_ACLED_Data_Sf)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n# Validate the spatial data to check for any invalid geometries (e.g., self-intersections, broken polygons)\nSagaing_ACLED_Validity &lt;- st_is_valid(Sagaing_ACLED_Data_Sf)\n\n# Identify any invalid geometries and print them for inspection, if found\nSagaing_invalid &lt;- which(!Sagaing_ACLED_Validity)\nif (length(Sagaing_invalid) &gt; 0) {\n  print(\"Sagaing is Invalid!\")\n  print(Sagaing_ACLED_Data_Sf[Sagaing_invalid, ])\n} else {\n  # If all geometries are valid, print confirmation\n  print(\"Sagaing_ACLED_Data_Sf is valid!\")\n}\n\n[1] \"Sagaing_ACLED_Data_Sf is valid!\"\n\n# Convert the simple features object to a Spatial Data Frame for compatibility with spatial functions\nSagaing_ACLED_SFDF &lt;- as_Spatial(Sagaing_ACLED_Data_Sf)\n\n# Final output - Sagaing ACLED data in spatial data frame format, ready for analysis\nSagaing_ACLED_SFDF\n\nclass       : SpatialPointsDataFrame \nfeatures    : 5346 \nextent      : -16397.05, 256586.9, 2393568, 2914063  (xmin, xmax, ymin, ymax)\ncrs         : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nvariables   : 20\nnames       : event_id_cnty, event_date, year,          disorder_type,                 event_type,                                      actor1, inter1,            actor2, inter2, interaction,               location, latitude, longitude, fatalities, quarter_year, ... \nmin values  :      MMR10952,      18640, 2021,     Political violence, Explosions/Remote violence, ABSDF: All Burma Students' Democratic Front,      1, Civilians (China),      0,          17,               55 Maing,   21.605,   93.9575,          0,      Q1-2021, ... \nmax values  :      MMR65891,      19898, 2024, Strategic developments, Violence against civilians,             Zero Guerrilla Force - Myingyan,      7,                NA,      7,          70, Zin Ka Le (Zin Ka Lin),  26.3006,   96.6034,        175,      Q4-2023, ..."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-the-owin-window-for-myanmar.",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-the-owin-window-for-myanmar.",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "5.1 Setting up the Owin Window for Myanmar.",
    "text": "5.1 Setting up the Owin Window for Myanmar.\nIn this part of the code, we are setting up a spatial window for Myanmar, which defines the boundaries within which the spatial point pattern analysis will take place. This is done using the owin function from the spatstat package, which converts the polygonal boundary of Myanmar into a format that can be used for further spatial analysis.\n\nYangonMandalaySagaing\n\n\n\nYangon_Sf &lt;- M_State_Sf %&gt;% \n  filter(state %in% c(\"Yangon\"))\nYangon &lt;- as_Spatial(Yangon_Sf)\nYangon_Owin &lt;- as.owin(Yangon_Sf)\nplot(Yangon_Owin)\n\n\n\n\n\n\n\nsummary(Yangon_Owin)\n\nWindow: polygonal boundary\n8 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1            3832  2.79639e+10      9.97e-01\npolygon 2 (hole)        3 -5.16800e+02     -1.84e-08\npolygon 3              14  6.05403e+05      2.16e-05\npolygon 4              11  4.56071e+05      1.63e-05\npolygon 5              20  5.15327e+06      1.84e-04\npolygon 6              37  7.35365e+06      2.62e-04\npolygon 7              48  2.70772e+07      9.65e-04\npolygon 8             180  4.75716e+07      1.70e-03\nenclosing rectangle: [7305087, 7698916] x [2582788, 3397886] units\n                     (393800 x 815100 units)\nWindow area = 28052100000 square units\nFraction of frame area: 0.0874\n\n\n\n\n\nMandalay_Sf &lt;- M_State_Sf %&gt;% \n  filter(state %in% c(\"Mandalay\"))\nMandalay &lt;- as_Spatial(Mandalay_Sf)\nMandalay_Owin &lt;- as.owin(Mandalay_Sf)\nplot(Mandalay_Owin)\n\n\n\n\n\n\n\nsummary(Mandalay_Owin)\n\nWindow: polygonal boundary\nsingle connected closed polygon with 5914 vertices\nenclosing rectangle: [6990555, 7369406] x [3760343, 4336524] units\n                     (378900 x 576200 units)\nWindow area = 79199300000 square units\nFraction of frame area: 0.363\n\n\n\n\n\nSagaing_Sf &lt;- M_State_Sf %&gt;% \n  filter(state %in% c(\"Sagaing\"))\nSagaing &lt;- as_Spatial(Sagaing_Sf)\nSagaing_Owin &lt;- as.owin(Sagaing_Sf)\nplot(Sagaing_Owin)\n\n\n\n\n\n\n\nsummary(Sagaing_Owin)\n\nWindow: polygonal boundary\nsingle connected closed polygon with 5882 vertices\nenclosing rectangle: [6600929, 7143229] x [3910303, 4901317] units\n                     (542300 x 991000 units)\nWindow area = 2.21637e+11 square units\nFraction of frame area: 0.412\n\n\n\n\n\n\n5.2 Setting up the ACLED Spatial Class\n\n\n5.2.1 Converting Spatial Class Into Generic PPP Format\n\nYangonMandalaySagaing\n\n\n\n# Yangon_ACLED_Data\n# Yangon_ACLED_Data_Sf\n# Yangon_ACLED_SFDF \n\nYangon_ACLED_coords &lt;- st_coordinates(Yangon_ACLED_Data_Sf)\n\n# Define the window using the bounding box\nYangon_ACLED_bbox &lt;- st_bbox(Yangon_ACLED_Data_Sf)\nYangon_ACLED_window &lt;- owin(xrange = Yangon_ACLED_bbox[c(\"xmin\", \"xmax\")], yrange = Yangon_ACLED_bbox[c(\"ymin\", \"ymax\")])\n\n# Create the ppp object\nYangon_ACLED_ppp &lt;- ppp(x = Yangon_ACLED_coords[, 1], y = Yangon_ACLED_coords[, 2], window = Yangon_ACLED_window)\n\nWarning: data contain duplicated points\n\n# Check the ppp object\nsummary(Yangon_ACLED_ppp)\n\nPlanar point pattern:  1489 points\nAverage intensity 3.865152e-08 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 9 decimal places\n\nWindow: rectangle = [7470244, 7680669] x [3162567, 3345642] units\n                    (210400 x 183100 units)\nWindow area = 38523700000 square units\n\nplot(Yangon_ACLED_ppp)\n\n\n\n\n\n\n\n\n\n\n\n#Mandalay_ACLED_Data\n# Mandalay_ACLED_Data_Sf\n# Mandalay_ACLED_SFDF \nMandalay_ACLED_coords &lt;- st_coordinates(Mandalay_ACLED_Data_Sf)\n\n# Define the window using the bounding box\nMandalay_ACLED_bbox &lt;- st_bbox(Mandalay_ACLED_Data_Sf)\nMandalay_ACLED_window &lt;- owin(xrange = Mandalay_ACLED_bbox[c(\"xmin\", \"xmax\")], yrange = Mandalay_ACLED_bbox[c(\"ymin\", \"ymax\")])\n\n# Create the ppp object\nMandalay_ACLED_ppp &lt;- ppp(x = Mandalay_ACLED_coords[, 1], y = Mandalay_ACLED_coords[, 2], window = Mandalay_ACLED_window)\n\nWarning: data contain duplicated points\n\n# Check the ppp object\nsummary(Mandalay_ACLED_ppp)\n\nPlanar point pattern:  2021 points\nAverage intensity 353.7831 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 4 decimal places\n\nWindow: rectangle = [94.849, 96.6148] x [20.4319, 23.667] units\n                    (1.766 x 3.235 units)\nWindow area = 5.71254 square units\n\nplot(Mandalay_ACLED_ppp)\n\n\n\n\n\n\n\n\n\n\n\nSagaing_ACLED_coords &lt;- st_coordinates(Sagaing_ACLED_Data_Sf)\n\n# Define the window using the bounding box\nSagaing_ACLED_bbox &lt;- st_bbox(Sagaing_ACLED_Data_Sf)\nSagaing_ACLED_window &lt;- owin(xrange = Sagaing_ACLED_bbox[c(\"xmin\", \"xmax\")], yrange = Sagaing_ACLED_bbox[c(\"ymin\", \"ymax\")])\n\n# Create the ppp object\nSagaing_ACLED_ppp &lt;- ppp(x = Sagaing_ACLED_coords[, 1], y = Sagaing_ACLED_coords[, 2], window = Sagaing_ACLED_window)\n\nWarning: data contain duplicated points\n\n# Check the ppp object\nsummary(Sagaing_ACLED_ppp)\n\nPlanar point pattern:  5346 points\nAverage intensity 430.2932 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 4 decimal places\n\nWindow: rectangle = [93.9575, 96.6034] x [21.605, 26.3006] units\n                    (2.646 x 4.696 units)\nWindow area = 12.4241 square units\n\nplot(Sagaing_ACLED_ppp)\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.2.2 Dealing with duplicate conflicts\n\n5.2.2.1 Check For Duplicate\n\nYangonMandalaySagaing\n\n\n\nany(duplicated(Yangon_ACLED_ppp))\n\n[1] TRUE\n\nsum(multiplicity(Yangon_ACLED_ppp) &gt; 1)\n\n[1] 1432\n\n\n\n\n\nany(duplicated(Yangon_ACLED_ppp))\n\n[1] TRUE\n\nsum(multiplicity(Yangon_ACLED_ppp) &gt; 1)\n\n[1] 1432\n\n\n\n\n\n\n\n\n\n\n5.2.2.2 Unique Marking them\n\nYangonMandalaySagaing\n\n\n\nYangon_marks &lt;- rep(1, npoints(Yangon_ACLED_ppp))\nYangon_marks[duplicated(Yangon_ACLED_ppp)] &lt;- 2\n\n# Create a new ppp object with marks attached to each point\nmarked_Yangon_ACLED_ppp &lt;- ppp(x = Yangon_ACLED_coords[, 1], y = Yangon_ACLED_coords[, 2], window = Yangon_ACLED_window, marks = Yangon_marks)\n\nWarning: data contain duplicated points\n\n# Check the ppp object with unique marks\nsummary(marked_Yangon_ACLED_ppp)\n\nMarked planar point pattern:  1489 points\nAverage intensity 3.865152e-08 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 9 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   2.000   2.000   1.916   2.000   2.000 \n\nWindow: rectangle = [7470244, 7680669] x [3162567, 3345642] units\n                    (210400 x 183100 units)\nWindow area = 38523700000 square units\n\n\n\nplot(marked_Yangon_ACLED_ppp, main = \"Yangon Conflicts with Unique Marks\", cols = c(\"black\", \"red\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhy use mark and not jitter or delete for these duplicates?\nWhen dealing with conflict data, such as ACLED, uniquely marking events is essential to preserve both the spatial and temporal accuracy of key occurrences. Events often take place at the same location but during different time periods, and jittering the data would distort their true geographic positions, while deleting them would erase important historical information. By marking events as unique, we ensure that the dataset retains its integrity, allowing for the analysis of recurring conflicts without compromising precision. This approach ensures that both spatial and temporal patterns of conflict hotspots are maintained, which is crucial for understanding the dynamics of the events over time.\n\n\n\n\n\n5.3.1 Combining Point Events and State’s Owin Object\n\nYangonMandalay\n\n\n\nmarked_Yangon_ACLED_ppp[Yangon_Owin]\n\nMarked planar point pattern: 1489 points\nmarks are numeric, of storage type  'double'\nwindow: polygonal boundary\nenclosing rectangle: [7305087, 7698916] x [2582788, 3397886] units\n\n\n\nplot(marked_Yangon_ACLED_ppp[Yangon_Owin])"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-adaptive-vs-fixed-bandwidth",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-adaptive-vs-fixed-bandwidth",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "5.1 Setting up Adaptive vs Fixed Bandwidth",
    "text": "5.1 Setting up Adaptive vs Fixed Bandwidth\n6.1 Quarterly Kernel Density\n6.2"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#combining-them-both",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#combining-them-both",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "5.3 Combining them both",
    "text": "5.3 Combining them both\nFinally, we will merge the owin object (state boundary) and the spatial point pattern data (conflict events) into a single object. This combination ensures that:\n\nThe spatial window constrains the analysis, focusing on the area within each state’s boundary.\nAll conflict events are accurately represented within the confines of the defined boundary.\n\nThis step allows for robust spatial point pattern analysis, ensuring that both the boundaries and events are properly accounted for. With this merged object, we can perform advanced geospatial techniques, such as analyzing the distribution of conflict events, identifying hotspots, and calculating density functions within the state.\n\nYangonMandalaySagaing\n\n\n\nYangon_ACLED_ppp = Yangon_ACLED_ppp[Yangon_Owin]\nplot(Yangon_ACLED_ppp)\n\n\n\n\n\n\n\n\n\n\n\nMandalay_ACLED_ppp = Mandalay_ACLED_ppp[Mandalay_Owin]\nplot(Mandalay_ACLED_ppp)\n\n\n\n\n\n\n\n\n\n\n\nSagaing_ACLED_ppp = Sagaing_ACLED_ppp[Sagaing_Owin]\nplot(Sagaing_ACLED_ppp)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#getting-the-bandwidth",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#getting-the-bandwidth",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "5.6 getting the bandwidth",
    "text": "5.6 getting the bandwidth"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-the-owin-window-for-states.",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-the-owin-window-for-states.",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "5.1 Setting up the Owin Window for States.",
    "text": "5.1 Setting up the Owin Window for States.\nIn this step, we are setting up an owin object for each state using the spatstat package. An owin object defines the spatial window—or the boundary—within which our point pattern analysis will take place. Essentially, this window will encapsulate the polygonal boundary of each state, allowing us to focus on conflict data within those precise boundaries.\nTo create the owin object, we will:\n\nExtract the polygon boundaries for each state from the spatial data.\nConvert these boundaries into an owin object using the as.owin() function.\nThese spatial windows will ensure that all spatial operations, such as density estimation and pattern analysis, occur strictly within the boundaries of the specified state (e.g., Yangon, Mandalay, Sagaing).\n\nThis setup is crucial for ensuring that our spatial analysis focuses only on relevant geographic areas and doesn’t incorporate any points outside the boundaries.\n\nYangonMandalaySagaing\n\n\n\nYangon_Sf &lt;- M_State_Sf %&gt;% \n  filter(state %in% c(\"Yangon\"))\n# Step 1: Extract the individual polygons from the multipolygon\nyangon_polygons &lt;- st_cast(Yangon_Sf$geometry, \"POLYGON\")\nyangon_polygons_filtered &lt;- yangon_polygons[-c(1, 2)]\nyangon_multipolygon_filtered &lt;- st_combine(yangon_polygons_filtered)\n# Add the filtered multipolygon back to the Yangon_Sf object\nYangon_Sf$geometry &lt;- yangon_multipolygon_filtered\nYangon &lt;- as_Spatial(Yangon_Sf)\nYangon_Owin &lt;- as.owin(Yangon_Sf)\nplot(Yangon_Owin)\n\n\n\n\n\n\n\nsummary(Yangon_Owin)\n\nWindow: polygonal boundary\n6 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1            3832  9.84832e+09      1.00e+00\npolygon 2 (hole)        3 -1.78834e+02     -1.82e-08\npolygon 3              14  2.11571e+05      2.15e-05\npolygon 4              11  1.59536e+05      1.62e-05\npolygon 5              20  1.79201e+06      1.82e-04\npolygon 6              37  2.56010e+06      2.60e-04\nenclosing rectangle: [140506.53, 268404.01] x [1805599.6, 1970174] units\n                     (127900 x 164600 units)\nWindow area = 9853040000 square units\nFraction of frame area: 0.468\n\n\n\n\n\n# Filter the dataset to only include data for Mandalay state\nMandalay_Sf &lt;- M_State_Sf %&gt;% \n  filter(state %in% c(\"Mandalay\"))\n# Convert the Mandalay spatial dataframe into a Spatial Data Frame for further spatial operations\nMandalay &lt;- as_Spatial(Mandalay_Sf)\n\n# Convert the Mandalay spatial dataframe into an owin object for spatial point pattern analysis\nMandalay_Owin &lt;- as.owin(Mandalay_Sf)\n\n# Plot the owin object to visualize the boundaries of Mandalay\nplot(Mandalay_Owin)\n\n\n\n\n\n\n\n# Provide a summary of the owin object, showing its properties like dimensions and bounding box\nsummary(Mandalay_Owin)\n\nWindow: polygonal boundary\nsingle connected closed polygon with 5914 vertices\nenclosing rectangle: [66291.97, 282396.46] x [2234807.4, 2622191.5] units\n                     (216100 x 387400 units)\nWindow area = 30998600000 square units\nFraction of frame area: 0.37\n\n\n\n\n\n# Filter the dataset to only include data for Sagaing state\nSagaing_Sf &lt;- M_State_Sf %&gt;% \n  filter(state %in% c(\"Sagaing\"))\n\n# Convert the Sagaing spatial dataframe into a Spatial Data Frame for further spatial operations\nSagaing &lt;- as_Spatial(Sagaing_Sf)\n\n# Convert the Sagaing spatial dataframe into an owin object for spatial point pattern analysis\nSagaing_Owin &lt;- as.owin(Sagaing_Sf)\n# Plot the owin object to visualize the boundaries of Sagaing\nplot(Sagaing_Owin)\n\n\n\n\n\n\n\n# Provide a summary of the owin object, showing its properties like dimensions and bounding box\nsummary(Sagaing_Owin)\n\nWindow: polygonal boundary\nsingle connected closed polygon with 5882 vertices\nenclosing rectangle: [-17699.96, 308341.37] x [2390344.6, 3029739.1] units\n                     (326000 x 639400 units)\nWindow area = 9.3875e+10 square units\nFraction of frame area: 0.45"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "1.0 ~ 7.0 covers Global Measures of Spatial Autocorrelation\n8.0 onwards cover Local Measures of Spatial Autocorrelation"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#computing-queen-contiguity-based-neighbours",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#computing-queen-contiguity-based-neighbours",
    "title": "Spatial Weights and Applications",
    "section": "4.1 Computing (QUEEN) contiguity based neighbours",
    "text": "4.1 Computing (QUEEN) contiguity based neighbours\n\nComputing Queen Contiguity Weight Matrix\n\n\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE):\n\npoly2nb creates a neighborhood list based on polygon boundaries.\nhunan is the spatial polygon data (likely a SpatialPolygonsDataFrame or sf object).\nqueen=TRUE specifies that the Queen contiguity rule should be used. This means that two polygons are considered neighbors if they share at least one point (either a boundary or a corner).\nwm_q stores the neighborhood structure as an object.\n\nsummary(wm_q):\n\nThis provides a summary of the neighborhood list, showing how many neighbors each polygon has and other summary statistics.\n\n\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours.\n\n\n\n\nNeighboursGet Their NamesNeighbour NamesRetrieve the GDPPC of Neighbour countries With NamesList Each Country’s Neighbour\n\n\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, we use the following code chunk, to which we see they have 5 neighbours\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\n\n\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\n\n\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\n\n# Retrieve the GDPPC values for the neighbors and the first polygon\ngdp_values &lt;- c(hunan$GDPPC[1], hunan$GDPPC[nb1])\n\n# Retrieve the county names for the first polygon and its neighbors\ncounty_names &lt;- c(hunan$NAME_3[1], hunan$NAME_3[nb1])\n\n# Assign the county names as names of the GDPPC values\nnames(gdp_values) &lt;- county_names\n\n# Display the GDPPC values with county names\ngdp_values\n\nAnxiang Hanshou  Jinshi      Li     Nan Taoyuan \n  23667   20981   34592   24473   21311   22879 \n\n\n\n\n\n# Initialize a list to store the data for all polygons\ngdp_data &lt;- lapply(seq_along(wm_q), function(i) {\n  # Get the neighbors of polygon i\n  neighbors &lt;- wm_q[[i]]\n  \n  # Get the GDPPC values for the polygon and its neighbors\n  gdp_values &lt;- c(hunan$GDPPC[i], hunan$GDPPC[neighbors])\n  \n  # Get the county names for the polygon and its neighbors\n  county_names &lt;- c(hunan$NAME_3[i], hunan$NAME_3[neighbors])\n  \n  # Create a tibble for each polygon with neighbors\n  data &lt;- tibble(\n    Polygon = county_names[1],  # Main polygon name\n    Neighbor = county_names[-1],  # Neighbor names\n    GDPPC = gdp_values[-1],  # Neighbor GDPPC values\n    Neighbour_GDPPC = gdp_values[1]  # Main polygon GDPPC\n  )\n  \n  return(data)\n})\n\n# Combine all rows into a single data frame\ngdp_df &lt;- bind_rows(gdp_data)\n\n# View the combined data in a cleaner format\ngdp_df\n\n# A tibble: 448 × 4\n   Polygon Neighbor  GDPPC Neighbour_GDPPC\n   &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;           &lt;dbl&gt;\n 1 Anxiang Hanshou   20981           23667\n 2 Anxiang Jinshi    34592           23667\n 3 Anxiang Li        24473           23667\n 4 Anxiang Nan       21311           23667\n 5 Anxiang Taoyuan   22879           23667\n 6 Hanshou Anxiang   23667           20981\n 7 Hanshou Nan       21311           20981\n 8 Hanshou Yuanjiang 26258           20981\n 9 Hanshou Taojiang  19509           20981\n10 Hanshou Taoyuan   22879           20981\n# ℹ 438 more rows"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#creating-rook-contiguity-based-neighbours",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#creating-rook-contiguity-based-neighbours",
    "title": "Spatial Weights and Applications",
    "section": "4.2 Creating (ROOK) contiguity based neighbours",
    "text": "4.2 Creating (ROOK) contiguity based neighbours\n\nComputing Root Contiguity Weight Matrix\n\n\nInstead of queen true, we use False here\n\nwm_r  &lt;- poly2nb(hunan, queen= FALSE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan using the rook. The most connected area unit has 10 neighbours. There are two area units with only one heighbours.\n\n\n\n\nNeighboursGet Their NamesNeighbour NamesRetrieve the GDPPC of Neighbour countries With NamesList Each Country’s Neighbour\n\n\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, we use the following code chunk, to which we see they have 4 neighbours\n\nwm_r[[1]]\n\n[1]  3  4 57 85\n\n\n\n\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\n\n\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(3,4,57,85)]\n\n[1] \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_r[[1]]\n\n# Retrieve the GDPPC values for the neighbors and the first polygon\ngdp_values &lt;- c(hunan$GDPPC[1], hunan$GDPPC[nb1])\n\n# Retrieve the county names for the first polygon and its neighbors\ncounty_names &lt;- c(hunan$NAME_3[1], hunan$NAME_3[nb1])\n\n# Assign the county names as names of the GDPPC values\nnames(gdp_values) &lt;- county_names\n\n# Display the GDPPC values with county names\ngdp_values\n\nAnxiang  Jinshi      Li     Nan Taoyuan \n  23667   34592   24473   21311   22879 \n\n\n\n\n\n# Initialize a list to store the data for all polygons\ngdp_data &lt;- lapply(seq_along(wm_q), function(i) {\n  # Get the neighbors of polygon i\n  neighbors &lt;- wm_r[[i]]\n  \n  # Get the GDPPC values for the polygon and its neighbors\n  gdp_values &lt;- c(hunan$GDPPC[i], hunan$GDPPC[neighbors])\n  \n  # Get the county names for the polygon and its neighbors\n  county_names &lt;- c(hunan$NAME_3[i], hunan$NAME_3[neighbors])\n  \n  # Create a tibble for each polygon with neighbors\n  data &lt;- tibble(\n    Polygon = county_names[1],  # Main polygon name\n    Neighbor = county_names[-1],  # Neighbor names\n    GDPPC = gdp_values[-1],  # Neighbor GDPPC values\n    Neighbour_GDPPC = gdp_values[1]  # Main polygon GDPPC\n  )\n  \n  return(data)\n})\n\n# Combine all rows into a single data frame\ngdp_df &lt;- bind_rows(gdp_data)\n\n# View the combined data in a cleaner format\ngdp_df\n\n# A tibble: 440 × 4\n   Polygon Neighbor  GDPPC Neighbour_GDPPC\n   &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;           &lt;dbl&gt;\n 1 Anxiang Jinshi    34592           23667\n 2 Anxiang Li        24473           23667\n 3 Anxiang Nan       21311           23667\n 4 Anxiang Taoyuan   22879           23667\n 5 Hanshou Nan       21311           20981\n 6 Hanshou Yuanjiang 26258           20981\n 7 Hanshou Taojiang  19509           20981\n 8 Hanshou Taoyuan   22879           20981\n 9 Jinshi  Anxiang   23667           34592\n10 Jinshi  Li        24473           34592\n# ℹ 430 more rows"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#visualizing-contiguity-weights",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#visualizing-contiguity-weights",
    "title": "Spatial Weights and Applications",
    "section": "4.3 Visualizing Contiguity Weights",
    "text": "4.3 Visualizing Contiguity Weights\nTo create a connectivity graph for polygons, we first need to obtain points for each polygon, which can be done using their centroids. The centroids will serve as the points for the graph.\nThe process involves calculating the centroids using the sf package. Instead of directly using st_centroid on the spatial data object, we need to extract the centroid coordinates into a separate data frame. This is done by applying the st_centroid function to the geometry column of the spatial data using a mapping function (map_dbl from the purrr package).\nBy mapping st_centroid over the geometry column, we can extract the longitude (the first value in each centroid) using double bracket notation [[1]]. This prepares the longitude values for further use in creating the connectivity graph.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]]) #This allows us to get only the longitude, which is the first value in each centroid.\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]]) #We do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\ncoords &lt;- cbind(longitude, latitude) # Now that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\nhead(coords) #We check the first few observations to see if things are formatted correctly.\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n4.3.1 Plotting Contiguity based Neighbours Map\n\nQueen’sKing’sSide By Side Comparison\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#determine-cut-off-distance",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#determine-cut-off-distance",
    "title": "Spatial Weights and Applications",
    "section": "5.1 Determine Cut-Off Distance",
    "text": "5.1 Determine Cut-Off Distance\n\n# Extract the coordinates of the regions\n#coords &lt;- coordinates(hunan)\n\n# Find the k-nearest neighbors\nk1 &lt;- knn2nb(knearneigh(coords))\n# Calculate the distances between the neighbors\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\n# Display a summary of the distances\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#computing-fixed-and-adaptive-distance-weight-matrix",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#computing-fixed-and-adaptive-distance-weight-matrix",
    "title": "Spatial Weights and Applications",
    "section": "5.2 Computing Fixed and Adaptive Distance Weight Matrix",
    "text": "5.2 Computing Fixed and Adaptive Distance Weight Matrix\n\n\n\n\n\n\nNote\n\n\n\nWhen to use fixed or adaptive?\n\nFixed Distance Weighting: Use when spatial points are distributed evenly and when you want a constant radius of influence for all regions.\nAdaptive Distance Weighting: Use when spatial points are unevenly distributed and when you want each region to have a comparable number of neighbors, regardless of their physical distance.\n\n\n\n\nFixed DistanceAdaptive Distance\n\n\nCompute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\n\n\n\n\n\nNote\n\n\n\nQuiz: What is the meaning of “Average number of links: 3.681818” shown above?\n“Average number of links: 3.681818” refers to the average number of neighboring regions each region in the dataset has, based on the distance threshold defined earlier 62km.\n“Average number of links: 3.681818” means that, on average, each region has around 3.68 neighbors within a 62-kilometer radius.\n\n\nVisualizing the weight matrix\n\nneighbor_counts &lt;- data.frame(\n  County = hunan$County,\n  Neighbors = card(wm_d62)  # card() gives the number of neighbors for each region\n)\n\n# View the data frame\nprint(neighbor_counts)\n\n          County Neighbors\n1        Anxiang         5\n2        Hanshou         4\n3         Jinshi         4\n4             Li         3\n5          Linli         4\n6         Shimen         1\n7        Liuyang         2\n8      Ningxiang         4\n9      Wangcheng         4\n10         Anren         4\n11       Guidong         3\n12         Jiahe         5\n13         Linwu         4\n14       Rucheng         2\n15       Yizhang         1\n16      Yongxing         4\n17        Zixing         3\n18     Changning         3\n19      Hengdong         5\n20       Hengnan         5\n21      Hengshan         6\n22       Leiyang         4\n23        Qidong         3\n24        Chenxi         4\n25     Zhongfang         4\n26       Huitong         4\n27      Jingzhou         2\n28        Mayang         6\n29       Tongdao         2\n30      Xinhuang         1\n31          Xupu         2\n32      Yuanling         1\n33      Zhijiang         5\n34 Lengshuijiang         3\n35    Shuangfeng         6\n36        Xinhua         5\n37       Chengbu         2\n38        Dongan         3\n39       Dongkou         4\n40       Longhui         3\n41      Shaodong         5\n42       Suining         5\n43        Wugang         3\n44       Xinning         2\n45       Xinshao         6\n46      Shaoshan         5\n47    Xiangxiang         5\n48       Baojing         5\n49     Fenghuang         4\n50       Guzhang         6\n51       Huayuan         4\n52        Jishou         6\n53      Longshan         2\n54          Luxi         5\n55      Yongshun         4\n56         Anhua         1\n57           Nan         5\n58     Yuanjiang         5\n59      Jianghua         3\n60       Lanshan         4\n61      Ningyuan         5\n62     Shuangpai         4\n63       Xintian         5\n64       Huarong         4\n65      Linxiang         1\n66         Miluo         5\n67     Pingjiang         2\n68      Xiangyin         4\n69          Cili         2\n70       Chaling         3\n71        Liling         2\n72       Yanling         3\n73           You         4\n74       Zhuzhou         5\n75       Sangzhi         2\n76       Yueyang         3\n77        Qiyang         3\n78      Taojiang         2\n79      Shaoyang         4\n80      Lianyuan         5\n81     Hongjiang         5\n82      Hengyang         6\n83       Guiyang         4\n84      Changsha         4\n85       Taoyuan         2\n86      Xiangtan         4\n87           Dao         4\n88     Jiangyong         2\n\n# Or use View() in RStudio for an interactive table view\n\nPlotting It\n\nFirst Plot: The base map of the regions (Hunan) is drawn using their geographic boundaries.\nSecond Plot: The distance-based neighbor links are added, connecting regions that are within 62 km of each other.\nThird Plot: The k-nearest neighbor links are added as red arrows, showing the regions’ closest neighbors.\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\nComparing it against 1st nearest and distance link.\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, we can display the content of the matrix by using str().\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\nPlotting it and against 1st nearest and distance link\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(knn6, coords, add=TRUE, pch = 19, cex = 0.6)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#spatial-lag-with-row-standardized-weights",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#spatial-lag-with-row-standardized-weights",
    "title": "Spatial Weights and Applications",
    "section": "8.1 spatial lag with row-standardized weights",
    "text": "8.1 spatial lag with row-standardized weights\ncompute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\nlag.listw(rswm_q, hunan$GDPPC):\n\nThis calculates the spatial lag of GDP per capita (GDPPC) for each region using the row-standardized weights (rswm_q).\nFor each region, the function computes the weighted average of the GDPPC values of its neighboring regions.\nSince we are using row-standardized weights, the influence of each neighboring region is scaled based on the number of neighbors. If a region has 4 neighbors, each neighbor’s influence will be 1441​.\n\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nIn the earlier section, we retrieved the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: Can you see the meaning of Spatial lag with row-standardized weights now?\nThe spatial lag with row-standardized weights helps quantify the average impact of neighboring regions on a specific variable (e.g., GDP per capita). It shows how a region’s characteristics, such as economic performance, are influenced by its neighbors, with the weights for each region’s neighbors summing to 1 for consistency across regions.\n\nSpatial Lag: Represents the weighted average of a region’s neighbors’ values, with equal weight assigned to each neighbor in the row-standardized approach.\nRow-Standardized Weights: Since the sum of the weights for each region’s neighbors equals 1, the spatial lag becomes the arithmetic mean of its neighbors’ values. More neighbors dilute the influence of any single one.\nPractical Use: Spatial lag reflects how the GDP of neighboring regions affects a region’s own GDP. If there is a mismatch between a region’s GDP and that of its neighbors, this will be evident in the spatial lag, making it a valuable tool in spatial econometrics for understanding regional dynamics.\n\n\n\nAppend the spatially lag GDPPC Values\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\nhead(hunan)\n\nSimple feature collection with 6 features and 36 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3 Shape_Leng Shape_Area  County    City\n1 Changde 21098 Anxiang      County   1.869074 0.10056190 Anxiang Changde\n2 Changde 21100 Hanshou      County   2.360691 0.19978745 Hanshou Changde\n3 Changde 21101  Jinshi County City   1.425620 0.05302413  Jinshi Changde\n4 Changde 21102      Li      County   3.474325 0.18908121      Li Changde\n5 Changde 21103   Linli      County   2.289506 0.11450357   Linli Changde\n6 Changde 21104  Shimen      County   4.171918 0.37194707  Shimen Changde\n  avg_wage deposite     FAI Gov_Rev Gov_Exp     GDP GDPPC     GIO   Loan  NIPCR\n1    31935   5517.2  3541.0  243.64  1779.5 12482.0 23667  5108.9 2806.9 7693.7\n2    32265   7979.0  8665.0  386.13  2062.4 15788.0 20981 13491.0 4550.0 8269.9\n3    28692   4581.7  4777.0  373.31  1148.4  8706.9 34592 10935.0 2242.0 8169.9\n4    32541  13487.0 16066.0  709.61  2459.5 20322.0 24473 18402.0 6748.0 8377.0\n5    32667    564.1  7781.2  336.86  1538.7 10355.0 25554  8214.0  358.0 8143.1\n6    33261   8334.4 10531.0  548.33  2178.8 16293.0 27137 17795.0 6026.5 6156.0\n   Bed    Emp  EmpR EmpRT Pri_Stu Sec_Stu Household Household_R NOIP Pop_R\n1 1931 336.39 270.5 205.9  19.584  17.819     148.1       135.4   53 346.0\n2 2560 456.78 388.8 246.7  42.097  33.029     240.2       208.7   95 553.2\n3  848 122.78  82.1  61.7   8.723   7.592      81.9        43.7   77  92.4\n4 2038 513.44 426.8 227.1  38.975  33.938     268.5       256.0   96 539.7\n5 1440 307.36 272.2 100.8  23.286  18.943     129.1       157.2   99 246.6\n6 2502 392.05 329.6 193.8  29.245  26.104     190.6       184.7  122 399.2\n    RSCG Pop_T    Agri Service Disp_Inc      RORP    ROREmp lag GDPPC\n1 3957.9 528.3 4524.41   14100    16610 0.6549309 0.8041262  24847.20\n2 4460.5 804.6 6545.35   17727    18925 0.6875466 0.8511756  22724.80\n3 3683.0 251.8 2562.46    7525    19498 0.3669579 0.6686757  24143.25\n4 7110.2 832.5 7562.34   53160    18985 0.6482883 0.8312558  27737.50\n5 3604.9 409.3 3583.91    7031    18604 0.6024921 0.8856065  27270.25\n6 6490.7 600.5 5266.51    6981    19275 0.6647794 0.8407091  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nPlot both GDPPC and spatial Lag GDPPC for comparison.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#spatial-lag-as-a-sum-of-neighbouring-values",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#spatial-lag-as-a-sum-of-neighbouring-values",
    "title": "Spatial Weights and Applications",
    "section": "8.2 spatial lag as a sum of neighbouring values",
    "text": "8.2 spatial lag as a sum of neighbouring values\nCalculating the spatial lag by summing the GDP per capita (GDPPC) values of neighboring regions. Unlike row-standardized weights, where each neighbor’s value is averaged, here each neighbor’s GDPPC is simply added up without adjusting for the number of neighbors (since style = \"B\" is used, indicating binary weights). This approach gives an unweighted sum of neighboring values.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\n\nb_weights: A binary weight matrix where each neighbor is assigned a weight of 1. The function 0*x + 1 ensures that for each neighbor, the weight is 1, no matter the distance or number of neighbors.\nb_weights2: Converts the neighbor list wm_q to a binary weight matrix, meaning all neighboring polygons are equally weighted with no standardization.\n\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\n\nlag.listw(b_weights2, hunan$GDPPC): This function calculates the spatial lag as the sum of GDPPC values of neighboring regions based on the binary weights. It returns a vector of summed GDPPC values for each region.\nlag_sum: Combines the region names (hunan$NAME_3) with the spatial lag values (summed GDPPC) into a list.\nlag.res: Converts this list into a data frame and assigns appropriate column names (“NAME_3” and “lag_sum GDPPC”).\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: Can you understand the meaning of Spatial lag as a sum of neighboring values now?\nThis method of calculating spatial lag highlights the cumulative economic influence of neighboring regions. Regions with more neighbors will tend to have larger summed values, whereas regions with fewer neighbors may have lower sums, which can be important when considering spatial spillover effects.\n\nSpatial Lag as a Sum: In this approach, the spatial lag is the sum of the GDPPC values of a region’s neighbors. Unlike row-standardized weights where values are averaged, here each neighbor’s GDPPC is simply added up, emphasizing the total contribution from neighboring regions.\nExample: If a region has three neighbors with GDPPC values of 20000, 25000, and 30000, the spatial lag would be the sum of these values: 20000+25000+30000=7500020000 + 25000 + 30000 = 7500020000+25000+30000=75000.\n\n\n\n\nhunan &lt;- left_join(hunan, lag.res)\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#spatial-window-average",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#spatial-window-average",
    "title": "Spatial Weights and Applications",
    "section": "8.3 spatial window average",
    "text": "8.3 spatial window average\nmodifying the neighbor structure to include each polygon itself as its own neighbor (i.e., adding a diagonal element), followed by computing the spatial lag of the GDPPC (Gross Domestic Product Per Capita) for each region, and finally visualizing and comparing the results.\n\n8.3.1. Include Self in Neighbor List:\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\n\ninclude.self(wm_q): This function adds the diagonal element to the neighbor list, meaning that each region is now considered its own neighbor, in addition to its original neighbors.\n\nFor example, if region 1 originally had neighbors 2 and 3, after using include.self(), region 1 will now also be its own neighbor.\n\nwm_qs[[1]]: Displays the neighbors of region 1, which now includes itself.\n\n\n\n8.3.2. Convert to Weights List:\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\n\nnb2listw(wm_qs): Converts the updated neighbor list (with diagonal elements) into a weights list. This weights list will now include self-influence (i.e., each region is also its own neighbor with a certain weight).\nWeights List: The resulting object stores the spatial weights for each region based on its new neighbor structure (including itself).\n\n\n\n8.3.3 Calculate Spatial Lag (with Self):\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nlag.listw(wm_qs, hunan$GDPPC): Computes the spatial lag of the GDPPC values using the updated weights list (wm_qs). The spatial lag now includes the influence of the region itself, in addition to its neighbors.\n\nThis means that when calculating the spatial lag for a region, its own GDPPC value is considered in the weighted average along with its neighbors’ values.\n\n\n\n8.3.4. Store Results and Modify Data:\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\nhunan %&gt;%\n  select(\"County\", \"lag GDPPC\", \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\n\nStore Lag Results: A new list, lag.list.wm_qs, is created to store the names of the regions (hunan$NAME_3) and their corresponding spatial lag values.\nConvert to Data Frame: The list is converted into a data frame (lag_wm_qs.res), where each row contains a region’s name and its calculated spatial lag (including self).\nColumn Names: The columns are renamed for clarity, with lag_window_avg GDPPC indicating the spatial lag values, including the diagonal elements (self).\n\n\n\n8.3.5 Visualize the Results: and Interpret\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nAdding Self as a Neighbor: The code includes each region as its own neighbor, which means when calculating the spatial lag (the weighted average of neighboring values), the region’s own value is now part of the calculation.\nSpatial Lag Comparison: Two versions of the spatial lag are created:\n\nWithout self: The original spatial lag where only neighboring regions influence the lagged value.\nWith self: The spatial lag that includes the region’s own value in the weighted average."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#spatial-window-sum",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#spatial-window-sum",
    "title": "Spatial Weights and Applications",
    "section": "8.4 spatial window sum",
    "text": "8.4 spatial window sum\nThe spatial window sum calculates the sum of neighboring values for each region without using row-standardized weights. Unlike row-standardized weights, where each neighbor’s influence is normalized to ensure that the weights sum to 1, the spatial window sum uses binary weights (equal weight for each neighbor) but directly sums the values of the neighboring regions, including the region itself as its own neighbor (with the help of include.self()).\n\n8.4.1 Add Diagonal Element (Include Self as Neighbor):\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\ninclude.self(wm_q): This function modifies the neighbor list (wm_q) so that each region now considers itself as one of its neighbors. This allows the region’s own GDPPC value to be included when calculating the spatial sum\n\n\n8.4.2 Create Binary Weights: & Convert Neighbor to weight matrix\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\nb_weights2 &lt;- nb2listw(wm_qs, glist = b_weights, style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\n\nlapply(wm_qs, function(x) 0*x + 1): This creates binary weights, where each neighbor, including the region itself, is given a weight of 1. This means that when calculating the spatial sum, each neighboring region’s GDPPC is added without adjusting for the number of neighbors.\nExample of b_weights[1]: For the first region, this shows the binary weights assigned to its neighbors, which will all be 1 (since 0*x + 1 results in 1 for each neighbor).\nnb2listw(wm_qs, glist = b_weights, style = \"B\"): Converts the neighbor list with binary weights (b_weights) into a spatial weight matrix.\n\nstyle = \"B\" means the matrix is binary (each neighbor gets an equal weight of 1).\nThis weight matrix is used to calculate the spatial window sum, where each neighboring region’s value is simply summed up.\n\n\n\n\n8.4.3 Calculate Spatial Window Sum for GDPPC:\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\n\nlag.listw(b_weights2, hunan$GDPPC): This calculates the spatial window sum of the GDPPC values using the binary weights matrix (b_weights2). Each region’s GDPPC value and its neighbors’ GDPPC values are summed up directly.\nw_sum_gdppc: Stores the list of region names (hunan$NAME_3) along with the spatial window sum of GDPPC values for each region.\n\n\n\n8.4.4 visualise and interpret the results\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nSpatial Window Sum: This method calculates the sum of neighboring values without normalizing by the number of neighbors (i.e., without row-standardization). Each region’s value is added together with its neighbors’ values, including itself.\nCode Breakdown:\n\nFirst, the diagonal (self) element is added to the neighbor list using include.self().\nBinary weights (1 for each neighbor, including self) are applied to compute the spatial window sum using the lag.listw() function.\nThe spatial window sum is then visualized alongside the row-standardized spatial lag to compare the two approaches.\n\nComparison: The spatial window sum gives a total influence of neighbors, whereas row-standardized weights give an average influence. Both approaches offer different insights into the spatial relationships between regions."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#computing-contiguity-spatial-weights",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#computing-contiguity-spatial-weights",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "4.1 Computing Contiguity Spatial Weights",
    "text": "4.1 Computing Contiguity Spatial Weights\n\nComputing Contiguity Spatial Weights\n\n\n\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\nMore specifically, the code chunk below is used to compute Queen contiguity weight matrix.\n\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#row-standardised-weights-matrix",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#row-standardised-weights-matrix",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "4.2 Row-standardised weights matrix",
    "text": "4.2 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWhat can we learn from the code chunk above?\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#marons-i-test",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#marons-i-test",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "5.1 Maron’s I test",
    "text": "5.1 Maron’s I test\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\nNote\n\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\nStatistical Conclusion:\n\nSince the p-value is extremely small (1.095e-06), we reject the null hypothesis that there is no spatial autocorrelation in GDPPC.\nThe positive Moran’s I statistic (0.3007) indicates that there is significant positive spatial autocorrelation in GDPPC, meaning areas with similar GDPPC values tend to be located near each other.\nIn other words, high GDPPC values are clustered with other high GDPPC values, and low GDPPC values are clustered with other low GDPPC values.\n\nFinal Conclusion:\nThere is strong evidence of positive spatial autocorrelation in the GDP per capita (GDPPC) values across the regions, suggesting that the spatial distribution of GDPPC is not random, but rather exhibits a clustered pattern."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#computing-monte-carlo-morans-i",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#computing-monte-carlo-morans-i",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "5.2 Computing Monte Carlo Moran’s I",
    "text": "5.2 Computing Monte Carlo Moran’s I\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\nQuestion: What statistical conclustion can you draw from the output above?\nStatistical Conclusion:\n\nMoran’s I = 0.30075 suggests positive spatial autocorrelation, meaning similar GDPPC values cluster together in geographic space.\nThe p-value = 0.001 is highly significant (typically less than 0.05 is considered significant), allowing us to reject the null hypothesis that there is no spatial autocorrelation.\nSince the observed rank is 1000, it means the observed Moran’s I is the most extreme value compared to all simulated random distributions, indicating that the spatial pattern is very unlikely to have occurred by chance.\n\nFinal Conclusion:\nThere is strong evidence of positive spatial autocorrelation in the GDPPC values across the regions. The Monte Carlo simulation supports the conclusion that the clustering of similar GDPPC values is statistically significant, not random, with a very small probability (p-value = 0.001) of occurring under the null hypothesis of no spatial autocorrelation."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#visualising-monte-carlo-morans-i",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#visualising-monte-carlo-morans-i",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "5.3 Visualising Monte Carlo Moran’s I",
    "text": "5.3 Visualising Monte Carlo Moran’s I\nIn the code chunk below hist() and abline() of R Graphics are used.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n\n\nQuestion: What statistical observation can you draw from the output above?\n\nHistogram of Simulated Moran’s I:\n\nThe histogram shows the distribution of simulated Moran’s I values. The distribution is centered around 0 (as indicated by the red line) and shows a somewhat normal shape, which is expected under the null hypothesis of no spatial autocorrelation.\nThe distribution has a slight skew towards positive values, as seen from the histogram extending further to the right than the left.\n\nInterpretation:\n\nThe mean of the simulations is close to zero (-0.015), which is expected under the null hypothesis of no spatial autocorrelation.\nThe variance (0.00437) is relatively small, indicating that the values of the simulated Moran’s I are clustered around the mean, with few extreme values.\nThe histogram shows that most of the simulated Moran’s I values are concentrated between -0.1 and 0.1, with a slight positive skew.\nThe observed Moran’s I statistic (from your previous output) was 0.30075, which is much larger than the maximum simulated value (0.27593). This indicates that the observed value is an outlier and strongly suggests positive spatial autocorrelation that is unlikely to occur by chance.\n\nConclusion:\n\nThe histogram and summary statistics from the Monte Carlo simulation indicate that Moran’s I values under the null hypothesis of no spatial autocorrelation are generally distributed around zero.\nThe observed Moran’s I statistic (from earlier) of 0.30075 is much higher than almost all of the simulated values, which confirms that the observed spatial autocorrelation in GDPPC is statistically significant and unlikely to have occurred by random chance.\n\n\nChallenge: Plotting with Ggplot.\n\ndf &lt;- data.frame(simulated_moran = bperm$res)\n\n# Create the histogram with ggplot2\nggplot(df, aes(x = simulated_moran)) +\n  geom_histogram(bins = 20, fill = \"lightgray\", color = \"black\") +\n  geom_vline(xintercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(x = \"Simulated Moran's I\", y = \"Frequency\") +\n  theme_minimal() +\n  ggtitle(\"Histogram of Simulated Moran's I\")"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#gearys-c-test",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#gearys-c-test",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "6.1 Geary’s C test",
    "text": "6.1 Geary’s C test\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\nSince the Geary’s C statistic is less than 1 (0.6907), this suggests positive spatial autocorrelation in GDPPC, meaning similar GDPPC values tend to cluster together.\nThe p-value is highly significant (0.0001526), so we can reject the null hypothesis of no spatial autocorrelation.\nThis result indicates that there is significant positive spatial autocorrelation in GDPPC across the regions, with similar GDPPC values being geographically proximate."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#computing-monte-carlo-gearys-c",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#computing-monte-carlo-gearys-c",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "6.2 Computing Monte Carlo Geary’s C",
    "text": "6.2 Computing Monte Carlo Geary’s C\nThe code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\nThe Geary C statistic of 0.69072 (observed rank = 1) is significantly different from the values generated under the null hypothesis in the Monte Carlo simulation.\nThe p-value = 0.001 confirms that the observed positive spatial autocorrelation is statistically significant and unlikely to have occurred by random chance."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#visualising-the-monte-carlo-gearys-c",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#visualising-the-monte-carlo-gearys-c",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "6.3 Visualising the Monte Carlo Geary’s C",
    "text": "6.3 Visualising the Monte Carlo Geary’s C\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\") \n\n\n\n\n\n\n\n\n\nStatistical Observations:\n\nThe mean and median Geary’s C values from the Monte Carlo simulation are very close to 1, as expected under the null hypothesis of no spatial autocorrelation.\nThe distribution of simulated values is roughly normal and centered around 1, with most values falling within the range of 0.9 to 1.1.\nGeary’s C statistic for the observed data (0.6907 from your previous output) is much lower than the simulated values, suggesting that the observed spatial autocorrelation is statistically significant and unlikely to have occurred by random chance.\nThe p-value from the Monte Carlo simulation (0.001) indicates that the observed Geary’s C is significantly different from the values generated under the null hypothesis, further supporting the conclusion of positive spatial autocorrelation.\n\n\n\nConclusion:\nThe histogram and summary statistics show that under random conditions (null hypothesis), the Geary’s C statistic tends to be around 1. However, the observed value of 0.6907 is much lower, indicating positive spatial autocorrelation, with similar GDPPC values clustering together geographically. This result is statistically significant based on the Monte Carlo p-value (0.001)."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#spatial-correlogram",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#spatial-correlogram",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "7.0 Spatial Correlogram",
    "text": "7.0 Spatial Correlogram\nSpatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\n7.1 Compute Moran’s I correlogram\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\nBy plotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nQuestion: What statistical observation can you draw from the plot above?\n\n\nSignificant Spatial Autocorrelation at Lag 1 and Lag 2:\n\nLag 1: Moran’s I = 0.3007, with a p-value = 2.139e-06 (significant at the 0.001 level). This confirms strong positive spatial autocorrelation at the nearest neighbors.\nLag 2: Moran’s I = 0.2061, with a p-value = 2.029e-06 (significant at the 0.001 level). Spatial autocorrelation is still positive and significant, though weaker than at lag 1.\n\nLag 3: Moran’s I = 0.0668, p-value = 0.0404 (significant at the 0.05 level), showing very weak but statistically significant positive spatial autocorrelation.\nLag 4: Moran’s I = 0.0299, p-value = 0.226, indicating no significant spatial autocorrelation.\nSignificant Negative Spatial Autocorrelation at Lag 5 and Lag 6:\n\nLag 5: Moran’s I = -0.1530, with a p-value = 5.984e-05 (significant at the 0.001 level). This suggests negative spatial autocorrelation at this distance, meaning regions that are farther apart have dissimilar GDPPC values.\nLag 6: Moran’s I = -0.1187, with a p-value = 0.0088 (significant at the 0.01 level). This further indicates negative spatial autocorrelation at longer distances.\n\n\n\n\nSummary of Statistical Observations:\n\nStrong positive spatial autocorrelation is observed at lag 1 and lag 2, meaning that neighboring regions tend to have similar GDPPC values.\nWeak positive spatial autocorrelation is observed at lag 3, but it is close to insignificant.\nNegative spatial autocorrelation is observed at lags 5 and 6, meaning regions farther apart tend to have dissimilar GDPPC values.\nThe statistical significance of these findings is confirmed by the p-values: significant positive autocorrelation at shorter distances (lags 1 and 2) and significant negative autocorrelation at longer distances (lags 5 and 6).\n\nIn conclusion, GDPPC in the regions of Hunan exhibits significant clustering of similar values at short distances and dissimilar values at larger distances."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#compute-gearys-c-correlogram-and-plot",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#compute-gearys-c-correlogram-and-plot",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "7.2 Compute Geary’s C correlogram and plot",
    "text": "7.2 Compute Geary’s C correlogram and plot\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#compute-queen-contiguity-weight-matrix-with-spdep.",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#compute-queen-contiguity-weight-matrix-with-spdep.",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "9.1 Compute queen contiguity weight matrix with SPDEP.",
    "text": "9.1 Compute queen contiguity weight matrix with SPDEP.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#row-standardised-weights-matrix-1",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#row-standardised-weights-matrix-1",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "9.2 Row-standardised weights matrix",
    "text": "9.2 Row-standardised weights matrix\nassign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#computing-local-morans-i",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#computing-local-morans-i",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "9.3 Computing local Moran’s I",
    "text": "9.3 Computing local Moran’s I\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\nThe code chunk below list the content of the local Moran matrix derived by using printCoefmat().\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n9.3.1 Mapping the local Moran’s I\nBefore mapping the local Moran’s I map, it is wise to append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame. The code chunks below can be used to perform the task. The out SpatialPolygonDataFrame is called hunan.localMI.\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n9.3.2 Mapping local Moran’s I values\nUsing choropleth mapping functions of tmap package, we can plot the local Moran’s I values by using the code chinks below.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n9.3.3 Mapping local Moran’s I p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\nThe code chunks below produce a choropleth map of Moran’s I p-values by using functions of tmap package.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n9.3.4 Mapping both local Moran’s I values and p-values\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#plotting-moran-scatterplot-with-standardised-variable",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#plotting-moran-scatterplot-with-standardised-variable",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "10.2 Plotting Moran scatterplot with standardised variable",
    "text": "10.2 Plotting Moran scatterplot with standardised variable\nFirst we will use scale() to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% as.vector \n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.\nNow, we are ready to plot the Moran scatterplot again by using the code chunk below.\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#preparing-lisa-map-classes",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#preparing-lisa-map-classes",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "10.3 Preparing LISA map classes",
    "text": "10.3 Preparing LISA map classes\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext, derives the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\nThis is follow by centering the local Moran’s around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\nThese four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4      \n\nLastly, places non-significant Moran in the category 0.\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\nIn fact, we can combined all the steps into one single code chunk as shown below:\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I &lt;- localMI[,1]   \nsignif &lt;- 0.05       \nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4    \nquadrant[localMI[,5]&gt;signif] &lt;- 0"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#plotting-lisa-map",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#plotting-lisa-map",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "10.4 Plotting LISA map",
    "text": "10.4 Plotting LISA map\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\nWe can also include the local Moran’s I map and p-value map as shown below for easy comparison.\n\ntmap_arrange(localMI.map, pvalue.map, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nWhat Observation can you draw from the maps?\n\n\nHigh-High Clusters (Red): Wealthy regions are concentrated in the northeast, indicating strong clustering of high GDP per capita (GDPPC). These clusters are statistically significant with very low p-values (&lt; 0.001).\nLow-Low Clusters (Blue): Less wealthy regions are clustered in the southwest, showing spatial autocorrelation, but with less significance compared to the High-High areas.\nOutliers (Low-High and High-Low): Some regions exhibit disparities, where high GDPPC areas are surrounded by low GDPPC areas, but these are less prominent.\nSignificance: The northeastern High-High clusters show the strongest statistical significance, while other regions exhibit weaker clustering patterns."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#getis-and-ords-g-statistics",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#getis-and-ords-g-statistics",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "11.1 Getis and Ord’s G-Statistics",
    "text": "11.1 Getis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#deriving-distance-based-weight-matrix",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#deriving-distance-based-weight-matrix",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "11.2 Deriving distance-based weight matrix",
    "text": "11.2 Deriving distance-based weight matrix\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\n11.2.1 Deriving the centroid\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid(). We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n112.2 Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\nthe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n11.2.3 Computing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\nThe output spatial weights object is called wm62_lw."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "11.3 Computing adaptive distance weight matrix",
    "text": "11.3 Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#computing-gi-statistics",
    "href": "Hands_On_Exercises/Hands_On_Exercise_6/Hands_On_Exercise6.html#computing-gi-statistics",
    "title": "Hands on - 6 Global Measures of Spatial Autocorrelation & Local Measures of Spatial Autocorrelation",
    "section": "12 Computing Gi statistics",
    "text": "12 Computing Gi statistics\n\n12.1 Gi statistics using fixed distance\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nIn fact, the code chunk above performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\n\n12.2 Mapping Gi values with fixed distance weights\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nObservation\n\nHigh Gi Clusters (Red): The central-northeastern regions show significant clustering of high GDPPC (Gi &gt; 5), indicating these areas have high values of GDPPC surrounded by similarly high values. These clusters are statistically significant.\nLow Gi Clusters (Blue): The southwestern regions show low Gi values (Gi &lt; -2), indicating significant clustering of low GDPPC. These areas are clusters of low GDPPC surrounded by other low GDPPC areas.\nNeutral Areas: The rest of the region, indicated by lighter colors, exhibits less significant clustering or neutral values, showing that GDPPC in these areas is neither high nor low in a statistically significant sense.\n\nIn summary, the Gi map reveals significant clustering of high GDPPC in the northeast and low GDPPC in the southwest.\n\n\n12.3 Gi statistics using adaptive distance\nThe code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n12.4 Mapping Gi values with adaptive distance weights\nIt is time for us to visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n\n\n\nHigh Gi Clusters (Dark Red): The northeastern region shows significant clustering of high GDP per capita (GDPPC) (Gi &gt; 4), indicating that these areas have high GDPPC surrounded by other high GDPPC areas. This suggests a strong spatial concentration of wealth in this region.\nLow Gi Clusters (Dark Blue): The southwestern region shows significant clustering of low GDPPC (Gi &lt; -2), meaning that these areas have low GDPPC surrounded by other low GDPPC areas. This highlights a spatial concentration of less wealthy areas.\nModerate Clusters (Light Red/Blue): The areas with lighter red or blue shading represent less intense clustering but still show spatial associations of either high or low GDPPC.\n\nIn summary, the Gi map indicates strong clustering of high GDPPC in the northeast and low GDPPC clustering in the southwest, suggesting distinct areas of wealth and poverty."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-the-acled-spatial-class",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-the-acled-spatial-class",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "5.2 Setting up the ACLED Spatial Class",
    "text": "5.2 Setting up the ACLED Spatial Class\nAfter defining the owin window for each state, we need to convert the conflict data into a suitable spatial point pattern object (typically using spatstat’s ppp class). This class is essential for performing spatial point pattern analysis, as it links the geographic coordinates of conflict events to the state boundary.\nHere’s what we’ll do:\n\nWe will first ensure that the conflict data is transformed into the appropriate spatial projection (UTM or other applicable projections).\nThe conflict data points will be linked to the owin window to define where these events occur within the state’s boundary.\nThe result will be a ppp (point pattern) object, which is necessary for conducting spatial operations like density estimation, K-function analysis, or G-function analysis.\n\nThis step transforms our dataset into a fully spatially aware format, ready for statistical analysis.\n\nYangonMandalaySagaing\n\n\n\n# Extract the coordinates (longitude, latitude) from the Yangon spatial object\nYangon_ACLED_coords &lt;- st_coordinates(Yangon_ACLED_Data_Sf)\n\n# Define the bounding box (xmin, xmax, ymin, ymax) for Yangon, which sets the spatial extent of the window\nYangon_ACLED_bbox &lt;- st_bbox(Yangon_ACLED_Data_Sf)\n\n# Create the spatial window (owin object) for Yangon using the bounding box ranges\nYangon_ACLED_window &lt;- owin(xrange = Yangon_ACLED_bbox[c(\"xmin\", \"xmax\")], yrange = Yangon_ACLED_bbox[c(\"ymin\", \"ymax\")])\n\n# Create a ppp (point pattern) object for Yangon using the extracted coordinates and the defined window\nYangon_ACLED_ppp &lt;- ppp(x = Yangon_ACLED_coords[, 1], y = Yangon_ACLED_coords[, 2], window = Yangon_ACLED_window)\n# Check the summary of the ppp object to verify the number of points, window dimensions, and other properties\nsummary(Yangon_ACLED_ppp)\n\nPlanar point pattern:  1489 points\nAverage intensity 1.074751e-07 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 10 decimal places\n\nWindow: rectangle = [148595.03, 259745.55] x [1819680.1, 1944325.3] units\n                    (111200 x 124600 units)\nWindow area = 13854400000 square units\n\n# Plot the ppp object to visually inspect the spatial distribution of conflict points in Yangon\nplot(Yangon_ACLED_ppp)\n\n\n\n\n\n\n\n\n\n\n\n# Extract the coordinates (longitude, latitude) from the Mandalay spatial object\nMandalay_ACLED_coords &lt;- st_coordinates(Mandalay_ACLED_Data_Sf)\n\n# Define the bounding box (xmin, xmax, ymin, ymax) for Mandalay, which sets the spatial extent of the window\nMandalay_ACLED_bbox &lt;- st_bbox(Mandalay_ACLED_Data_Sf)\n\n# Create the spatial window (owin object) for Mandalay using the bounding box ranges\nMandalay_ACLED_window &lt;- owin(xrange = Mandalay_ACLED_bbox[c(\"xmin\", \"xmax\")], yrange = Mandalay_ACLED_bbox[c(\"ymin\", \"ymax\")])\n\n# Create a ppp (point pattern) object for Mandalay using the extracted coordinates and the defined window\nMandalay_ACLED_ppp &lt;- ppp(x = Mandalay_ACLED_coords[, 1], y = Mandalay_ACLED_coords[, 2], window = Mandalay_ACLED_window)\n\n# Check the summary of the ppp object to verify the number of points, window dimensions, and other properties\nsummary(Mandalay_ACLED_ppp)\n\nPlanar point pattern:  2021 points\nAverage intensity 3.011815e-08 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nWindow: rectangle = [68129.21, 255317.22] x [2261880.7, 2620356.6] units\n                    (187200 x 358500 units)\nWindow area = 67102400000 square units\n\n# Plot the ppp object to visually inspect the spatial distribution of conflict points in Mandalay\nplot(Mandalay_ACLED_ppp)\n\n\n\n\n\n\n\n\n\n\n\n# Extract the coordinates (longitude, latitude) from the Sagaing spatial object\nSagaing_ACLED_coords &lt;- st_coordinates(Sagaing_ACLED_Data_Sf)\n\n# Define the bounding box (xmin, xmax, ymin, ymax) for Sagaing, which sets the spatial extent of the window\nSagaing_ACLED_bbox &lt;- st_bbox(Sagaing_ACLED_Data_Sf)\n\n# Create the spatial window (owin object) for Sagaing using the bounding box ranges\nSagaing_ACLED_window &lt;- owin(xrange = Sagaing_ACLED_bbox[c(\"xmin\", \"xmax\")], yrange = Sagaing_ACLED_bbox[c(\"ymin\", \"ymax\")])\n\n# Create a ppp (point pattern) object for Sagaing using the extracted coordinates and the defined window\nSagaing_ACLED_ppp &lt;- ppp(x = Sagaing_ACLED_coords[, 1], y = Sagaing_ACLED_coords[, 2], window = Sagaing_ACLED_window)\n# Check the summary of the ppp object to verify the number of points, window dimensions, and other properties\nsummary(Sagaing_ACLED_ppp)\n\nPlanar point pattern:  5346 points\nAverage intensity 3.762491e-08 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 13 decimal places\n\nWindow: rectangle = [-16397.05, 256586.9] x [2393568.1, 2914062.9] units\n                    (273000 x 520500 units)\nWindow area = 1.42087e+11 square units\n\n# Plot the ppp object to visually inspect the spatial distribution of conflict points in Sagaing\nplot(Sagaing_ACLED_ppp)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhy dont you jitter, delete or mark any conflicts here?\nThe reason I did not apply jittering, deletion, or marking of the conflicts at this stage is that all the conflicts are unique and occurred across different time zones. Since there is no overlap in terms of exact location or time, it makes no sense to modify the data at this point. We will consider jittering later if we find that events are clustered too closely together in space, but for now, each conflict is distinct, and no adjustments are necessary."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-a-function-to-create-quarterly-for-each-state",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-a-function-to-create-quarterly-for-each-state",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "7.1 Setting up a function to create quarterly for each state",
    "text": "7.1 Setting up a function to create quarterly for each state\nWe will create a function that takes the conflict data for each state and computes the quarterly KDE. This function will:\n\nFilter the conflict events by quarter.\nApply the KDE to estimate the spatial density of events for that quarter.\nReturn a KDE layer that can be used for visualization and analysis.\n\n\n\nFull Code\n\n\nprocess_quarter_conflicts &lt;- function(region_sf, region_window, region_name, data_sf, sigma_type, kernel_method) {\n  # Extract unique quarters (reversed for correct order)\n  quarters &lt;- rev(unique(data_sf$quarter_year))\n  \n  # Initialize empty lists to store ppp and KDE objects\n  region_quarters_conflict &lt;- list()\n  kde_plot_list &lt;- list()\n  \n  # Step 2: Loop over each quarter and process conflict data\n  for (quarter in quarters) {\n    # Filter the data for the current quarter\n    quarter_data &lt;- data_sf %&gt;%\n      filter(quarter_year == quarter)\n    \n    # Extract coordinates for this quarter\n    quarter_coords &lt;- st_coordinates(quarter_data)\n    \n    # Create a ppp object for this quarter\n    quarter_ppp &lt;- ppp(\n      x = quarter_coords[, 1],\n      y = quarter_coords[, 2],\n      window = region_window\n    )\n    \n    # Step 3: Remove rejected points that fall outside the window\n    valid_points &lt;- inside.owin(quarter_ppp$x, quarter_ppp$y, region_window)\n    quarter_ppp &lt;- quarter_ppp[valid_points]\n    \n    # Step 4: Jitter duplicates to avoid overplotting\n    is_duplicate &lt;- duplicated(quarter_ppp)\n    jittered_x &lt;- quarter_ppp$x + ifelse(is_duplicate, runif(npoints(quarter_ppp), -0.1, 0.1), 0)\n    jittered_y &lt;- quarter_ppp$y + ifelse(is_duplicate, runif(npoints(quarter_ppp), -0.1, 0.1), 0)\n    \n    # Create a jittered ppp object with the new coordinates\n    jittered_ppp &lt;- ppp(\n      x = jittered_x,\n      y = jittered_y,\n      window = region_window\n    )\n    \n    # Step 5: Store the jittered ppp object for later use\n    region_quarters_conflict[[quarter]] &lt;- jittered_ppp\n    \n    # Step 6: Rescale to kilometers and calculate KDE with specified sigma type and kernel method\n    jittered_ppp_km &lt;- rescale(jittered_ppp, 1000, \"km\")\n    \n    # Use selected sigma type\n    if (sigma_type == \"scott\") {\n      sigma_value &lt;- bw.scott(jittered_ppp_km)\n      kde_quarter &lt;- density(jittered_ppp_km, sigma = bw.scott(jittered_ppp_km), edge = TRUE, kernel = kernel_method)\n    } else if (sigma_type == \"diggle\") {\n      sigma_value &lt;- bw.scott(jittered_ppp_km)\n      kde_quarter &lt;- density(jittered_ppp_km, sigma = bw.diggle(jittered_ppp_km), edge = TRUE, kernel = kernel_method)\n    } else if (sigma_type == \"ppl\") {\n      sigma_value &lt;- bw.scott(jittered_ppp_km)\n      kde_quarter &lt;- density(jittered_ppp_km, sigma = bw.ppl(jittered_ppp_km), edge = TRUE, kernel = kernel_method)\n    } else if (sigma_type == \"cvl\") {\n      sigma_value &lt;- bw.scott(jittered_ppp_km)\n      kde_quarter &lt;- density(jittered_ppp_km, sigma = bw.CvL(jittered_ppp_km), edge = TRUE, kernel = kernel_method)\n    } else {\n      stop(\"Invalid sigma_type specified.\")\n    }\n    \n    # Step 7: Store the KDE object for later use\n    kde_plot_list[[quarter]] &lt;- kde_quarter\n    \n    # Print a message after processing each quarter\n    print(paste(\"KDE - Quarter:\", quarter, \"| Kernel:\", kernel_method, \"| Sigma:\", sigma_type, \" | Sigma Value: \", sigma_value))\n  }\n  \n  # Return the processed ppp and KDE objects\n  return(list(\n    \"ppp_list\" = region_quarters_conflict,\n    \"kde_list\" = kde_plot_list\n  ))\n}"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-a-function-to-display-the-visual-across-quarters",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-a-function-to-display-the-visual-across-quarters",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "7.2 Setting up a function to display the visual across quarters",
    "text": "7.2 Setting up a function to display the visual across quarters\nNext, we will create a function to visualize the KDE layers for each quarter, enabling us to compare the intensity of conflict events over time. The function will:\n\nTake the KDE layers from each quarter.\nDisplay them side by side or as an animation to show how conflict density changes across quarters.\nThis visualization will help us observe trends, including whether conflicts are becoming more localized or dispersed over time.\n\n\n# Visualization Function for Conflict Points and KDE\nvisualize_conflict_results &lt;- function(results, region_name, sigma_type, kernel_method) {\n  ppp_list &lt;- results$ppp_list\n  kde_list &lt;- results$kde_list\n  \n  # Plotting Kernel Density Estimates (KDE) for each quarter\n  kde_plots &lt;- lapply(names(kde_list), function(quarter) {\n    kde_data &lt;- as.data.frame(as.im(kde_list[[quarter]]))\n    \n    ggplot() +\n      geom_raster(data = kde_data, aes(x = x, y = y, fill = value), alpha = 0.8) +\n      scale_fill_viridis_c(option = \"inferno\", name = \"Density\") +\n      labs(title = paste(\"KDE for Civilian Conflict\", region_name, \"-\", quarter)) +\n      theme_void() +  # Removes axis, background, and grid\n      theme(\n        plot.title = element_text(hjust = 0.5, face = \"bold\", size = 10, margin = margin(t = 10, b = 10)),  # Centers and adds margin to the title\n        plot.margin = margin(t = 5, r = 5, b = 5, l = 5)  # Adjusts the margin around the plot\n      )\n  })\n  \n  # Combine all plots into a grid layout with a main title\n  kde_grid &lt;- grid.arrange(grobs = kde_plots, ncol = 4, top = textGrob(\n    paste(region_name, \" Civilian Conflicts KDE By\", sigma_type, \"Using\", kernel_method, \"Kernel\"),\n    gp = gpar(fontface = \"bold\", fontsize = 16)\n  ))\n  \n  return(kde_grid)\n}"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#states-quarterly-kernel-density-estimation.",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#states-quarterly-kernel-density-estimation.",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "7.3 State’s Quarterly Kernel Density estimation.",
    "text": "7.3 State’s Quarterly Kernel Density estimation.\nFor each state, we will calculate and visualize the Kernel Density Estimation (KDE) using two different kernels. We focus on (You can use any we are flexible in the function above!)\n\nKernel 1: Gaussian Kernel\nKernel 2: Epanechnikov Kernel\n\nThe Gaussian Kernel is smooth and gives a global view of the density, whereas the Epanechnikov Kernel is more efficient and provides sharper boundaries, making it easier to identify clusters or hotspots.\nWe will also compute the KDE with different bandwidths, which controls the smoothness of the density estimates. A larger bandwidth results in smoother KDE, while a smaller bandwidth captures more local variations.\n\n7.3.1 Yangon\n\n7.3.1.1 Kernel 1: Gaussian Kernel\n\nDiggleScottCvLPPL\n\n\n\nYangon_Results_Diggle_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Yangon_Sf,\n  region_window = Yangon_Owin,\n  region_name = \"Yangon\",\n  data_sf = Yangon_ACLED_Data_Sf,\n  sigma_type = \"diggle\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\n# Step 4: Visualize the results with a main title\nvisualizations &lt;- visualize_conflict_results(Yangon_Results_Diggle_Gaussian, \"Yangon\", \"Diggle\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\nYangon_Results_Scott_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Yangon_Sf,\n  region_window = Yangon_Owin,\n  region_name = \"Yangon\",\n  data_sf = Yangon_ACLED_Data_Sf,\n  sigma_type = \"scott\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\n# Step 4: Visualize the results with a main title\nYangon_Results_Scott_Gaussian_Visualisation &lt;- visualize_conflict_results(Yangon_Results_Scott_Gaussian, \"Yangon\", \"Scott\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\nYangon_Results_CvL_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Yangon_Sf,\n  region_window = Yangon_Owin,\n  region_name = \"Yangon\",\n  data_sf = Yangon_ACLED_Data_Sf,\n  sigma_type = \"cvl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nYangon_Results_CvL_Gaussian_visualizations &lt;- visualize_conflict_results(Yangon_Results_CvL_Gaussian, \"Yangon\", \"CvL\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\nYangon_Results_PPL_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Yangon_Sf,\n  region_window = Yangon_Owin,\n  region_name = \"Yangon\",\n  data_sf = Yangon_ACLED_Data_Sf,\n  sigma_type = \"ppl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\n# Step 4: Visualize the results with a main title\nYangon_Results_PPL_Gaussian_visualizations &lt;- visualize_conflict_results(Yangon_Results_PPL_Gaussian, \"Yangon\", \"PPL\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.1.2 Kernel 2: Epanechnikov Kernel\n\nDiggleScottCvLPPL\n\n\n\nYangon_Results_Diggle_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Yangon_Sf,\n  region_window = Yangon_Owin,\n  region_name = \"Yangon\",\n  data_sf = Yangon_ACLED_Data_Sf,\n  sigma_type = \"diggle\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nYangon_Results_Diggle_Epanechnikov_visualizations &lt;- visualize_conflict_results(Yangon_Results_Diggle_Epanechnikov, \"Yangon\", \"Diggle\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\nYangon_Results_Scott_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Yangon_Sf,\n  region_window = Yangon_Owin,\n  region_name = \"Yangon\",\n  data_sf = Yangon_ACLED_Data_Sf,\n  sigma_type = \"scott\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nYangon_Results_Scot_Epanechnikov_visualizations &lt;- visualize_conflict_results(Yangon_Results_Scott_Epanechnikov, \"Yangon\", \"Scott\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\nYangon_Results_CvL_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Yangon_Sf,\n  region_window = Yangon_Owin,\n  region_name = \"Yangon\",\n  data_sf = Yangon_ACLED_Data_Sf,\n  sigma_type = \"cvl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nYangon_Results_CvL_Epanechnikov_visualizations &lt;- visualize_conflict_results(Yangon_Results_CvL_Epanechnikov, \"Yangon\", \"CvL\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\nYangon_Results_PPL_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Yangon_Sf,\n  region_window = Yangon_Owin,\n  region_name = \"Yangon\",\n  data_sf = Yangon_ACLED_Data_Sf,\n  sigma_type = \"ppl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nYangon_Results_PPL_Epanechnikov_visualizations &lt;- visualize_conflict_results(Yangon_Results_PPL_Epanechnikov, \"Yangon\", \"PPL\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.1.3 Analysis and Interpretation.\n\nWe used Scott’s bandwidth and the Epanechnikov kernel to model the spatial distribution of civilian conflicts in Yangon from 2021 to 2024. Scott’s method provides an optimal balance between bias and variance, ensuring smoother KDE without losing significant details. The Epanechnikov kernel minimizes error and focuses on areas with higher density, effectively capturing conflict hotspots while reducing the impact of outliers.\nKey Observations:\n\nCentral Yangon Hotspot: Conflict density remains consistently high in central Yangon throughout the period.\nTemporal Shifts: Conflict intensity fluctuates across quarters, peaking in certain periods (e.g., Q3-2022 and Q1-2024), with some spread into surrounding areas over time.\nDensity Spread: While central areas remain the most affected, the gradual spread suggests an intensification or expansion of conflicts.\n\nIn summary, Scott’s bandwidth and the Epanechnikov kernel provided a precise view of conflict clustering and temporal changes, revealing critical patterns in civilian-related conflict hotspots in Yangon.\n\n\n\n7.3.2 Mandalay\n\n7.3.2.1 Mandalay Kernel 1: Gaussian Kernel\n\nDiggleScottCvLPPL\n\n\n\nMandalay_Results_Diggle_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Mandalay_Sf,\n  region_window = Mandalay_Owin,\n  region_name = \"Mandalay\",\n  data_sf = Mandalay_ACLED_Data_Sf,\n  sigma_type = \"diggle\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nMandalay_Results_Diggle_Gaussian_visualizations &lt;- visualize_conflict_results(Mandalay_Results_Diggle_Gaussian, \"Mandalay\", \"Diggle\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\nMandalay_Results_Scott_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Mandalay_Sf,\n  region_window = Mandalay_Owin,\n  region_name = \"Mandalay\",\n  data_sf = Mandalay_ACLED_Data_Sf,\n  sigma_type = \"scott\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nMandalay_Results_Scott_Gaussian_visualizations &lt;- visualize_conflict_results(Mandalay_Results_Scott_Gaussian, \"Mandalay\", \"Scott\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\nMandalay_Results_CvL_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Mandalay_Sf,\n  region_window = Mandalay_Owin,\n  region_name = \"Mandalay\",\n  data_sf = Mandalay_ACLED_Data_Sf,\n  sigma_type = \"cvl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nMandalay_Results_CvL_Gaussian_visualizations &lt;- visualize_conflict_results(Mandalay_Results_CvL_Gaussian, \"Mandalay\", \"CvL\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\nMandalay_Results_PPL_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Mandalay_Sf,\n  region_window = Mandalay_Owin,\n  region_name = \"Mandalay\",\n  data_sf = Mandalay_ACLED_Data_Sf,\n  sigma_type = \"ppl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nMandalay_Results_PPL_Gaussian_visualizations &lt;- visualize_conflict_results(Mandalay_Results_PPL_Gaussian, \"Mandalay\", \"PPL\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.2.2 Mandalay Kernel 2: Epanechnikov Kernel\n\nDiggleScottCvLPPL\n\n\n\nMandalay_Results_Diggle_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Mandalay_Sf,\n  region_window = Mandalay_Owin,\n  region_name = \"Mandalay\",\n  data_sf = Mandalay_ACLED_Data_Sf,\n  sigma_type = \"diggle\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nMandalay_Results_Diggle_Epanechnikov_visualizations &lt;- visualize_conflict_results(Mandalay_Results_Diggle_Epanechnikov, \"Mandalay \", \"Diggle\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\nMandalay_Results_Scott_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Mandalay_Sf,\n  region_window = Mandalay_Owin,\n  region_name = \"Mandalay\",\n  data_sf = Mandalay_ACLED_Data_Sf,\n  sigma_type = \"scott\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nMandalay_Results_Scott_Epanechnikov_visualizations &lt;- visualize_conflict_results(Mandalay_Results_Scott_Epanechnikov, \"Mandalay \", \"Scott\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\nMandalay_Results_CvL_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Mandalay_Sf,\n  region_window = Mandalay_Owin,\n  region_name = \"Mandalay \",\n  data_sf = Mandalay_ACLED_Data_Sf,\n  sigma_type = \"cvl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nMandalay_Results_CvL_Epanechnikov_visualizations &lt;- visualize_conflict_results(Mandalay_Results_CvL_Epanechnikov, \"Mandalay \", \"CvL\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\nMandalay_Results_PPL_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Mandalay_Sf,\n  region_window = Mandalay_Owin,\n  region_name = \"Mandalay\",\n  data_sf = Mandalay_ACLED_Data_Sf,\n  sigma_type = \"ppl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nMandalay_Results_PPL_Epanechnikov_visualizations &lt;- visualize_conflict_results(Mandalay_Results_PPL_Epanechnikov, \"Mandalay \", \"PPL\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.2.3 Analysis and Interpretation\n\nWe applied Scott’s bandwidth and the Epanechnikov kernel for the Mandalay civilian conflict KDE, as it provides optimal smoothing and reduces variance. The kernel effectively focuses on dense areas, capturing conflict intensity over time without distortion from outliers.\nKey Observations:\n\nCentral Mandalay Hotspot: Consistent conflict density is observed in central Mandalay across all quarters, with peaks in Q3-2022 and Q1-2023.\nSpatiotemporal Patterns: Conflict density fluctuates quarter by quarter, with spread toward the north in several periods, indicating shifts in conflict zones.\nStability vs Spread: While central Mandalay remains a key hotspot, the spread of conflicts over time suggests areas of emerging concern.\n\nThis KDE approach reveals both stable hotspots and the evolving nature of conflicts in Mandalay, providing insights into the intensity and movement of conflict zones across different periods.\n\n\n\n7.3.3 Sagaing\n\n7.3.3.1 Sagaing Kernel 1: Gaussian Kernel\n\nDiggleScottCvLPPL\n\n\n\nSagaing_Results_Diggle_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Sagaing_Sf,\n  region_window = Sagaing_Owin,\n  region_name = \"Sagaing\",\n  data_sf = Sagaing_ACLED_Data_Sf,\n  sigma_type = \"diggle\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nSagaing_Results_Diggle_Gaussian_visualizations &lt;- visualize_conflict_results(Sagaing_Results_Diggle_Gaussian, \"Sagaing\", \"Diggle\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\nSagaing_Results_Scott_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Sagaing_Sf,\n  region_window = Sagaing_Owin,\n  region_name = \"Sagaing\",\n  data_sf = Sagaing_ACLED_Data_Sf,\n  sigma_type = \"scott\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nSagaing_Results_Scott_Gaussian_visualizations &lt;- visualize_conflict_results(Sagaing_Results_Scott_Gaussian, \"Sagaing\", \"Scott\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\nSagaing_Results_CVL_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Sagaing_Sf,\n  region_window = Sagaing_Owin,\n  region_name = \"Sagaing\",\n  data_sf = Sagaing_ACLED_Data_Sf,\n  sigma_type = \"cvl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nSagaing_Results_CVL_Gaussian_visualizations &lt;- visualize_conflict_results(Sagaing_Results_CVL_Gaussian, \"Sagaing\", \"CVL\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\nSagaing_Results_PPL_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Sagaing_Sf,\n  region_window = Sagaing_Owin,\n  region_name = \"Sagaing\",\n  data_sf = Sagaing_ACLED_Data_Sf,\n  sigma_type = \"ppl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nSagaing_Results_PPL_Gaussian_visualizations &lt;- visualize_conflict_results(Sagaing_Results_PPL_Gaussian, \"Sagaing\", \"PPL\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.3.2 Sagaing Kernel 2: Epanechnikov Kernel\n\nDiggleScottCvLPPL\n\n\n\nSagaing_Results_Diggle_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Sagaing_Sf,\n  region_window = Sagaing_Owin,\n  region_name = \"Sagaing\",\n  data_sf = Sagaing_ACLED_Data_Sf,\n  sigma_type = \"diggle\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nSagaing_Results_Diggle_Epanechnikov_visualizations &lt;- visualize_conflict_results(Sagaing_Results_Diggle_Epanechnikov, \"Sagaing\", \"Diggle\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\nSagaing_Results_Scott_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Sagaing_Sf,\n  region_window = Sagaing_Owin,\n  region_name = \"Sagaing\",\n  data_sf = Sagaing_ACLED_Data_Sf,\n  sigma_type = \"scott\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nSagaing_Results_Scott_Epanechnikov_visualizations &lt;- visualize_conflict_results(Sagaing_Results_Scott_Epanechnikov, \"Sagaing\", \"Scott\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\nSagaing_Results_Cvl_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Sagaing_Sf,\n  region_window = Sagaing_Owin,\n  region_name = \"Sagaing\",\n  data_sf = Sagaing_ACLED_Data_Sf,\n  sigma_type = \"cvl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nSagaing_Results_CvL_Epanechnikov_visualizations &lt;- visualize_conflict_results(Sagaing_Results_Cvl_Epanechnikov, \"Sagaing\", \"CvL\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\nSagaing_Results_PPL_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Sagaing_Sf,\n  region_window = Sagaing_Owin,\n  region_name = \"Sagaing\",\n  data_sf = Sagaing_ACLED_Data_Sf,\n  sigma_type = \"ppl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nSagaing_Results_PPL_Epanechnikov_visualizations &lt;- visualize_conflict_results(Sagaing_Results_PPL_Epanechnikov, \"Sagaing\", \"PPL\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.3.3 Analysis and Interpretation\n\nIn Sagaing, we again utilized Scott’s bandwidth and the Epanechnikov kernel for KDE to assess the spatiotemporal distribution of civilian conflict events. This method ensures that key dense areas are well-represented while minimizing the impact of noise from less significant areas.\nKey Observations:\n\nConsistent Hotspot: The southern region of Sagaing consistently shows high-density conflict areas throughout the quarters, especially peaking during Q3-2022 and Q1-2023.\nEmerging Zones: Some quarters, such as Q1-2022 and Q3-2023, show increased conflict spread to the north, indicating a potential shift in conflict locations.\nStability and Peaks: The core conflict areas maintain their intensity, while certain periods experience an expansion of conflict areas, with a notable rise in density during the mid-2022 period.\n\nThese patterns highlight that conflict zones in Sagaing are relatively stable with periods of increased intensity, particularly in southern areas. This provides critical insights into when and where civilian conflict events have intensified."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#yangon-6",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#yangon-6",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "8.1 Yangon",
    "text": "8.1 Yangon\nFor the Yangon conflict events, we’ll perform a detailed spatial point pattern analysis using the Clark-Evans test, Ripley’s K-function, and L-function. This will help us understand whether the conflict events are randomly distributed, clustered, or dispersed, and at what scales clustering occurs.\n\nNull and Alternative Hypothesis:\n\nHo (Null Hypothesis): The distribution of civilian-related conflicts in Yangon is randomly distributed (CSR: Complete Spatial Randomness).\nH1 (Alternative Hypothesis): The distribution of civilian-related conflicts in Yangon is not randomly distributed (it is clustered or dispersed).\n\n\n\n8.1.1 Yangon’s Clark and Evan Test\n\n# Perform the Clark-Evans test for clustering\nYangon_ClarksEvan &lt;- clarkevans.test(Yangon_ACLED_ppp, \n                                      correction = \"none\", \n                                      clipregion = Yangon_Owin, \n                                      alternative = c(\"clustered\"),\n                                      nsim = 30)\n\n# Print Clark-Evans p-value and R-statistic\nprint(Yangon_ClarksEvan)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  Yangon_ACLED_ppp\nR = 0.11849, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n8.1.2 Yangon’s K-Function Method\n\nK-FunctionEnvelope Test\n\n\n\nK_Yangon &lt;- Kest(Yangon_ACLED_ppp, correction = \"Ripley\")\n\n\n# Step 2: Plot the K-function, showing K(d) - r\nplot(K_Yangon, . -r ~ r, ylab = \"K(d) - r\", xlab = \"d(KM)\", main = \"Ripley's K-Function for Yangon Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\nK_Yangon_CSR &lt;- envelope(Yangon_ACLED_ppp, Kest, nsim = 30, rank = 1, global = TRUE)\n\n\nplot(K_Yangon_CSR, . - r ~ r, xlab = \"d(KM\", ylab = \"K(d) - r\", main = \"Envelope for K-Function (CSR) - Yangon Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\n\n8.1.2.2 Yangon’s K-Function Method Observation Table\n\n# Step 1: Define key distances (e.g., 20000m, 30000m, 40000m)\nkey_distances &lt;- c(5, 10, 15,20,25)\n\n# Step 2: Extract observed K-function values and CSR bounds at distances closest to key distances\nclosest_indices &lt;- sapply(key_distances, function(d) which.min(abs(K_Yangon_CSR$r - d)))\n\n# Step 3: Create a table summarizing observed and CSR envelope bounds at the closest distances\nobserved_table &lt;- data.frame(\n  Distance = K_Yangon_CSR$r[closest_indices],       # Actual distances used in the analysis\n  K_Obs = K_Yangon_CSR$obs[closest_indices],        # Observed K-function values\n  K_Lo = K_Yangon_CSR$lo[closest_indices],          # Lower bound of CSR envelope\n  K_Hi = K_Yangon_CSR$hi[closest_indices]           # Upper bound of CSR envelope\n)\n\n# Display the observed table\nprint(observed_table)\n\n  Distance     K_Obs       K_Lo      K_Hi\n1  4.99309  1822.917   35.71503  120.9307\n2  9.98618  5226.240  270.68366  355.8994\n3 14.97927  8118.862  662.29805  747.5137\n4 20.02663  9683.831 1217.37812 1302.5938\n5 25.01972 10687.263 1923.98668 2009.2024\n\n\n\n\n\n8.1.2 Yangon’s L Functions\n\nL FunctionEnvelope Test\n\n\n\nL_Yangon &lt;- Lest(Yangon_ACLED_ppp, correction = \"Ripley\")\n\n\nplot(L_Yangon, . -r ~ r, ylab = \"L(d) - r\", xlab = \"d(KM)\", main = \"Ripley's L-Function for Yangon Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\nL_Yangon_CSR &lt;- envelope(Yangon_ACLED_ppp, Lest, nsim = 30, rank = 1, global = TRUE, savefuns = TRUE)\n\n\nplot(L_Yangon_CSR, . - r ~ r, xlab = \"d(km)\", ylab = \"L(d) - r\", main = \"Envelope for L-Function (CSR) - Yangon Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.1.2.2 Yangon’s L Functions Observation Table\n\nkey_distances &lt;- c(5, 10, 15,20,25)\n# Step 2: Extract observed K-function values and CSR bounds at distances closest to key distances\nclosest_indices &lt;- sapply(key_distances, function(d) which.min(abs(L_Yangon_CSR$r - d)))\n# Step 3: Create a table summarizing observed and CSR envelope bounds at the closest distances\nobserved_table &lt;- data.frame(\n  Distance = L_Yangon_CSR$r[closest_indices],       # Actual distances used in the analysis\n  L_Obs = L_Yangon_CSR$obs[closest_indices],        # Observed K-function values\n  L_Lo = L_Yangon_CSR$lo[closest_indices],          # Lower bound of CSR envelope\n  L_Hi = L_Yangon_CSR$hi[closest_indices]           # Upper bound of CSR envelope\n)\n# Display the observed table\nprint(observed_table)\n\n  Distance    L_Obs      L_Lo      L_Hi\n1  4.99309 24.08843  4.836161  5.150019\n2  9.98618 40.78681  9.829251 10.143108\n3 14.97927 50.83615 14.822341 15.136198\n4 20.02663 55.51990 19.869703 20.183561\n5 25.01972 58.32548 24.862793 25.176651\n\n\n\n\n8.1.4 Yangons- Analysis and Interpretation\nBased on the analysis of the Clark-Evans test, K-function, and L-function, we can draw the following conclusions:\n\nClark-Evans Test:\n\nR = 0.099924, p-value &lt; 2.2e-16 . The R-value is less than 1, and the p-value is very small, which means the civilian related conflict events in Yangon are not randomly distributed and are significantly clustered.\n\nK-function Analysis:\n\n\nThe observed K-function consistently exceeds the upper bound of the CSR envelope across all distances, indicating that the clustering is prominent over a wide range of distances (up to 25km). The clustering becomes more pronounced as the distance increases.\n\nL-function Analysis:\nx\n\nThe observed L-function also exceeds the CSR envelope’s upper bounds, confirming the presence of clustering at multiple spatial scales. This supports the findings from the K-function.\n\n\nObserved Tables:\n\n\n\n\n\n\n\n\n\n\n\n\nDistance\nK_Obs\nK_Lo\nK_Hi\nL_OBV\nL_Lo\nL_Hi\n\n\n\n\n4.99309\n1822.917\n35.71503\n120.9307\n24.0883\n4.836161\n5.150019\n\n\n9.98618\n5226.240\n270.68366\n355.8994\n40.78681\n9.829251\n10.14311\n\n\n14.97927\n8118.682\n662.29806\n747.5137\n50.83615\n14.82234\n15.1362\n\n\n20.02663\n9683.831\n1217.37812\n1302.5938\n55.5199\n19.8697\n20.18356\n\n\n25.01972\n10687.263\n1923.98668\n2009.202\n53.32548\n24.86279\n25.17665\n\n\n\n\nThe observed K-function and L-function tables confirm that the observed values are significantly higher than the expected values under CSR, particularly at distances of 5km, 10km, 15km, and beyond, suggesting clustering at larger spatial scales.\n\n\n\nWe reject the null hypothesis of Complete Spatial Randomness (CSR) for Yangon civilian-related conflicts. The Clark-Evans test shows significant clustering, and both the K-function and L-function support this finding by indicating clustering over a broad range of distances. The observed tables further confirm this, as the observed values consistently exceed the CSR bounds. Therefore, the civilian conflict events in Yangon are significantly clustered rather than randomly distributed."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#mandalay-6",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#mandalay-6",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "8.2 Mandalay",
    "text": "8.2 Mandalay\nFor the Mandalay conflict events, we’ll perform a detailed spatial point pattern analysis using the Clark-Evans test, Ripley’s K-function, and L-function. This will help us understand whether the conflict events are randomly distributed, clustered, or dispersed, and at what scales clustering occurs.\n\nNull and Alternative Hypothesis:\n\nHo (Null Hypothesis): The distribution of civilian-related conflicts in Mandalay is randomly distributed (CSR: Complete Spatial Randomness).\nH1 (Alternative Hypothesis): The distribution of civilian-related conflicts in Mandalay is not randomly distributed (it is clustered or dispersed).\n\n\n\n8.2.1 Clarks Evan Test\n\n# Perform the Clark-Evans test for clustering\nMandalay_ClarksEvan &lt;- clarkevans.test(Mandalay_ACLED_ppp, \n                              correction = \"none\", \n                              clipregion = Mandalay_Owin, \n                              alternative = c(\"clustered\"),\n                              nsim = 30)\n# Print Clark-Evans p-value and R-statistic\nprint(Mandalay_ClarksEvan)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  Mandalay_ACLED_ppp\nR = 0.2192, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n8.2.2 K Function\n\nK-Function DataK-Function Envelope Test\n\n\n\nK_Mandalay &lt;- Kest(Mandalay_ACLED_ppp, correction = \"Ripley\")\n\n\nplot(K_Mandalay, . -r ~ r, ylab = \"K(d) - r\", xlab = \"d(KM)\", main = \"Ripley's K-Function for Mandalay Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\nK_Mandalay_CSR &lt;- envelope(Mandalay_ACLED_ppp, Kest, nsim = 30, rank = 1, global = TRUE)\n\n\nplot(K_Mandalay_CSR, . -r ~ r, ylab = \"K(d) - r\", xlab = \"d(Km)\", main = \"Ripley's K-Function for Mandalay Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\n\n8.2.2.2 Observed Table (K-Function at Key Distances)\n\n# Step 1: Define key distances (e.g., 20000m, 30000m, 40000m)\nkey_distances &lt;- c(10,20,30,40)\n\n# Step 2: Extract observed K-function values and CSR bounds at distances closest to key distances\nclosest_indices &lt;- sapply(key_distances, function(d) which.min(abs(K_Mandalay_CSR$r - d)))\n\n# Step 3: Create a table summarizing observed and CSR envelope bounds at the closest distances\nobserved_table &lt;- data.frame(\n  Distance = K_Mandalay_CSR$r[closest_indices],       # Actual distances used in the analysis\n  K_Obs = K_Mandalay_CSR$obs[closest_indices],        # Observed K-function values\n  K_Lo = K_Mandalay_CSR$lo[closest_indices],          # Lower bound of CSR envelope\n  K_Hi = K_Mandalay_CSR$hi[closest_indices]           # Upper bound of CSR envelope\n)\n\n# Display the observed table\nprint(observed_table)\n\n   Distance     K_Obs      K_Lo      K_Hi\n1  9.962643  7305.334  260.9636  362.6693\n2 20.016687 10852.795 1207.8820 1309.5878\n3 29.979331 15847.857 2772.6858 2874.3915\n4 40.033374 21114.336 4984.0867 5085.7925\n\n\n\n\n\n8.2.3 L Function\n\nMandalay L FunctionMandalay Envelope Test\n\n\n\nL_Mandalay &lt;- Lest(Mandalay_ACLED_ppp, correction = \"Ripley\")\n\n\nplot(L_Mandalay, . -r ~ r, ylab = \"L(d) - r\", xlab = \"d(KM)\", main = \"Ripley's L-Function for Mandalay Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\nL_Mandalay_CSR &lt;- envelope(Mandalay_ACLED_ppp, Lest, nsim = 30, rank = 1, global = TRUE, savefuns = TRUE)\n\n\nplot(L_Mandalay_CSR, . - r ~ r, xlab = \"d(KM)\", ylab = \"L(d) - r\", main = \"Envelope for L-Function (CSR) - Mandalay Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\n\n8.2.3.2 Observed Table (L-Function at Key Distances)\n\nkey_distances &lt;- c(10,20,30,40)\n\n# Step 2: Extract observed K-function values and CSR bounds at distances closest to key distances\nclosest_indices &lt;- sapply(key_distances, function(d) which.min(abs(L_Mandalay_CSR$r - d)))\n\n# Step 3: Create a table summarizing observed and CSR envelope bounds at the closest distances\nobserved_table &lt;- data.frame(\n  Distance = L_Mandalay_CSR$r[closest_indices],       # Actual distances used in the analysis\n  L_Obs = L_Mandalay_CSR$obs[closest_indices],        # Observed K-function values\n  L_Lo = L_Mandalay_CSR$lo[closest_indices],          # Lower bound of CSR envelope\n  L_Hi = L_Mandalay_CSR$hi[closest_indices]           # Upper bound of CSR envelope\n)\n\n# Display the observed table\nprint(observed_table)\n\n   Distance    L_Obs      L_Lo     L_Hi\n1  9.962643 48.22199  9.689332 10.23595\n2 20.016687 58.77544 19.743376 20.29000\n3 29.979331 71.02485 29.706020 30.25264\n4 40.033374 81.98111 39.760063 40.30669\n\n\n\n\n\n8.2.4 Mandalay- Analysis and Interpretation\nBased on the analysis of the Clark-Evans test, K-function, and L-function, we can draw the following conclusions:\n\nClark-Evans Test:\n\nR = 0.14898, p-value &lt; 2.2e-16. The R-value is less than 1, and the p-value is very small, which means the civilian related conflict events in Mandalay are not randomly distributed and are significantly clustered.\n\nK-function Analysis:\n\n\nThe observed K-function consistently exceeds the upper bound of the CSR envelope across all distances, indicating that the clustering is prominent over a wide range of distances (up to 70km). The clustering becomes more pronounced as the distance increases.\n\nL-function Analysis:\n\n\nThe observed L-function also exceeds the CSR envelope’s upper bounds, confirming the presence of clustering at multiple spatial scales. This supports the findings from the K-function.\n\nObserved Tables:\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistance\nK_Obs\nK_Lo\nK_Hi\nL_Obs\nL_Lo\nL_Hi\n\n\n\n\n9.962643\n7305.334\n260.9636\n362.6693\n48.22199\n9.689332\n10.23595\n\n\n20.016687\n10852.795\n1207.8820\n1309.5878\n58.77544\n19.743376\n20.2900\n\n\n29.979331\n15847.857\n2772.6858\n2874.3915\n71.02485\n29.706020\n30.25264\n\n\n40.033374\n21114.336\n4984.0867\n5085.7925\n81.9811\n39.760063\n40.30\n\n\n\n\nThe observed K-function and L-function tables confirm that the observed values are significantly higher than the expected values under CSR, particularly at distances of 20km, 30km, 40km, and beyond, suggesting clustering at larger spatial scales.\n\nWe reject the null hypothesis of Complete Spatial Randomness (CSR) for Mandalay civilian-related conflicts. The Clark-Evans test shows significant clustering, and both the K-function and L-function support this finding by indicating clustering over a broad range of distances. The observed tables further confirm this, as the observed values consistently exceed the CSR bounds. Therefore, the civilian conflict events in Mandalay are significantly clustered rather than randomly distributed."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#sagaing-5",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#sagaing-5",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "8.3 Sagaing",
    "text": "8.3 Sagaing\nFor the Sagaing conflict events, we’ll perform a detailed spatial point pattern analysis using the Clark-Evans test, Ripley’s K-function, and L-function. This will help us understand whether the conflict events are randomly distributed, clustered, or dispersed, and at what scales clustering occurs.\n\nNull and Alternative Hypothesis:\n\nHo (Null Hypothesis): The distribution of civilian-related conflicts in Sagaing is randomly distributed (CSR: Complete Spatial Randomness).\nH1 (Alternative Hypothesis): The distribution of civilian-related conflicts in Sagaing is not randomly distributed (it is clustered or dispersed).\n\n\n\n8.3.1 Clarks Evan Test\n\n# Perform the Clark-Evans test for clustering\nSagaing_ClarksEvan &lt;- clarkevans.test(Sagaing_ACLED_ppp, \n                              correction = \"none\", \n                              clipregion = Sagaing_Owin, \n                              alternative = c(\"clustered\"),\n                              nsim = 30)\n# Print Clark-Evans p-value and R-statistic\nprint(Sagaing_ClarksEvan)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  Sagaing_ACLED_ppp\nR = 0.1827, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\nK-Function MethodEnvelope Test\n\n\n\nK_Sagaing &lt;- Kest(Sagaing_ACLED_ppp, correction = \"Ripley\")\n\n\nplot(K_Sagaing, . -r ~ r, ylab = \"K(d) - r\", xlab = \"d(KM)\", main = \"Ripley's K-Function for Sagaing Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\nK_Sagaing_CSR &lt;- envelope(Sagaing_ACLED_ppp, Kest, nsim = 30, rank = 1, global = TRUE)\n\n\nplot(K_Sagaing_CSR, . - r ~ r, xlab = \"d(KM)\", ylab = \"K(d) - r\", main = \"Envelope for K-Function (CSR) - Sagaing Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\n\n8.3.2.2 Observed Table (K-Function at Key Distances)\n\n# Step 1: Define key distances (e.g., 20000m, 30000m, 40000m)\nkey_distances &lt;- c(20,30,40,50,60,70)\n\n# Step 2: Extract observed K-function values and CSR bounds at distances closest to key distances\nclosest_indices &lt;- sapply(key_distances, function(d) which.min(abs(K_Sagaing_CSR$r - d)))\n\n# Step 3: Create a table summarizing observed and CSR envelope bounds at the closest distances\nobserved_table &lt;- data.frame(\n  Distance = K_Sagaing_CSR$r[closest_indices],       # Actual distances used in the analysis\n  K_Obs = K_Sagaing_CSR$obs[closest_indices],        # Observed K-function values\n  K_Lo = K_Sagaing_CSR$lo[closest_indices],          # Lower bound of CSR envelope\n  K_Hi = K_Sagaing_CSR$hi[closest_indices]           # Upper bound of CSR envelope\n)\n\n# Display the observed table\nprint(observed_table)\n\n  Distance     K_Obs      K_Lo      K_Hi\n1 19.99394  7021.421  1186.336  1325.415\n2 29.99091 12903.634  2756.181  2895.260\n3 39.98788 19530.590  4953.964  5093.043\n4 49.98485 26873.240  7779.685  7918.764\n5 59.98182 34286.168 11233.343 11372.422\n6 68.24599 40939.246 14562.475 14701.554\n\n\n\n\n\n8.3.3 L-Function Method\n\nL FunctionEnvelope Test\n\n\n\n# Step 1: Calculate the L-function (Ripley's L) for Sagaing conflicts\nL_Sagaing &lt;- Lest(Sagaing_ACLED_ppp, correction = \"Ripley\")\n\n\n# Step 2: Plot the L-function, showing L(d) - r\nplot(L_Sagaing, . - r ~ r, ylab = \"L(d) - r\", xlab = \"d(km)\", main = \"Ripley's L-Function for Sagaing Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\nL_Sagaing_CSR &lt;- envelope(Sagaing_ACLED_ppp, Lest, nsim = 30, rank = 1, global = TRUE)\n\n\nplot(L_Sagaing_CSR, . - r ~ r, xlab = \"d(KM)\", ylab = \"K(d) - r\", main = \"Envelope for L-Function (CSR) - Sagaing Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\n\n8.3.3.3 Observed Table (L-Function at Key Distances)\n\nkey_distances &lt;- c(20,30,40,50,60,70)\n\n# Step 2: Extract observed K-function values and CSR bounds at distances closest to key distances\nclosest_indices &lt;- sapply(key_distances, function(d) which.min(abs(L_Sagaing_CSR$r - d)))\n\n# Step 3: Create a table summarizing observed and CSR envelope bounds at the closest distances\nobserved_table &lt;- data.frame(\n  Distance = L_Sagaing_CSR$r[closest_indices],       # Actual distances used in the analysis\n  L_Obs = L_Sagaing_CSR$obs[closest_indices],        # Observed K-function values\n  L_Lo = L_Sagaing_CSR$lo[closest_indices],          # Lower bound of CSR envelope\n  L_Hi = L_Sagaing_CSR$hi[closest_indices]           # Upper bound of CSR envelope\n)\n\n# Display the observed table\nprint(observed_table)\n\n  Distance     L_Obs     L_Lo     L_Hi\n1 19.99394  47.27566 19.81300 20.17488\n2 29.99091  64.08864 29.80997 30.17185\n3 39.98788  78.84656 39.80694 40.16882\n4 49.98485  92.48793 49.80391 50.16579\n5 59.98182 104.46830 59.80088 60.16277\n6 68.24599 114.15501 68.06505 68.42693\n\n\n\n\n\n8.3.4 Sagaing - Analysis and Interpretation\nBased on the analysis of the Clark-Evans test, K-function, and L-function, we can draw the following conclusions:\n\nClark-Evans Test:\n\nR = 0.1485, p-value &lt; 2.2e-16 . The R-value is less than 1, and the p-value is very small, which means the conflict events in Sagaing are not randomly distributed and are significantly clustered.\n\nK-function Analysis:\n\n\nThe observed K-function consistently exceeds the upper bound of the CSR envelope across all distances, indicating that the clustering is prominent over a wide range of distances (up to 70km). The clustering becomes more pronounced as the distance increases.\n\nL-function Analysis:\n\n\nThe observed L-function also exceeds the CSR envelope’s upper bounds, confirming the presence of clustering at multiple spatial scales. This supports the findings from the K-function.\n\nObserved Tables:\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistance\nK_Obs\nK_Lo\nK_Hi\nL_Obs\nL_Lo\nL_Hi\n\n\n\n\n19.99394\n7021.421\n1186.336\n1325.415\n19.81300\n20.17488\n20.17488\n\n\n29.99091\n12903.634\n2756.181\n2895.260\n64.08864\n29.80997\n30.17185\n\n\n39.98788\n19530.590\n4963.964\n5093.043\n78.84656\n39.80694\n40.16882\n\n\n49.98485\n26873.240\n7797.685\n7916.764\n92.48793\n49.80391\n50.16579\n\n\n59.98182\n34286.168\n11233.343\n11372.422\n104.46830\n59.80088\n60.16277\n\n\n68.24599\n40939.246\n1456,475\n14701.554\n114.15501\n68.06505\n68.4269\n\n\n\n\nThe observed K-function and L-function tables confirm that the observed values are significantly higher than the expected values under CSR, particularly at distances of 20km, 30km, 40km, and beyond, suggesting clustering at larger spatial scales.\n\nWe reject the null hypothesis of Complete Spatial Randomness (CSR) for Sagaing civilian-related conflicts. The Clark-Evans test shows significant clustering, and both the K-function and L-function support this finding by indicating clustering over a broad range of distances. The observed tables further confirm this, as the observed values consistently exceed the CSR bounds. Therefore, the conflict events in Sagaing are significantly clustered rather than randomly distributed."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#steps-for-code-breakdown.",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#steps-for-code-breakdown.",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "9.1 Steps for code Breakdown.",
    "text": "9.1 Steps for code Breakdown.\n\nStep 1: Convert data to sf object to ensure compatibility for spatial analysis.\nStep 2: Extract longitude and latitude from the geometry column for plotting and analysis.\nStep 3: Create numeric and factor representations of quarters for time-based KDE and distinct plotting.\nStep 4: Generate a point pattern object (ppp) for spatial analysis with quarter factors as marks.\nStep 5: Assign circle sizes to each quarter for visual differentiation.\nStep 6: Plot the base map (Yangon) without data points.\nStep 7: Add points with sizes based on quarters to the map for visualization.\nStep 8: Add a legend to explain the circle sizes and quarters.\nStep 9: Create a numeric point pattern for KDE based on quarter information.\nStep 10: Perform KDE analysis on the spatio-temporal point pattern.\nStep 11: Define the quarters to be plotted for KDE analysis.\nStep 12: Set up a 4x4 plotting grid to display multiple KDE plots.\nStep 13: Loop through quarters and plot KDE layers for each, visualizing conflict intensity over time."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#yangon-quarter-year-spatio-temporal-kde",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#yangon-quarter-year-spatio-temporal-kde",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "9.2 Yangon Quarter Year Spatio-Temporal KDE",
    "text": "9.2 Yangon Quarter Year Spatio-Temporal KDE\n\nCode PreparationYangon Quarter Year OwinYangon Quarter Year KDEYangon Quarter Year KDE Animation And Analysis\n\n\n\n# Step 1: Ensure Yangon_QuarterYear_Sf is an sf object (if not already)\nYangon_QuarterYear_Sf &lt;- st_as_sf(Yangon_ACLED_Data_Sf)\n\n# Step 2: Extract the coordinates (longitude and latitude) from the geometry column\ncoords &lt;- st_coordinates(Yangon_QuarterYear_Sf)\n\n# Step 3: Convert quarter_numeric to factor for distinct quarters (for plotting the circles)\nYangon_QuarterYear_Sf &lt;- Yangon_QuarterYear_Sf %&gt;%\n  mutate(\n    year = as.numeric(sub(\".*-\", \"\", quarter_year)),                  # Extract the year (e.g., 2023)\n    quarter = as.numeric(sub(\"Q\", \"\", sub(\"-.*\", \"\", quarter_year))), # Extract the quarter (e.g., Q1 -&gt; 1)\n    \n    # Continuous representation of time (factor for distinct quarters)\n    quarter_numeric_factor = as.factor(year * 10 + quarter),  # Convert to factor for plotting the circles\n    quarter_numeric = year * 10 + quarter  # Keep as numeric for time-based KDE analysis\n  )\n\n# Step 4: Create the point pattern object using ppp() with factor marks (for distinct quarter plotting)\nYangon_QuarterYear_PPP_Factor &lt;- ppp(\n  x = coords[, 1],  # Longitude (x-coordinates)\n  y = coords[, 2],  # Latitude (y-coordinates)\n  window = Yangon_Owin,  # Spatial window (Yangon_Owin)\n  marks = Yangon_QuarterYear_Sf$quarter_numeric_factor  # Use factor for visualizing distinct quarters\n)\n\n\n# Step 5: Assign 14 unique sizes to the 14 unique quarter_numeric values\n# Create 14 different circle sizes, e.g., from 1 to 3 in size\nunique_quarters &lt;- levels(Yangon_QuarterYear_Sf$quarter_numeric_factor)  # Get the unique quarter levels (14 levels)\ncircle_sizes &lt;- seq(1, 3, length.out = length(unique_quarters))  # Generate 14 sizes from 1 to 3\n\n# Map each unique quarter_numeric level to a circle size\ncircle_size_map &lt;- setNames(circle_sizes, unique_quarters)  # Create a named vector to map quarter to size\n\n\n\n\n# Apply the circle size mapping to each point based on its quarter_numeric_factor\npoint_circle_sizes &lt;- circle_size_map[Yangon_QuarterYear_Sf$quarter_numeric_factor]\n\n# Step 6: Plot the base map (Yangon_Owin) without points\nplot(Yangon_Owin, main = \"Yangon Quarter-Year Owin with Unique Circle Sizes\")\n\n# Step 7: Add the points with the unique circle sizes based on quarter_numeric\npoints(coords[, 1], coords[, 2], cex = point_circle_sizes, pch = 16, col = \"black\")  # Add circles on top of base map\n\n# Step 8: Add a custom legend to show the quarter_numeric values and corresponding circle sizes\nlegend(\"topright\", legend = unique_quarters, \n       pch = 16, \n       pt.cex = circle_sizes,  # Show unique circle sizes in the legend\n       col = \"black\", \n       title = \"Quarters (Circle Size)\")\n\n\n\n\n\n\n\n\n\n\n\nYangon_QuarterYear_PPP_Numeric &lt;- ppp(\n  x = coords[, 1],  # Longitude (x-coordinates)\n  y = coords[, 2],  # Latitude (y-coordinates)\n  window = Yangon_Owin,  # Spatial window (Yangon_Owin)\n  marks = Yangon_QuarterYear_Sf$quarter_numeric  # Use numeric for KDE analysis (time-based)\n)\nYangon_QuarterYear_PPP_Numeric &lt;- rescale(Yangon_QuarterYear_PPP_Numeric, 1000, \"km\")\n\n\nYangon_QuarterYear_KDE &lt;- spattemp.density(Yangon_QuarterYear_PPP_Numeric)\n\nmulti_color_palette &lt;- colorRampPalette(c(\"blue\", \"green\", \"yellow\", \"red\"))\n\n\n# Define the quarters for which you want to plot the KDE\ntims &lt;- c(20211, 20212, 20213, 20214, 20221, 20222, 20223, 20224, \n          20231, 20232, 20233, 20234, 20241, 20242)\n\n#Set up the plotting window to display multiple plots in a grid (4 rows, 4 columns)\npar(mfrow=c(4, 4), mar=c(2, 2, 2, 2), oma=c(0, 0, 2, 0))  # Adjust margins and add outer margin for title\n\n# Loop through the 'tims' vector and plot the KDE for each time point (from left to right)\nfor(i in tims) { \n    plot(Yangon_QuarterYear_KDE, i, \n         override.par=FALSE,  # Keep the graphical parameters unchanged\n         fix.range=TRUE,      # Fix the range of the KDE\n         main=paste(\"Quarter\", i),  # Title for each plot\n         ribside = \"right\", \n         col = multi_color_palette(100))  # Use 'inferno' color gradient\n         \n    # Remove the x and y axis labels for a cleaner look\n    axis(1, labels=FALSE)\n    axis(2, labels=FALSE)\n}\n\n#dd a unified title across all plots (e.g., the duration of analysis)\nmtext(\"Quarterly Spatio-Temporal KDE for Civilian Conflict Intensity in Yangon\", \n      outer=TRUE, cex=1.5, font=2)\n\n\n\n\n\n\n\n\n\n\n\nmulti_color_palette &lt;- colorRampPalette(c(\"blue\", \"green\", \"yellow\", \"red\"))\n\n# Save the animation as a GIF\nsaveGIF({\n  # Loop over the valid quarter times\n  for(i in tims){ \n    suppressWarnings({\n      plot(Yangon_QuarterYear_KDE, i, \n           override.par=FALSE,  # Keep graphical parameters unchanged\n           fix.range=TRUE,      # Fix the range of the KDE\n           main=paste(\"Mandalay Civilian Related Conflict KDE at Quarter\", i),  # Title for each plot\n           ribside = \"right\",  # Legend on the right\n           col = multi_color_palette(100))  # Apply multi-color gradient\n    })\n  }\n}, movie.name = \"yangonkde_animation.gif\", interval = 0.5, ani.width = 800, ani.height = 800)\n\n\nIn Yangon, the spatio-temporal KDE analysis shows a reduction in overall conflict intensity from 2021 to 2024. However, it is important to note that while the intensity has decreased, clustering is still evident within the same few areas.\n\nKey Observations:\n\n2021 to 2022: Widespread high-intensity conflict areas in central Yangon are prominent in 2021 and early 2022, indicated by the larger red and orange zones.\n2023 to 2024: Although the intensity diminishes over time, the clustering remains persistent in specific areas. The high-intensity zones shrink, but they consistently appear in similar locations, suggesting that while the scale of conflict has reduced, these areas remain focal points for civilian conflict.\n\nThe persistent clustering, even as intensity diminishes, indicates that certain regions continue to experience conflicts, requiring targeted interventions in those zones."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#mandalay-quarter-year-spatio-temporal-kde",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#mandalay-quarter-year-spatio-temporal-kde",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "9.3 Mandalay Quarter Year Spatio-Temporal KDE",
    "text": "9.3 Mandalay Quarter Year Spatio-Temporal KDE\n\nMandalay Quarter Year Code PreparationMandalay Quarter Year OwinMandalay Quarter Year KDEMandalay Quarter Year KDE Animation And Analysis\n\n\n\n# Step 1: Ensure Mandalay_QuarterYear_Sf is an sf object (if not already)\nMandalay_QuarterYear_Sf &lt;- st_as_sf(Mandalay_ACLED_Data_Sf)\n\n# Step 2: Extract the coordinates (longitude and latitude) from the geometry column\ncoords &lt;- st_coordinates(Mandalay_QuarterYear_Sf)\n\n# Step 3: Convert quarter_numeric to factor for distinct quarters (for plotting the circles)\nMandalay_QuarterYear_Sf &lt;- Mandalay_QuarterYear_Sf %&gt;%\n  mutate(\n    year = as.numeric(sub(\".*-\", \"\", quarter_year)),                  # Extract the year (e.g., 2023)\n    quarter = as.numeric(sub(\"Q\", \"\", sub(\"-.*\", \"\", quarter_year))), # Extract the quarter (e.g., Q1 -&gt; 1)\n    \n    # Continuous representation of time (factor for distinct quarters)\n    quarter_numeric_factor = as.factor(year * 10 + quarter),  # Convert to factor for plotting the circles\n    quarter_numeric = year * 10 + quarter  # Keep as numeric for time-based KDE analysis\n  )\n\n# Step 4: Create the point pattern object using ppp() with factor marks (for distinct quarter plotting)\nMandalay_QuarterYear_PPP_Factor &lt;- ppp(\n  x = coords[, 1],  # Longitude (x-coordinates)\n  y = coords[, 2],  # Latitude (y-coordinates)\n  window = Mandalay_Owin,  # Spatial window (Mandalay_Owin)\n  marks = Mandalay_QuarterYear_Sf$quarter_numeric_factor  # Use factor for visualizing distinct quarters\n)\n\n\n# Step 5: Assign 14 unique sizes to the 14 unique quarter_numeric values\n# Create 14 different circle sizes, e.g., from 1 to 3 in size\nunique_quarters &lt;- levels(Mandalay_QuarterYear_Sf$quarter_numeric_factor)  # Get the unique quarter levels (14 levels)\ncircle_sizes &lt;- seq(1, 3, length.out = length(unique_quarters))  # Generate 14 sizes from 1 to 3\n\n# Map each unique quarter_numeric level to a circle size\ncircle_size_map &lt;- setNames(circle_sizes, unique_quarters)  # Create a named vector to map quarter to size\n\n\n\n\n# Apply the circle size mapping to each point based on its quarter_numeric_factor\npoint_circle_sizes &lt;- circle_size_map[Mandalay_QuarterYear_Sf$quarter_numeric_factor]\n\n# Step 6: Plot the base map (Mandalay_Owin) without points\nplot(Mandalay_Owin, main = \"Mandalay Quarter-Year Owin with Unique Circle Sizes\")\n\n# Step 7: Add the points with the unique circle sizes based on quarter_numeric\npoints(coords[, 1], coords[, 2], cex = point_circle_sizes, pch = 16, col = \"black\")  # Add circles on top of base map\n\n# Step 8: Add a custom legend to show the quarter_numeric values and corresponding circle sizes\nlegend(\"topright\", legend = unique_quarters, \n       pch = 16, \n       pt.cex = circle_sizes,  # Show unique circle sizes in the legend\n       col = \"black\", \n       title = \"Quarters (Circle Size)\")\n\n\n\n\n\n\n\n\n\n\n\nMandalay_QuarterYear_PPP_Numeric &lt;- ppp(\n  x = coords[, 1],  # Longitude (x-coordinates)\n  y = coords[, 2],  # Latitude (y-coordinates)\n  window = Mandalay_Owin,  # Spatial window (Mandalay_Owin)\n  marks = Mandalay_QuarterYear_Sf$quarter_numeric  # Use numeric for KDE analysis (time-based)\n)\n\nMandalay_QuarterYear_KDE &lt;- spattemp.density(Mandalay_QuarterYear_PPP_Numeric)\n\nmulti_color_palette &lt;- colorRampPalette(c(\"blue\", \"green\", \"yellow\", \"red\"))\n\n\n# Define the quarters for which you want to plot the KDE\ntims &lt;- c(20211, 20212, 20213, 20214, 20221, 20222, 20223, 20224, \n          20231, 20232, 20233, 20234, 20241, 20242)\n\n#Set up the plotting window to display multiple plots in a grid (4 rows, 4 columns)\npar(mfrow=c(4, 4), mar=c(2, 2, 2, 2), oma=c(0, 0, 2, 0))  # Adjust margins and add outer margin for title\n\n# Loop through the 'tims' vector and plot the KDE for each time point (from left to right)\nfor(i in tims) { \n  plot(Mandalay_QuarterYear_KDE, i, \n       override.par=FALSE,  # Keep the graphical parameters unchanged\n       fix.range=TRUE,      # Fix the range of the KDE\n       main=paste(\"Quarter\", i),  # Title for each plot\n       ribside = \"right\", \n       col = multi_color_palette(100))  # Use 'inferno' color gradient\n  \n  # Remove the x and y axis labels for a cleaner look\n  axis(1, labels=FALSE)\n  axis(2, labels=FALSE)\n}\n\n#dd a unified title across all plots (e.g., the duration of analysis)\nmtext(\"Quarterly Spatio-Temporal KDE for Civilian Conflict Intensity in Mandalay\", \n      outer=TRUE, cex=1.5, font=2)\n\n\n\n\n\n\n\n\n\n\n\nmulti_color_palette &lt;- colorRampPalette(c(\"blue\", \"green\", \"yellow\", \"red\"))\n\n# Save the animation as a GIF\nsaveGIF({\n  # Loop over the valid quarter times\n  for(i in tims){ \n    suppressWarnings({\n      plot(Mandalay_QuarterYear_KDE, i, \n           override.par=FALSE,  # Keep graphical parameters unchanged\n           fix.range=TRUE,      # Fix the range of the KDE\n           main=paste(\"Mandalay Civilian Related Conflict KDE at Quarter\", i),  # Title for each plot\n           ribside = \"right\",  # Legend on the right\n           col = multi_color_palette(100))  # Apply multi-color gradient\n    })\n  }\n}, movie.name = \"Mandalaykde_animation.gif\", interval = 0.5, ani.width = 800, ani.height = 800)\n\n\nIn Mandalay, the spatio-temporal KDE analysis similarly shows a general reduction in conflict intensity over time, from 2021 to 2024. However, like in Yangon, clustering remains within the same key areas across the quarters.\n\nKey Observations:\n\n2021 to 2022: High-intensity conflicts are concentrated in central and northern Mandalay, as shown by the red and orange clusters, particularly in early 2021 and 2022.\n2023 to 2024: The intensity of the conflicts decreases over time, but these clusters persist in similar regions, particularly in central Mandalay. This indicates that although conflict intensity is declining, these areas continue to be hotspots for civilian conflict.\n\nThus, the persistence of clustering in the same areas despite decreasing conflict intensity highlights the need for focused intervention strategies in these conflict-prone regions."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#sagaing-quarter-year-spatio-temporal-kde",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#sagaing-quarter-year-spatio-temporal-kde",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "9.4 Sagaing Quarter Year Spatio-Temporal KDE",
    "text": "9.4 Sagaing Quarter Year Spatio-Temporal KDE\n\nSagaing Quarter Year Code PreparationSagaing Quarter Year OwinSagaing Quarter Year KDESagaing Quarter Year KDE Animation\n\n\n\n# Step 1: Ensure Sagaing_QuarterYear_Sf is an sf object (if not already)\nSagaing_QuarterYear_Sf &lt;- st_as_sf(Sagaing_ACLED_Data_Sf)\n\n# Step 2: Extract the coordinates (longitude and latitude) from the geometry column\ncoords &lt;- st_coordinates(Sagaing_QuarterYear_Sf)\n\n# Step 3: Convert quarter_numeric to factor for distinct quarters (for plotting the circles)\nSagaing_QuarterYear_Sf &lt;- Sagaing_QuarterYear_Sf %&gt;%\n  mutate(\n    year = as.numeric(sub(\".*-\", \"\", quarter_year)),                  # Extract the year (e.g., 2023)\n    quarter = as.numeric(sub(\"Q\", \"\", sub(\"-.*\", \"\", quarter_year))), # Extract the quarter (e.g., Q1 -&gt; 1)\n    \n    # Continuous representation of time (factor for distinct quarters)\n    quarter_numeric_factor = as.factor(year * 10 + quarter),  # Convert to factor for plotting the circles\n    quarter_numeric = year * 10 + quarter  # Keep as numeric for time-based KDE analysis\n  )\n\n# Step 4: Create the point pattern object using ppp() with factor marks (for distinct quarter plotting)\nSagaing_QuarterYear_PPP_Factor &lt;- ppp(\n  x = coords[, 1],  # Longitude (x-coordinates)\n  y = coords[, 2],  # Latitude (y-coordinates)\n  window = Sagaing_Owin,  # Spatial window (Sagaing_Owin)\n  marks = Sagaing_QuarterYear_Sf$quarter_numeric_factor  # Use factor for visualizing distinct quarters\n)\n\n\n# Step 5: Assign 14 unique sizes to the 14 unique quarter_numeric values\n# Create 14 different circle sizes, e.g., from 1 to 3 in size\nunique_quarters &lt;- levels(Sagaing_QuarterYear_Sf$quarter_numeric_factor)  # Get the unique quarter levels (14 levels)\ncircle_sizes &lt;- seq(1, 3, length.out = length(unique_quarters))  # Generate 14 sizes from 1 to 3\n\n# Map each unique quarter_numeric level to a circle size\ncircle_size_map &lt;- setNames(circle_sizes, unique_quarters)  # Create a named vector to map quarter to size\n\n\n\n\n# Apply the circle size mapping to each point based on its quarter_numeric_factor\npoint_circle_sizes &lt;- circle_size_map[Sagaing_QuarterYear_Sf$quarter_numeric_factor]\n\n# Step 6: Plot the base map (Sagaing_Owin) without points\nplot(Sagaing_Owin, main = \"Sagaing Quarter-Year Owin with Unique Circle Sizes\")\n\n# Step 7: Add the points with the unique circle sizes based on quarter_numeric\npoints(coords[, 1], coords[, 2], cex = point_circle_sizes, pch = 16, col = \"black\")  # Add circles on top of base map\n\n# Step 8: Add a custom legend to show the quarter_numeric values and corresponding circle sizes\nlegend(\"topright\", legend = unique_quarters, \n       pch = 16, \n       pt.cex = circle_sizes,  # Show unique circle sizes in the legend\n       col = \"black\", \n       title = \"Quarters (Circle Size)\")\n\n\n\n\n\n\n\n\n\n\n\nSagaing_QuarterYear_PPP_Numeric &lt;- ppp(\n  x = coords[, 1],  # Longitude (x-coordinates)\n  y = coords[, 2],  # Latitude (y-coordinates)\n  window = Sagaing_Owin,  # Spatial window (Sagaing_Owin)\n  marks = Sagaing_QuarterYear_Sf$quarter_numeric  # Use numeric for KDE analysis (time-based)\n)\n\nSagaing_QuarterYear_KDE &lt;- spattemp.density(Sagaing_QuarterYear_PPP_Numeric)\n\nmulti_color_palette &lt;- colorRampPalette(c(\"blue\", \"green\", \"yellow\", \"red\"))\n\n\n# Define the quarters for which you want to plot the KDE\ntims &lt;- c(20211, 20212, 20213, 20214, 20221, 20222, 20223, 20224, \n          20231, 20232, 20233, 20234, 20241, 20242)\n\n#Set up the plotting window to display multiple plots in a grid (4 rows, 4 columns)\npar(mfrow=c(4, 4), mar=c(2, 2, 2, 2), oma=c(0, 0, 2, 0))  # Adjust margins and add outer margin for title\n\n# Loop through the 'tims' vector and plot the KDE for each time point (from left to right)\nfor(i in tims) { \n  plot(Sagaing_QuarterYear_KDE, i, \n       override.par=FALSE,  # Keep the graphical parameters unchanged\n       fix.range=TRUE,      # Fix the range of the KDE\n       main=paste(\"Quarter\", i),  # Title for each plot\n       ribside = \"right\", \n       col = multi_color_palette(100))  # Use 'inferno' color gradient\n  \n  # Remove the x and y axis labels for a cleaner look\n  axis(1, labels=FALSE)\n  axis(2, labels=FALSE)\n}\n\n#dd a unified title across all plots (e.g., the duration of analysis)\nmtext(\"Quarterly Spatio-Temporal KDE for Civilian Conflict Intensity in Sagaing\", \n      outer=TRUE, cex=1.5, font=2)\n\n\n\n\n\n\n\n\n\n\n\nmulti_color_palette &lt;- colorRampPalette(c(\"blue\", \"green\", \"yellow\", \"red\"))\n\n# Save the animation as a GIF\nsaveGIF({\n  # Loop over the valid quarter times\n  for(i in tims){ \n    suppressWarnings({\n      plot(Sagaing_QuarterYear_KDE, i, \n           override.par=FALSE,  # Keep graphical parameters unchanged\n           fix.range=TRUE,      # Fix the range of the KDE\n           main=paste(\"Sagaing Civilian Related Conflict KDE at Quarter\", i),  # Title for each plot\n           ribside = \"right\",  # Legend on the right\n           col = multi_color_palette(100))  # Apply multi-color gradient\n    })\n  }\n}, movie.name = \"Sagaingkde_animation.gif\", interval = 0.5, ani.width = 800, ani.height = 800)\n\n\nSpatio-Temporal KDE analysis for Sagaing across multiple quarters, we observe significant spatial clustering of civilian-related conflicts over time. The conflict intensity remains localized in specific regions, with fluctuations in density between quarters.\n\nKey Observations:\n\nConsistent Clustering: Conflict events are consistently clustered in the central and southern regions of Sagaing, as indicated by the green to red areas over time. These regions show recurring intensity, highlighting persistent conflict zones.\nTemporal Fluctuations: Some quarters, such as 20212, 20213, and 20222, exhibit relatively lower conflict intensity, while 20224 shows a resurgence in intensity.\nLocalized Hotspots: The southern region shows a spike in density during 20241, followed by a steady reduction in the later quarters.\n\n\n\nConclusion:\nThere is ongoing clustering in the same geographic regions of Sagaing, with peaks of conflict intensity in specific quarters. This indicates that while the overall distribution of conflicts remains stable, certain periods witness heightened violence."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#yangon-7",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#yangon-7",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "10.1 Yangon",
    "text": "10.1 Yangon\nFor the conflict events in Sagaing, we performed a detailed spatial point pattern analysis by computing the cross-K function for each pair of years (e.g., 2021 vs. 2022, 2021 vs. 2023, etc.). The cross-K function allows us to investigate how conflict events in one year relate to conflict events in another year, revealing whether the events are clustered, dispersed, or randomly distributed across space between different time periods.\n\nNull and Alternative Hypotheses:\n\nHo (Null Hypothesis): The distribution of conflict events in Yangon follows Complete Spatio-Temporal Randomness (CSTR), meaning the events are randomly distributed in both space and time.\nH1 (Alternative Hypothesis): The distribution of conflict events in Yangon does not follow CSTR and instead shows signs of clustering or dispersion in both space and time.\n\n\n\n10.1.1 Yangon’s Cross K Calculation\n\nCodeOutput and Charts\n\n\n\n# Create the spatial point pattern (ppp) object for Yangon\nYangon_ppp_years &lt;- ppp(\n  x = Yangon_ACLED_co[, 1],  # Longitude\n  y = Yangon_ACLED_co[, 2],  # Latitude\n  window = Yangon_Owin  # Spatial observation window (owin object)\n)\n\n# Add a mark that groups quarters by year (e.g., 2021, 2022, 2023, 2024)\nYangon_ppp_years$marks &lt;- as.factor(substr(Yangon_QuarterYear_Sf$quarter_numeric, 1, 4))\nYangon_ppp_years &lt;- rescale(Yangon_ppp_years, 1000, \"km\")\n# Store the unique years in the data\nunique_years &lt;- levels(Yangon_ppp_years$marks)\n\n# Function to compute cross-K function between two years\ncross_k_function_by_year &lt;- function(ppp_object, year1, year2) {\n  # Compute the cross-K function for the two selected years within the same ppp object\n  K_cross &lt;- Kcross(ppp_object, i = year1, j = year2)\n  return(K_cross)\n}\n\n# Initialize an empty list to store each year's comparison\nYangon_k_results &lt;- list()\n\n# Loop through pairs of years to compute and store cross-K functions\nfor (i in 1:(length(unique_years) - 1)) {\n  for (j in (i + 1):length(unique_years)) {\n    year1 &lt;- unique_years[i]\n    year2 &lt;- unique_years[j]\n    \n    # Print progress\n    cat(\"Computing K-Function for\", year1, \"and\", year2, \"\\n\")\n    \n    # Compute the cross-K function for these two years and store it in a named variable\n    result_name &lt;- paste0(\"Yangon_k_\", year1, \"_vs_\", year2)\n    Yangon_k_results[[result_name]] &lt;- cross_k_function_by_year(Yangon_ppp_years, year1, year2)\n  }\n}\n\n# Save individual year comparison results as variables\nYangon_k_2021_vs_2022 &lt;- Yangon_k_results[[\"Yangon_k_2021_vs_2022\"]]\nYangon_k_2021_vs_2023 &lt;- Yangon_k_results[[\"Yangon_k_2021_vs_2023\"]]\nYangon_k_2021_vs_2024 &lt;- Yangon_k_results[[\"Yangon_k_2021_vs_2024\"]]\nYangon_k_2022_vs_2023 &lt;- Yangon_k_results[[\"Yangon_k_2022_vs_2023\"]]\nYangon_k_2022_vs_2024 &lt;- Yangon_k_results[[\"Yangon_k_2022_vs_2024\"]]\nYangon_k_2023_vs_2024 &lt;- Yangon_k_results[[\"Yangon_k_2023_vs_2024\"]]\n\n# Set up the layout for multiple plots (2 rows, 3 columns for all year comparisons)\n\n\n\n\npar(mfrow = c(2, 1))\n# Plotting each comparison\nplot(Yangon_k_2021_vs_2022, main = \"K-Function: Yangon Civilian Related Conflict KDE 2021 vs 2022\")\nplot(Yangon_k_2021_vs_2023, main = \"K-Function: Yangon Civilian Related Conflict KDE 2021 vs 2023\")\n\n\n\n\n\n\n\nplot(Yangon_k_2021_vs_2024, main = \"K-Function: Yangon Civilian Related Conflict KDE 2021 vs 2024\")\nplot(Yangon_k_2022_vs_2023, main = \"K-Function: Yangon Civilian Related Conflict KDE 2022 vs 2023\")\n\n\n\n\n\n\n\nplot(Yangon_k_2022_vs_2024, main = \"K-Function: Yangon Civilian Related Conflict KDE 2022 vs 2024\")\nplot(Yangon_k_2023_vs_2024, main = \"K-Function: Yangon Civilian Related Conflict KDE 2023 vs 2024\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n10.1.2 Yangon’s Cross K Analysis\n\n10.1.2.1 Yangon’s Individual Years Comparision\n\n10.1.2.1.1 2021 vs 2022\n\n\nThe observed K-function lies consistently above the CSR envelope, indicating significant clustering between events from 2021 and 2022 at distances up to approximately 25 km.\nThe clustering effect becomes more prominent at larger distances, suggesting that events from 2021 tend to cluster with events from 2022 across larger spatial scales.\n\n\n\n10.1.2.1.2 2021 vs 2023\n\n\nThe K-function for 2021 vs 2023 is also above the CSR envelope, indicating clustering between these two years.\nHowever, the clustering is slightly less prominent compared to 2021 vs 2022, suggesting that while clustering persists, the relationship between events from 2021 and 2023 is somewhat weaker than between 2021 and 2022.\n\n\n\n10.1.2.1.3 2021 vs 2024\n\n\nThe clustering is still evident between 2021 and 2024, but the clustering intensity appears to be weaker at larger distances. The observed K-function shows less deviation from the CSR envelope, indicating that the spatial clustering effect is declining as we compare events separated by more time.\n\n\n\n10.1.2.1.4 2022 vs 2023\n\n\nThe K-function here indicates significant clustering at smaller distances, but the intensity decreases more rapidly beyond 15 km.\nThe spatial clustering between 2022 and 2023 is still present but somewhat weaker compared to other year-pair comparisons.\n\n\n\n10.1.2.1.5 2022 vs 2024\n\n\nThe 2022 vs 2024 K-function shows clustering, though it is less pronounced than in the previous year comparisons.\nThe clustering effect diminishes as the events from these two years become more spatially dispersed, particularly beyond 15 km.\n\n\n\n10.1.2.1.6 2023 vs 2024\n\n\nThe K-function for 2023 vs 2024 shows the least clustering effect of all the comparisons.\nThere is minimal deviation from the CSR line, indicating that the events from these two years are closer to being randomly distributed, with only mild clustering observed at smaller distances.\n\n\n\n\n10.1.2.1 Overall Years Comparison\n\nClustering is strongest between events that are closer in time (e.g., 2021 vs 2022), with the strength of clustering generally decreasing as the time difference between events increases (e.g., 2021 vs 2024).\nThis suggests that civilian conflict events in Yangon have a spatial-temporal dependence, where events in one year are more likely to occur near events from the following year, but this effect diminishes over time."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#mandalay-7",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#mandalay-7",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "10.2 Mandalay",
    "text": "10.2 Mandalay\nFor the conflict events in Mandalay, we performed a detailed spatial point pattern analysis by computing the cross-K function for each pair of years (e.g., 2021 vs. 2022, 2021 vs. 2023, etc.). The cross-K function allows us to investigate how conflict events in one year relate to conflict events in another year, revealing whether the events are clustered, dispersed, or randomly distributed across space between different time periods.\n\nNull and Alternative Hypotheses:\n\nHo (Null Hypothesis): The distribution of conflict events in Mandalay follows Complete Spatio-Temporal Randomness (CSTR), meaning the events are randomly distributed in both space and time.\nH1 (Alternative Hypothesis): The distribution of conflict events in Mandalay does not follow CSTR and instead shows signs of clustering or dispersion in both space and time.\n\n\n\n10.2.1 Mandalay’s Cross K Calculation\n\nCodeOutput and Charts\n\n\n\n# Create the spatial point pattern (ppp) object for Mandalay\nMandalay_ppp_years &lt;- ppp(\n  x = Mandalay_ACLED_co[, 1],  # Longitude\n  y = Mandalay_ACLED_co[, 2],  # Latitude\n  window = Mandalay_Owin  # Spatial observation window (owin object)\n)\n\n# Add a mark that groups quarters by year (e.g., 2021, 2022, 2023, 2024)\nMandalay_ppp_years$marks &lt;- as.factor(substr(Mandalay_QuarterYear_Sf$quarter_numeric, 1, 4))\n# Store the unique years in the data\nunique_years &lt;- levels(Mandalay_ppp_years$marks)\nMandalay_ppp_years &lt;- rescale(Mandalay_ppp_years, 1000, \"km\")\n\n# Function to compute cross-K function between two years\ncross_k_function_by_year &lt;- function(ppp_object, year1, year2) {\n  # Compute the cross-K function for the two selected years within the same ppp object\n  K_cross &lt;- Kcross(ppp_object, i = year1, j = year2)\n  return(K_cross)\n}\n\n# Initialize an empty list to store each year's comparison\nMandalay_k_results &lt;- list()\n\n# Loop through pairs of years to compute and store cross-K functions\nfor (i in 1:(length(unique_years) - 1)) {\n  for (j in (i + 1):length(unique_years)) {\n    year1 &lt;- unique_years[i]\n    year2 &lt;- unique_years[j]\n    \n    # Print progress\n    cat(\"Computing K-Function for\", year1, \"and\", year2, \"\\n\")\n    \n    # Compute the cross-K function for these two years and store it in a named variable\n    result_name &lt;- paste0(\"Mandalay_k_\", year1, \"_vs_\", year2)\n    Mandalay_k_results[[result_name]] &lt;- cross_k_function_by_year(Mandalay_ppp_years, year1, year2)\n  }\n}\n\n# Save individual year comparison results as variables\nMandalay_k_2021_vs_2022 &lt;- Mandalay_k_results[[\"Mandalay_k_2021_vs_2022\"]]\nMandalay_k_2021_vs_2023 &lt;- Mandalay_k_results[[\"Mandalay_k_2021_vs_2023\"]]\nMandalay_k_2021_vs_2024 &lt;- Mandalay_k_results[[\"Mandalay_k_2021_vs_2024\"]]\nMandalay_k_2022_vs_2023 &lt;- Mandalay_k_results[[\"Mandalay_k_2022_vs_2023\"]]\nMandalay_k_2022_vs_2024 &lt;- Mandalay_k_results[[\"Mandalay_k_2022_vs_2024\"]]\nMandalay_k_2023_vs_2024 &lt;- Mandalay_k_results[[\"Mandalay_k_2023_vs_2024\"]]\n\n\n\n\n# Set up the layout for multiple plots (2 rows, 3 columns for all year comparisons)\npar(mfrow = c(2, 1))\n\n# Plotting each comparison\nplot(Sagaing_k_2021_vs_2022, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2021 vs 2022\")\nplot(Sagaing_k_2021_vs_2023, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2021 vs 2023\")\n\n\n\n\n\n\n\nplot(Sagaing_k_2021_vs_2024, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2021 vs 2024\")\nplot(Sagaing_k_2022_vs_2023, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2022 vs 2023\")\n\n\n\n\n\n\n\nplot(Sagaing_k_2022_vs_2024, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2022 vs 2024\")\nplot(Sagaing_k_2023_vs_2024, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2023 vs 2024\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n10.2.2 Mandalay’s Cross K Analysis\n\n10.2.2.1 Mandalay’s Individual Years Comparison\n\n10.1.2.1.1 2021 vs 2022\n\n\nThe K-function for 2021 vs 2022 shows significant clustering at all distances. The observed K-function is consistently above the CSR envelope, indicating that conflict events from 2021 tend to cluster near those from 2022.\nThe clustering effect appears to intensify as the distance increases, suggesting a broad spatial clustering pattern for conflicts in 2021 and 2022.\n\n\n\n10.2.2.1.2 2021 vs 2023\n\n\nthe K-function for 2021 vs 2023 also shows clustering, but it is slightly less pronounced than in the 2021 vs 2022 comparison.\nThe clustering becomes more noticeable at distances beyond 10 km, implying that conflict events from these two years tend to cluster over medium to larger distances.\nHowever, the clustering effect weakens somewhat compared to the previous year comparison.\n\n\n\n10.2.2.1.3 2021 vs 2024\n\n\nClustering between 2021 and 2024 is still present, but the intensity is weaker compared to the previous year pairs.\nThe observed K-function does show some clustering above the CSR line, but the deviation from randomness is smaller, suggesting that events from 2021 and 2024 are less spatially related than the closer years (2021 vs 2022).\n\n\n\n10.2.2.1.4 2022 vs 2023\n\n\nThe clustering between 2022 and 2023 remains significant, especially at larger distances, with the observed K-function clearly above the CSR envelope.\nSimilar to earlier comparisons, this suggests that conflict events from these two years cluster over wider distances, continuing the spatial clustering trend seen in other comparisons.\n\n\n\n10.2.2.5 2022 vs 2024\n\n\nThe 2022 vs 2024 K-function shows clustering, although the intensity is weaker, particularly at smaller distances.\nThere is a slight increase in clustering at larger distances, but the deviation from the CSR envelope is less pronounced compared to the earlier year comparisons.\n\n\n\n10.2.2.6 2023 vs 2024\n\n\nThe K-function for 2023 vs 2024 shows clustering, though this is the weakest of all the comparisons.\nThe clustering effect becomes more noticeable at distances greater than 10 km, but overall, the spatial relationship between events from 2023 and 2024 is closer to random compared to earlier year comparisons.\n\n\n\n\n10.2.2.1 Mandalay Overall Years Comparison\n\nSimilar to the Yangon analysis, the spatial clustering is strongest between conflict events that are closer in time, such as 2021 vs 2022 and 2022 vs 2023.\n\n\n\nAs the time gap between years increases, the clustering effect becomes weaker, with the least clustering observed between 2023 and 2024.\n\nThese results suggest that conflicts in Mandalay show spatio-temporal clustering, with events from one year often clustering near those from the next, but this effect diminishes as the time gap between years grows."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#sagaing-6",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#sagaing-6",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "10.3 Sagaing",
    "text": "10.3 Sagaing\nFor the conflict events in Sagaing, we performed a detailed spatial point pattern analysis by computing the cross-K function for each pair of years (e.g., 2021 vs. 2022, 2021 vs. 2023, etc.). The cross-K function allows us to investigate how conflict events in one year relate to conflict events in another year, revealing whether the events are clustered, dispersed, or randomly distributed across space between different time periods.\nNull and Alternative Hypotheses:\n\nHo (Null Hypothesis): The distribution of conflict events in Sagaing follows Complete Spatio-Temporal Randomness (CSTR), meaning the events are randomly distributed in both space and time.\nH1 (Alternative Hypothesis): The distribution of conflict events in Sagaing does not follow CSTR and instead shows signs of clustering or dispersion in both space and time.\n\n\n10.3.1 Sagaing’s Cross K Calculation\n\nCodeOutput and Charts\n\n\n\nSagaing_ppp_years &lt;- ppp(\n  x = Sagaing_ACLED_co[, 1],  # Longitude\n  y = Sagaing_ACLED_co[, 2],  # Latitude\n  window = Sagaing_Owin  # Spatial observation window (owin object)\n)\n\n# Add a mark that groups quarters by year (e.g., 2021, 2022, 2023, 2024)\nSagaing_ppp_years$marks &lt;- as.factor(substr(Sagaing_QuarterYear_Sf$quarter_numeric, 1, 4))\nSagaing_ppp_years &lt;- rescale(Sagaing_ppp_years, 1000, \"km\")\n# Store the unique years in the data\nunique_years &lt;- levels(Sagaing_ppp_years$marks)\n\n# Function to compute cross-K function between two years\ncross_k_function_by_year &lt;- function(ppp_object, year1, year2) {\n  # Compute the cross-K function for the two selected years within the same ppp object\n  K_cross &lt;- Kcross(ppp_object, i = year1, j = year2)\n  return(K_cross)\n}\n\n# Initialize an empty list to store each year's comparison\nSagaing_k_results &lt;- list()\n\n# Loop through pairs of years to compute and store cross-K functions\nfor (i in 1:(length(unique_years) - 1)) {\n  for (j in (i + 1):length(unique_years)) {\n    year1 &lt;- unique_years[i]\n    year2 &lt;- unique_years[j]\n    \n    # Print progress\n    cat(\"Computing K-Function for\", year1, \"and\", year2, \"\\n\")\n    \n    # Compute the cross-K function for these two years and store it in a named variable\n    result_name &lt;- paste0(\"Sagaing_k_\", year1, \"_vs_\", year2)\n    Sagaing_k_results[[result_name]] &lt;- cross_k_function_by_year(Sagaing_ppp_years, year1, year2)\n  }\n}\n\n# Save individual year comparison results as variables\nSagaing_k_2021_vs_2022 &lt;- Sagaing_k_results[[\"Sagaing_k_2021_vs_2022\"]]\nSagaing_k_2021_vs_2023 &lt;- Sagaing_k_results[[\"Sagaing_k_2021_vs_2023\"]]\nSagaing_k_2021_vs_2024 &lt;- Sagaing_k_results[[\"Sagaing_k_2021_vs_2024\"]]\nSagaing_k_2022_vs_2023 &lt;- Sagaing_k_results[[\"Sagaing_k_2022_vs_2023\"]]\nSagaing_k_2022_vs_2024 &lt;- Sagaing_k_results[[\"Sagaing_k_2022_vs_2024\"]]\nSagaing_k_2023_vs_2024 &lt;- Sagaing_k_results[[\"Sagaing_k_2023_vs_2024\"]]\n\n# Save individual year comparison results as variables\nSagaing_k_2021_vs_2022 &lt;- Sagaing_k_results[[\"Sagaing_k_2021_vs_2022\"]]\nSagaing_k_2021_vs_2023 &lt;- Sagaing_k_results[[\"Sagaing_k_2021_vs_2023\"]]\nSagaing_k_2021_vs_2024 &lt;- Sagaing_k_results[[\"Sagaing_k_2021_vs_2024\"]]\nSagaing_k_2022_vs_2023 &lt;- Sagaing_k_results[[\"Sagaing_k_2022_vs_2023\"]]\nSagaing_k_2022_vs_2024 &lt;- Sagaing_k_results[[\"Sagaing_k_2022_vs_2024\"]]\nSagaing_k_2023_vs_2024 &lt;- Sagaing_k_results[[\"Sagaing_k_2023_vs_2024\"]]\n\n\n\n\npar(mfrow = c(2, 1))\n# Plotting each comparison\nplot(Sagaing_k_2021_vs_2022, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2021 vs 2022\")\nplot(Sagaing_k_2021_vs_2023, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2021 vs 2023\")\n\n\n\n\n\n\n\nplot(Sagaing_k_2021_vs_2024, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2021 vs 2024\")\nplot(Sagaing_k_2022_vs_2023, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2022 vs 2023\")\n\n\n\n\n\n\n\nplot(Sagaing_k_2022_vs_2024, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2022 vs 2024\")\nplot(Sagaing_k_2023_vs_2024, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2023 vs 2024\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n10.3.2 Sagaing’s Cross K Analysis\n\n10.3.2.1 Sagaing’s Individual Years Comparison\n\n10.3.2.1.1 2021 vs 2022\n\n\nThe observed K-function r is consistently higher than the CSR (Complete Spatial Randomness) envelope across almost all distances. This indicates that the conflict events in 2021 and 2022 are significantly clustered in space. The clustering effect becomes more pronounced at larger distances, especially after 20 km.\nThe trans K-function also follows a similar pattern, showing clustering beyond the expected CSR pattern.\nThe Kbord function demonstrates that boundary corrections had minimal impact on the general clustering trends observed.\n\n\n\n10.3.2.1.2 2021 vs 2023\n\n\nSimilar to the comparison between 2021 and 2022, the K-function in 2021 vs 2023 also shows a high degree of clustering, with obs(r) being higher than CSR across nearly all distances.\nThere is a slightly more pronounced clustering effect around 30 to 40 km, where the gap between the observed K and CSR becomes wider. This suggests an increase in conflict density over time.\n\n\n\n10.3.2.1.3 2021 vs 2024\n\n\nthe K-function for 2021 vs 2024 shows a consistent pattern of clustering across distances, although the observed values tend to rise more sharply after 40 km, indicating that conflicts in 2024 were more dispersed initially but clustered significantly at larger spatial scales.\nThe results suggest that the spatial distribution of conflicts in 2024 is slightly different, possibly influenced by external factors that caused conflicts to be more spread out in space.\n\n\n\n10.3.2.1.4 2022 vs 2023\n\n\nThe comparison between 2022 and 2024 reveals strong clustering over a wide range of distances, with significant increases after 30 km.\nThis suggests that conflicts in 2024 are more spatially concentrated at larger distances compared to 2022.\n\n\n\n10.3.2.1.5 2022 vs 2024\n\n\nThe comparison between 2022 and 2024 reveals strong clustering over a wide range of distances, with significant increases after 30 km.\nThis suggests that conflicts in 2024 are more spatially concentrated at larger distances compared to 2022.\n\n\n\n10.3.2.1.6 2023 vs 2024\n\n\nThe clustering trend continues between 2023 and 2024, with notable increases in clustering beyond 40 km. The gap between the observed K and CSR remains large, indicating that the conflict events in 2023 and 2024 were not randomly distributed but exhibited significant spatial clustering.\n\n\n\n\n10.3.2.1 Sagaing Overall Years Comparison\n\nAcross all years (2021-2024), the K-functions suggest that civilian-related conflict events in Sagaing are significantly clustered rather than randomly distributed. The degree of clustering varies slightly across the years, with some years (such as 2024) showing stronger clustering at larger distances (over 40 km). This indicates that the conflict dynamics in Sagaing are evolving over time, possibly due to changes in political, social, or environmental factors."
  }
]