[
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "",
    "text": "The study of armed conflicts in Myanmar has gained critical importance in understanding the geographical distribution and intensity of violence across different regions. Myanmar’s complex ethnic composition and ongoing civil strife make it a unique case for geospatial analysis. This project aims to apply spatial and spatio-temporal point pattern analysis methods to uncover the patterns of armed conflict between January 2021 and June 2024.\nBy leveraging conflict data from the Armed Conflict Location & Event Data (ACLED) and geospatial tools, we will focus on visualizing and interpreting conflict density through heat maps, Kernel Density Estimation (KDE), and advanced spatio-temporal analysis.\n\nOur analysis will focus on four types of conflict events:\n\nBattles,\nExplosion/Remote violence,\nStrategic developments,\nViolence against civilians,\n\nwith particular attention paid to quarterly patterns in conflict occurrence."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#installing-the-required-packages",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#installing-the-required-packages",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "2.1 Installing the required Packages",
    "text": "2.1 Installing the required Packages\nKey Packages Used in the Project:\n\nsf: Handles simple features in R, allowing for spatial data manipulation and analysis. It is crucial for reading and managing geospatial data like shapefiles (e.g., Myanmar’s administrative boundaries).\nraster: Used for raster-based spatial data manipulation, especially for working with raster maps, such as Kernel Density Estimation (KDE) results.\nspatstat: A powerful package for spatial point pattern analysis. It helps to analyze and visualize spatial point data, particularly for identifying clusters or patterns in armed conflict events.\nsparr: Builds on spatstat and focuses on performing spatial and spatio-temporal kernel smoothing, which will be crucial for KDE and heatmap creation.\ntmap: A thematic mapping package that will allow us to create maps, including KDE visualizations on an OpenStreetMap base.\ntidyverse: A collection of data manipulation packages like dplyr, ggplot2, and purrr. It’s essential for data cleaning, manipulation, and visualization tasks.\nstpp: Used for spatio-temporal point pattern analysis, crucial for analyzing how conflict events evolve in both space and time.\nskimr: A quick and comprehensive tool to provide summaries and descriptive statistics for datasets, helping in the initial exploration.\ngganimate: Extends ggplot2 to create animated visualizations. We can use this for animated time-series or evolving conflict maps.\nggplot2: The core plotting package in R, essential for creating visualizations like time series plots and KDE heatmaps.\nplotly: Useful for creating interactive visualizations, allowing users to explore spatial data interactively (e.g., hover over points to see conflict details).\npacman: is a package management tool in R designed to streamline the process of loading and installing packages.\n\n\npacman::p_load(sf, raster, spatstat, sparr, tmap, tidyverse, stpp, skimr, gganimate, ggplot2, plotly, flexdashboard, DT,gridExtra, rlist, grid, animation)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#data-set-involved-in-this-topic",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#data-set-involved-in-this-topic",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "2.2 Data-set involved in this topic",
    "text": "2.2 Data-set involved in this topic\nFor this analysis, we use two key datasets:\n\n2.2.1 ACLED Armed Conflict Data\nLocation & Event Data (ACLED)platform, which maintains an extensive record of conflict events globally. For this specific analysis, we will limit the dataset by filtering based on the following parameters to streamline data preparation and minimize the need for extensive data cleaning:\n\n\n\n\n\n\n\nData Parameter\nFilter Category\n\n\n\n\nDate Range\nFrom 01/01/2021 to 30/06/2024.\n\n\nEvent Type\n1. Battles\n2. Violence Against Civilians\n3. Explosions/Remote Violence\n4. Strategic Developments\n\n\nCountry\nMyanmar\n\n\n\n\n\nACLED Configuration Image\n\n\n\n\n\nCode to Import ACLED Dataset\n\n\nACLEDData &lt;- read_csv(\"data/raw/aspatial/2021-01-01-2024-06-30-Myanmar.csv\")\n\nRows: 42608 Columns: 35\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): event_id_cnty, event_date, disorder_type, event_type, sub_event_ty...\ndbl (15): year, time_precision, inter1, inter2, interaction, iso, latitude, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n2.2.1.1 Understanding the data set fields.\nReferencing this ACLED Official codebook, this is the dataset that we are working with, not to bore you with the details are mainly interested in the following fields,\n\nEvent ID: Unique identifier for each conflict event.\nEvent Date: Date of occurrence.\nEvent Type: Type of conflict event (e.g., Battles, Remote Violence).\nLatitude/Longitude: Coordinates of the event.\nFatalities: Number of fatalities resulting from the event.\nActors: The groups or individuals involved in the conflict (e.g., state actors, ethnic armed groups).\nAdmin Levels: Administrative region, district, and township where the event took place.\n\nIf you’re interested in the data set fields to explore more, here’s the full fields!\n\n\nACLED Full Table Fields Summary\n\n\n\n\nFields name\nFields Description\nValues\n\n\nevent_id_cnty\nA unique alphanumeric event identifier by number and country acronym. This identifier remains constant even when the event details are updated.\nE.g. ETH9766\n\n\nevent_date\nThe date on which the event took place. Recorded as Year-Month-Day.\nE.g. 2023-02-16\n\n\nyear\nThe year in which the event took place.\nE.g. 2018\n\n\ntime_precision\nA numeric code between 1 and 3 indicating the level of precision of the date recorded for the event. The higher the number, the lower the precision.\n1, 2, or 3; with 1 being the most precise.\n\n\ndisorder_type\nThe disorder category an event belongs to.\nPolitical violence, Demonstrations, or Strategic developments.\n\n\nevent_type\nThe type of event; further specifies the nature of the event.\nE.g. BattlesFor the full list of ACLED event types, see the ACLED Event Types table.\n\n\nsub_event_type\nA subcategory of the event type.\nE.g. Armed clashFor the full list of ACLED sub-event types, see the ACLED Event Types table.\n\n\nactor1\nOne of two main actors involved in the event (does not necessarily indicate the aggressor).\nE.g. Rioters (Papua New Guinea)\n\n\nassoc_actor_1\nActor(s) involved in the event alongside ‘Actor 1’ or actor designations that further identify ‘Actor 1’.\nE.g. Labor Group (Spain); Women (Spain)Can have multiple actors separated by a semicolon, or can be blank.\n\n\ninter1\nA numeric code between 0 and 8 indicating the type of ‘Actor 1’ (for more, see the section Actor Names, Types, and ‘Inter’ Codes).\n1, 2, 3, 4, 5, 6, 7, or 8.\n\n\nactor2\nOne of two main actors involved in the event (does not necessarily indicate the target or victim).\nE.g. Civilians (Kenya)Can be blank.\n\n\nassoc_actor_2\nActor(s) involved in the event alongside ‘Actor 2’ or actor designation further identifying ‘Actor 2’.\nE.g. Labor Group (Spain); Women (Spain)Can have multiple actors separated by a semicolon, or can be blank.\n\n\ninter2\nA numeric code between 0 to 8 indicating the type of ‘Actor 2’ (for more, see the section Actor Names, Types, and ‘Inter’ Codes).\n0, 1, 2, 3, 4, 5, 6, 7, or 8.\n\n\ninteraction\nA two-digit numeric code (combination of ‘Inter 1’ and ‘Inter 2’) indicating the two actor types interacting in the event (for more, see the section Actor Names, Types, and ‘Inter’ Codes).\nE.g.3, 58\n\n\ncivilian_targeting\nThis column indicates whether the event involved civilian targeting.\nEither ‘Civilians targeted’ or blank.\n\n\niso\nA unique three-digit numeric code assigned to each country or territory according to ISO 3166.\nE.g. 231 for Ethiopia\n\n\nregion\nThe region of the world where the event took place.\nE.g. Eastern Africa\n\n\ncountry\nThe country or territory in which the event took place.\nE.g. Ethiopia\n\n\nadmin1\nThe largest sub-national administrative region in which the event took place.\nE.g. Oromia\n\n\nadmin2\nThe second largest sub-national administrative region in which the event took place.\nE.g. ArsiCan be blank.\n\n\nadmin3\nThe third largest sub-national administrative region in which the event took place.\nE.g. MertiCan be blank.\n\n\nlocation\nThe name of the location at which the event took place.\nE.g. Abomsa\n\n\nlatitude\nThe latitude of the location in four decimal degrees notation (EPSG:32647).\nE.g. 8.5907\n\n\nlongitude\nThe longitude of the location in four decimal degrees notation (EPSG:32647).\nE.g. 39.8588\n\n\ngeo_precision\nA numeric code between 1 and 3 indicating the level of certainty of the location recorded for the event. The higher the number, the lower the precision.\n1, 2, or 3; with 1 being the most precise.\n\n\nsource\nThe sources used to record the event. Separated by a semicolon.\nE.g. Ansar Allah; Yemen Data Project\n\n\nsource_ scale\nAn indication of the geographic closeness of the used sources to the event (for more, see the section Source Scale).\nE.g. Local partner-National\n\n\nnotes\nA short description of the event.\nE.g. On 16 February 2023, OLF-Shane abducted an unidentified number of civilians after stopping a vehicle in an area near Abomsa (Merti, Arsi, Oromia). The abductees were traveling from Adama to Abomsa, Arsi.\n\n\nfatalities\nThe number of reported fatalities arising from an event. When there are conflicting reports, the most conservative estimate is recorded.\nE.g. 3No information on fatalities is recorded as 0 reported fatalities.\n\n\ntags\nAdditional structured information about the event. Separated by a semicolon.\nE.g. women targeted: politicians; sexual violence\n\n\ntimestamp\nAn automatically generated Unix timestamp that represents the exact date and time an event was uploaded to the ACLED API.\nE.g. 1676909320\n\n\n\n\n\n\n\n2.2.2 Myanmar Administrative Boundaries (Shapefiles):\nObtained through Geonode Mimu, this shapefile helps us to build the map and set the boundary zone of each district of myanmar. This dataset provides the geographical boundaries of Myanmar’s administrative divisions, from the national level down to the township level. It is essential for mapping conflict events to specific regions.\n\n\nCode to Import Shapefile Dataset\n\n\nStateDistrict\n\n\n\nM_State_Sf &lt;- st_read(dsn=\"data/raw/geospatial/stateLevel\", layer = \"mmr_polbnda_adm1_250k_mimu_1\") \n\nReading layer `mmr_polbnda_adm1_250k_mimu_1' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Take_Home_Exercises\\Take_Home_Exercise_1\\data\\raw\\geospatial\\stateLevel' \n  using driver `ESRI Shapefile'\nSimple feature collection with 15 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\nM_State_Sf\n\nSimple feature collection with 15 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   OBJECTID          ST ST_PCODE           ST_RG          ST_MMR PCode_V\n1         1  Ayeyarwady   MMR017          Region  ဧရာဝတီတိုင်းဒေသကြီး     9.4\n2         2        Bago   MMR111          Region    ပဲခူးတိုင်းဒေသကြီး     9.4\n3         4        Chin   MMR004           State       ချင်းပြည်နယ်     9.4\n4         5      Kachin   MMR001           State       ကချင်ပြည်နယ်     9.4\n5         6       Kayah   MMR002           State       ကယားပြည်နယ်     9.4\n6         7       Kayin   MMR003           State        ကရင်ပြည်နယ်     9.4\n7         8      Magway   MMR009          Region   မကွေးတိုင်းဒေသကြီး     9.4\n8         9    Mandalay   MMR010          Region မန္တလေးတိုင်းဒေသကြီး     9.4\n9        10         Mon   MMR011           State         မွန်ပြည်နယ်     9.4\n10       11 Nay Pyi Taw   MMR018 Union Territory        နေပြည်တော်     9.4\n                         geometry\n1  MULTIPOLYGON (((95.20798 15...\n2  MULTIPOLYGON (((96.17964 19...\n3  MULTIPOLYGON (((93.36931 24...\n4  MULTIPOLYGON (((97.59674 28...\n5  MULTIPOLYGON (((97.1759 19....\n6  MULTIPOLYGON (((97.81508 16...\n7  MULTIPOLYGON (((94.11699 22...\n8  MULTIPOLYGON (((96.14023 23...\n9  MULTIPOLYGON (((97.73689 15...\n10 MULTIPOLYGON (((96.32013 20...\n\n\n\n\n\nM_District_Sf &lt;- st_read(dsn=\"data/raw/geospatial\", layer = \"mmr_polbnda_adm2_250k_mimu\") \n\nReading layer `mmr_polbnda_adm2_250k_mimu' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Take_Home_Exercises\\Take_Home_Exercise_1\\data\\raw\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 80 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\nM_District_Sf\n\nSimple feature collection with 80 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   OBJECTID          ST ST_PCODE         DT   DT_PCODE      DT_MMR PCode_V\n1         1  Ayeyarwady   MMR017   Hinthada MMR017D002    ဟင်္သာတခရိုင်     9.4\n2         2  Ayeyarwady   MMR017    Labutta MMR017D004    လပွတ္တာခရိုင်     9.4\n3         3  Ayeyarwady   MMR017     Maubin MMR017D005     မအူပင်ခရိုင်     9.4\n4         4  Ayeyarwady   MMR017  Myaungmya MMR017D003 မြောင်းမြခရိုင်     9.4\n5         5  Ayeyarwady   MMR017    Pathein MMR017D001      ပုသိမ်ခရိုင်     9.4\n6         6  Ayeyarwady   MMR017     Pyapon MMR017D006     ဖျာပုံခရိုင်     9.4\n7         7 Bago (East)   MMR007       Bago MMR007D001      ပဲခူးခရိုင်     9.4\n8         8 Bago (East)   MMR007    Taungoo MMR007D002    တောင်ငူခရိုင်     9.4\n9         9 Bago (West)   MMR008       Pyay MMR008D001      ပြည်ခရိုင်     9.4\n10       10 Bago (West)   MMR008 Thayarwady MMR008D002   သာယာဝတီခရိုင်     9.4\n                         geometry\n1  MULTIPOLYGON (((95.12637 18...\n2  MULTIPOLYGON (((95.04462 15...\n3  MULTIPOLYGON (((95.38231 17...\n4  MULTIPOLYGON (((94.6942 16....\n5  MULTIPOLYGON (((94.27572 15...\n6  MULTIPOLYGON (((95.20798 15...\n7  MULTIPOLYGON (((95.90674 18...\n8  MULTIPOLYGON (((96.17964 19...\n9  MULTIPOLYGON (((95.70458 19...\n10 MULTIPOLYGON (((95.85173 18...\n\n\n\n\n\n\n\n2.2.2.1 Understanding the data set fields.\n\n\n\n\n\n\n\nField Name\nDescription\n\n\nOBJECTID\nThis is a unique identifier for each feature in the dataset, typically used to identify individual records or polygons in the shapefile.\n\n\nST\nThis represents the State or Region in Myanmar. For example, in your dataset, “Ayeyarwady” refers to a state/region.\n\n\nST_PCODE\nThis stands for State Postal Code. It is a standardized code that represents each state or region in Myanmar, such as “MMR017” for Ayeyarwady.\n\n\nDT\nThis stands for District or Township within the respective state/region. For example, “Hinthada” is a district or township within Ayeyarwady.\n\n\nDT_PCODE\nThis stands for District/Township Postal Code. It is a standardized postal code for each district or township, such as “MMR017D002” for the Hinthada district/township in Ayeyarwady.\n\n\nDT_MMR\nThis field could be the District/Township name in Myanmar script, written in the local language. It may be an alternative representation of the “DT” field, showing the name of the district/township in Myanmar’s native language.\n\n\nPCODE_V\nThis could be a Version of the Postal Code or a verification value used internally in the dataset. In this case, the value is “9.4”, possibly indicating a specific version of postal codes or an accuracy measure.\n\n\ngeometry\nThis column represents the spatial data for each district/township. It contains the geometrical shape (MULTIPOLYGON) defining the boundaries of the state or district/township, with coordinates provided in longitude and latitude."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#myanmar-shapefile",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#myanmar-shapefile",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "3.1 Myanmar Shapefile",
    "text": "3.1 Myanmar Shapefile\n\n3.1.1 Setting the CRS for the\nSince Myanmar uses CRS of 32647 and when we download the map it’s in WGS84, we should change it to 32647 .\n\nStateDistrict\n\n\n\nst_crs(M_State_Sf)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n# Set the CRS for m_sf, assuming the appropriate CRS is WGS 84 (EPSG:32647)\nM_State_Sf &lt;- st_transform(M_State_Sf, crs = 32647)\n# Verify that the CRS has been correctly set\nprint(st_crs(M_State_Sf))\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\n\n\nst_crs(M_District_Sf)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n# Set the CRS for m_sf, assuming the appropriate CRS is WGS 84 (EPSG:32647)\nM_District_Sf &lt;- st_transform(M_District_Sf, crs = 32647)\n# Verify that the CRS has been correctly set\nprint(st_crs(M_District_Sf))\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\n\n\n\n\n3.1.2 Renaming and removal of column names\n\nStateDistrict\n\n\n\ncolnames(M_State_Sf) &lt;- c(\"OBJECTID\", \"state\",\"state_code\",\"type\", \"state_myr\", \"mimi_version\", \"geometry\")\n\nM_State_Sf_Cleansed &lt;- M_State_Sf %&gt;% select(state, type, state_myr ,geometry)\n\n\n\n\ncolnames(M_District_Sf) &lt;- c(\"OBJECTID\", \"state\", \"state_code\", \"district\", \"district_code\", \"district_mmr\", \"mimi_version\", \"geometry\")\n\nM_District_Sf_Cleansed &lt;- M_District_Sf %&gt;% select(state, district, district_mmr, geometry)\n\n\n\n\n\n\n3.1.3 Checking for validity of data\nWhen working with spatial data, it’s crucial to ensure that all geometries are valid. Invalid geometries can cause errors in analysis and visualization.\n\nChecking Validity with st_is_valid():\nIdentifying Invalid Geometries:\nFixing Invalid Geometries with st_make_valid()\n\n\nStateDistrict\n\n\n\n#checking if it's valid\nM_State_Sf_Validity &lt;- st_is_valid(M_State_Sf_Cleansed)\nM_State_Sf_Invalid &lt;- which(!M_State_Sf_Validity)\nif (length(M_State_Sf_Invalid) &gt; 0) {\n  print(\"MPZ Invalid!\")\n  print(M_State_Sf_cleansed[M_State_Sf_Invalid, ])\n} else {\n  print(\"it's valid!\")\n}\n\n[1] \"it's valid!\"\n\n\n\n\n\n#checking if it's valid\nM_District_Sf_Validity &lt;- st_is_valid(M_District_Sf_Cleansed)\nM_District_Sf_Invalid &lt;- which(!M_District_Sf_Validity)\nif (length(M_District_Sf_Invalid) &gt; 0) {\n  print(\"MPZ Invalid!\")\n  print(M_District_Sf_cleansed[M_District_Sf_Invalid, ])\n} else {\n  print(\"it's valid!\")\n}\n\n[1] \"it's valid!\"\n\n\n\n\n\n\n\n3.1.4 Visualizing the mynamar map\nOn the top right, you can toggle between the district level and also the state level to understand more about the boundaries of Myanmar.\n\nStateDistrict\n\n\n\ntm_shape(M_State_Sf_Cleansed) +  # Base map (Myanmar boundaries)\n  tm_basemap(server = \"OpenStreetMap.HOT\") +  # Add OpenStreetMap as the basemap\n  tm_polygons(\"state\",  # Color the base map by state\n              palette = \"Set3\",  # Use Set3 color palette for states\n              border.col = \"gray\",  # Border color for the states\n              alpha = 0.5,  # Semi-transparent polygons\n              title = \"State\",  # Legend title for states\n              legend.show = TRUE  # Show legend for state colors\n             ) +\n  tm_layout(main.title = \"States of Myanmar\",  # Main map title\n            legend.outside = TRUE)  # Position the legend outside the map\n\n\n\n\n\n\n\n\n\n\nThere is more than 80 district here, so it only showcases 30 :)\n\ntm_shape(M_District_Sf_Cleansed) +  # Base map (Myanmar boundaries)\n  tm_basemap(server = \"OpenStreetMap.HOT\") +  # Add OpenStreetMap as the basemap\n  tm_polygons(\"district\",  # Color the base map by state\n              palette = \"Set3\",  # Use Set3 color palette for states\n              border.col = \"gray\",  # Border color for the states\n              alpha = 0.5,  # Semi-transparent polygons\n              title = \"District\",  # Legend title for states\n              legend.show = TRUE  # Show legend for state colors\n             ) +\n  tm_layout(main.title = \"District of Myanmar\",  # Main map title\n            legend.outside = TRUE)  # Position the legend outside the map\n\nWarning: Number of levels of the variable \"district\" is 80, which is larger\nthan max.categories (which is 30), so levels are combined. Set\ntmap_options(max.categories = 80) in the layer function to show all levels.\n\n\nSome legend labels were too wide. These labels have been resized to 0.51, 0.48, 0.53, 0.52, 0.49. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#acled-data",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#acled-data",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "3.2 ACLED Data",
    "text": "3.2 ACLED Data\n\n3.2.1 Changing the Column Names\nSince Myanmar’s regional hierarchy follows State, District, and Township levels, we will rename the columns accordingly:\n\nadmin1 → State\nadmin2 → District\nadmin3 → Township\n\nThis is important because different countries use different administrative hierarchies. For example, in Singapore, the hierarchy is organized by Region and Subzones. Adjusting these names ensures that our dataset aligns with Myanmar’s specific regional structure for accurate analysis.\n\nACLEDData_Cleanse &lt;- ACLEDData %&gt;%\n  select(event_id_cnty, event_date, year, disorder_type, event_type, actor1, inter1, \n         actor2, inter2, interaction, admin1, admin2, admin3, location, latitude, \n         longitude, fatalities) %&gt;%\n  rename(state = admin1, district = admin2, township = admin3) %&gt;%\n  mutate(across(where(is.character), ~ replace_na(.x, \"NA\")),  # Replace NA in character columns with \"NA\"\n         across(where(is.numeric), ~ replace_na(.x, 0)))  # Replace NA in numeric columns with 0\n\n\n\n3.2.2 Adding a “Quarter-Year” Column\nTo facilitate our temporal analysis, we need to add a “quarter-year” column based on the event_date field. This can be done by adjusting the date format to represent the quarter and year, ensuring that each event is categorized by the specific quarter it occurred in (e.g., Q1-2021, Q2-2022). This will allow for easier analysis of conflict trends over time.\n\n# Convert event_date to Date format (if it's not already a date)\nACLEDData_Cleanse$event_date &lt;- as.Date(ACLEDData_Cleanse$event_date, format=\"%d-%b-%y\")  # Adjust the format if needed\n# Add a new column that shows the quarter and year\nACLEDData_Cleanse &lt;- ACLEDData_Cleanse %&gt;%\n  mutate(quarter_year = paste0(\"Q\", quarter(event_date), \"-\", year(event_date)))\n\nhead(ACLEDData_Cleanse)\n\n# A tibble: 6 × 18\n  event_id_cnty event_date  year disorder_type   event_type actor1 inter1 actor2\n  &lt;chr&gt;         &lt;date&gt;     &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;      &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; \n1 MMR64313      2024-06-30  2024 Political viol… Battles    Peopl…      3 Milit…\n2 MMR64320      2024-06-30  2024 Political viol… Battles    Peopl…      3 Milit…\n3 MMR64321      2024-06-30  2024 Political viol… Battles    Peopl…      3 Milit…\n4 MMR64322      2024-06-30  2024 Strategic deve… Strategic… Milit…      1 NA    \n5 MMR64323      2024-06-30  2024 Political viol… Battles    PKDF …      3 Milit…\n6 MMR64324      2024-06-30  2024 Strategic deve… Strategic… Milit…      1 NA    \n# ℹ 10 more variables: inter2 &lt;dbl&gt;, interaction &lt;dbl&gt;, state &lt;chr&gt;,\n#   district &lt;chr&gt;, township &lt;chr&gt;, location &lt;chr&gt;, latitude &lt;dbl&gt;,\n#   longitude &lt;dbl&gt;, fatalities &lt;dbl&gt;, quarter_year &lt;chr&gt;\n\n\n\n\n3.2.3 Joining ACLED’s Codebook Description\nACLED’s stores their data for the column “interaction” and “inter1” and “inter2” in codes, using their code book, let’s reorganise their data for simplier view, we can reference the code book here to know what each code represent. Map it out as a csv file read it in and change accordingly.\n\n3.2.3.1 Left joining inter1 and inter’s description.\nFor more details about each inter code read here.\n\nACLEDActorInterCode &lt;- read_csv(\"data/raw/aspatial/ActorTypesInterCode.csv\")\n\nRows: 8 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Description\ndbl (1): code\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nACLEDData_Cleanse &lt;- ACLEDData_Cleanse %&gt;%\n  left_join(ACLEDActorInterCode, by = c(\"inter1\" = \"code\")) %&gt;%\n  rename(inter1_description = Description)\n# Left join again for inter2\nACLEDData_Cleanse &lt;- ACLEDData_Cleanse %&gt;%\n  left_join(ACLEDActorInterCode, by = c(\"inter2\" = \"code\")) %&gt;%\n  rename(inter2_description = Description)\n\nhead(ACLEDData_Cleanse)\n\n# A tibble: 6 × 20\n  event_id_cnty event_date  year disorder_type   event_type actor1 inter1 actor2\n  &lt;chr&gt;         &lt;date&gt;     &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;      &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; \n1 MMR64313      2024-06-30  2024 Political viol… Battles    Peopl…      3 Milit…\n2 MMR64320      2024-06-30  2024 Political viol… Battles    Peopl…      3 Milit…\n3 MMR64321      2024-06-30  2024 Political viol… Battles    Peopl…      3 Milit…\n4 MMR64322      2024-06-30  2024 Strategic deve… Strategic… Milit…      1 NA    \n5 MMR64323      2024-06-30  2024 Political viol… Battles    PKDF …      3 Milit…\n6 MMR64324      2024-06-30  2024 Strategic deve… Strategic… Milit…      1 NA    \n# ℹ 12 more variables: inter2 &lt;dbl&gt;, interaction &lt;dbl&gt;, state &lt;chr&gt;,\n#   district &lt;chr&gt;, township &lt;chr&gt;, location &lt;chr&gt;, latitude &lt;dbl&gt;,\n#   longitude &lt;dbl&gt;, fatalities &lt;dbl&gt;, quarter_year &lt;chr&gt;,\n#   inter1_description &lt;chr&gt;, inter2_description &lt;chr&gt;\n\n\n\n\n3.2.3.2 Left joining interaction description.\nFor more details about each interaction code read here.\n\nACLEDInteractionCode &lt;- read_csv(\"data/raw/aspatial/AcledInteractionCodes.csv\")\n\nRows: 44 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Description\ndbl (1): code\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nACLEDData_Cleanse &lt;- ACLEDData_Cleanse %&gt;%\n  left_join(ACLEDInteractionCode, by = c(\"interaction\" = \"code\")) %&gt;%\n  rename(interaction_description = Description)\nhead(ACLEDData_Cleanse)\n\n# A tibble: 6 × 21\n  event_id_cnty event_date  year disorder_type   event_type actor1 inter1 actor2\n  &lt;chr&gt;         &lt;date&gt;     &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;      &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; \n1 MMR64313      2024-06-30  2024 Political viol… Battles    Peopl…      3 Milit…\n2 MMR64320      2024-06-30  2024 Political viol… Battles    Peopl…      3 Milit…\n3 MMR64321      2024-06-30  2024 Political viol… Battles    Peopl…      3 Milit…\n4 MMR64322      2024-06-30  2024 Strategic deve… Strategic… Milit…      1 NA    \n5 MMR64323      2024-06-30  2024 Political viol… Battles    PKDF …      3 Milit…\n6 MMR64324      2024-06-30  2024 Strategic deve… Strategic… Milit…      1 NA    \n# ℹ 13 more variables: inter2 &lt;dbl&gt;, interaction &lt;dbl&gt;, state &lt;chr&gt;,\n#   district &lt;chr&gt;, township &lt;chr&gt;, location &lt;chr&gt;, latitude &lt;dbl&gt;,\n#   longitude &lt;dbl&gt;, fatalities &lt;dbl&gt;, quarter_year &lt;chr&gt;,\n#   inter1_description &lt;chr&gt;, inter2_description &lt;chr&gt;,\n#   interaction_description &lt;chr&gt;\n\n\n\n\n\n3.2.3 Making it a SF Object and reverse geolocate state and district\nSince ACLED provides longitude and latitude data, I prefer to reverse geolocate the points to match Myanmar’s official state and district boundaries. We are uncertain how ACLED assigns these regions, so to ensure consistency, we remove the original state and district columns from the ACLED data and replace them with the geolocated values.\nSteps:\n\nConvert ACLED Data to an SF Object: Using longitude and latitude coordinates, transform the ACLED dataset into a spatial object. Remember thatt we have to set CRS 32647 here as well.\nPerform a Spatial Join: Match the points from ACLED with the corresponding state and district boundaries from the m_sf shapefile, selecting only those columns.\nRemove Original Columns: After the spatial join, drop the original state, district, and township columns from the ACLED dataset.\nRename the Joined Columns: Rename the newly joined state.y and district.y to state and district, effectively replacing the original columns with the reverse-geolocated values.\n\n\n# Step 1: Convert ACLEDDataCleanse to an sf object using longitude and latitude\nACLEDData_Cleanse_Sf &lt;- st_as_sf(ACLEDData_Cleanse, coords = c(\"longitude\", \"latitude\"), crs = 4326, remove = FALSE)\n\n# Step 2: Transform ACLEDDataCleanse_sf to the same CRS as m_sf (EPSG: 32647)\nACLEDData_Cleanse_Sf &lt;- st_transform(ACLEDData_Cleanse_Sf, crs = 32647)\n\n# Step 3: Perform a spatial join, selecting only the state and district from m_sf\nreverse_geolocated_state &lt;- st_join(ACLEDData_Cleanse_Sf, M_State_Sf_Cleansed[, c(\"state\")], join = st_intersects)\n\n# Step 2: Spatial join to add 'district' from M_District_Sf_Cleansed\nreverse_geolocated_district &lt;- st_join(reverse_geolocated_state, M_District_Sf_Cleansed[, c(\"district\")], join = st_intersects)\n\n# Step 3: Remove original 'state', 'district', and 'township' columns from ACLEDData_Cleanse (if they exist)\n# This step removes the original columns, and then renames the newly joined columns\nACLEDData_Cleanse_Sf &lt;- reverse_geolocated_district %&gt;%\n  select(-contains(\"state.x\"), -contains(\"district.x\"), -contains(\"township\")) %&gt;%  # Remove old state, district, township columns\n  rename(state = state.y, district = district.y)  # Rename newly joined columns\n\nACLEDData_Cleanse &lt;- st_drop_geometry(ACLEDData_Cleanse_Sf)\n\n# View the updated data\nprint(ACLEDData_Cleanse_Sf)\n\nSimple feature collection with 42608 features and 20 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -208804.4 ymin: 1103500 xmax: 640934.5 ymax: 3042960\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 42,608 × 21\n   event_id_cnty event_date  year disorder_type  event_type actor1 inter1 actor2\n   &lt;chr&gt;         &lt;date&gt;     &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; \n 1 MMR64313      2024-06-30  2024 Political vio… Battles    Peopl…      3 Milit…\n 2 MMR64320      2024-06-30  2024 Political vio… Battles    Peopl…      3 Milit…\n 3 MMR64321      2024-06-30  2024 Political vio… Battles    Peopl…      3 Milit…\n 4 MMR64322      2024-06-30  2024 Strategic dev… Strategic… Milit…      1 NA    \n 5 MMR64323      2024-06-30  2024 Political vio… Battles    PKDF …      3 Milit…\n 6 MMR64324      2024-06-30  2024 Strategic dev… Strategic… Milit…      1 NA    \n 7 MMR64325      2024-06-30  2024 Political vio… Battles    Milit…      1 PSLF/…\n 8 MMR64326      2024-06-30  2024 Political vio… Battles    PSLF/…      2 Milit…\n 9 MMR64328      2024-06-30  2024 Political vio… Battles    Milit…      1 PSLF/…\n10 MMR64330      2024-06-30  2024 Political vio… Battles    Milit…      1 PSLF/…\n# ℹ 42,598 more rows\n# ℹ 13 more variables: inter2 &lt;dbl&gt;, interaction &lt;dbl&gt;, location &lt;chr&gt;,\n#   latitude &lt;dbl&gt;, longitude &lt;dbl&gt;, fatalities &lt;dbl&gt;, quarter_year &lt;chr&gt;,\n#   inter1_description &lt;chr&gt;, inter2_description &lt;chr&gt;,\n#   interaction_description &lt;chr&gt;, geometry &lt;POINT [m]&gt;, state &lt;chr&gt;,\n#   district &lt;chr&gt;\n\n\n\n\n3.2.5 Visualizing it by Event Type\n\n# Set tmap mode to plot for static maps\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n# Create the tmap object with the base map and event markers\ntm_basemap(server = \"OpenStreetMap\") +  # Add OpenStreetMap as the base map\n  \n  # Add Myanmar state boundaries with transparency\n  tm_shape(M_State_Sf_Cleansed) + \n  tm_polygons(\"state\", alpha = 0.3, border.col = \"gray\", \n              title = \"State Boundaries\", legend.show = TRUE) +  # Add a legend for state boundaries\n  \n  # Add event markers (bubbles) with size based on fatalities\n  tm_shape(ACLEDData_Cleanse_Sf) + \n  tm_bubbles(size = \"fatalities\",  # Marker size based on fatalities\n             col = \"event_type\",  # Color markers by event type\n             palette = \"Set1\",  # Use Set1 color palette for event types\n             border.col = \"black\",  # Border color for bubbles\n             border.alpha = 0.5,  # Semi-transparent border\n             title.size = \"Number of Fatalities\",  # Title for bubble size legend\n             title.col = \"Event Types\",  # Title for event type legend\n             legend.size.show = TRUE,  # Show legend for bubble size\n             legend.col.show = TRUE) +  # Show legend for event types\n  \n  # Layout settings for the map, including title and legend positioning\n  tm_layout(main.title = \"Myanmar's State Conflicts by Fatalities\",  # Main map title\n            main.title.size = 1.5,  # Title font size\n            legend.outside = TRUE,  # Position legend outside the map\n            legend.outside.size = 0.5,  # Adjust size of outside legend\n            legend.position = c(\"left\", \"top\"),  # Position for the event type legend\n            legend.title.size = 1.2,  # Size of the legend title\n            legend.text.size = 1,  # Size of the legend text\n            legend.bg.color = \"white\",  # Background color for the legend\n            legend.bg.alpha = 0.5,  # Transparency for the legend background\n            inner.margins = c(0.05, 0.05, 0.05, 0.05))  # Inner margins for the map\n\nlegend.postion is used for plot mode. Use view.legend.position in tm_view to set the legend position in view mode.\n\n\nLegend for symbol sizes not available in view mode."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#aggregation-of-data-for-exploratory-purposes",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#aggregation-of-data-for-exploratory-purposes",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "4.1 Aggregation of Data for exploratory purposes",
    "text": "4.1 Aggregation of Data for exploratory purposes\nStep 1: Filter Data for Civilians\nIn this first step, the data (ACLEDData_Cleanse) is filtered so that only rows where either “Civilians” are involved in the conflict (inter1_description or inter2_description) are kept. Additionally, rows where the state information is missing (NA) are removed because these conflicts can’t be assigned to a specific geographical area.\n\nfiltered_data &lt;- ACLEDData_Cleanse %&gt;%\n  filter((inter1_description == \"Civilians\" | inter2_description == \"Civilians\") & !is.na(state))\n\nStep 2: Calculate State Area in Square Kilometers\nNext, the code calculates the area for each state from the M_State_Sf_Cleansed spatial dataset. The st_area function retrieves the area in square meters, and dividing by 1 million (1e6) converts it into square kilometers. This information will be used later to calculate conflict and fatality density.\n\nstate_area_km2 &lt;- st_area(M_State_Sf_Cleansed) / 1e6\nstate_area_df &lt;- data.frame(state = M_State_Sf_Cleansed$state, area_km2 = as.numeric(state_area_km2))\n\nStep 3: Aggregate Total Conflicts and Fatalities by State\nThe next step is to group the filtered data by state and calculate two key metrics: the total number of conflicts and the total number of fatalities for each state. This is done using group_by and summarise.\n\nagg_data_by_state &lt;- filtered_data %&gt;%\n  group_by(state) %&gt;%\n  summarise(\n    total_conflicts = n(), \n    total_fatalities = sum(fatalities, na.rm = TRUE), \n    .groups = \"drop\"\n  )\n\nStep 4: Convert to Non-Spatial Data Frame\nHere, the spatial data is converted into a regular data frame by dropping the geometry information. This allows easier manipulation of the non-spatial data for further processing.\n\nfiltered_data_df &lt;- st_drop_geometry(filtered_data)\n\nStep 5: Prepare Data Frame for Yearly Data\nTo store yearly conflict and fatality data for each state, an empty data frame is initialized by selecting distinct states from the filtered data\n\nfinal_result &lt;- filtered_data_df %&gt;% select(state) %&gt;% distinct()\n\nStep 6: Loop Through Each Year and Calculate Yearly Conflicts/Fatalities\nIn this step, the code iterates over each unique year in the dataset. For each year, it calculates the total conflicts and fatalities for each state. The results are merged back into the final_result data frame, with columns named according to the year (e.g., conflicts_2021, fatalities_2021).\n\nunique_years &lt;- unique(filtered_data_df$year)\n\nfor (yr in unique_years) {\n  yearly_data &lt;- filtered_data_df %&gt;%\n    filter(year == yr) %&gt;%\n    group_by(state) %&gt;%\n    summarise(\n      conflicts = n(), \n      fatalities = sum(fatalities, na.rm = TRUE)\n    ) %&gt;%\n    rename_at(vars(conflicts, fatalities), ~ paste0(., \"_\", yr))  # Rename with year\n  \n  final_result &lt;- left_join(final_result, yearly_data, by = \"state\")\n}\n\nStep 7: Replace NAs with 0\nAny missing data for a state-year combination (e.g., a state with no conflicts in a particular year) is replaced with 0 to avoid leaving gaps in the analysis.\n\nfinal_result &lt;- final_result %&gt;%\n  mutate(across(everything(), ~ ifelse(is.na(.), 0, .)))\n\nStep 8: Calculate Conflict and Fatality Density\nNow, the code calculates the density of conflicts and fatalities per square kilometer for each state. The results from Step 3 (agg_data_by_state) are joined with the state area data from Step 2. The density is simply the number of conflicts or fatalities divided by the area in square kilometers.\n\nagg_data_with_density &lt;- agg_data_by_state %&gt;%\n  left_join(state_area_df, by = \"state\") %&gt;%\n  mutate(\n    conflict_density = total_conflicts / area_km2,\n    fatality_density = total_fatalities / area_km2\n  )\n\nStep 9: Merge Yearly Data and Density with Spatial Data\nFinally, the spatial data (M_State_Sf_Cleansed) is merged with the yearly conflict/fatality data (final_result) and the density data (agg_data_with_density). Additional calculations are made to find the fatality-per-conflict ratio which are then added to the final spatial dataset.\n\nfinalized_map &lt;- M_State_Sf_Cleansed %&gt;%\n  left_join(final_result, by = \"state\") %&gt;%\n  left_join(agg_data_with_density, by = \"state\")\n\nfinalized_map &lt;- finalized_map %&gt;%\n  mutate(conflict_fatality_ratio = ifelse(total_fatalities == 0, NA, total_fatalities / total_conflicts))\n\nfinalized_map &lt;- finalized_map %&gt;%\n  mutate(\n    fatality_per_conflict = ifelse(total_conflicts == 0, NA, total_fatalities / total_conflicts),\n  )\n\nfinalized_map &lt;- finalized_map %&gt;%\n  mutate(\n    rank_total_conflicts = rank(-total_conflicts, ties.method = \"min\"),  # Rank total_conflicts (largest to smallest)\n    rank_total_fatalities = rank(-total_fatalities, ties.method = \"min\"),  # Rank total_fatalities (largest to smallest)\n    rank_conflict_density = rank(-conflict_density, ties.method = \"min\"),  # Rank conflict_density (largest to smallest)\n    rank_fatality_density = rank(-fatality_density, ties.method = \"min\"),  # Rank fatality_density (largest to smallest)\n    rank_fatality_per_conflict = rank(-fatality_per_conflict, ties.method = \"min\")  # Rank fatality_per_conflict (largest to smallest)\n  )\n\nFinal Output: Display the Data\nThe finalized_map contains all the processed information, including conflict/fatality counts, densities, and state geometry, which can now be visualized or further analyzed.\n\nhead(finalized_map)\n\nSimple feature collection with 6 features and 23 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -162806.6 ymin: 1682875 xmax: 491639.1 ymax: 3158467\nProjected CRS: WGS 84 / UTM zone 47N\n       state   type      state_myr conflicts_2024 fatalities_2024\n1 Ayeyarwady Region ဧရာဝတီတိုင်းဒေသကြီး             64               9\n2       Bago Region   ပဲခူးတိုင်းဒေသကြီး            194             128\n3       Chin  State      ချင်းပြည်နယ်             72              52\n4     Kachin  State      ကချင်ပြည်နယ်            160              95\n5      Kayah  State      ကယားပြည်နယ်             21              38\n6      Kayin  State       ကရင်ပြည်နယ်             52              59\n  conflicts_2023 fatalities_2023 conflicts_2022 fatalities_2022 conflicts_2021\n1             83               7            177              29            233\n2            339             220            172              61            191\n3            101              76            204              80            160\n4            316             133            226             140            221\n5            113              74            149              87            114\n6            165              83            165              86            116\n  fatalities_2021 total_conflicts total_fatalities area_km2 conflict_density\n1              34             557               79 33738.82       0.01650917\n2              87             896              496 38556.99       0.02323833\n3              32             537              240 36276.56       0.01480295\n4              71             923              439 88977.32       0.01037343\n5             108             397              307 11763.10       0.03374961\n6              57             498              285 30337.59       0.01641528\n  fatality_density                       geometry conflict_fatality_ratio\n1      0.002341516 MULTIPOLYGON (((93411.72 17...               0.1418312\n2      0.012864076 MULTIPOLYGON (((203949.9 21...               0.5535714\n3      0.006615843 MULTIPOLYGON (((-72918.03 2...               0.4469274\n4      0.004933841 MULTIPOLYGON (((362696.3 31...               0.4756230\n5      0.026098563 MULTIPOLYGON (((309155.7 22...               0.7732997\n6      0.009394287 MULTIPOLYGON (((373551.3 18...               0.5722892\n  fatality_per_conflict rank_total_conflicts rank_total_fatalities\n1             0.1418312                   11                    14\n2             0.5535714                    9                     6\n3             0.4469274                   12                    13\n4             0.4756230                    8                     7\n5             0.7732997                   14                    10\n6             0.5722892                   13                    12\n  rank_conflict_density rank_fatality_density rank_fatality_per_conflict\n1                    10                    15                         15\n2                     9                     8                          4\n3                    12                    11                          9\n4                    15                    13                          6\n5                     6                     4                          1\n6                    11                    10                          3\n\n\n\n4.2 Visualizing the aggregated data.\nFor each column that we created earlier, we can now showcase it in a choropleth map to highlight the states with the highest values in each category. These maps will help visually identify which state has the highest value for each column. You can navigate through the tabset to explore the different metrics and easily view the data on a map!\n\nTotal Civilian ConflictsTotal Fatalities for civilians related conflicts.Civilian Conflict DensityFatality DensityFatality Per Civilian Conflict\n\n\n\n# Create the tmap object for total civilian conflicts\ntm_total_conflicts &lt;- \n  # Layer for total civilian conflicts\n  tm_shape(finalized_map) +\n  tm_polygons(\"total_conflicts\", \n              title = \"Total Civilian Related Conflicts\",\n              palette = \"Reds\", \n              border.col = \"black\", \n              alpha = 0.8,  # Transparency for polygons\n              border.alpha = 0.5,  # Semi-transparent border\n              id = \"state\") +  # Set state as identifier for the polygons\n\n  # Layout settings matching your style\n  tm_layout(\n    main.title = \"Myanmar's State by Total Civilian Related Conflicts\",  # Main map title\n    main.title.size = 1.0,  # Title font size\n    legend.outside = TRUE,  # Position legend outside the map\n    legend.outside.size = 0.5,  # Adjust size of outside legend\n    legend.position = c(\"left\", \"top\"),  # Position for the event type legend\n    legend.title.size = 1.2,  # Size of the legend title\n    legend.text.size = 1,  # Size of the legend text\n    legend.bg.color = \"white\",  # Background color for the legend\n    legend.bg.alpha = 0.5,  # Transparency for the legend background\n    inner.margins = c(0.05, 0.05, 0.05, 0.05)  # Set inner margins for better spacing\n  )\ntm_total_conflicts\n\n\n\n\n\n\n\n\n\n\n\n# Create the tmap object for total civilian conflicts\ntm_total_fatalities &lt;- tm_basemap(server = c(\"Esri.WorldGrayCanvas\", \"OpenStreetMap\", \"Esri.WorldTopoMap\")) +\n  # Layer for total civilian conflicts\n  tm_shape(finalized_map) +\n  tm_polygons(\"total_fatalities\", \n              title = \"Total Fatalities by Civilian Related Conflicts\",\n              palette = \"Blues\", \n              border.col = \"black\", \n              alpha = 0.8,  # Transparency for polygons\n              border.alpha = 0.5,  # Semi-transparent border\n              id = \"state\") +  # Set state as identifier for the polygons\n\n  # Layout settings matching your style\n  tm_layout(\n    main.title = \"Myanmar's State by Total Fatatlies For Civilian Related Conflicts\",  # Main map title\n    main.title.size = 1.0,  # Title font size\n    legend.outside = TRUE,  # Position legend outside the map\n    legend.outside.size = 0.5,  # Adjust size of outside legend\n    legend.position = c(\"left\", \"top\"),  # Position for the event type legend\n    legend.title.size = 1.2,  # Size of the legend title\n    legend.text.size = 1,  # Size of the legend text\n    legend.bg.color = \"white\",  # Background color for the legend\n    legend.bg.alpha = 0.5,  # Transparency for the legend background\n    inner.margins = c(0.05, 0.05, 0.05, 0.05)  # Set inner margins for better spacing\n  )\n\ntm_total_fatalities\n\n\n\n\n\n\n\n\n\n\n\ntm_conflict_density &lt;-\n  # Layer for total civilian conflicts\n  tm_shape(finalized_map) +\n  tm_polygons(\"conflict_density\", \n              title = \"Myanmar State by Civilian Related Conflicts Density\",\n              palette = \"Blues\", \n              border.col = \"black\", \n              alpha = 0.8,  # Transparency for polygons\n              border.alpha = 0.5,  # Semi-transparent border\n              id = \"state\") +  # Set state as identifier for the polygons\n\n  # Layout settings matching your style\n  tm_layout(\n    main.title = \"Myanmar State by Civilian Related Conflicts Density\",  # Main map title\n    main.title.size = 1.0,  # Title font size\n    legend.outside = TRUE,  # Position legend outside the map\n    legend.outside.size = 0.5,  # Adjust size of outside legend\n    legend.position = c(\"left\", \"top\"),  # Position for the event type legend\n    legend.title.size = 1.2,  # Size of the legend title\n    legend.text.size = 1,  # Size of the legend text\n    legend.bg.color = \"white\",  # Background color for the legend\n    legend.bg.alpha = 0.5,  # Transparency for the legend background\n    inner.margins = c(0.05, 0.05, 0.05, 0.05)  # Set inner margins for better spacing\n  )\n\ntm_conflict_density\n\n\n\n\n\n\n\n\n\n\n\ntm_fatalities_conflict &lt;- \n  # Layer for total civilian conflicts\n  tm_shape(finalized_map) +\n  tm_polygons(\"fatality_density\", \n              title = \"Myanmar State by Fatalies For Civilians Related Conflicts Density Per Km^2\",\n              palette = \"Blues\", \n              border.col = \"black\", \n              alpha = 0.8,  # Transparency for polygons\n              border.alpha = 0.5,  # Semi-transparent border\n              id = \"state\") +  # Set state as identifier for the polygons\n\n  # Layout settings matching your style\n  tm_layout(\n    main.title = \"Myanmar State by Fatalies For Civilians Related Conflicts Density Per Km^2\",  # Main map title\n    main.title.size = 1.0,  # Title font size\n    legend.outside = TRUE,  # Position legend outside the map\n    legend.outside.size = 0.5,  # Adjust size of outside legend\n    legend.position = c(\"left\", \"top\"),  # Position for the event type legend\n    legend.title.size = 1.0,  # Size of the legend title\n    legend.text.size = 0.8,  # Size of the legend text\n    legend.bg.color = \"white\",  # Background color for the legend\n    legend.bg.alpha = 0.5,  # Transparency for the legend background\n    inner.margins = c(0.05, 0.05, 0.05, 0.05)  # Set inner margins for better spacing\n  )\n\ntm_fatalities_conflict\n\n\n\n\n\n\n\n\n\n\n\ntm_fatalities_density &lt;-\n  # Layer for total civilian conflicts\n  tm_shape(finalized_map) +\n  tm_polygons(\"fatality_per_conflict\", \n              title = \"Myanmar State by Fatalies for Civilian Related Conflicts\",\n              palette = \"Blues\", \n              border.col = \"black\", \n              alpha = 0.8,  # Transparency for polygons\n              border.alpha = 0.5,  # Semi-transparent border\n              id = \"state\") +  # Set state as identifier for the polygons\n\n  # Layout settings matching your style\n  tm_layout(\n    main.title = \"Myanmar State by Fatalies for Civilian Related Conflicts\",  # Main map title\n    main.title.size = 1.0,  # Title font size\n    legend.outside = TRUE,  # Position legend outside the map\n    legend.outside.size = 0.5,  # Adjust size of outside legend\n    legend.position = c(\"left\", \"top\"),  # Position for the event type legend\n    legend.title.size = 1.0,  # Size of the legend title\n    legend.text.size = 0.8,  # Size of the legend text\n    legend.bg.color = \"white\",  # Background color for the legend\n    legend.bg.alpha = 0.5,  # Transparency for the legend background\n    inner.margins = c(0.05, 0.05, 0.05, 0.05)  # Set inner margins for better spacing\n  )\n\ntm_fatalities_density"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#analysis-on-the-aggregated-data-to-find-top-3-state-to-analyse",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#analysis-on-the-aggregated-data-to-find-top-3-state-to-analyse",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "4.3 Analysis on the aggregated data to find top 3 state to analyse",
    "text": "4.3 Analysis on the aggregated data to find top 3 state to analyse\n\n4.3.1 Choose which States to analyse?\nWith the maps above, everyone can choose what they would like to analyze, whether it’s total civilian conflicts or fatalities by state. However, I would like to focus on the central question:\nWhich state has the highest amount of conflict and fatality density?\nBy using density, I’ve aimed to assess fatalities in relation to conflicts and ensure a fair comparison by adjusting for density.\n\n\n\n\n\n\nNote\n\n\n\nKeep in mind, this is not the most precise analysis, as other factors—such as ethnicity, population demographics, and gender—could also be considered. However, for the purpose of this study, I have chosen to focus on solely on the state’s conflict and fatality density.\n\n\nConflict Density: This is the number of conflicts per square kilometer in a state.\n\nConflict Density=Total ConflictsArea of State (km²) = Conflict Density=Area of State (km²)Total Conflicts​\nThis tells you how many conflicts occur per unit of area (1 km²) in each state.\nFatality Density: This is the number of fatalities per square kilometer.\nFatality Density=Total FatalitiesArea of State (km²) = Fatality Density=Area of State (km²)Total Fatalities​\n\n\n\n4.3.2 Viewing the top 3 states across\nUsing the map below, you can interactively explore the Conflict and Fatality Density. We observe that the top three states are as follows, and here’s how they compare across the data set.\nYou can use the layer toggle to switch between fatalities and conflicts, or click on the map layers to view detailed, aggregated data for each state.\n\n# Step 1: Set tmap mode to view for interactive maps\n\n# Step 2: Define popup variables to show all relevant columns when clicking on a state\npopup_variables &lt;- c( \n                     \"Total Civilian Conflicts\" = \"total_conflicts\",\n                     \"Fatalities\" = \"total_fatalities\",\n                     \"Civilian Conflict Density\" = \"conflict_density\",\n                     \"Fatality Density\" = \"fatality_density\",\n                     \"Fatality Per Civilian Conflict\" = \"fatality_per_conflict\",\n                     \"Ranked For Total Conflict By State (Out of 15)\" = \"rank_total_conflicts\",\n                     \"Ranked For Total Fatalities By State (Out of 15)\" = \"rank_total_fatalities\",\n                     \"Ranked For Conflict Density By State (Out of 15)\" = \"rank_conflict_density\",\n                     \"Ranked For Fatalities Density By State (Out of 15)\" = \"rank_fatality_density\",\n                     \"Ranked For Fatalies/Conflict By State (Out of 15)\" = \"rank_fatality_per_conflict\"\n                     )\n\n# Step 3: Create the map with 6 layers for toggling\ntm &lt;- tm_basemap(server = \"OpenStreetMap\") +\n  tm_shape(finalized_map) +\n  tm_polygons(\"conflict_density\", \n              title = \"Civilian Conflict Density\",\n              palette = \"Oranges\", \n              border.col = \"black\",\n              popup.vars = popup_variables,\n              id = \"state\", \n              group = \"Civilian Conflict Density\") +\n  tm_shape(finalized_map) +\n  tm_polygons(\"fatality_density\", \n              title = \"Fatality Density\",\n              palette = \"Purples\", \n              border.col = \"black\",\n              popup.vars = popup_variables,\n              id = \"state\", \n              group = \"Fatality Density\") +\n  tm_layout(\n    legend.outside = TRUE,\n    legend.outside.size = 0.5,  # Adjust the size of the legend\n    legend.position = c(\"left\", \"top\")  # Position the legend\n  )\n# Step 5: Display the interactive map\ntm\n\nlegend.postion is used for plot mode. Use view.legend.position in tm_view to set the legend position in view mode.\n\n\n\n\n\n\nHere we build the bar chart to view rank the states base on the variables.\n\nfinalized_data_df &lt;- as.data.frame(st_drop_geometry(finalized_map))\n# Sort the data by conflict_density and fatality_density in descending order\nfinalized_data_df &lt;- finalized_data_df %&gt;%\n  arrange(desc(conflict_density), desc(fatality_density))\n\n# Format the densities to show \"per km²\"\nfinalized_data_df$conflict_density_label &lt;- paste0(round(finalized_data_df$conflict_density, 2), \" per km²\")\nfinalized_data_df$fatality_density_label &lt;- paste0(round(finalized_data_df$fatality_density, 2), \" per km²\")\n\n# Create bar chart for Conflict Density (sorted by conflict_density)\nconflict_density_plot &lt;- ggplot(finalized_data_df, aes(x = reorder(state, -conflict_density), y = conflict_density)) +\n  geom_bar(stat = \"identity\", fill = \"orange\") +\n  geom_text(aes(label = conflict_density_label), vjust = 1.8, size = 2.0, color = \"black\", position = position_stack(vjust = 0.5)) +  # Place text at bottom of bar\n  ggtitle(\"Top States by Conflict Density (per km²)\") +\n  xlab(\"State\") +\n  ylab(\"Conflict Density (per km²)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# Create bar chart for Fatality Density (sorted by fatality_density)\nfatality_density_plot &lt;- ggplot(finalized_data_df, aes(x = reorder(state, -fatality_density), y = fatality_density)) +\n  geom_bar(stat = \"identity\", fill = \"purple\") +\n  geom_text(aes(label = fatality_density_label), vjust = 1.8, size = 2.0, color = \"black\", position = position_stack(vjust = 0.5)) +  # Place text at bottom of bar\n  ggtitle(\"Top States by Fatality Density (per km²)\") +\n  xlab(\"State\") +\n  ylab(\"Fatality Density (per km²)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# Display both charts side by side\ngrid.arrange(conflict_density_plot, fatality_density_plot, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n4.3.3 Top 3 Chosen state for further analysis\n\n4.3.3.1 Yangon\n\n\n\nYangon, Myanmar’s largest city and former capital, remains the country’s economic and cultural hub. Although it is no longer the political capital, Yangon holds the highest population density in the country, making it a vital urban center with significant influence.\nAccording to the data, Yangon ranks 5th for total conflicts, with 1,489 civilian conflicts reported, and 8th in fatalities, with 431 deaths. However, it stands out with the highest civilian conflict density (0.0531) and fatality density (0.01536) among Myanmar’s 15 states. This means that while the overall number of conflicts may not be the highest, they are more concentrated within Yangon’s urban area, resulting in the highest per-unit area conflict rate.\nYangon’s urbanization and strategic economic importance likely make it a hotspot for civilian unrest. Social tensions in a densely populated city lead to frequent conflicts, reflected in its rank of 1st for conflict density and fatality density. Despite fewer total conflicts compared to other states, Yangon’s density of unrest highlights its vulnerability to civil tensions.\n\n\n4.3.3.2 Mandalay\n\nMandalay, the second-largest city in Myanmar, is known for its cultural significance and central location in the country. It holds a key strategic position in the economy and transportation networks, making it vulnerable to unrest.\nThe data shows Mandalay ranks 2nd for total civilian conflicts with 2,021 conflicts and 950 fatalities. Its civilian conflict density is 0.0255, placing it 3rd in density, while its fatality density is 0.0120, ranked 2nd. Despite being second in conflict counts, the concentration of conflicts and fatalities suggests that civil unrest is deeply rooted in the region, but not as dense as in Yangon.\nMandalay’s high fatality-to-conflict ratio (0.4701 fatalities per conflict) highlights the deadly nature of conflicts, ranking 7th in fatalities per conflict. This reflects a region where conflicts, though frequent, lead to significant loss of life compared to other states.\n\n\n4.3.3.3 Sagaling.\n\nSagaing, located in northern Myanmar, is one of the country’s most conflict-ridden regions, often affected by armed insurgencies and ethnic clashes due to its proximity to volatile borders.\nThe data reveals that Sagaing ranks 1st in total civilian conflicts with 5,346 conflicts and 3,319 fatalities, giving it the highest fatality count as well. However, its civilian conflict density is 0.0241 (ranked 3rd) and its fatality density is 0.01497 (ranked 3rd), indicating a widespread yet slightly less concentrated conflict zone compared to Yangon and Mandalay.\nSagaing’s fatality per civilian conflict ratio of 0.6208 ranks 2nd, emphasizing the high lethality of conflicts in the region. With both the largest number of conflicts and a high fatality rate, Sagaing represents one of the most dangerous and unstable areas in Myanmar for civilians/"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#final-round-of-cleansing-acled-data",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#final-round-of-cleansing-acled-data",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "4.4 Final Round of Cleansing ACLED Data",
    "text": "4.4 Final Round of Cleansing ACLED Data\nIn this final stage of the data cleansing process, we focus on preparing the ACLED (Armed Conflict Location & Event Data) for the different states. The key steps include:\n\nFiltering: We first filter the dataset to focus on data specific to Yangon.\nConverting to Spatial Format: Using the st_as_sf() function, we transform the filtered data into a simple features (sf) object, a format commonly used for spatial data in R. This involves specifying longitude and latitude as the coordinates and setting the correct WGS84 (CRS 4326) coordinate system for global geographic data.\nCoordinate System Transformation: We apply the st_transform() function to project the spatial data from WGS84 (CRS 4326) to UTM Zone 47N (CRS 32647), which is more appropriate for spatial analysis in Myanmar. This step ensures accurate distance and area calculations.\nValidity Check: Using st_is_valid(), we validate the geometries in the spatial data to ensure there are no invalid shapes, such as self-intersecting polygons, which could cause errors during analysis.\nConversion to Spatial Data Frame: Finally, we convert the sf object into a Spatial Data Frame (as_Spatial()) for compatibility with specific spatial analysis functions that require this format.\n\nThis process ensures that the States data is accurately represented in a geospatial format, with proper coordinate transformation and validity checks applied. It prepares the data for further geospatial operations, such as mapping and spatial pattern analysis, with the confidence that the dataset is clean and valid for use.\n\nYangonMandalaySagaing\n\n\n\n# Filter data for Yangon state from the entire ACLED dataset\nYangon_ACLED_Data &lt;- filtered_data %&gt;% \n  filter(state %in% c(\"Yangon\"))\n\n# Check the class of the data to confirm it's a dataframe\nclass(Yangon_ACLED_Data)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n# Convert the filtered data into a spatial format (simple features object)\n# Use longitude and latitude columns as coordinates, with WGS84 (CRS 4326) as the coordinate system\nYangon_ACLED_Data_Sf &lt;- st_as_sf(Yangon_ACLED_Data, coords = c(\"longitude\", \"latitude\"), crs = 4326, remove = FALSE)\n\n# Transform the coordinate system to UTM Zone 47N (CRS 32647) for better spatial precision in Myanmar\nYangon_ACLED_Data_Sf &lt;- st_transform(Yangon_ACLED_Data_Sf, crs = 32647)\n\n# Check the class of the spatial object to confirm conversion\nclass(Yangon_ACLED_Data_Sf)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n# Validate the spatial object to ensure all geometries are valid (no broken or self-intersecting geometries)\nYangon_ACLED_Validity &lt;- st_is_valid(Yangon_ACLED_Data_Sf)\n\n# Identify any invalid geometries and print them if they exist\nYangon_invalid &lt;- which(!Yangon_ACLED_Validity)\nif (length(Yangon_invalid) &gt; 0) {\n  print(\"Yangon is Invalid!\")\n  print(Yangon_ACLED_Data_Sf[Yangon_invalid, ])\n} else {\n  print(\"Yangon_ACLED_Data_Sf is valid!\")\n}\n\n[1] \"Yangon_ACLED_Data_Sf is valid!\"\n\n# Convert the sf object into a Spatial Data Frame (for compatibility with certain spatial analysis functions)\nYangon_ACLED_SFDF &lt;- as_Spatial(Yangon_ACLED_Data_Sf)\n\n# Final output - Yangon ACLED data in spatial data frame format, ready for analysis\nYangon_ACLED_SFDF\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1489 \nextent      : 148595, 259745.5, 1819680, 1944325  (xmin, xmax, ymin, ymax)\ncrs         : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nvariables   : 20\nnames       : event_id_cnty, event_date, year,          disorder_type,                 event_type,                       actor1, inter1,                actor2, inter2, interaction,      location, latitude, longitude, fatalities, quarter_year, ... \nmin values  :      MMR10949,      18633, 2021,     Political violence, Explosions/Remote violence,           5 Brothers Younger,      1, Civilians (Australia),      0,          17,     Ah Hpyauk,  16.4389,   95.6934,          0,      Q1-2021, ... \nmax values  :      MMR64089,      19895, 2024, Strategic developments, Violence against civilians, YUG: Yangon Urban Guerrillas,      7,                    NA,      7,          70, Zee Hpyu Kone,  17.5612,   96.7448,         13,      Q4-2023, ... \n\n\n\n\n\n# Filter data for Mandalay state from the entire ACLED dataset\nMandalay_ACLED_Data &lt;- filtered_data %&gt;% \n  filter(state %in% c(\"Mandalay\"))\n# Check the class of the filtered data to confirm it's still a dataframe\nclass(Mandalay_ACLED_Data)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n# Convert the filtered data into a spatial format (simple features object)\n# Longitude and latitude are used as coordinates, and WGS84 (CRS 4326) is set as the coordinate system\nMandalay_ACLED_Data_Sf &lt;- st_as_sf(Mandalay_ACLED_Data, coords = c(\"longitude\", \"latitude\"), crs = 4326, remove = FALSE)\n\n# Transform the coordinate system to UTM Zone 47N (CRS 32647) for better accuracy in the Myanmar region\nMandalay_ACLED_Data_Sf &lt;- st_transform(Mandalay_ACLED_Data_Sf, crs = 32647)\n\n# Verify that the data has been successfully converted into a spatial object\nclass(Mandalay_ACLED_Data_Sf)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n# Validate the spatial data to check for any invalid geometries (e.g., self-intersections, broken polygons)\nMandalay_ACLED_Validity &lt;- st_is_valid(Mandalay_ACLED_Data_Sf)\n\n# Identify any invalid geometries and print them for inspection, if found\nMandalay_invalid &lt;- which(!Mandalay_ACLED_Validity)\nif (length(Mandalay_invalid) &gt; 0) {\n  print(\"Mandalay is Invalid!\")\n  print(Mandalay_ACLED_Data_Sf[Mandalay_invalid, ])\n} else {\n  # If all geometries are valid, print confirmation\n  print(\"Mandalay_ACLED_Data_Sf is valid!\")\n}\n\n[1] \"Mandalay_ACLED_Data_Sf is valid!\"\n\n# Convert the simple features object to a Spatial Data Frame for compatibility with spatial functions\nMandalay_ACLED_SFDF &lt;- as_Spatial(Mandalay_ACLED_Data_Sf)\n\n# Final output - Mandalay ACLED data in spatial data frame format, ready for analysis\nMandalay_ACLED_SFDF\n\nclass       : SpatialPointsDataFrame \nfeatures    : 2021 \nextent      : 68129.21, 255317.2, 2261881, 2620357  (xmin, xmax, ymin, ymax)\ncrs         : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nvariables   : 20\nnames       : event_id_cnty, event_date, year,          disorder_type,                 event_type,                                   actor1, inter1,              actor2, inter2, interaction,         location, latitude, longitude, fatalities, quarter_year, ... \nmin values  :      MMR10960,      18640, 2021,     Political violence, Explosions/Remote violence, 21KPG: 21 Guerrilla Force - Kyaukpadaung,      1, Civilians (Myanmar),      0,          17, 4 Maing Kan Thar,  20.4319,    94.849,          0,      Q1-2021, ... \nmax values  :      MMR64318,      19904, 2024, Strategic developments, Violence against civilians,          Zero Guerrilla Force - Myingyan,      7,                  NA,      7,          70,       Zin Chaung,   23.667,   96.6148,         10,      Q4-2023, ... \n\n\n\n\n\nSagaing_ACLED_Data &lt;- filtered_data %&gt;% \n  filter(state %in% c(\"Sagaing\"))\n\n# Check the class of the filtered data to confirm it's still a dataframe\nclass(Sagaing_ACLED_Data)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n# Convert the filtered data into a spatial format (simple features object)\n# Longitude and latitude are used as coordinates, and WGS84 (CRS 4326) is set as the coordinate system\nSagaing_ACLED_Data_Sf &lt;- st_as_sf(Sagaing_ACLED_Data, coords = c(\"longitude\", \"latitude\"), crs = 4326, remove = FALSE)\n\n# Transform the coordinate system to UTM Zone 47N (CRS 32647) for better accuracy in the Myanmar region\nSagaing_ACLED_Data_Sf &lt;- st_transform(Sagaing_ACLED_Data_Sf, crs = 32647)\n\n# Verify that the data has been successfully converted into a spatial object\nclass(Sagaing_ACLED_Data_Sf)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n# Validate the spatial data to check for any invalid geometries (e.g., self-intersections, broken polygons)\nSagaing_ACLED_Validity &lt;- st_is_valid(Sagaing_ACLED_Data_Sf)\n\n# Identify any invalid geometries and print them for inspection, if found\nSagaing_invalid &lt;- which(!Sagaing_ACLED_Validity)\nif (length(Sagaing_invalid) &gt; 0) {\n  print(\"Sagaing is Invalid!\")\n  print(Sagaing_ACLED_Data_Sf[Sagaing_invalid, ])\n} else {\n  # If all geometries are valid, print confirmation\n  print(\"Sagaing_ACLED_Data_Sf is valid!\")\n}\n\n[1] \"Sagaing_ACLED_Data_Sf is valid!\"\n\n# Convert the simple features object to a Spatial Data Frame for compatibility with spatial functions\nSagaing_ACLED_SFDF &lt;- as_Spatial(Sagaing_ACLED_Data_Sf)\n\n# Final output - Sagaing ACLED data in spatial data frame format, ready for analysis\nSagaing_ACLED_SFDF\n\nclass       : SpatialPointsDataFrame \nfeatures    : 5346 \nextent      : -16397.05, 256586.9, 2393568, 2914063  (xmin, xmax, ymin, ymax)\ncrs         : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nvariables   : 20\nnames       : event_id_cnty, event_date, year,          disorder_type,                 event_type,                                      actor1, inter1,            actor2, inter2, interaction,               location, latitude, longitude, fatalities, quarter_year, ... \nmin values  :      MMR10952,      18640, 2021,     Political violence, Explosions/Remote violence, ABSDF: All Burma Students' Democratic Front,      1, Civilians (China),      0,          17,               55 Maing,   21.605,   93.9575,          0,      Q1-2021, ... \nmax values  :      MMR65891,      19898, 2024, Strategic developments, Violence against civilians,             Zero Guerrilla Force - Myingyan,      7,                NA,      7,          70, Zin Ka Le (Zin Ka Lin),  26.3006,   96.6034,        175,      Q4-2023, ..."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-the-owin-window-for-states.",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-the-owin-window-for-states.",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "5.1 Setting up the Owin Window for States.",
    "text": "5.1 Setting up the Owin Window for States.\nIn this step, we are setting up an owin object for each state using the spatstat package. An owin object defines the spatial window—or the boundary—within which our point pattern analysis will take place. Essentially, this window will encapsulate the polygonal boundary of each state, allowing us to focus on conflict data within those precise boundaries.\nTo create the owin object, we will:\n\nExtract the polygon boundaries for each state from the spatial data.\nConvert these boundaries into an owin object using the as.owin() function.\nThese spatial windows will ensure that all spatial operations, such as density estimation and pattern analysis, occur strictly within the boundaries of the specified state (e.g., Yangon, Mandalay, Sagaing).\n\nThis setup is crucial for ensuring that our spatial analysis focuses only on relevant geographic areas and doesn’t incorporate any points outside the boundaries.\n\nYangonMandalaySagaing\n\n\n\nYangon_Sf &lt;- M_State_Sf %&gt;% \n  filter(state %in% c(\"Yangon\"))\n# Step 1: Extract the individual polygons from the multipolygon\nyangon_polygons &lt;- st_cast(Yangon_Sf$geometry, \"POLYGON\")\nyangon_polygons_filtered &lt;- yangon_polygons[-c(1, 2)]\nyangon_multipolygon_filtered &lt;- st_combine(yangon_polygons_filtered)\n# Add the filtered multipolygon back to the Yangon_Sf object\nYangon_Sf$geometry &lt;- yangon_multipolygon_filtered\nYangon &lt;- as_Spatial(Yangon_Sf)\nYangon_Owin &lt;- as.owin(Yangon_Sf)\nplot(Yangon_Owin)\n\n\n\n\n\n\n\nsummary(Yangon_Owin)\n\nWindow: polygonal boundary\n6 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1            3832  9.84832e+09      1.00e+00\npolygon 2 (hole)        3 -1.78834e+02     -1.82e-08\npolygon 3              14  2.11571e+05      2.15e-05\npolygon 4              11  1.59536e+05      1.62e-05\npolygon 5              20  1.79201e+06      1.82e-04\npolygon 6              37  2.56010e+06      2.60e-04\nenclosing rectangle: [140506.53, 268404.01] x [1805599.6, 1970174] units\n                     (127900 x 164600 units)\nWindow area = 9853040000 square units\nFraction of frame area: 0.468\n\n\n\n\n\n# Filter the dataset to only include data for Mandalay state\nMandalay_Sf &lt;- M_State_Sf %&gt;% \n  filter(state %in% c(\"Mandalay\"))\n# Convert the Mandalay spatial dataframe into a Spatial Data Frame for further spatial operations\nMandalay &lt;- as_Spatial(Mandalay_Sf)\n\n# Convert the Mandalay spatial dataframe into an owin object for spatial point pattern analysis\nMandalay_Owin &lt;- as.owin(Mandalay_Sf)\n\n# Plot the owin object to visualize the boundaries of Mandalay\nplot(Mandalay_Owin)\n\n\n\n\n\n\n\n# Provide a summary of the owin object, showing its properties like dimensions and bounding box\nsummary(Mandalay_Owin)\n\nWindow: polygonal boundary\nsingle connected closed polygon with 5914 vertices\nenclosing rectangle: [66291.97, 282396.46] x [2234807.4, 2622191.5] units\n                     (216100 x 387400 units)\nWindow area = 30998600000 square units\nFraction of frame area: 0.37\n\n\n\n\n\n# Filter the dataset to only include data for Sagaing state\nSagaing_Sf &lt;- M_State_Sf %&gt;% \n  filter(state %in% c(\"Sagaing\"))\n\n# Convert the Sagaing spatial dataframe into a Spatial Data Frame for further spatial operations\nSagaing &lt;- as_Spatial(Sagaing_Sf)\n\n# Convert the Sagaing spatial dataframe into an owin object for spatial point pattern analysis\nSagaing_Owin &lt;- as.owin(Sagaing_Sf)\n# Plot the owin object to visualize the boundaries of Sagaing\nplot(Sagaing_Owin)\n\n\n\n\n\n\n\n# Provide a summary of the owin object, showing its properties like dimensions and bounding box\nsummary(Sagaing_Owin)\n\nWindow: polygonal boundary\nsingle connected closed polygon with 5882 vertices\nenclosing rectangle: [-17699.96, 308341.37] x [2390344.6, 3029739.1] units\n                     (326000 x 639400 units)\nWindow area = 9.3875e+10 square units\nFraction of frame area: 0.45"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-the-acled-spatial-class",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-the-acled-spatial-class",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "5.2 Setting up the ACLED Spatial Class",
    "text": "5.2 Setting up the ACLED Spatial Class\nAfter defining the owin window for each state, we need to convert the conflict data into a suitable spatial point pattern object (typically using spatstat’s ppp class). This class is essential for performing spatial point pattern analysis, as it links the geographic coordinates of conflict events to the state boundary.\nHere’s what we’ll do:\n\nWe will first ensure that the conflict data is transformed into the appropriate spatial projection (UTM or other applicable projections).\nThe conflict data points will be linked to the owin window to define where these events occur within the state’s boundary.\nThe result will be a ppp (point pattern) object, which is necessary for conducting spatial operations like density estimation, K-function analysis, or G-function analysis.\n\nThis step transforms our dataset into a fully spatially aware format, ready for statistical analysis.\n\nYangonMandalaySagaing\n\n\n\n# Extract the coordinates (longitude, latitude) from the Yangon spatial object\nYangon_ACLED_coords &lt;- st_coordinates(Yangon_ACLED_Data_Sf)\n\n# Define the bounding box (xmin, xmax, ymin, ymax) for Yangon, which sets the spatial extent of the window\nYangon_ACLED_bbox &lt;- st_bbox(Yangon_ACLED_Data_Sf)\n\n# Create the spatial window (owin object) for Yangon using the bounding box ranges\nYangon_ACLED_window &lt;- owin(xrange = Yangon_ACLED_bbox[c(\"xmin\", \"xmax\")], yrange = Yangon_ACLED_bbox[c(\"ymin\", \"ymax\")])\n\n# Create a ppp (point pattern) object for Yangon using the extracted coordinates and the defined window\nYangon_ACLED_ppp &lt;- ppp(x = Yangon_ACLED_coords[, 1], y = Yangon_ACLED_coords[, 2], window = Yangon_ACLED_window)\n# Check the summary of the ppp object to verify the number of points, window dimensions, and other properties\nsummary(Yangon_ACLED_ppp)\n\nPlanar point pattern:  1489 points\nAverage intensity 1.074751e-07 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 10 decimal places\n\nWindow: rectangle = [148595.03, 259745.55] x [1819680.1, 1944325.3] units\n                    (111200 x 124600 units)\nWindow area = 13854400000 square units\n\n# Plot the ppp object to visually inspect the spatial distribution of conflict points in Yangon\nplot(Yangon_ACLED_ppp)\n\n\n\n\n\n\n\n\n\n\n\n# Extract the coordinates (longitude, latitude) from the Mandalay spatial object\nMandalay_ACLED_coords &lt;- st_coordinates(Mandalay_ACLED_Data_Sf)\n\n# Define the bounding box (xmin, xmax, ymin, ymax) for Mandalay, which sets the spatial extent of the window\nMandalay_ACLED_bbox &lt;- st_bbox(Mandalay_ACLED_Data_Sf)\n\n# Create the spatial window (owin object) for Mandalay using the bounding box ranges\nMandalay_ACLED_window &lt;- owin(xrange = Mandalay_ACLED_bbox[c(\"xmin\", \"xmax\")], yrange = Mandalay_ACLED_bbox[c(\"ymin\", \"ymax\")])\n\n# Create a ppp (point pattern) object for Mandalay using the extracted coordinates and the defined window\nMandalay_ACLED_ppp &lt;- ppp(x = Mandalay_ACLED_coords[, 1], y = Mandalay_ACLED_coords[, 2], window = Mandalay_ACLED_window)\n\n# Check the summary of the ppp object to verify the number of points, window dimensions, and other properties\nsummary(Mandalay_ACLED_ppp)\n\nPlanar point pattern:  2021 points\nAverage intensity 3.011815e-08 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nWindow: rectangle = [68129.21, 255317.22] x [2261880.7, 2620356.6] units\n                    (187200 x 358500 units)\nWindow area = 67102400000 square units\n\n# Plot the ppp object to visually inspect the spatial distribution of conflict points in Mandalay\nplot(Mandalay_ACLED_ppp)\n\n\n\n\n\n\n\n\n\n\n\n# Extract the coordinates (longitude, latitude) from the Sagaing spatial object\nSagaing_ACLED_coords &lt;- st_coordinates(Sagaing_ACLED_Data_Sf)\n\n# Define the bounding box (xmin, xmax, ymin, ymax) for Sagaing, which sets the spatial extent of the window\nSagaing_ACLED_bbox &lt;- st_bbox(Sagaing_ACLED_Data_Sf)\n\n# Create the spatial window (owin object) for Sagaing using the bounding box ranges\nSagaing_ACLED_window &lt;- owin(xrange = Sagaing_ACLED_bbox[c(\"xmin\", \"xmax\")], yrange = Sagaing_ACLED_bbox[c(\"ymin\", \"ymax\")])\n\n# Create a ppp (point pattern) object for Sagaing using the extracted coordinates and the defined window\nSagaing_ACLED_ppp &lt;- ppp(x = Sagaing_ACLED_coords[, 1], y = Sagaing_ACLED_coords[, 2], window = Sagaing_ACLED_window)\n# Check the summary of the ppp object to verify the number of points, window dimensions, and other properties\nsummary(Sagaing_ACLED_ppp)\n\nPlanar point pattern:  5346 points\nAverage intensity 3.762491e-08 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 13 decimal places\n\nWindow: rectangle = [-16397.05, 256586.9] x [2393568.1, 2914062.9] units\n                    (273000 x 520500 units)\nWindow area = 1.42087e+11 square units\n\n# Plot the ppp object to visually inspect the spatial distribution of conflict points in Sagaing\nplot(Sagaing_ACLED_ppp)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhy dont you jitter, delete or mark any conflicts here?\nThe reason I did not apply jittering, deletion, or marking of the conflicts at this stage is that all the conflicts are unique and occurred across different time zones. Since there is no overlap in terms of exact location or time, it makes no sense to modify the data at this point. We will consider jittering later if we find that events are clustered too closely together in space, but for now, each conflict is distinct, and no adjustments are necessary."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#combining-them-both",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#combining-them-both",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "5.3 Combining them both",
    "text": "5.3 Combining them both\nFinally, we will merge the owin object (state boundary) and the spatial point pattern data (conflict events) into a single object. This combination ensures that:\n\nThe spatial window constrains the analysis, focusing on the area within each state’s boundary.\nAll conflict events are accurately represented within the confines of the defined boundary.\n\nThis step allows for robust spatial point pattern analysis, ensuring that both the boundaries and events are properly accounted for. With this merged object, we can perform advanced geospatial techniques, such as analyzing the distribution of conflict events, identifying hotspots, and calculating density functions within the state.\n\nYangonMandalaySagaing\n\n\n\nYangon_ACLED_ppp = Yangon_ACLED_ppp[Yangon_Owin]\nplot(Yangon_ACLED_ppp)\n\n\n\n\n\n\n\n\n\n\n\nMandalay_ACLED_ppp = Mandalay_ACLED_ppp[Mandalay_Owin]\nplot(Mandalay_ACLED_ppp)\n\n\n\n\n\n\n\n\n\n\n\nSagaing_ACLED_ppp = Sagaing_ACLED_ppp[Sagaing_Owin]\nplot(Sagaing_ACLED_ppp)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-a-function-to-create-quarterly-for-each-state",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-a-function-to-create-quarterly-for-each-state",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "7.1 Setting up a function to create quarterly for each state",
    "text": "7.1 Setting up a function to create quarterly for each state\nWe will create a function that takes the conflict data for each state and computes the quarterly KDE. This function will:\n\nFilter the conflict events by quarter.\nApply the KDE to estimate the spatial density of events for that quarter.\nReturn a KDE layer that can be used for visualization and analysis.\n\n\n\nFull Code\n\n\nprocess_quarter_conflicts &lt;- function(region_sf, region_window, region_name, data_sf, sigma_type, kernel_method) {\n  # Extract unique quarters (reversed for correct order)\n  quarters &lt;- rev(unique(data_sf$quarter_year))\n  \n  # Initialize empty lists to store ppp and KDE objects\n  region_quarters_conflict &lt;- list()\n  kde_plot_list &lt;- list()\n  \n  # Step 2: Loop over each quarter and process conflict data\n  for (quarter in quarters) {\n    # Filter the data for the current quarter\n    quarter_data &lt;- data_sf %&gt;%\n      filter(quarter_year == quarter)\n    \n    # Extract coordinates for this quarter\n    quarter_coords &lt;- st_coordinates(quarter_data)\n    \n    # Create a ppp object for this quarter\n    quarter_ppp &lt;- ppp(\n      x = quarter_coords[, 1],\n      y = quarter_coords[, 2],\n      window = region_window\n    )\n    \n    # Step 3: Remove rejected points that fall outside the window\n    valid_points &lt;- inside.owin(quarter_ppp$x, quarter_ppp$y, region_window)\n    quarter_ppp &lt;- quarter_ppp[valid_points]\n    \n    # Step 4: Jitter duplicates to avoid overplotting\n    is_duplicate &lt;- duplicated(quarter_ppp)\n    jittered_x &lt;- quarter_ppp$x + ifelse(is_duplicate, runif(npoints(quarter_ppp), -0.1, 0.1), 0)\n    jittered_y &lt;- quarter_ppp$y + ifelse(is_duplicate, runif(npoints(quarter_ppp), -0.1, 0.1), 0)\n    \n    # Create a jittered ppp object with the new coordinates\n    jittered_ppp &lt;- ppp(\n      x = jittered_x,\n      y = jittered_y,\n      window = region_window\n    )\n    \n    # Step 5: Store the jittered ppp object for later use\n    region_quarters_conflict[[quarter]] &lt;- jittered_ppp\n    \n    # Step 6: Rescale to kilometers and calculate KDE with specified sigma type and kernel method\n    jittered_ppp_km &lt;- rescale(jittered_ppp, 1000, \"km\")\n    \n    # Use selected sigma type\n    if (sigma_type == \"scott\") {\n      sigma_value &lt;- bw.scott(jittered_ppp_km)\n      kde_quarter &lt;- density(jittered_ppp_km, sigma = bw.scott(jittered_ppp_km), edge = TRUE, kernel = kernel_method)\n    } else if (sigma_type == \"diggle\") {\n      sigma_value &lt;- bw.scott(jittered_ppp_km)\n      kde_quarter &lt;- density(jittered_ppp_km, sigma = bw.diggle(jittered_ppp_km), edge = TRUE, kernel = kernel_method)\n    } else if (sigma_type == \"ppl\") {\n      sigma_value &lt;- bw.scott(jittered_ppp_km)\n      kde_quarter &lt;- density(jittered_ppp_km, sigma = bw.ppl(jittered_ppp_km), edge = TRUE, kernel = kernel_method)\n    } else if (sigma_type == \"cvl\") {\n      sigma_value &lt;- bw.scott(jittered_ppp_km)\n      kde_quarter &lt;- density(jittered_ppp_km, sigma = bw.CvL(jittered_ppp_km), edge = TRUE, kernel = kernel_method)\n    } else {\n      stop(\"Invalid sigma_type specified.\")\n    }\n    \n    # Step 7: Store the KDE object for later use\n    kde_plot_list[[quarter]] &lt;- kde_quarter\n    \n    # Print a message after processing each quarter\n    print(paste(\"KDE - Quarter:\", quarter, \"| Kernel:\", kernel_method, \"| Sigma:\", sigma_type, \" | Sigma Value: \", sigma_value))\n  }\n  \n  # Return the processed ppp and KDE objects\n  return(list(\n    \"ppp_list\" = region_quarters_conflict,\n    \"kde_list\" = kde_plot_list\n  ))\n}"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-a-function-to-display-the-visual-across-quarters",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#setting-up-a-function-to-display-the-visual-across-quarters",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "7.2 Setting up a function to display the visual across quarters",
    "text": "7.2 Setting up a function to display the visual across quarters\nNext, we will create a function to visualize the KDE layers for each quarter, enabling us to compare the intensity of conflict events over time. The function will:\n\nTake the KDE layers from each quarter.\nDisplay them side by side or as an animation to show how conflict density changes across quarters.\nThis visualization will help us observe trends, including whether conflicts are becoming more localized or dispersed over time.\n\n\n# Visualization Function for Conflict Points and KDE\nvisualize_conflict_results &lt;- function(results, region_name, sigma_type, kernel_method) {\n  ppp_list &lt;- results$ppp_list\n  kde_list &lt;- results$kde_list\n  \n  # Plotting Kernel Density Estimates (KDE) for each quarter\n  kde_plots &lt;- lapply(names(kde_list), function(quarter) {\n    kde_data &lt;- as.data.frame(as.im(kde_list[[quarter]]))\n    \n    ggplot() +\n      geom_raster(data = kde_data, aes(x = x, y = y, fill = value), alpha = 0.8) +\n      scale_fill_viridis_c(option = \"inferno\", name = \"Density\") +\n      labs(title = paste(\"KDE for Civilian Conflict\", region_name, \"-\", quarter)) +\n      theme_void() +  # Removes axis, background, and grid\n      theme(\n        plot.title = element_text(hjust = 0.5, face = \"bold\", size = 10, margin = margin(t = 10, b = 10)),  # Centers and adds margin to the title\n        plot.margin = margin(t = 5, r = 5, b = 5, l = 5)  # Adjusts the margin around the plot\n      )\n  })\n  \n  # Combine all plots into a grid layout with a main title\n  kde_grid &lt;- grid.arrange(grobs = kde_plots, ncol = 4, top = textGrob(\n    paste(region_name, \" Civilian Conflicts KDE By\", sigma_type, \"Using\", kernel_method, \"Kernel\"),\n    gp = gpar(fontface = \"bold\", fontsize = 16)\n  ))\n  \n  return(kde_grid)\n}"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#states-quarterly-kernel-density-estimation.",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#states-quarterly-kernel-density-estimation.",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "7.3 State’s Quarterly Kernel Density estimation.",
    "text": "7.3 State’s Quarterly Kernel Density estimation.\nFor each state, we will calculate and visualize the Kernel Density Estimation (KDE) using two different kernels. We focus on (You can use any we are flexible in the function above!)\n\nKernel 1: Gaussian Kernel\nKernel 2: Epanechnikov Kernel\n\nThe Gaussian Kernel is smooth and gives a global view of the density, whereas the Epanechnikov Kernel is more efficient and provides sharper boundaries, making it easier to identify clusters or hotspots.\nWe will also compute the KDE with different bandwidths, which controls the smoothness of the density estimates. A larger bandwidth results in smoother KDE, while a smaller bandwidth captures more local variations.\n\n7.3.1 Yangon\n\n7.3.1.1 Kernel 1: Gaussian Kernel\n\nDiggleScottCvLPPL\n\n\n\nYangon_Results_Diggle_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Yangon_Sf,\n  region_window = Yangon_Owin,\n  region_name = \"Yangon\",\n  data_sf = Yangon_ACLED_Data_Sf,\n  sigma_type = \"diggle\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\n# Step 4: Visualize the results with a main title\nvisualizations &lt;- visualize_conflict_results(Yangon_Results_Diggle_Gaussian, \"Yangon\", \"Diggle\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\nYangon_Results_Scott_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Yangon_Sf,\n  region_window = Yangon_Owin,\n  region_name = \"Yangon\",\n  data_sf = Yangon_ACLED_Data_Sf,\n  sigma_type = \"scott\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\n# Step 4: Visualize the results with a main title\nYangon_Results_Scott_Gaussian_Visualisation &lt;- visualize_conflict_results(Yangon_Results_Scott_Gaussian, \"Yangon\", \"Scott\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\nYangon_Results_CvL_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Yangon_Sf,\n  region_window = Yangon_Owin,\n  region_name = \"Yangon\",\n  data_sf = Yangon_ACLED_Data_Sf,\n  sigma_type = \"cvl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nYangon_Results_CvL_Gaussian_visualizations &lt;- visualize_conflict_results(Yangon_Results_CvL_Gaussian, \"Yangon\", \"CvL\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\nYangon_Results_PPL_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Yangon_Sf,\n  region_window = Yangon_Owin,\n  region_name = \"Yangon\",\n  data_sf = Yangon_ACLED_Data_Sf,\n  sigma_type = \"ppl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\n# Step 4: Visualize the results with a main title\nYangon_Results_PPL_Gaussian_visualizations &lt;- visualize_conflict_results(Yangon_Results_PPL_Gaussian, \"Yangon\", \"PPL\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.1.2 Kernel 2: Epanechnikov Kernel\n\nDiggleScottCvLPPL\n\n\n\nYangon_Results_Diggle_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Yangon_Sf,\n  region_window = Yangon_Owin,\n  region_name = \"Yangon\",\n  data_sf = Yangon_ACLED_Data_Sf,\n  sigma_type = \"diggle\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nYangon_Results_Diggle_Epanechnikov_visualizations &lt;- visualize_conflict_results(Yangon_Results_Diggle_Epanechnikov, \"Yangon\", \"Diggle\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\nYangon_Results_Scott_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Yangon_Sf,\n  region_window = Yangon_Owin,\n  region_name = \"Yangon\",\n  data_sf = Yangon_ACLED_Data_Sf,\n  sigma_type = \"scott\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nYangon_Results_Scot_Epanechnikov_visualizations &lt;- visualize_conflict_results(Yangon_Results_Scott_Epanechnikov, \"Yangon\", \"Scott\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\nYangon_Results_CvL_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Yangon_Sf,\n  region_window = Yangon_Owin,\n  region_name = \"Yangon\",\n  data_sf = Yangon_ACLED_Data_Sf,\n  sigma_type = \"cvl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nYangon_Results_CvL_Epanechnikov_visualizations &lt;- visualize_conflict_results(Yangon_Results_CvL_Epanechnikov, \"Yangon\", \"CvL\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\nYangon_Results_PPL_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Yangon_Sf,\n  region_window = Yangon_Owin,\n  region_name = \"Yangon\",\n  data_sf = Yangon_ACLED_Data_Sf,\n  sigma_type = \"ppl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nYangon_Results_PPL_Epanechnikov_visualizations &lt;- visualize_conflict_results(Yangon_Results_PPL_Epanechnikov, \"Yangon\", \"PPL\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.1.3 Analysis and Interpretation.\n\nWe used Scott’s bandwidth and the Epanechnikov kernel to model the spatial distribution of civilian conflicts in Yangon from 2021 to 2024. Scott’s method provides an optimal balance between bias and variance, ensuring smoother KDE without losing significant details. The Epanechnikov kernel minimizes error and focuses on areas with higher density, effectively capturing conflict hotspots while reducing the impact of outliers.\nKey Observations:\n\nCentral Yangon Hotspot: Conflict density remains consistently high in central Yangon throughout the period.\nTemporal Shifts: Conflict intensity fluctuates across quarters, peaking in certain periods (e.g., Q3-2022 and Q1-2024), with some spread into surrounding areas over time.\nDensity Spread: While central areas remain the most affected, the gradual spread suggests an intensification or expansion of conflicts.\n\nIn summary, Scott’s bandwidth and the Epanechnikov kernel provided a precise view of conflict clustering and temporal changes, revealing critical patterns in civilian-related conflict hotspots in Yangon.\n\n\n\n7.3.2 Mandalay\n\n7.3.2.1 Mandalay Kernel 1: Gaussian Kernel\n\nDiggleScottCvLPPL\n\n\n\nMandalay_Results_Diggle_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Mandalay_Sf,\n  region_window = Mandalay_Owin,\n  region_name = \"Mandalay\",\n  data_sf = Mandalay_ACLED_Data_Sf,\n  sigma_type = \"diggle\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nMandalay_Results_Diggle_Gaussian_visualizations &lt;- visualize_conflict_results(Mandalay_Results_Diggle_Gaussian, \"Mandalay\", \"Diggle\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\nMandalay_Results_Scott_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Mandalay_Sf,\n  region_window = Mandalay_Owin,\n  region_name = \"Mandalay\",\n  data_sf = Mandalay_ACLED_Data_Sf,\n  sigma_type = \"scott\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nMandalay_Results_Scott_Gaussian_visualizations &lt;- visualize_conflict_results(Mandalay_Results_Scott_Gaussian, \"Mandalay\", \"Scott\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\nMandalay_Results_CvL_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Mandalay_Sf,\n  region_window = Mandalay_Owin,\n  region_name = \"Mandalay\",\n  data_sf = Mandalay_ACLED_Data_Sf,\n  sigma_type = \"cvl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nMandalay_Results_CvL_Gaussian_visualizations &lt;- visualize_conflict_results(Mandalay_Results_CvL_Gaussian, \"Mandalay\", \"CvL\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\nMandalay_Results_PPL_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Mandalay_Sf,\n  region_window = Mandalay_Owin,\n  region_name = \"Mandalay\",\n  data_sf = Mandalay_ACLED_Data_Sf,\n  sigma_type = \"ppl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nMandalay_Results_PPL_Gaussian_visualizations &lt;- visualize_conflict_results(Mandalay_Results_PPL_Gaussian, \"Mandalay\", \"PPL\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.2.2 Mandalay Kernel 2: Epanechnikov Kernel\n\nDiggleScottCvLPPL\n\n\n\nMandalay_Results_Diggle_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Mandalay_Sf,\n  region_window = Mandalay_Owin,\n  region_name = \"Mandalay\",\n  data_sf = Mandalay_ACLED_Data_Sf,\n  sigma_type = \"diggle\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nMandalay_Results_Diggle_Epanechnikov_visualizations &lt;- visualize_conflict_results(Mandalay_Results_Diggle_Epanechnikov, \"Mandalay \", \"Diggle\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\nMandalay_Results_Scott_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Mandalay_Sf,\n  region_window = Mandalay_Owin,\n  region_name = \"Mandalay\",\n  data_sf = Mandalay_ACLED_Data_Sf,\n  sigma_type = \"scott\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nMandalay_Results_Scott_Epanechnikov_visualizations &lt;- visualize_conflict_results(Mandalay_Results_Scott_Epanechnikov, \"Mandalay \", \"Scott\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\nMandalay_Results_CvL_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Mandalay_Sf,\n  region_window = Mandalay_Owin,\n  region_name = \"Mandalay \",\n  data_sf = Mandalay_ACLED_Data_Sf,\n  sigma_type = \"cvl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nMandalay_Results_CvL_Epanechnikov_visualizations &lt;- visualize_conflict_results(Mandalay_Results_CvL_Epanechnikov, \"Mandalay \", \"CvL\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\nMandalay_Results_PPL_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Mandalay_Sf,\n  region_window = Mandalay_Owin,\n  region_name = \"Mandalay\",\n  data_sf = Mandalay_ACLED_Data_Sf,\n  sigma_type = \"ppl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nMandalay_Results_PPL_Epanechnikov_visualizations &lt;- visualize_conflict_results(Mandalay_Results_PPL_Epanechnikov, \"Mandalay \", \"PPL\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.2.3 Analysis and Interpretation\n\nWe applied Scott’s bandwidth and the Epanechnikov kernel for the Mandalay civilian conflict KDE, as it provides optimal smoothing and reduces variance. The kernel effectively focuses on dense areas, capturing conflict intensity over time without distortion from outliers.\nKey Observations:\n\nCentral Mandalay Hotspot: Consistent conflict density is observed in central Mandalay across all quarters, with peaks in Q3-2022 and Q1-2023.\nSpatiotemporal Patterns: Conflict density fluctuates quarter by quarter, with spread toward the north in several periods, indicating shifts in conflict zones.\nStability vs Spread: While central Mandalay remains a key hotspot, the spread of conflicts over time suggests areas of emerging concern.\n\nThis KDE approach reveals both stable hotspots and the evolving nature of conflicts in Mandalay, providing insights into the intensity and movement of conflict zones across different periods.\n\n\n\n7.3.3 Sagaing\n\n7.3.3.1 Sagaing Kernel 1: Gaussian Kernel\n\nDiggleScottCvLPPL\n\n\n\nSagaing_Results_Diggle_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Sagaing_Sf,\n  region_window = Sagaing_Owin,\n  region_name = \"Sagaing\",\n  data_sf = Sagaing_ACLED_Data_Sf,\n  sigma_type = \"diggle\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nSagaing_Results_Diggle_Gaussian_visualizations &lt;- visualize_conflict_results(Sagaing_Results_Diggle_Gaussian, \"Sagaing\", \"Diggle\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\nSagaing_Results_Scott_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Sagaing_Sf,\n  region_window = Sagaing_Owin,\n  region_name = \"Sagaing\",\n  data_sf = Sagaing_ACLED_Data_Sf,\n  sigma_type = \"scott\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nSagaing_Results_Scott_Gaussian_visualizations &lt;- visualize_conflict_results(Sagaing_Results_Scott_Gaussian, \"Sagaing\", \"Scott\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\nSagaing_Results_CVL_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Sagaing_Sf,\n  region_window = Sagaing_Owin,\n  region_name = \"Sagaing\",\n  data_sf = Sagaing_ACLED_Data_Sf,\n  sigma_type = \"cvl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nSagaing_Results_CVL_Gaussian_visualizations &lt;- visualize_conflict_results(Sagaing_Results_CVL_Gaussian, \"Sagaing\", \"CVL\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\nSagaing_Results_PPL_Gaussian &lt;- process_quarter_conflicts(\n  region_sf = Sagaing_Sf,\n  region_window = Sagaing_Owin,\n  region_name = \"Sagaing\",\n  data_sf = Sagaing_ACLED_Data_Sf,\n  sigma_type = \"ppl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"gaussian\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nSagaing_Results_PPL_Gaussian_visualizations &lt;- visualize_conflict_results(Sagaing_Results_PPL_Gaussian, \"Sagaing\", \"PPL\", \"Gaussian\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.3.2 Sagaing Kernel 2: Epanechnikov Kernel\n\nDiggleScottCvLPPL\n\n\n\nSagaing_Results_Diggle_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Sagaing_Sf,\n  region_window = Sagaing_Owin,\n  region_name = \"Sagaing\",\n  data_sf = Sagaing_ACLED_Data_Sf,\n  sigma_type = \"diggle\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nSagaing_Results_Diggle_Epanechnikov_visualizations &lt;- visualize_conflict_results(Sagaing_Results_Diggle_Epanechnikov, \"Sagaing\", \"Diggle\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\nSagaing_Results_Scott_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Sagaing_Sf,\n  region_window = Sagaing_Owin,\n  region_name = \"Sagaing\",\n  data_sf = Sagaing_ACLED_Data_Sf,\n  sigma_type = \"scott\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nSagaing_Results_Scott_Epanechnikov_visualizations &lt;- visualize_conflict_results(Sagaing_Results_Scott_Epanechnikov, \"Sagaing\", \"Scott\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\nSagaing_Results_Cvl_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Sagaing_Sf,\n  region_window = Sagaing_Owin,\n  region_name = \"Sagaing\",\n  data_sf = Sagaing_ACLED_Data_Sf,\n  sigma_type = \"cvl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nSagaing_Results_CvL_Epanechnikov_visualizations &lt;- visualize_conflict_results(Sagaing_Results_Cvl_Epanechnikov, \"Sagaing\", \"CvL\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\nSagaing_Results_PPL_Epanechnikov &lt;- process_quarter_conflicts(\n  region_sf = Sagaing_Sf,\n  region_window = Sagaing_Owin,\n  region_name = \"Sagaing\",\n  data_sf = Sagaing_ACLED_Data_Sf,\n  sigma_type = \"ppl\",  # Can change to \"scott\", \"diggle\", or \"ppl\"\n  kernel_method = \"epanechnikov\"  # Can change to \"epanechnikov\", \"quartic\", or others\n)\n\n\nSagaing_Results_PPL_Epanechnikov_visualizations &lt;- visualize_conflict_results(Sagaing_Results_PPL_Epanechnikov, \"Sagaing\", \"PPL\", \"Epanechnikov\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.3.3 Analysis and Interpretation\n\nIn Sagaing, we again utilized Scott’s bandwidth and the Epanechnikov kernel for KDE to assess the spatiotemporal distribution of civilian conflict events. This method ensures that key dense areas are well-represented while minimizing the impact of noise from less significant areas.\nKey Observations:\n\nConsistent Hotspot: The southern region of Sagaing consistently shows high-density conflict areas throughout the quarters, especially peaking during Q3-2022 and Q1-2023.\nEmerging Zones: Some quarters, such as Q1-2022 and Q3-2023, show increased conflict spread to the north, indicating a potential shift in conflict locations.\nStability and Peaks: The core conflict areas maintain their intensity, while certain periods experience an expansion of conflict areas, with a notable rise in density during the mid-2022 period.\n\nThese patterns highlight that conflict zones in Sagaing are relatively stable with periods of increased intensity, particularly in southern areas. This provides critical insights into when and where civilian conflict events have intensified."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#yangon-6",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#yangon-6",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "8.1 Yangon",
    "text": "8.1 Yangon\nFor the Yangon conflict events, we’ll perform a detailed spatial point pattern analysis using the Clark-Evans test, Ripley’s K-function, and L-function. This will help us understand whether the conflict events are randomly distributed, clustered, or dispersed, and at what scales clustering occurs.\n\nNull and Alternative Hypothesis:\n\nHo (Null Hypothesis): The distribution of civilian-related conflicts in Yangon is randomly distributed (CSR: Complete Spatial Randomness).\nH1 (Alternative Hypothesis): The distribution of civilian-related conflicts in Yangon is not randomly distributed (it is clustered or dispersed).\n\n\n\n8.1.1 Yangon’s Clark and Evan Test\n\n# Perform the Clark-Evans test for clustering\nYangon_ClarksEvan &lt;- clarkevans.test(Yangon_ACLED_ppp, \n                                      correction = \"none\", \n                                      clipregion = Yangon_Owin, \n                                      alternative = c(\"clustered\"),\n                                      nsim = 30)\n\n# Print Clark-Evans p-value and R-statistic\nprint(Yangon_ClarksEvan)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  Yangon_ACLED_ppp\nR = 0.11849, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n8.1.2 Yangon’s K-Function Method\n\nK-FunctionEnvelope Test\n\n\n\nK_Yangon &lt;- Kest(Yangon_ACLED_ppp, correction = \"Ripley\")\n\n\n# Step 2: Plot the K-function, showing K(d) - r\nplot(K_Yangon, . -r ~ r, ylab = \"K(d) - r\", xlab = \"d(KM)\", main = \"Ripley's K-Function for Yangon Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\nK_Yangon_CSR &lt;- envelope(Yangon_ACLED_ppp, Kest, nsim = 30, rank = 1, global = TRUE)\n\n\nplot(K_Yangon_CSR, . - r ~ r, xlab = \"d(KM\", ylab = \"K(d) - r\", main = \"Envelope for K-Function (CSR) - Yangon Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\n\n8.1.2.2 Yangon’s K-Function Method Observation Table\n\n# Step 1: Define key distances (e.g., 20000m, 30000m, 40000m)\nkey_distances &lt;- c(5, 10, 15,20,25)\n\n# Step 2: Extract observed K-function values and CSR bounds at distances closest to key distances\nclosest_indices &lt;- sapply(key_distances, function(d) which.min(abs(K_Yangon_CSR$r - d)))\n\n# Step 3: Create a table summarizing observed and CSR envelope bounds at the closest distances\nobserved_table &lt;- data.frame(\n  Distance = K_Yangon_CSR$r[closest_indices],       # Actual distances used in the analysis\n  K_Obs = K_Yangon_CSR$obs[closest_indices],        # Observed K-function values\n  K_Lo = K_Yangon_CSR$lo[closest_indices],          # Lower bound of CSR envelope\n  K_Hi = K_Yangon_CSR$hi[closest_indices]           # Upper bound of CSR envelope\n)\n\n# Display the observed table\nprint(observed_table)\n\n  Distance     K_Obs       K_Lo      K_Hi\n1  4.99309  1822.917   35.71503  120.9307\n2  9.98618  5226.240  270.68366  355.8994\n3 14.97927  8118.862  662.29805  747.5137\n4 20.02663  9683.831 1217.37812 1302.5938\n5 25.01972 10687.263 1923.98668 2009.2024\n\n\n\n\n\n8.1.2 Yangon’s L Functions\n\nL FunctionEnvelope Test\n\n\n\nL_Yangon &lt;- Lest(Yangon_ACLED_ppp, correction = \"Ripley\")\n\n\nplot(L_Yangon, . -r ~ r, ylab = \"L(d) - r\", xlab = \"d(KM)\", main = \"Ripley's L-Function for Yangon Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\nL_Yangon_CSR &lt;- envelope(Yangon_ACLED_ppp, Lest, nsim = 30, rank = 1, global = TRUE, savefuns = TRUE)\n\n\nplot(L_Yangon_CSR, . - r ~ r, xlab = \"d(km)\", ylab = \"L(d) - r\", main = \"Envelope for L-Function (CSR) - Yangon Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.1.2.2 Yangon’s L Functions Observation Table\n\nkey_distances &lt;- c(5, 10, 15,20,25)\n# Step 2: Extract observed K-function values and CSR bounds at distances closest to key distances\nclosest_indices &lt;- sapply(key_distances, function(d) which.min(abs(L_Yangon_CSR$r - d)))\n# Step 3: Create a table summarizing observed and CSR envelope bounds at the closest distances\nobserved_table &lt;- data.frame(\n  Distance = L_Yangon_CSR$r[closest_indices],       # Actual distances used in the analysis\n  L_Obs = L_Yangon_CSR$obs[closest_indices],        # Observed K-function values\n  L_Lo = L_Yangon_CSR$lo[closest_indices],          # Lower bound of CSR envelope\n  L_Hi = L_Yangon_CSR$hi[closest_indices]           # Upper bound of CSR envelope\n)\n# Display the observed table\nprint(observed_table)\n\n  Distance    L_Obs      L_Lo      L_Hi\n1  4.99309 24.08843  4.836161  5.150019\n2  9.98618 40.78681  9.829251 10.143108\n3 14.97927 50.83615 14.822341 15.136198\n4 20.02663 55.51990 19.869703 20.183561\n5 25.01972 58.32548 24.862793 25.176651\n\n\n\n\n8.1.4 Yangons- Analysis and Interpretation\nBased on the analysis of the Clark-Evans test, K-function, and L-function, we can draw the following conclusions:\n\nClark-Evans Test:\n\nR = 0.099924, p-value &lt; 2.2e-16 . The R-value is less than 1, and the p-value is very small, which means the civilian related conflict events in Yangon are not randomly distributed and are significantly clustered.\n\nK-function Analysis:\n\n\nThe observed K-function consistently exceeds the upper bound of the CSR envelope across all distances, indicating that the clustering is prominent over a wide range of distances (up to 25km). The clustering becomes more pronounced as the distance increases.\n\nL-function Analysis:\nx\n\nThe observed L-function also exceeds the CSR envelope’s upper bounds, confirming the presence of clustering at multiple spatial scales. This supports the findings from the K-function.\n\n\nObserved Tables:\n\n\n\n\n\n\n\n\n\n\n\n\nDistance\nK_Obs\nK_Lo\nK_Hi\nL_OBV\nL_Lo\nL_Hi\n\n\n\n\n4.99309\n1822.917\n35.71503\n120.9307\n24.0883\n4.836161\n5.150019\n\n\n9.98618\n5226.240\n270.68366\n355.8994\n40.78681\n9.829251\n10.14311\n\n\n14.97927\n8118.682\n662.29806\n747.5137\n50.83615\n14.82234\n15.1362\n\n\n20.02663\n9683.831\n1217.37812\n1302.5938\n55.5199\n19.8697\n20.18356\n\n\n25.01972\n10687.263\n1923.98668\n2009.202\n53.32548\n24.86279\n25.17665\n\n\n\n\nThe observed K-function and L-function tables confirm that the observed values are significantly higher than the expected values under CSR, particularly at distances of 5km, 10km, 15km, and beyond, suggesting clustering at larger spatial scales.\n\n\n\nWe reject the null hypothesis of Complete Spatial Randomness (CSR) for Yangon civilian-related conflicts. The Clark-Evans test shows significant clustering, and both the K-function and L-function support this finding by indicating clustering over a broad range of distances. The observed tables further confirm this, as the observed values consistently exceed the CSR bounds. Therefore, the civilian conflict events in Yangon are significantly clustered rather than randomly distributed."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#mandalay-6",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#mandalay-6",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "8.2 Mandalay",
    "text": "8.2 Mandalay\nFor the Mandalay conflict events, we’ll perform a detailed spatial point pattern analysis using the Clark-Evans test, Ripley’s K-function, and L-function. This will help us understand whether the conflict events are randomly distributed, clustered, or dispersed, and at what scales clustering occurs.\n\nNull and Alternative Hypothesis:\n\nHo (Null Hypothesis): The distribution of civilian-related conflicts in Mandalay is randomly distributed (CSR: Complete Spatial Randomness).\nH1 (Alternative Hypothesis): The distribution of civilian-related conflicts in Mandalay is not randomly distributed (it is clustered or dispersed).\n\n\n\n8.2.1 Clarks Evan Test\n\n# Perform the Clark-Evans test for clustering\nMandalay_ClarksEvan &lt;- clarkevans.test(Mandalay_ACLED_ppp, \n                              correction = \"none\", \n                              clipregion = Mandalay_Owin, \n                              alternative = c(\"clustered\"),\n                              nsim = 30)\n# Print Clark-Evans p-value and R-statistic\nprint(Mandalay_ClarksEvan)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  Mandalay_ACLED_ppp\nR = 0.2192, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n8.2.2 K Function\n\nK-Function DataK-Function Envelope Test\n\n\n\nK_Mandalay &lt;- Kest(Mandalay_ACLED_ppp, correction = \"Ripley\")\n\n\nplot(K_Mandalay, . -r ~ r, ylab = \"K(d) - r\", xlab = \"d(KM)\", main = \"Ripley's K-Function for Mandalay Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\nK_Mandalay_CSR &lt;- envelope(Mandalay_ACLED_ppp, Kest, nsim = 30, rank = 1, global = TRUE)\n\n\nplot(K_Mandalay_CSR, . -r ~ r, ylab = \"K(d) - r\", xlab = \"d(Km)\", main = \"Ripley's K-Function for Mandalay Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\n\n8.2.2.2 Observed Table (K-Function at Key Distances)\n\n# Step 1: Define key distances (e.g., 20000m, 30000m, 40000m)\nkey_distances &lt;- c(10,20,30,40)\n\n# Step 2: Extract observed K-function values and CSR bounds at distances closest to key distances\nclosest_indices &lt;- sapply(key_distances, function(d) which.min(abs(K_Mandalay_CSR$r - d)))\n\n# Step 3: Create a table summarizing observed and CSR envelope bounds at the closest distances\nobserved_table &lt;- data.frame(\n  Distance = K_Mandalay_CSR$r[closest_indices],       # Actual distances used in the analysis\n  K_Obs = K_Mandalay_CSR$obs[closest_indices],        # Observed K-function values\n  K_Lo = K_Mandalay_CSR$lo[closest_indices],          # Lower bound of CSR envelope\n  K_Hi = K_Mandalay_CSR$hi[closest_indices]           # Upper bound of CSR envelope\n)\n\n# Display the observed table\nprint(observed_table)\n\n   Distance     K_Obs      K_Lo      K_Hi\n1  9.962643  7305.334  260.9636  362.6693\n2 20.016687 10852.795 1207.8820 1309.5878\n3 29.979331 15847.857 2772.6858 2874.3915\n4 40.033374 21114.336 4984.0867 5085.7925\n\n\n\n\n\n8.2.3 L Function\n\nMandalay L FunctionMandalay Envelope Test\n\n\n\nL_Mandalay &lt;- Lest(Mandalay_ACLED_ppp, correction = \"Ripley\")\n\n\nplot(L_Mandalay, . -r ~ r, ylab = \"L(d) - r\", xlab = \"d(KM)\", main = \"Ripley's L-Function for Mandalay Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\nL_Mandalay_CSR &lt;- envelope(Mandalay_ACLED_ppp, Lest, nsim = 30, rank = 1, global = TRUE, savefuns = TRUE)\n\n\nplot(L_Mandalay_CSR, . - r ~ r, xlab = \"d(KM)\", ylab = \"L(d) - r\", main = \"Envelope for L-Function (CSR) - Mandalay Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\n\n8.2.3.2 Observed Table (L-Function at Key Distances)\n\nkey_distances &lt;- c(10,20,30,40)\n\n# Step 2: Extract observed K-function values and CSR bounds at distances closest to key distances\nclosest_indices &lt;- sapply(key_distances, function(d) which.min(abs(L_Mandalay_CSR$r - d)))\n\n# Step 3: Create a table summarizing observed and CSR envelope bounds at the closest distances\nobserved_table &lt;- data.frame(\n  Distance = L_Mandalay_CSR$r[closest_indices],       # Actual distances used in the analysis\n  L_Obs = L_Mandalay_CSR$obs[closest_indices],        # Observed K-function values\n  L_Lo = L_Mandalay_CSR$lo[closest_indices],          # Lower bound of CSR envelope\n  L_Hi = L_Mandalay_CSR$hi[closest_indices]           # Upper bound of CSR envelope\n)\n\n# Display the observed table\nprint(observed_table)\n\n   Distance    L_Obs      L_Lo     L_Hi\n1  9.962643 48.22199  9.689332 10.23595\n2 20.016687 58.77544 19.743376 20.29000\n3 29.979331 71.02485 29.706020 30.25264\n4 40.033374 81.98111 39.760063 40.30669\n\n\n\n\n\n8.2.4 Mandalay- Analysis and Interpretation\nBased on the analysis of the Clark-Evans test, K-function, and L-function, we can draw the following conclusions:\n\nClark-Evans Test:\n\nR = 0.14898, p-value &lt; 2.2e-16. The R-value is less than 1, and the p-value is very small, which means the civilian related conflict events in Mandalay are not randomly distributed and are significantly clustered.\n\nK-function Analysis:\n\n\nThe observed K-function consistently exceeds the upper bound of the CSR envelope across all distances, indicating that the clustering is prominent over a wide range of distances (up to 70km). The clustering becomes more pronounced as the distance increases.\n\nL-function Analysis:\n\n\nThe observed L-function also exceeds the CSR envelope’s upper bounds, confirming the presence of clustering at multiple spatial scales. This supports the findings from the K-function.\n\nObserved Tables:\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistance\nK_Obs\nK_Lo\nK_Hi\nL_Obs\nL_Lo\nL_Hi\n\n\n\n\n9.962643\n7305.334\n260.9636\n362.6693\n48.22199\n9.689332\n10.23595\n\n\n20.016687\n10852.795\n1207.8820\n1309.5878\n58.77544\n19.743376\n20.2900\n\n\n29.979331\n15847.857\n2772.6858\n2874.3915\n71.02485\n29.706020\n30.25264\n\n\n40.033374\n21114.336\n4984.0867\n5085.7925\n81.9811\n39.760063\n40.30\n\n\n\n\nThe observed K-function and L-function tables confirm that the observed values are significantly higher than the expected values under CSR, particularly at distances of 20km, 30km, 40km, and beyond, suggesting clustering at larger spatial scales.\n\nWe reject the null hypothesis of Complete Spatial Randomness (CSR) for Mandalay civilian-related conflicts. The Clark-Evans test shows significant clustering, and both the K-function and L-function support this finding by indicating clustering over a broad range of distances. The observed tables further confirm this, as the observed values consistently exceed the CSR bounds. Therefore, the civilian conflict events in Mandalay are significantly clustered rather than randomly distributed."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#sagaing-5",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#sagaing-5",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "8.3 Sagaing",
    "text": "8.3 Sagaing\nFor the Sagaing conflict events, we’ll perform a detailed spatial point pattern analysis using the Clark-Evans test, Ripley’s K-function, and L-function. This will help us understand whether the conflict events are randomly distributed, clustered, or dispersed, and at what scales clustering occurs.\n\nNull and Alternative Hypothesis:\n\nHo (Null Hypothesis): The distribution of civilian-related conflicts in Sagaing is randomly distributed (CSR: Complete Spatial Randomness).\nH1 (Alternative Hypothesis): The distribution of civilian-related conflicts in Sagaing is not randomly distributed (it is clustered or dispersed).\n\n\n\n8.3.1 Clarks Evan Test\n\n# Perform the Clark-Evans test for clustering\nSagaing_ClarksEvan &lt;- clarkevans.test(Sagaing_ACLED_ppp, \n                              correction = \"none\", \n                              clipregion = Sagaing_Owin, \n                              alternative = c(\"clustered\"),\n                              nsim = 30)\n# Print Clark-Evans p-value and R-statistic\nprint(Sagaing_ClarksEvan)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  Sagaing_ACLED_ppp\nR = 0.1827, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\nK-Function MethodEnvelope Test\n\n\n\nK_Sagaing &lt;- Kest(Sagaing_ACLED_ppp, correction = \"Ripley\")\n\n\nplot(K_Sagaing, . -r ~ r, ylab = \"K(d) - r\", xlab = \"d(KM)\", main = \"Ripley's K-Function for Sagaing Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\nK_Sagaing_CSR &lt;- envelope(Sagaing_ACLED_ppp, Kest, nsim = 30, rank = 1, global = TRUE)\n\n\nplot(K_Sagaing_CSR, . - r ~ r, xlab = \"d(KM)\", ylab = \"K(d) - r\", main = \"Envelope for K-Function (CSR) - Sagaing Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\n\n8.3.2.2 Observed Table (K-Function at Key Distances)\n\n# Step 1: Define key distances (e.g., 20000m, 30000m, 40000m)\nkey_distances &lt;- c(20,30,40,50,60,70)\n\n# Step 2: Extract observed K-function values and CSR bounds at distances closest to key distances\nclosest_indices &lt;- sapply(key_distances, function(d) which.min(abs(K_Sagaing_CSR$r - d)))\n\n# Step 3: Create a table summarizing observed and CSR envelope bounds at the closest distances\nobserved_table &lt;- data.frame(\n  Distance = K_Sagaing_CSR$r[closest_indices],       # Actual distances used in the analysis\n  K_Obs = K_Sagaing_CSR$obs[closest_indices],        # Observed K-function values\n  K_Lo = K_Sagaing_CSR$lo[closest_indices],          # Lower bound of CSR envelope\n  K_Hi = K_Sagaing_CSR$hi[closest_indices]           # Upper bound of CSR envelope\n)\n\n# Display the observed table\nprint(observed_table)\n\n  Distance     K_Obs      K_Lo      K_Hi\n1 19.99394  7021.421  1186.336  1325.415\n2 29.99091 12903.634  2756.181  2895.260\n3 39.98788 19530.590  4953.964  5093.043\n4 49.98485 26873.240  7779.685  7918.764\n5 59.98182 34286.168 11233.343 11372.422\n6 68.24599 40939.246 14562.475 14701.554\n\n\n\n\n\n8.3.3 L-Function Method\n\nL FunctionEnvelope Test\n\n\n\n# Step 1: Calculate the L-function (Ripley's L) for Sagaing conflicts\nL_Sagaing &lt;- Lest(Sagaing_ACLED_ppp, correction = \"Ripley\")\n\n\n# Step 2: Plot the L-function, showing L(d) - r\nplot(L_Sagaing, . - r ~ r, ylab = \"L(d) - r\", xlab = \"d(km)\", main = \"Ripley's L-Function for Sagaing Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\nL_Sagaing_CSR &lt;- envelope(Sagaing_ACLED_ppp, Lest, nsim = 30, rank = 1, global = TRUE)\n\n\nplot(L_Sagaing_CSR, . - r ~ r, xlab = \"d(KM)\", ylab = \"K(d) - r\", main = \"Envelope for L-Function (CSR) - Sagaing Civilian Related Conflicts\")\n\n\n\n\n\n\n\n\n\n\n\n\n8.3.3.3 Observed Table (L-Function at Key Distances)\n\nkey_distances &lt;- c(20,30,40,50,60,70)\n\n# Step 2: Extract observed K-function values and CSR bounds at distances closest to key distances\nclosest_indices &lt;- sapply(key_distances, function(d) which.min(abs(L_Sagaing_CSR$r - d)))\n\n# Step 3: Create a table summarizing observed and CSR envelope bounds at the closest distances\nobserved_table &lt;- data.frame(\n  Distance = L_Sagaing_CSR$r[closest_indices],       # Actual distances used in the analysis\n  L_Obs = L_Sagaing_CSR$obs[closest_indices],        # Observed K-function values\n  L_Lo = L_Sagaing_CSR$lo[closest_indices],          # Lower bound of CSR envelope\n  L_Hi = L_Sagaing_CSR$hi[closest_indices]           # Upper bound of CSR envelope\n)\n\n# Display the observed table\nprint(observed_table)\n\n  Distance     L_Obs     L_Lo     L_Hi\n1 19.99394  47.27566 19.81300 20.17488\n2 29.99091  64.08864 29.80997 30.17185\n3 39.98788  78.84656 39.80694 40.16882\n4 49.98485  92.48793 49.80391 50.16579\n5 59.98182 104.46830 59.80088 60.16277\n6 68.24599 114.15501 68.06505 68.42693\n\n\n\n\n\n8.3.4 Sagaing - Analysis and Interpretation\nBased on the analysis of the Clark-Evans test, K-function, and L-function, we can draw the following conclusions:\n\nClark-Evans Test:\n\nR = 0.1485, p-value &lt; 2.2e-16 . The R-value is less than 1, and the p-value is very small, which means the conflict events in Sagaing are not randomly distributed and are significantly clustered.\n\nK-function Analysis:\n\n\nThe observed K-function consistently exceeds the upper bound of the CSR envelope across all distances, indicating that the clustering is prominent over a wide range of distances (up to 70km). The clustering becomes more pronounced as the distance increases.\n\nL-function Analysis:\n\n\nThe observed L-function also exceeds the CSR envelope’s upper bounds, confirming the presence of clustering at multiple spatial scales. This supports the findings from the K-function.\n\nObserved Tables:\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistance\nK_Obs\nK_Lo\nK_Hi\nL_Obs\nL_Lo\nL_Hi\n\n\n\n\n19.99394\n7021.421\n1186.336\n1325.415\n19.81300\n20.17488\n20.17488\n\n\n29.99091\n12903.634\n2756.181\n2895.260\n64.08864\n29.80997\n30.17185\n\n\n39.98788\n19530.590\n4963.964\n5093.043\n78.84656\n39.80694\n40.16882\n\n\n49.98485\n26873.240\n7797.685\n7916.764\n92.48793\n49.80391\n50.16579\n\n\n59.98182\n34286.168\n11233.343\n11372.422\n104.46830\n59.80088\n60.16277\n\n\n68.24599\n40939.246\n1456,475\n14701.554\n114.15501\n68.06505\n68.4269\n\n\n\n\nThe observed K-function and L-function tables confirm that the observed values are significantly higher than the expected values under CSR, particularly at distances of 20km, 30km, 40km, and beyond, suggesting clustering at larger spatial scales.\n\nWe reject the null hypothesis of Complete Spatial Randomness (CSR) for Sagaing civilian-related conflicts. The Clark-Evans test shows significant clustering, and both the K-function and L-function support this finding by indicating clustering over a broad range of distances. The observed tables further confirm this, as the observed values consistently exceed the CSR bounds. Therefore, the conflict events in Sagaing are significantly clustered rather than randomly distributed."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#steps-for-code-breakdown.",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#steps-for-code-breakdown.",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "9.1 Steps for code Breakdown.",
    "text": "9.1 Steps for code Breakdown.\n\nStep 1: Convert data to sf object to ensure compatibility for spatial analysis.\nStep 2: Extract longitude and latitude from the geometry column for plotting and analysis.\nStep 3: Create numeric and factor representations of quarters for time-based KDE and distinct plotting.\nStep 4: Generate a point pattern object (ppp) for spatial analysis with quarter factors as marks.\nStep 5: Assign circle sizes to each quarter for visual differentiation.\nStep 6: Plot the base map (Yangon) without data points.\nStep 7: Add points with sizes based on quarters to the map for visualization.\nStep 8: Add a legend to explain the circle sizes and quarters.\nStep 9: Create a numeric point pattern for KDE based on quarter information.\nStep 10: Perform KDE analysis on the spatio-temporal point pattern.\nStep 11: Define the quarters to be plotted for KDE analysis.\nStep 12: Set up a 4x4 plotting grid to display multiple KDE plots.\nStep 13: Loop through quarters and plot KDE layers for each, visualizing conflict intensity over time."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#yangon-quarter-year-spatio-temporal-kde",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#yangon-quarter-year-spatio-temporal-kde",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "9.2 Yangon Quarter Year Spatio-Temporal KDE",
    "text": "9.2 Yangon Quarter Year Spatio-Temporal KDE\n\nCode PreparationYangon Quarter Year OwinYangon Quarter Year KDEYangon Quarter Year KDE Animation And Analysis\n\n\n\n# Step 1: Ensure Yangon_QuarterYear_Sf is an sf object (if not already)\nYangon_QuarterYear_Sf &lt;- st_as_sf(Yangon_ACLED_Data_Sf)\n\n# Step 2: Extract the coordinates (longitude and latitude) from the geometry column\ncoords &lt;- st_coordinates(Yangon_QuarterYear_Sf)\n\n# Step 3: Convert quarter_numeric to factor for distinct quarters (for plotting the circles)\nYangon_QuarterYear_Sf &lt;- Yangon_QuarterYear_Sf %&gt;%\n  mutate(\n    year = as.numeric(sub(\".*-\", \"\", quarter_year)),                  # Extract the year (e.g., 2023)\n    quarter = as.numeric(sub(\"Q\", \"\", sub(\"-.*\", \"\", quarter_year))), # Extract the quarter (e.g., Q1 -&gt; 1)\n    \n    # Continuous representation of time (factor for distinct quarters)\n    quarter_numeric_factor = as.factor(year * 10 + quarter),  # Convert to factor for plotting the circles\n    quarter_numeric = year * 10 + quarter  # Keep as numeric for time-based KDE analysis\n  )\n\n# Step 4: Create the point pattern object using ppp() with factor marks (for distinct quarter plotting)\nYangon_QuarterYear_PPP_Factor &lt;- ppp(\n  x = coords[, 1],  # Longitude (x-coordinates)\n  y = coords[, 2],  # Latitude (y-coordinates)\n  window = Yangon_Owin,  # Spatial window (Yangon_Owin)\n  marks = Yangon_QuarterYear_Sf$quarter_numeric_factor  # Use factor for visualizing distinct quarters\n)\n\n\n# Step 5: Assign 14 unique sizes to the 14 unique quarter_numeric values\n# Create 14 different circle sizes, e.g., from 1 to 3 in size\nunique_quarters &lt;- levels(Yangon_QuarterYear_Sf$quarter_numeric_factor)  # Get the unique quarter levels (14 levels)\ncircle_sizes &lt;- seq(1, 3, length.out = length(unique_quarters))  # Generate 14 sizes from 1 to 3\n\n# Map each unique quarter_numeric level to a circle size\ncircle_size_map &lt;- setNames(circle_sizes, unique_quarters)  # Create a named vector to map quarter to size\n\n\n\n\n# Apply the circle size mapping to each point based on its quarter_numeric_factor\npoint_circle_sizes &lt;- circle_size_map[Yangon_QuarterYear_Sf$quarter_numeric_factor]\n\n# Step 6: Plot the base map (Yangon_Owin) without points\nplot(Yangon_Owin, main = \"Yangon Quarter-Year Owin with Unique Circle Sizes\")\n\n# Step 7: Add the points with the unique circle sizes based on quarter_numeric\npoints(coords[, 1], coords[, 2], cex = point_circle_sizes, pch = 16, col = \"black\")  # Add circles on top of base map\n\n# Step 8: Add a custom legend to show the quarter_numeric values and corresponding circle sizes\nlegend(\"topright\", legend = unique_quarters, \n       pch = 16, \n       pt.cex = circle_sizes,  # Show unique circle sizes in the legend\n       col = \"black\", \n       title = \"Quarters (Circle Size)\")\n\n\n\n\n\n\n\n\n\n\n\nYangon_QuarterYear_PPP_Numeric &lt;- ppp(\n  x = coords[, 1],  # Longitude (x-coordinates)\n  y = coords[, 2],  # Latitude (y-coordinates)\n  window = Yangon_Owin,  # Spatial window (Yangon_Owin)\n  marks = Yangon_QuarterYear_Sf$quarter_numeric  # Use numeric for KDE analysis (time-based)\n)\nYangon_QuarterYear_PPP_Numeric &lt;- rescale(Yangon_QuarterYear_PPP_Numeric, 1000, \"km\")\n\n\nYangon_QuarterYear_KDE &lt;- spattemp.density(Yangon_QuarterYear_PPP_Numeric)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nmulti_color_palette &lt;- colorRampPalette(c(\"blue\", \"green\", \"yellow\", \"red\"))\n\n\n# Define the quarters for which you want to plot the KDE\ntims &lt;- c(20211, 20212, 20213, 20214, 20221, 20222, 20223, 20224, \n          20231, 20232, 20233, 20234, 20241, 20242)\n\n#Set up the plotting window to display multiple plots in a grid (4 rows, 4 columns)\npar(mfrow=c(4, 4), mar=c(2, 2, 2, 2), oma=c(0, 0, 2, 0))  # Adjust margins and add outer margin for title\n\n# Loop through the 'tims' vector and plot the KDE for each time point (from left to right)\nfor(i in tims) { \n    plot(Yangon_QuarterYear_KDE, i, \n         override.par=FALSE,  # Keep the graphical parameters unchanged\n         fix.range=TRUE,      # Fix the range of the KDE\n         main=paste(\"Quarter\", i),  # Title for each plot\n         ribside = \"right\", \n         col = multi_color_palette(100))  # Use 'inferno' color gradient\n         \n    # Remove the x and y axis labels for a cleaner look\n    axis(1, labels=FALSE)\n    axis(2, labels=FALSE)\n}\n\n#dd a unified title across all plots (e.g., the duration of analysis)\nmtext(\"Quarterly Spatio-Temporal KDE for Civilian Conflict Intensity in Yangon\", \n      outer=TRUE, cex=1.5, font=2)\n\n\n\n\n\n\n\n\n\n\n\nmulti_color_palette &lt;- colorRampPalette(c(\"blue\", \"green\", \"yellow\", \"red\"))\n\n# Save the animation as a GIF\nsaveGIF({\n  # Loop over the valid quarter times\n  for(i in tims){ \n    suppressWarnings({\n      plot(Yangon_QuarterYear_KDE, i, \n           override.par=FALSE,  # Keep graphical parameters unchanged\n           fix.range=TRUE,      # Fix the range of the KDE\n           main=paste(\"Mandalay Civilian Related Conflict KDE at Quarter\", i),  # Title for each plot\n           ribside = \"right\",  # Legend on the right\n           col = multi_color_palette(100))  # Apply multi-color gradient\n    })\n  }\n}, movie.name = \"yangonkde_animation.gif\", interval = 0.5, ani.width = 800, ani.height = 800)\n\n\nIn Yangon, the spatio-temporal KDE analysis shows a reduction in overall conflict intensity from 2021 to 2024. However, it is important to note that while the intensity has decreased, clustering is still evident within the same few areas.\n\nKey Observations:\n\n2021 to 2022: Widespread high-intensity conflict areas in central Yangon are prominent in 2021 and early 2022, indicated by the larger red and orange zones.\n2023 to 2024: Although the intensity diminishes over time, the clustering remains persistent in specific areas. The high-intensity zones shrink, but they consistently appear in similar locations, suggesting that while the scale of conflict has reduced, these areas remain focal points for civilian conflict.\n\nThe persistent clustering, even as intensity diminishes, indicates that certain regions continue to experience conflicts, requiring targeted interventions in those zones."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#mandalay-quarter-year-spatio-temporal-kde",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#mandalay-quarter-year-spatio-temporal-kde",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "9.3 Mandalay Quarter Year Spatio-Temporal KDE",
    "text": "9.3 Mandalay Quarter Year Spatio-Temporal KDE\n\nMandalay Quarter Year Code PreparationMandalay Quarter Year OwinMandalay Quarter Year KDEMandalay Quarter Year KDE Animation And Analysis\n\n\n\n# Step 1: Ensure Mandalay_QuarterYear_Sf is an sf object (if not already)\nMandalay_QuarterYear_Sf &lt;- st_as_sf(Mandalay_ACLED_Data_Sf)\n\n# Step 2: Extract the coordinates (longitude and latitude) from the geometry column\ncoords &lt;- st_coordinates(Mandalay_QuarterYear_Sf)\n\n# Step 3: Convert quarter_numeric to factor for distinct quarters (for plotting the circles)\nMandalay_QuarterYear_Sf &lt;- Mandalay_QuarterYear_Sf %&gt;%\n  mutate(\n    year = as.numeric(sub(\".*-\", \"\", quarter_year)),                  # Extract the year (e.g., 2023)\n    quarter = as.numeric(sub(\"Q\", \"\", sub(\"-.*\", \"\", quarter_year))), # Extract the quarter (e.g., Q1 -&gt; 1)\n    \n    # Continuous representation of time (factor for distinct quarters)\n    quarter_numeric_factor = as.factor(year * 10 + quarter),  # Convert to factor for plotting the circles\n    quarter_numeric = year * 10 + quarter  # Keep as numeric for time-based KDE analysis\n  )\n\n# Step 4: Create the point pattern object using ppp() with factor marks (for distinct quarter plotting)\nMandalay_QuarterYear_PPP_Factor &lt;- ppp(\n  x = coords[, 1],  # Longitude (x-coordinates)\n  y = coords[, 2],  # Latitude (y-coordinates)\n  window = Mandalay_Owin,  # Spatial window (Mandalay_Owin)\n  marks = Mandalay_QuarterYear_Sf$quarter_numeric_factor  # Use factor for visualizing distinct quarters\n)\n\n\n# Step 5: Assign 14 unique sizes to the 14 unique quarter_numeric values\n# Create 14 different circle sizes, e.g., from 1 to 3 in size\nunique_quarters &lt;- levels(Mandalay_QuarterYear_Sf$quarter_numeric_factor)  # Get the unique quarter levels (14 levels)\ncircle_sizes &lt;- seq(1, 3, length.out = length(unique_quarters))  # Generate 14 sizes from 1 to 3\n\n# Map each unique quarter_numeric level to a circle size\ncircle_size_map &lt;- setNames(circle_sizes, unique_quarters)  # Create a named vector to map quarter to size\n\n\n\n\n# Apply the circle size mapping to each point based on its quarter_numeric_factor\npoint_circle_sizes &lt;- circle_size_map[Mandalay_QuarterYear_Sf$quarter_numeric_factor]\n\n# Step 6: Plot the base map (Mandalay_Owin) without points\nplot(Mandalay_Owin, main = \"Mandalay Quarter-Year Owin with Unique Circle Sizes\")\n\n# Step 7: Add the points with the unique circle sizes based on quarter_numeric\npoints(coords[, 1], coords[, 2], cex = point_circle_sizes, pch = 16, col = \"black\")  # Add circles on top of base map\n\n# Step 8: Add a custom legend to show the quarter_numeric values and corresponding circle sizes\nlegend(\"topright\", legend = unique_quarters, \n       pch = 16, \n       pt.cex = circle_sizes,  # Show unique circle sizes in the legend\n       col = \"black\", \n       title = \"Quarters (Circle Size)\")\n\n\n\n\n\n\n\n\n\n\n\nMandalay_QuarterYear_PPP_Numeric &lt;- ppp(\n  x = coords[, 1],  # Longitude (x-coordinates)\n  y = coords[, 2],  # Latitude (y-coordinates)\n  window = Mandalay_Owin,  # Spatial window (Mandalay_Owin)\n  marks = Mandalay_QuarterYear_Sf$quarter_numeric  # Use numeric for KDE analysis (time-based)\n)\n\nMandalay_QuarterYear_KDE &lt;- spattemp.density(Mandalay_QuarterYear_PPP_Numeric)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nmulti_color_palette &lt;- colorRampPalette(c(\"blue\", \"green\", \"yellow\", \"red\"))\n\n\n# Define the quarters for which you want to plot the KDE\ntims &lt;- c(20211, 20212, 20213, 20214, 20221, 20222, 20223, 20224, \n          20231, 20232, 20233, 20234, 20241, 20242)\n\n#Set up the plotting window to display multiple plots in a grid (4 rows, 4 columns)\npar(mfrow=c(4, 4), mar=c(2, 2, 2, 2), oma=c(0, 0, 2, 0))  # Adjust margins and add outer margin for title\n\n# Loop through the 'tims' vector and plot the KDE for each time point (from left to right)\nfor(i in tims) { \n  plot(Mandalay_QuarterYear_KDE, i, \n       override.par=FALSE,  # Keep the graphical parameters unchanged\n       fix.range=TRUE,      # Fix the range of the KDE\n       main=paste(\"Quarter\", i),  # Title for each plot\n       ribside = \"right\", \n       col = multi_color_palette(100))  # Use 'inferno' color gradient\n  \n  # Remove the x and y axis labels for a cleaner look\n  axis(1, labels=FALSE)\n  axis(2, labels=FALSE)\n}\n\n#dd a unified title across all plots (e.g., the duration of analysis)\nmtext(\"Quarterly Spatio-Temporal KDE for Civilian Conflict Intensity in Mandalay\", \n      outer=TRUE, cex=1.5, font=2)\n\n\n\n\n\n\n\n\n\n\n\nmulti_color_palette &lt;- colorRampPalette(c(\"blue\", \"green\", \"yellow\", \"red\"))\n\n# Save the animation as a GIF\nsaveGIF({\n  # Loop over the valid quarter times\n  for(i in tims){ \n    suppressWarnings({\n      plot(Mandalay_QuarterYear_KDE, i, \n           override.par=FALSE,  # Keep graphical parameters unchanged\n           fix.range=TRUE,      # Fix the range of the KDE\n           main=paste(\"Mandalay Civilian Related Conflict KDE at Quarter\", i),  # Title for each plot\n           ribside = \"right\",  # Legend on the right\n           col = multi_color_palette(100))  # Apply multi-color gradient\n    })\n  }\n}, movie.name = \"Mandalaykde_animation.gif\", interval = 0.5, ani.width = 800, ani.height = 800)\n\n\nIn Mandalay, the spatio-temporal KDE analysis similarly shows a general reduction in conflict intensity over time, from 2021 to 2024. However, like in Yangon, clustering remains within the same key areas across the quarters.\n\nKey Observations:\n\n2021 to 2022: High-intensity conflicts are concentrated in central and northern Mandalay, as shown by the red and orange clusters, particularly in early 2021 and 2022.\n2023 to 2024: The intensity of the conflicts decreases over time, but these clusters persist in similar regions, particularly in central Mandalay. This indicates that although conflict intensity is declining, these areas continue to be hotspots for civilian conflict.\n\nThus, the persistence of clustering in the same areas despite decreasing conflict intensity highlights the need for focused intervention strategies in these conflict-prone regions."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#sagaing-quarter-year-spatio-temporal-kde",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#sagaing-quarter-year-spatio-temporal-kde",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "9.4 Sagaing Quarter Year Spatio-Temporal KDE",
    "text": "9.4 Sagaing Quarter Year Spatio-Temporal KDE\n\nSagaing Quarter Year Code PreparationSagaing Quarter Year OwinSagaing Quarter Year KDESagaing Quarter Year KDE Animation\n\n\n\n# Step 1: Ensure Sagaing_QuarterYear_Sf is an sf object (if not already)\nSagaing_QuarterYear_Sf &lt;- st_as_sf(Sagaing_ACLED_Data_Sf)\n\n# Step 2: Extract the coordinates (longitude and latitude) from the geometry column\ncoords &lt;- st_coordinates(Sagaing_QuarterYear_Sf)\n\n# Step 3: Convert quarter_numeric to factor for distinct quarters (for plotting the circles)\nSagaing_QuarterYear_Sf &lt;- Sagaing_QuarterYear_Sf %&gt;%\n  mutate(\n    year = as.numeric(sub(\".*-\", \"\", quarter_year)),                  # Extract the year (e.g., 2023)\n    quarter = as.numeric(sub(\"Q\", \"\", sub(\"-.*\", \"\", quarter_year))), # Extract the quarter (e.g., Q1 -&gt; 1)\n    \n    # Continuous representation of time (factor for distinct quarters)\n    quarter_numeric_factor = as.factor(year * 10 + quarter),  # Convert to factor for plotting the circles\n    quarter_numeric = year * 10 + quarter  # Keep as numeric for time-based KDE analysis\n  )\n\n# Step 4: Create the point pattern object using ppp() with factor marks (for distinct quarter plotting)\nSagaing_QuarterYear_PPP_Factor &lt;- ppp(\n  x = coords[, 1],  # Longitude (x-coordinates)\n  y = coords[, 2],  # Latitude (y-coordinates)\n  window = Sagaing_Owin,  # Spatial window (Sagaing_Owin)\n  marks = Sagaing_QuarterYear_Sf$quarter_numeric_factor  # Use factor for visualizing distinct quarters\n)\n\n\n# Step 5: Assign 14 unique sizes to the 14 unique quarter_numeric values\n# Create 14 different circle sizes, e.g., from 1 to 3 in size\nunique_quarters &lt;- levels(Sagaing_QuarterYear_Sf$quarter_numeric_factor)  # Get the unique quarter levels (14 levels)\ncircle_sizes &lt;- seq(1, 3, length.out = length(unique_quarters))  # Generate 14 sizes from 1 to 3\n\n# Map each unique quarter_numeric level to a circle size\ncircle_size_map &lt;- setNames(circle_sizes, unique_quarters)  # Create a named vector to map quarter to size\n\n\n\n\n# Apply the circle size mapping to each point based on its quarter_numeric_factor\npoint_circle_sizes &lt;- circle_size_map[Sagaing_QuarterYear_Sf$quarter_numeric_factor]\n\n# Step 6: Plot the base map (Sagaing_Owin) without points\nplot(Sagaing_Owin, main = \"Sagaing Quarter-Year Owin with Unique Circle Sizes\")\n\n# Step 7: Add the points with the unique circle sizes based on quarter_numeric\npoints(coords[, 1], coords[, 2], cex = point_circle_sizes, pch = 16, col = \"black\")  # Add circles on top of base map\n\n# Step 8: Add a custom legend to show the quarter_numeric values and corresponding circle sizes\nlegend(\"topright\", legend = unique_quarters, \n       pch = 16, \n       pt.cex = circle_sizes,  # Show unique circle sizes in the legend\n       col = \"black\", \n       title = \"Quarters (Circle Size)\")\n\n\n\n\n\n\n\n\n\n\n\nSagaing_QuarterYear_PPP_Numeric &lt;- ppp(\n  x = coords[, 1],  # Longitude (x-coordinates)\n  y = coords[, 2],  # Latitude (y-coordinates)\n  window = Sagaing_Owin,  # Spatial window (Sagaing_Owin)\n  marks = Sagaing_QuarterYear_Sf$quarter_numeric  # Use numeric for KDE analysis (time-based)\n)\n\nSagaing_QuarterYear_KDE &lt;- spattemp.density(Sagaing_QuarterYear_PPP_Numeric)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nmulti_color_palette &lt;- colorRampPalette(c(\"blue\", \"green\", \"yellow\", \"red\"))\n\n\n# Define the quarters for which you want to plot the KDE\ntims &lt;- c(20211, 20212, 20213, 20214, 20221, 20222, 20223, 20224, \n          20231, 20232, 20233, 20234, 20241, 20242)\n\n#Set up the plotting window to display multiple plots in a grid (4 rows, 4 columns)\npar(mfrow=c(4, 4), mar=c(2, 2, 2, 2), oma=c(0, 0, 2, 0))  # Adjust margins and add outer margin for title\n\n# Loop through the 'tims' vector and plot the KDE for each time point (from left to right)\nfor(i in tims) { \n  plot(Sagaing_QuarterYear_KDE, i, \n       override.par=FALSE,  # Keep the graphical parameters unchanged\n       fix.range=TRUE,      # Fix the range of the KDE\n       main=paste(\"Quarter\", i),  # Title for each plot\n       ribside = \"right\", \n       col = multi_color_palette(100))  # Use 'inferno' color gradient\n  \n  # Remove the x and y axis labels for a cleaner look\n  axis(1, labels=FALSE)\n  axis(2, labels=FALSE)\n}\n\n#dd a unified title across all plots (e.g., the duration of analysis)\nmtext(\"Quarterly Spatio-Temporal KDE for Civilian Conflict Intensity in Sagaing\", \n      outer=TRUE, cex=1.5, font=2)\n\n\n\n\n\n\n\n\n\n\n\nmulti_color_palette &lt;- colorRampPalette(c(\"blue\", \"green\", \"yellow\", \"red\"))\n\n# Save the animation as a GIF\nsaveGIF({\n  # Loop over the valid quarter times\n  for(i in tims){ \n    suppressWarnings({\n      plot(Sagaing_QuarterYear_KDE, i, \n           override.par=FALSE,  # Keep graphical parameters unchanged\n           fix.range=TRUE,      # Fix the range of the KDE\n           main=paste(\"Sagaing Civilian Related Conflict KDE at Quarter\", i),  # Title for each plot\n           ribside = \"right\",  # Legend on the right\n           col = multi_color_palette(100))  # Apply multi-color gradient\n    })\n  }\n}, movie.name = \"Sagaingkde_animation.gif\", interval = 0.5, ani.width = 800, ani.height = 800)\n\n\nSpatio-Temporal KDE analysis for Sagaing across multiple quarters, we observe significant spatial clustering of civilian-related conflicts over time. The conflict intensity remains localized in specific regions, with fluctuations in density between quarters.\n\nKey Observations:\n\nConsistent Clustering: Conflict events are consistently clustered in the central and southern regions of Sagaing, as indicated by the green to red areas over time. These regions show recurring intensity, highlighting persistent conflict zones.\nTemporal Fluctuations: Some quarters, such as 20212, 20213, and 20222, exhibit relatively lower conflict intensity, while 20224 shows a resurgence in intensity.\nLocalized Hotspots: The southern region shows a spike in density during 20241, followed by a steady reduction in the later quarters.\n\n\n\nConclusion:\nThere is ongoing clustering in the same geographic regions of Sagaing, with peaks of conflict intensity in specific quarters. This indicates that while the overall distribution of conflicts remains stable, certain periods witness heightened violence."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#yangon-7",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#yangon-7",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "10.1 Yangon",
    "text": "10.1 Yangon\nFor the conflict events in Sagaing, we performed a detailed spatial point pattern analysis by computing the cross-K function for each pair of years (e.g., 2021 vs. 2022, 2021 vs. 2023, etc.). The cross-K function allows us to investigate how conflict events in one year relate to conflict events in another year, revealing whether the events are clustered, dispersed, or randomly distributed across space between different time periods.\n\nNull and Alternative Hypotheses:\n\nHo (Null Hypothesis): The distribution of conflict events in Yangon follows Complete Spatio-Temporal Randomness (CSTR), meaning the events are randomly distributed in both space and time.\nH1 (Alternative Hypothesis): The distribution of conflict events in Yangon does not follow CSTR and instead shows signs of clustering or dispersion in both space and time.\n\n\n\n10.1.1 Yangon’s Cross K Calculation\n\nCodeOutput and Charts\n\n\n\n# Create the spatial point pattern (ppp) object for Yangon\nYangon_ppp_years &lt;- ppp(\n  x = Yangon_ACLED_co[, 1],  # Longitude\n  y = Yangon_ACLED_co[, 2],  # Latitude\n  window = Yangon_Owin  # Spatial observation window (owin object)\n)\n\n# Add a mark that groups quarters by year (e.g., 2021, 2022, 2023, 2024)\nYangon_ppp_years$marks &lt;- as.factor(substr(Yangon_QuarterYear_Sf$quarter_numeric, 1, 4))\nYangon_ppp_years &lt;- rescale(Yangon_ppp_years, 1000, \"km\")\n# Store the unique years in the data\nunique_years &lt;- levels(Yangon_ppp_years$marks)\n\n# Function to compute cross-K function between two years\ncross_k_function_by_year &lt;- function(ppp_object, year1, year2) {\n  # Compute the cross-K function for the two selected years within the same ppp object\n  K_cross &lt;- Kcross(ppp_object, i = year1, j = year2)\n  return(K_cross)\n}\n\n# Initialize an empty list to store each year's comparison\nYangon_k_results &lt;- list()\n\n# Loop through pairs of years to compute and store cross-K functions\nfor (i in 1:(length(unique_years) - 1)) {\n  for (j in (i + 1):length(unique_years)) {\n    year1 &lt;- unique_years[i]\n    year2 &lt;- unique_years[j]\n    \n    # Print progress\n    cat(\"Computing K-Function for\", year1, \"and\", year2, \"\\n\")\n    \n    # Compute the cross-K function for these two years and store it in a named variable\n    result_name &lt;- paste0(\"Yangon_k_\", year1, \"_vs_\", year2)\n    Yangon_k_results[[result_name]] &lt;- cross_k_function_by_year(Yangon_ppp_years, year1, year2)\n  }\n}\n\n# Save individual year comparison results as variables\nYangon_k_2021_vs_2022 &lt;- Yangon_k_results[[\"Yangon_k_2021_vs_2022\"]]\nYangon_k_2021_vs_2023 &lt;- Yangon_k_results[[\"Yangon_k_2021_vs_2023\"]]\nYangon_k_2021_vs_2024 &lt;- Yangon_k_results[[\"Yangon_k_2021_vs_2024\"]]\nYangon_k_2022_vs_2023 &lt;- Yangon_k_results[[\"Yangon_k_2022_vs_2023\"]]\nYangon_k_2022_vs_2024 &lt;- Yangon_k_results[[\"Yangon_k_2022_vs_2024\"]]\nYangon_k_2023_vs_2024 &lt;- Yangon_k_results[[\"Yangon_k_2023_vs_2024\"]]\n\n# Set up the layout for multiple plots (2 rows, 3 columns for all year comparisons)\n\n\n\n\npar(mfrow = c(2, 1))\n# Plotting each comparison\nplot(Yangon_k_2021_vs_2022, main = \"K-Function: Yangon Civilian Related Conflict KDE 2021 vs 2022\")\nplot(Yangon_k_2021_vs_2023, main = \"K-Function: Yangon Civilian Related Conflict KDE 2021 vs 2023\")\n\n\n\n\n\n\n\nplot(Yangon_k_2021_vs_2024, main = \"K-Function: Yangon Civilian Related Conflict KDE 2021 vs 2024\")\nplot(Yangon_k_2022_vs_2023, main = \"K-Function: Yangon Civilian Related Conflict KDE 2022 vs 2023\")\n\n\n\n\n\n\n\nplot(Yangon_k_2022_vs_2024, main = \"K-Function: Yangon Civilian Related Conflict KDE 2022 vs 2024\")\nplot(Yangon_k_2023_vs_2024, main = \"K-Function: Yangon Civilian Related Conflict KDE 2023 vs 2024\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n10.1.2 Yangon’s Cross K Analysis\n\n10.1.2.1 Yangon’s Individual Years Comparision\n\n10.1.2.1.1 2021 vs 2022\n\n\nThe observed K-function lies consistently above the CSR envelope, indicating significant clustering between events from 2021 and 2022 at distances up to approximately 25 km.\nThe clustering effect becomes more prominent at larger distances, suggesting that events from 2021 tend to cluster with events from 2022 across larger spatial scales.\n\n\n\n10.1.2.1.2 2021 vs 2023\n\n\nThe K-function for 2021 vs 2023 is also above the CSR envelope, indicating clustering between these two years.\nHowever, the clustering is slightly less prominent compared to 2021 vs 2022, suggesting that while clustering persists, the relationship between events from 2021 and 2023 is somewhat weaker than between 2021 and 2022.\n\n\n\n10.1.2.1.3 2021 vs 2024\n\n\nThe clustering is still evident between 2021 and 2024, but the clustering intensity appears to be weaker at larger distances. The observed K-function shows less deviation from the CSR envelope, indicating that the spatial clustering effect is declining as we compare events separated by more time.\n\n\n\n10.1.2.1.4 2022 vs 2023\n\n\nThe K-function here indicates significant clustering at smaller distances, but the intensity decreases more rapidly beyond 15 km.\nThe spatial clustering between 2022 and 2023 is still present but somewhat weaker compared to other year-pair comparisons.\n\n\n\n10.1.2.1.5 2022 vs 2024\n\n\nThe 2022 vs 2024 K-function shows clustering, though it is less pronounced than in the previous year comparisons.\nThe clustering effect diminishes as the events from these two years become more spatially dispersed, particularly beyond 15 km.\n\n\n\n10.1.2.1.6 2023 vs 2024\n\n\nThe K-function for 2023 vs 2024 shows the least clustering effect of all the comparisons.\nThere is minimal deviation from the CSR line, indicating that the events from these two years are closer to being randomly distributed, with only mild clustering observed at smaller distances.\n\n\n\n\n10.1.2.1 Overall Years Comparison\n\nClustering is strongest between events that are closer in time (e.g., 2021 vs 2022), with the strength of clustering generally decreasing as the time difference between events increases (e.g., 2021 vs 2024).\nThis suggests that civilian conflict events in Yangon have a spatial-temporal dependence, where events in one year are more likely to occur near events from the following year, but this effect diminishes over time."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#mandalay-7",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#mandalay-7",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "10.2 Mandalay",
    "text": "10.2 Mandalay\nFor the conflict events in Mandalay, we performed a detailed spatial point pattern analysis by computing the cross-K function for each pair of years (e.g., 2021 vs. 2022, 2021 vs. 2023, etc.). The cross-K function allows us to investigate how conflict events in one year relate to conflict events in another year, revealing whether the events are clustered, dispersed, or randomly distributed across space between different time periods.\n\nNull and Alternative Hypotheses:\n\nHo (Null Hypothesis): The distribution of conflict events in Mandalay follows Complete Spatio-Temporal Randomness (CSTR), meaning the events are randomly distributed in both space and time.\nH1 (Alternative Hypothesis): The distribution of conflict events in Mandalay does not follow CSTR and instead shows signs of clustering or dispersion in both space and time.\n\n\n\n10.2.1 Mandalay’s Cross K Calculation\n\nCodeOutput and Charts\n\n\n\n# Create the spatial point pattern (ppp) object for Mandalay\nMandalay_ppp_years &lt;- ppp(\n  x = Mandalay_ACLED_co[, 1],  # Longitude\n  y = Mandalay_ACLED_co[, 2],  # Latitude\n  window = Mandalay_Owin  # Spatial observation window (owin object)\n)\n\n# Add a mark that groups quarters by year (e.g., 2021, 2022, 2023, 2024)\nMandalay_ppp_years$marks &lt;- as.factor(substr(Mandalay_QuarterYear_Sf$quarter_numeric, 1, 4))\n# Store the unique years in the data\nunique_years &lt;- levels(Mandalay_ppp_years$marks)\nMandalay_ppp_years &lt;- rescale(Mandalay_ppp_years, 1000, \"km\")\n\n# Function to compute cross-K function between two years\ncross_k_function_by_year &lt;- function(ppp_object, year1, year2) {\n  # Compute the cross-K function for the two selected years within the same ppp object\n  K_cross &lt;- Kcross(ppp_object, i = year1, j = year2)\n  return(K_cross)\n}\n\n# Initialize an empty list to store each year's comparison\nMandalay_k_results &lt;- list()\n\n# Loop through pairs of years to compute and store cross-K functions\nfor (i in 1:(length(unique_years) - 1)) {\n  for (j in (i + 1):length(unique_years)) {\n    year1 &lt;- unique_years[i]\n    year2 &lt;- unique_years[j]\n    \n    # Print progress\n    cat(\"Computing K-Function for\", year1, \"and\", year2, \"\\n\")\n    \n    # Compute the cross-K function for these two years and store it in a named variable\n    result_name &lt;- paste0(\"Mandalay_k_\", year1, \"_vs_\", year2)\n    Mandalay_k_results[[result_name]] &lt;- cross_k_function_by_year(Mandalay_ppp_years, year1, year2)\n  }\n}\n\n# Save individual year comparison results as variables\nMandalay_k_2021_vs_2022 &lt;- Mandalay_k_results[[\"Mandalay_k_2021_vs_2022\"]]\nMandalay_k_2021_vs_2023 &lt;- Mandalay_k_results[[\"Mandalay_k_2021_vs_2023\"]]\nMandalay_k_2021_vs_2024 &lt;- Mandalay_k_results[[\"Mandalay_k_2021_vs_2024\"]]\nMandalay_k_2022_vs_2023 &lt;- Mandalay_k_results[[\"Mandalay_k_2022_vs_2023\"]]\nMandalay_k_2022_vs_2024 &lt;- Mandalay_k_results[[\"Mandalay_k_2022_vs_2024\"]]\nMandalay_k_2023_vs_2024 &lt;- Mandalay_k_results[[\"Mandalay_k_2023_vs_2024\"]]\n\n\n\n\n# Set up the layout for multiple plots (2 rows, 3 columns for all year comparisons)\npar(mfrow = c(2, 1))\n\n# Plotting each comparison\nplot(Sagaing_k_2021_vs_2022, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2021 vs 2022\")\nplot(Sagaing_k_2021_vs_2023, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2021 vs 2023\")\n\n\n\n\n\n\n\nplot(Sagaing_k_2021_vs_2024, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2021 vs 2024\")\nplot(Sagaing_k_2022_vs_2023, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2022 vs 2023\")\n\n\n\n\n\n\n\nplot(Sagaing_k_2022_vs_2024, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2022 vs 2024\")\nplot(Sagaing_k_2023_vs_2024, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2023 vs 2024\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n10.2.2 Mandalay’s Cross K Analysis\n\n10.2.2.1 Mandalay’s Individual Years Comparison\n\n10.1.2.1.1 2021 vs 2022\n\n\nThe K-function for 2021 vs 2022 shows significant clustering at all distances. The observed K-function is consistently above the CSR envelope, indicating that conflict events from 2021 tend to cluster near those from 2022.\nThe clustering effect appears to intensify as the distance increases, suggesting a broad spatial clustering pattern for conflicts in 2021 and 2022.\n\n\n\n10.2.2.1.2 2021 vs 2023\n\n\nthe K-function for 2021 vs 2023 also shows clustering, but it is slightly less pronounced than in the 2021 vs 2022 comparison.\nThe clustering becomes more noticeable at distances beyond 10 km, implying that conflict events from these two years tend to cluster over medium to larger distances.\nHowever, the clustering effect weakens somewhat compared to the previous year comparison.\n\n\n\n10.2.2.1.3 2021 vs 2024\n\n\nClustering between 2021 and 2024 is still present, but the intensity is weaker compared to the previous year pairs.\nThe observed K-function does show some clustering above the CSR line, but the deviation from randomness is smaller, suggesting that events from 2021 and 2024 are less spatially related than the closer years (2021 vs 2022).\n\n\n\n10.2.2.1.4 2022 vs 2023\n\n\nThe clustering between 2022 and 2023 remains significant, especially at larger distances, with the observed K-function clearly above the CSR envelope.\nSimilar to earlier comparisons, this suggests that conflict events from these two years cluster over wider distances, continuing the spatial clustering trend seen in other comparisons.\n\n\n\n10.2.2.5 2022 vs 2024\n\n\nThe 2022 vs 2024 K-function shows clustering, although the intensity is weaker, particularly at smaller distances.\nThere is a slight increase in clustering at larger distances, but the deviation from the CSR envelope is less pronounced compared to the earlier year comparisons.\n\n\n\n10.2.2.6 2023 vs 2024\n\n\nThe K-function for 2023 vs 2024 shows clustering, though this is the weakest of all the comparisons.\nThe clustering effect becomes more noticeable at distances greater than 10 km, but overall, the spatial relationship between events from 2023 and 2024 is closer to random compared to earlier year comparisons.\n\n\n\n\n10.2.2.1 Mandalay Overall Years Comparison\n\nSimilar to the Yangon analysis, the spatial clustering is strongest between conflict events that are closer in time, such as 2021 vs 2022 and 2022 vs 2023.\nAs the time gap between years increases, the clustering effect becomes weaker, with the least clustering observed between 2023 and 2024.\n\nThese results suggest that conflicts in Mandalay show spatio-temporal clustering, with events from one year often clustering near those from the next, but this effect diminishes as the time gap between years grows."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#sagaing-6",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise1.html#sagaing-6",
    "title": "Take_Home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "10.3 Sagaing",
    "text": "10.3 Sagaing\nFor the conflict events in Sagaing, we performed a detailed spatial point pattern analysis by computing the cross-K function for each pair of years (e.g., 2021 vs. 2022, 2021 vs. 2023, etc.). The cross-K function allows us to investigate how conflict events in one year relate to conflict events in another year, revealing whether the events are clustered, dispersed, or randomly distributed across space between different time periods.\nNull and Alternative Hypotheses:\n\nHo (Null Hypothesis): The distribution of conflict events in Sagaing follows Complete Spatio-Temporal Randomness (CSTR), meaning the events are randomly distributed in both space and time.\nH1 (Alternative Hypothesis): The distribution of conflict events in Sagaing does not follow CSTR and instead shows signs of clustering or dispersion in both space and time.\n\n\n10.3.1 Sagaing’s Cross K Calculation\n\nCodeOutput and Charts\n\n\n\nSagaing_ppp_years &lt;- ppp(\n  x = Sagaing_ACLED_co[, 1],  # Longitude\n  y = Sagaing_ACLED_co[, 2],  # Latitude\n  window = Sagaing_Owin  # Spatial observation window (owin object)\n)\n\n# Add a mark that groups quarters by year (e.g., 2021, 2022, 2023, 2024)\nSagaing_ppp_years$marks &lt;- as.factor(substr(Sagaing_QuarterYear_Sf$quarter_numeric, 1, 4))\nSagaing_ppp_years &lt;- rescale(Sagaing_ppp_years, 1000, \"km\")\n# Store the unique years in the data\nunique_years &lt;- levels(Sagaing_ppp_years$marks)\n\n# Function to compute cross-K function between two years\ncross_k_function_by_year &lt;- function(ppp_object, year1, year2) {\n  # Compute the cross-K function for the two selected years within the same ppp object\n  K_cross &lt;- Kcross(ppp_object, i = year1, j = year2)\n  return(K_cross)\n}\n\n# Initialize an empty list to store each year's comparison\nSagaing_k_results &lt;- list()\n\n# Loop through pairs of years to compute and store cross-K functions\nfor (i in 1:(length(unique_years) - 1)) {\n  for (j in (i + 1):length(unique_years)) {\n    year1 &lt;- unique_years[i]\n    year2 &lt;- unique_years[j]\n    \n    # Print progress\n    cat(\"Computing K-Function for\", year1, \"and\", year2, \"\\n\")\n    \n    # Compute the cross-K function for these two years and store it in a named variable\n    result_name &lt;- paste0(\"Sagaing_k_\", year1, \"_vs_\", year2)\n    Sagaing_k_results[[result_name]] &lt;- cross_k_function_by_year(Sagaing_ppp_years, year1, year2)\n  }\n}\n\n# Save individual year comparison results as variables\nSagaing_k_2021_vs_2022 &lt;- Sagaing_k_results[[\"Sagaing_k_2021_vs_2022\"]]\nSagaing_k_2021_vs_2023 &lt;- Sagaing_k_results[[\"Sagaing_k_2021_vs_2023\"]]\nSagaing_k_2021_vs_2024 &lt;- Sagaing_k_results[[\"Sagaing_k_2021_vs_2024\"]]\nSagaing_k_2022_vs_2023 &lt;- Sagaing_k_results[[\"Sagaing_k_2022_vs_2023\"]]\nSagaing_k_2022_vs_2024 &lt;- Sagaing_k_results[[\"Sagaing_k_2022_vs_2024\"]]\nSagaing_k_2023_vs_2024 &lt;- Sagaing_k_results[[\"Sagaing_k_2023_vs_2024\"]]\n\n# Save individual year comparison results as variables\nSagaing_k_2021_vs_2022 &lt;- Sagaing_k_results[[\"Sagaing_k_2021_vs_2022\"]]\nSagaing_k_2021_vs_2023 &lt;- Sagaing_k_results[[\"Sagaing_k_2021_vs_2023\"]]\nSagaing_k_2021_vs_2024 &lt;- Sagaing_k_results[[\"Sagaing_k_2021_vs_2024\"]]\nSagaing_k_2022_vs_2023 &lt;- Sagaing_k_results[[\"Sagaing_k_2022_vs_2023\"]]\nSagaing_k_2022_vs_2024 &lt;- Sagaing_k_results[[\"Sagaing_k_2022_vs_2024\"]]\nSagaing_k_2023_vs_2024 &lt;- Sagaing_k_results[[\"Sagaing_k_2023_vs_2024\"]]\n\n\n\n\npar(mfrow = c(2, 1))\n# Plotting each comparison\nplot(Sagaing_k_2021_vs_2022, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2021 vs 2022\")\nplot(Sagaing_k_2021_vs_2023, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2021 vs 2023\")\n\n\n\n\n\n\n\nplot(Sagaing_k_2021_vs_2024, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2021 vs 2024\")\nplot(Sagaing_k_2022_vs_2023, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2022 vs 2023\")\n\n\n\n\n\n\n\nplot(Sagaing_k_2022_vs_2024, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2022 vs 2024\")\nplot(Sagaing_k_2023_vs_2024, main = \"K-Function: Sagaing Civilian Related Conflict KDE 2023 vs 2024\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n10.3.2 Sagaing’s Cross K Analysis\n\n10.3.2.1 Sagaing’s Individual Years Comparison\n\n10.3.2.1.1 2021 vs 2022\n\n\nThe observed K-function r is consistently higher than the CSR (Complete Spatial Randomness) envelope across almost all distances. This indicates that the conflict events in 2021 and 2022 are significantly clustered in space. The clustering effect becomes more pronounced at larger distances, especially after 20 km.\nThe trans K-function also follows a similar pattern, showing clustering beyond the expected CSR pattern.\nThe Kbord function demonstrates that boundary corrections had minimal impact on the general clustering trends observed.\n\n\n\n10.3.2.1.2 2021 vs 2023\n\n\nSimilar to the comparison between 2021 and 2022, the K-function in 2021 vs 2023 also shows a high degree of clustering, with obs(r) being higher than CSR across nearly all distances.\nThere is a slightly more pronounced clustering effect around 30 to 40 km, where the gap between the observed K and CSR becomes wider. This suggests an increase in conflict density over time.\n\n\n\n10.3.2.1.3 2021 vs 2024\n\n\nthe K-function for 2021 vs 2024 shows a consistent pattern of clustering across distances, although the observed values tend to rise more sharply after 40 km, indicating that conflicts in 2024 were more dispersed initially but clustered significantly at larger spatial scales.\nThe results suggest that the spatial distribution of conflicts in 2024 is slightly different, possibly influenced by external factors that caused conflicts to be more spread out in space.\n\n\n\n10.3.2.1.4 2022 vs 2023\n\n\nThe comparison between 2022 and 2024 reveals strong clustering over a wide range of distances, with significant increases after 30 km.\nThis suggests that conflicts in 2024 are more spatially concentrated at larger distances compared to 2022.\n\n\n\n10.3.2.1.5 2022 vs 2024\n\n\nThe comparison between 2022 and 2024 reveals strong clustering over a wide range of distances, with significant increases after 30 km.\nThis suggests that conflicts in 2024 are more spatially concentrated at larger distances compared to 2022.\n\n\n\n10.3.2.1.6 2023 vs 2024\n\n\nThe clustering trend continues between 2023 and 2024, with notable increases in clustering beyond 40 km. The gap between the observed K and CSR remains large, indicating that the conflict events in 2023 and 2024 were not randomly distributed but exhibited significant spatial clustering.\n\n\n\n\n10.3.2.1 Sagaing Overall Years Comparison\n\nAcross all years (2021-2024), the K-functions suggest that civilian-related conflict events in Sagaing are significantly clustered rather than randomly distributed. The degree of clustering varies slightly across the years, with some years (such as 2024) showing stronger clustering at larger distances (over 40 km). This indicates that the conflict dynamics in Sagaing are evolving over time, possibly due to changes in political, social, or environmental factors."
  },
  {
    "objectID": "template.html",
    "href": "template.html",
    "title": "In Class Exercise 1: Geospatial Data Science",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "",
    "text": "Drug abuse remains a global concern, with its impact ranging from deteriorating public health to increasing crime rates and economic instability. According to global reports, in 2021, 1 in 17 people aged 15–64 used drugs within the past year. Despite concerted efforts to combat drug trafficking and abuse, the numbers continue to rise, with drug consumption growing from 240 million users in 2011 to 296 million in 2021.\nThailand, geographically located near the infamous Golden Triangle—one of the largest illicit drug production regions in the world—faces its own drug crisis. This region’s proximity to Thailand, coupled with well-developed transportation networks, makes the country not only a prime target for drug trafficking but also a transit hub for drugs en route to third countries. As a result, drug abuse within Thailand has become a pressing issue, especially among youth populations. It is estimated that there are 2.7 million youths in Thailand involved with drugs, with vocational students representing a significant portion of these users.\nThe objective of this analysis is to investigate the spatial and temporal patterns of drug abuse across Thailand at the province level. By utilizing geospatial analysis methods, this report aims to answer three key questions:\n\nAre the indicators of drug abuse in Thailand spatially independent or spatially dependent?\nWhere are the clusters, outliers, and hotspots of drug abuse across Thailand’s provinces?\nHow do these patterns evolve over time, and what correlations exist between drug abuse and socio-economic factors such as education levels and unemployment rates?\n\nUnderstanding these patterns will provide key insights into where resources and interventions should be targeted to combat drug abuse effectively."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_3/Take_Home_Exercise3.html",
    "href": "Take_Home_Exercises/Take_Home_Exercise_3/Take_Home_Exercise3.html",
    "title": "In Class Exercise1: Geospatial Data Science",
    "section": "",
    "text": "There’s no In Class Exercise 1, so here’s a picture of a cat."
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_6/In_Class_Exercise6.html",
    "href": "In_Class_Exercises/In_Class_Exercise_6/In_Class_Exercise6.html",
    "title": "In Class Exercise 6 : Geospatial Data Science",
    "section": "",
    "text": "pacman::p_load(sf, spdep, tmap, tidyverse, sfdep)"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_6/In_Class_Exercise6.html#step-1-deriving-queens-contiguity-weights-sfdep-methods",
    "href": "In_Class_Exercises/In_Class_Exercise_6/In_Class_Exercise6.html#step-1-deriving-queens-contiguity-weights-sfdep-methods",
    "title": "In Class Exercise 6 : Geospatial Data Science",
    "section": "3.1 Step 1: Deriving Queen’s Contiguity Weights: SFDep Methods",
    "text": "3.1 Step 1: Deriving Queen’s Contiguity Weights: SFDep Methods\n\nwm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(\n        nb = st_contiguity(geometry),\n        wt = st_weights(nb, style = \"W\"),\n        .before = 1\n  )"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_6/In_Class_Exercise6.html#step-2-computing-global-moran-i",
    "href": "In_Class_Exercises/In_Class_Exercise_6/In_Class_Exercise6.html#step-2-computing-global-moran-i",
    "title": "In Class Exercise 6 : Geospatial Data Science",
    "section": "3.2 Step 2: Computing Global Moran’ I",
    "text": "3.2 Step 2: Computing Global Moran’ I\n\nmoranI &lt;- global_moran(wm_q$GDPPC, \n                       wm_q$nb,\n                       wm_q$wt\n                       )\n\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\nK is the average number that they found"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_6/In_Class_Exercise6.html#step-3-performing-global-morans-i-test",
    "href": "In_Class_Exercises/In_Class_Exercise_6/In_Class_Exercise6.html#step-3-performing-global-morans-i-test",
    "title": "In Class Exercise 6 : Geospatial Data Science",
    "section": "3.3 Step 3: performing Global Moran’s I Test",
    "text": "3.3 Step 3: performing Global Moran’s I Test\n\nglobal_moran_test(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt\n                  )\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nThis is basically the idea that MORAN I shows there’s clustering but not a strong one and since the P value is low, we do it.\nLook at the p-value first, then we do not have the statistical analysis."
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_6/In_Class_Exercise6.html#step-4-performing-global-morans-i-permutation-test-use-this-for-take-home--2",
    "href": "In_Class_Exercises/In_Class_Exercise_6/In_Class_Exercise6.html#step-4-performing-global-morans-i-permutation-test-use-this-for-take-home--2",
    "title": "In Class Exercise 6 : Geospatial Data Science",
    "section": "3.4 Step 4: Performing Global Moran’s I Permutation Test (Use this for Take Home -2)",
    "text": "3.4 Step 4: Performing Global Moran’s I Permutation Test (Use this for Take Home -2)\nDo this for statistical test, to ensure it’s reproducible, set seed.\n\nset.seed(1234)\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99\n                  )\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nThis simulates and permutates the the test permutation test. So basically we do 100 test and see if the p-value to reject or not."
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_6/In_Class_Exercise6.html#visualising-the-local-morans-i",
    "href": "In_Class_Exercises/In_Class_Exercise_6/In_Class_Exercise6.html#visualising-the-local-morans-i",
    "title": "In Class Exercise 6 : Geospatial Data Science",
    "section": "4.1 Visualising the Local Moran’s I",
    "text": "4.1 Visualising the Local Moran’s I\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_6/In_Class_Exercise6.html#section",
    "href": "In_Class_Exercises/In_Class_Exercise_6/In_Class_Exercise6.html#section",
    "title": "In Class Exercise 6 : Geospatial Data Science",
    "section": " ",
    "text": "tmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_fill(\"p_ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 2)"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_6/In_Class_Exercise6.html#visualising-the-local-morans-i-p-value-and-ii",
    "href": "In_Class_Exercises/In_Class_Exercise_6/In_Class_Exercise6.html#visualising-the-local-morans-i-p-value-and-ii",
    "title": "In Class Exercise 6 : Geospatial Data Science",
    "section": "4.3 Visualising the Local Moran’s I P value and II",
    "text": "4.3 Visualising the Local Moran’s I P value and II\n\nmap1 &lt;-\ntm_shape(lisa) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 2) \n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\") +\n  # breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf) \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 2)\n\ntmap_arrange(map1, map2, ncol =2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_6/In_Class_Exercise6.html#visualising-hotspot-and-cold-spot-areas.-with-signifcant-values",
    "href": "In_Class_Exercises/In_Class_Exercise_6/In_Class_Exercise6.html#visualising-hotspot-and-cold-spot-areas.-with-signifcant-values",
    "title": "In Class Exercise 6 : Geospatial Data Science",
    "section": "Visualising hotspot and cold spot areas. with signifcant values",
    "text": "Visualising hotspot and cold spot areas. with signifcant values\n\nHCSA_sig &lt;- HCSA %&gt;%\n  filter(p_sim &lt;0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html",
    "href": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html",
    "title": "In Class Exercise 4: Spatio-Temporal Point Patterns Analysis",
    "section": "",
    "text": "A spatio-temporal point process (also called space-time or spatial-temporal point process) is a random collection of points, where each point represents the time and location of an event. Examples of events include incidence of disease, sightings or births of a species, or the occurrences of fires, earthquakes, lightning strikes, tsunamis, or volcanic eruptions.\nThe analysis of spatio-temporal point patterns is becoming increasingly necessary, given the rapid emergence of geographically and temporally indexed data in a wide range of fields. Several spatio-temporal point patterns analysis methods have been introduced and implemented in R in the last ten years. This chapter shows how various R packages can be combined to run a set of spatio-temporal point pattern analyses in a guided and intuitive way. A real world forest fire events in Kepulauan Bangka Belitung, Indonesia from 1st January 2023 to 31st December 2023 is used to illustrate the methods, procedures and interpretations.\n\n\nThe specific question we would like to answer is:\n\nare the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nif the answer is NO, where and when the observed forest fire locations tend to cluster?"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#research-questions",
    "href": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#research-questions",
    "title": "In Class Exercise 4: Spatio-Temporal Point Patterns Analysis",
    "section": "",
    "text": "The specific question we would like to answer is:\n\nare the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nif the answer is NO, where and when the observed forest fire locations tend to cluster?"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#extracting-forest-fire-by-months",
    "href": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#extracting-forest-fire-by-months",
    "title": "In Class Exercise 4: Spatio-Temporal Point Patterns Analysis",
    "section": "5.1 Extracting forest fire by months",
    "text": "5.1 Extracting forest fire by months\n\nfire_month &lt;- forestFire_sf %&gt;%\n  dplyr::select(Month_num)"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#creating-the-ppp",
    "href": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#creating-the-ppp",
    "title": "In Class Exercise 4: Spatio-Temporal Point Patterns Analysis",
    "section": "5.2 Creating the PPP",
    "text": "5.2 Creating the PPP\n\nfire_month_ppp &lt;- as.ppp(fire_month)\nfire_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#including-owin-object",
    "href": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#including-owin-object",
    "title": "In Class Exercise 4: Spatio-Temporal Point Patterns Analysis",
    "section": "5.3 Including Owin Object",
    "text": "5.3 Including Owin Object\n\nfire_month_owin &lt;- fire_month_ppp[kbb_owin]\nhead(fire_month_owin)\n\nMarked planar point pattern: 6 points\nmarks are numeric, of storage type  'double'\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\nglimpse(fire_month_owin)\n\nList of 6\n $ window    :List of 5\n  ..$ type  : chr \"polygonal\"\n  ..$ xrange: num [1:2] 512067 705559\n  ..$ yrange: num [1:2] 9655398 9834006\n  ..$ bdry  :List of 2\n  .. ..$ :List of 2\n  .. ..$ :List of 2\n  ..$ units :List of 3\n  .. ..$ singular  : chr \"unit\"\n  .. ..$ plural    : chr \"units\"\n  .. ..$ multiplier: num 1\n  .. ..- attr(*, \"class\")= chr \"unitname\"\n  ..- attr(*, \"class\")= chr \"owin\"\n $ n         : int 741\n $ x         : num [1:741] 606179 661411 637809 654882 669934 ...\n $ y         : num [1:741] 9703062 9683536 9682757 9690665 9697468 ...\n $ markformat: chr \"vector\"\n $ marks     : num [1:741] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"ppp\"\n\nskim(fire_month_owin)\n\n\nData summary\n\n\nName\nfire_month_owin\n\n\nNumber of rows\n741\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nx\n0\n1\n620811.99\n39443.39\n521564.1\n595009.7\n624170.1\n653519.9\n695791\n▂▅▇▇▅\n\n\ny\n0\n1\n9733857.60\n44333.24\n9658137.5\n9696276.9\n9722669.8\n9774209.8\n9828767\n▆▇▃▆▃\n\n\nmarks\n0\n1\n8.58\n2.04\n1.0\n8.0\n9.0\n10.0\n12\n▁▁▃▇▇"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#computing-spatio-temporal-kde",
    "href": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#computing-spatio-temporal-kde",
    "title": "In Class Exercise 4: Spatio-Temporal Point Patterns Analysis",
    "section": "5.4 Computing Spatio-temporal KDE",
    "text": "5.4 Computing Spatio-temporal KDE\nSpattemp.density() of sparr package is used to compute the STYKDE.\n\nst_kde &lt;- spattemp.density(fire_month_owin)\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#plotting-the-spatio-temporal-kde-object",
    "href": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#plotting-the-spatio-temporal-kde-object",
    "title": "In Class Exercise 4: Spatio-Temporal Point Patterns Analysis",
    "section": "5.5 Plotting the spatio-temporal KDE Object",
    "text": "5.5 Plotting the spatio-temporal KDE Object\nplot for the KDE between july 2023 = december 2023.\n\ntims &lt;- c(7,8,9,10,11,12)\n par(mfcol = c(2,3))\n for(i in tims) {\n   plot(st_kde, i,\n        override.par=FALSE,\n        fix.range = TRUE,\n        main = paste(\"KDE at month\", i)\n        )\n }"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#plotting-the-stkde-object-by-day-of-year-improved",
    "href": "In_Class_Exercises/In_Class_Exercise_4/In_Class_Exercise4.html#plotting-the-stkde-object-by-day-of-year-improved",
    "title": "In Class Exercise 4: Spatio-Temporal Point Patterns Analysis",
    "section": "5.6 Plotting the STKDE Object By Day Of Year & Improved",
    "text": "5.6 Plotting the STKDE Object By Day Of Year & Improved\n\nfire_yday_ppp &lt;- forestFire_sf %&gt;% \n  dplyr::select(DayofYear) %&gt;%\n  as.ppp()\n\nfire_yday_owin &lt;- fire_yday_ppp[kbb_owin]\n\n\nset.seed(1234)\nBOOT.spattemp(fire_yday_owin) \n\nInitialising...Done.\nOptimising...\nh = 15102.47 \b; lambda = 16.84806 \nh = 16612.72 \b; lambda = 16.84806 \nh = 15102.47 \b; lambda = 1527.095 \nh = 15480.03 \b; lambda = 771.9715 \nh = 15668.81 \b; lambda = 394.4098 \nh = 15763.2 \b; lambda = 205.6289 \nh = 15810.4 \b; lambda = 111.2385 \nh = 15833.99 \b; lambda = 64.04328 \nh = 15845.79 \b; lambda = 40.44567 \nh = 15851.69 \b; lambda = 28.64687 \nh = 15863.49 \b; lambda = 5.049258 \nh = 15854.64 \b; lambda = 22.74746 \nh = 15860.54 \b; lambda = 10.94866 \nh = 15859.07 \b; lambda = 13.89836 \nh = 14348.82 \b; lambda = 13.89836 \nh = 13216.87 \b; lambda = 12.42351 \nh = 12460.27 \b; lambda = 15.37321 \nh = 10760.88 \b; lambda = 16.11064 \nh = 8875.282 \b; lambda = 11.68608 \nh = 10432.08 \b; lambda = 12.97658 \nh = 7976.084 \b; lambda = 16.66371 \nh = 9286.281 \b; lambda = 15.60366 \nh = 9615.08 \b; lambda = 18.73771 \nh = 9206.581 \b; lambda = 21.61828 \nh = 8140.483 \b; lambda = 18.23073 \nh = 8795.582 \b; lambda = 17.70071 \nh = 9124.381 \b; lambda = 20.83477 \nh = 9164.856 \b; lambda = 19.52699 \nh = 8345.358 \b; lambda = 18.48998 \nh = 9297.65 \b; lambda = 18.67578 \nh = 8928.375 \b; lambda = 16.8495 \nh = 9105.736 \b; lambda = 18.85762 \nDone.\n\n\n         h     lambda \n9105.73611   18.85762 \n\nkde_yday &lt;- spattemp.density(\n  fire_yday_owin,\n  h = 9000,\n  lambda = 19)\nsummary(kde_yday)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 9000 (spatial)\n  lambda = 19 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [10, 352]\n\nEvaluation\n  128 x 128 x 343 trivariate lattice\n  Density range: [2.001642e-19, 2.445724e-12]\n\n\n\n5.6.1 Making An Animated Time Series Gif Across Days\nFirst Make the data Streamlined into a Dataframe object\n\n# Assuming kde_yday$z.cond contains 343 frames (one for each day)\ndays &lt;- 1:343  # Adjust to match the number of days\n\n# Initialize an empty list to hold the data for each day\nkde_data_list &lt;- lapply(days, function(day) {\n  # Extract the kernel density image for each day from z.cond\n  kde_day &lt;- as.data.frame(kde_yday$z.cond[[day]])  # Convert to a data frame (adjust if necessary)\n  \n  # Rename the columns appropriately (adjust based on the actual structure)\n  colnames(kde_day) &lt;- c(\"x\", \"y\", \"value\")  # Ensure the correct column names for spatial data\n  \n  # Add a DayofYear column for animation\n  kde_day$DayofYear &lt;- day\n  \n  return(kde_day)\n})\n\n# Combine all days' data into a single data frame\nkde_data &lt;- do.call(rbind, kde_data_list)\n\n# Check the structure of the combined data\nstr(kde_data)  # Ensure it contains x, y, value, and DayofYear columns\n\n'data.frame':   1875867 obs. of  4 variables:\n $ x        : num  512823 512823 514334 514334 514334 ...\n $ y        : num  9776098 9777493 9770517 9771912 9773307 ...\n $ value    : num  2.11e-12 2.42e-12 1.19e-12 1.40e-12 1.64e-12 ...\n $ DayofYear: int  1 1 1 1 1 1 1 1 1 1 ...\n\n\nThen get plot data into gif.\n\nlibrary(ggplot2)\nlibrary(gganimate)\n\n# Create an animated plot using ggplot2\np &lt;- ggplot(kde_data, aes(x = x, y = y, fill = value)) +\n  geom_raster() +\n  scale_fill_viridis_c() +  # Use a color scale for density values\n  labs(title = \"Kernel Density Estimation for Day {frame_time}\",\n       x = \"Longitude\", y = \"Latitude\") +\n  coord_equal() +\n  transition_time(DayofYear) +  # Animate by DayofYear (1 to 343)\n  ease_aes('linear')\n\n# Animate the plot and save as a GIF\nanimate(p, nframes = 343, fps = 10, width = 800, height = 600, renderer = gifski_renderer(\"kde_animation_343_days.gif\"))\n\nResults!\n\n\ncoords &lt;- st_coordinates(forestFire_sf)\n\n\nfire_df &lt;- data.frame(\nx = coords[, 1],\ny = coords[, 2],\nt = forestFire_sf$`DayofYear`)\n\n\nfire_stpp &lt;- as.3dpoints(fire_df)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#libraries-and-packages",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#libraries-and-packages",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.1 Libraries and Packages",
    "text": "2.1 Libraries and Packages\n\nsf: Handles spatial data (geometries like points, lines, and polygons) and integrates well with other data manipulation tools.\ntidyverse: A collection of packages like dplyr and ggplot2 for data manipulation and visualization.\nlubridate: Simplifies date and time manipulation, making it easier to work with time-based data.\nsfdep: Provides tools for spatial dependency analysis, crucial for exploring spatial relationships and clustering.\ntmap: A package for creating beautiful thematic maps and interactive visualizations.\nggplot2: Part of tidyverse, used for creating static visualizations using a consistent grammar of graphics.\nknitr: Facilitates dynamic report generation, allowing for seamless integration of R code and outputs into documents.\nKendall: Provides statistical tools for Kendall’s rank correlation, useful for trend analysis in time series data.\nshiny: Builds interactive web applications directly from R, which is great for dashboards and data exploration.\nleaflet: Creates interactive maps, letting users visualize spatial data in a dynamic and user-friendly way.\npurrr: Part of tidyverse, it simplifies functional programming tasks, making it easier to work with lists and nested data.\nbroom: Helps in tidying up model outputs, converting complex statistical analysis into clean, interpretable data frames.\ngridExtra: Combines multiple plots into a single page, perfect for arranging complex visual layouts.\nrlang: Provides tools for metaprogramming in R, allowing us to write more flexible and efficient code.\n\n\npacman::p_load(sf, st, tidyverse, lubridate, sfdep, tmap, ggplot2, knitr, Kendall, shiny, leaflet, dplyr,purrr, broom, gridExtra,rlang, gganimate, grid, patchwork)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#reproducibility",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#reproducibility",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.2 Reproducibility",
    "text": "2.2 Reproducibility\nFor this analysis to be reproducible, we will set a seed to ensure that any random processes yield the same result each time the analysis is run:\n\nset.seed(1227)\n\nIn summary, the environment setup will be a combination of spatial analysis tools and general-purpose data manipulation libraries to ensure we can efficiently process and analyze spatial data."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#understanding-the-dataset",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#understanding-the-dataset",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "3.1 Understanding the Dataset",
    "text": "3.1 Understanding the Dataset\n\n3.1.1 Drug Abuse Data (Kaggle Dataset):\n\nThis dataset contains provincial-level information on drug abuse rates across multiple years.\n\n\nthai_drug_data &lt;- read_csv(\"data/raw/aspatial/thai_drug_offenses_2017_2022.csv\") \n\nRows: 7392 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): types_of_drug_offenses, province_th, province_en\ndbl (2): fiscal_year, no_cases\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nDrug Abuse Data Columns and Values\n\n\nFiscal Year The year in which the drug-related offenses were recorded, corresponding to the fiscal period of the data collection (e.g., 2017, 2018, 2019, 2020, 2021, 2022).\nType Of Drug Offenses The classification or type of drug offense committed (e.g., possession, trafficking, manufacturing), detailing the specific nature of the drug-related crime.\n\nType Includes\n\ndrug_use_cases\nsuspects_in_drug_use_cases\npossession_cases\nsuspects_in_possession_cases\npossession_with_intent_to_distribute_cases\nsuspects_in_possession_with_intent_to_distribute_cases\ntrafficking_cases\nsuspects_in_trafficking_cases\nproduction_cases\nsuspects_in_production_cases\nimport_cases\nsuspects_in_import_cases\nexport_cases\nsuspects_in_export_cases\nconspiracy_cases\nsuspects_in_conspiracy_cases\n\n\nNo Of Case The total number of drug-related cases reported for a given province and fiscal year, representing the count of offenses recorded.\nProvince_th The name of the province in Thai, used to identify the location of the reported drug offenses.\nProvince_en The name of the province in English, providing a translated version of the province for non-Thai speakers or international reference.\n\n\n\n\n3.1.2 Thailand Province Spatial Data (HDX Link):\nThe shapefile dataset contains the geographical boundaries of Thailand’s provinces, including Bangkok. Each polygon represents a province, allowing us to visualize the spatial distribution of drug abuse and analyze spatial patterns effectively.\n\nthailand_province &lt;- st_read(dsn = \"data/raw/geospatial\", layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Take_Home_Exercises\\Take_Home_Exercise_2\\data\\raw\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\n\n\nHDX Thai Shape file data\n\nThese are the columns within the Shape File:\n\nShape_Leng: The length of the boundary (perimeter) of the province’s polygon in the shapefile, typically measured in meters or kilometers.\nShape_Area: The area of the province’s polygon in the shapefile, usually measured in square meters or square kilometers.\nADMIN1_EN: The name of the province in English. This is a key identifier used to reference each province in the dataset.\nADM1_TH: The name of the province in Thai. This is the local language representation of the province name.\nADM1_PCODE The administrative code (or postal code) for the province. This is a standardized reference code for the administrative region.\nADM1_REF: A reference code or ID specific to the administrative level (province), typically used internally for referencing within GIS systems.\nADM1ALT1EN: An alternative English name for the province, if available. This might represent an old or variant name for the province in English.\nADM1ALT2EN: A second alternative English name for the province, if applicable. This could reflect historical or other variant names.\nADM1ALT1TH: An alternative Thai name for the province. This could reflect a regional or historical name in the local language.\nADM1ALT2TH A second alternative Thai name for the province, used if there are additional variants in the local language.\nADM0_EN: The name of the country (Thailand) in English. This is a reference to the country level of administration.\nADM0_TH The name of the country (Thailand) in Thai. This is the local language representation of the country name.\nADM0_PCODE The administrative code for the country (Thailand). This is a standardized reference code at the national level.\ndate The date when the data was collected or last updated. This indicates when the shapefile’s data was created or validated.\nvalidOn The date when the data became valid or effective. It’s typically used to track the validity of administrative boundaries.\nvalidTo The date when the data is no longer valid. This is useful for tracking changes in administrative boundaries over time (e.g., if a province’s borders were changed or merged with another).\ngeometry The spatial geometry of the province, represented as polygons in the shapefile. This field stores the geographical coordinates that define the boundaries of each province."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#initial-exploration",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#initial-exploration",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "3.2 Initial Exploration",
    "text": "3.2 Initial Exploration\nBefore we begin the spatial analysis, it is essential to explore and prepare the datasets to ensure they are ready for analysis. This includes checking for missing values, merging datasets, and creating visualizations to understand the general patterns of drug abuse across provinces.\n\nPreviewing the Spatial Data: We start by loading the shapefile to confirm that all provinces are represented and the boundaries are correct. This spatial dataset will form the backbone of the analysis, providing the geographical context for our study.\nCleaning and Aggregating: Any missing or erroneous data is cleaned, and the data is aggregated at the province level if needed. This ensures that the dataset is consistent and ready for analysis.\nSummary Statistics: We generate summary statistics for key variables, such as the average drug abuse rate across provinces, the distribution of education levels, and unemployment rates. This gives us a preliminary understanding of the data distribution before we move into more detailed spatial analysis."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#overview-of-drug-abuse-at-the-provincial-level",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#overview-of-drug-abuse-at-the-provincial-level",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "5.1 Overview of Drug Abuse at the Provincial Level",
    "text": "5.1 Overview of Drug Abuse at the Provincial Level\n\n5.1.1 Boxplot to view the Total Drug Cases across years across province in Thailand\nIn this first step, we will create descriptive statistics and summaries to get a sense of the total number of drug-related cases and the density of cases (cases per square kilometer) at the provincial level.\n\n# Create boxplot for Total Cases with data labels\n# Create boxplot for Total Cases with data labels for quartiles and outliers\nboxplot_total_cases &lt;- ggplot(thailand_province_df, aes(x = \"\", y = TotalCases)) +\n  geom_boxplot(fill = \"lightblue\", color = \"darkblue\", outlier.color = \"red\") +\n  stat_summary(fun.min = min, geom = \"text\", aes(label = paste(\"Min:\", round(..y.., 2))), vjust = 1.5, color = \"black\") +  # Label the minimum\n  stat_summary(fun.max = max, geom = \"text\", aes(label = paste(\"Max:\", round(..y.., 2))), vjust = -1.5, color = \"black\") +  # Label the maximum\n  stat_summary(fun = function(y) quantile(y, 0.25), geom = \"text\", aes(label = paste(\"1st Q:\", round(..y.., 2))), vjust = -0.5, hjust = 1.2, color = \"black\") +  # Label the 1st quartile\n  stat_summary(fun = function(y) quantile(y, 0.75), geom = \"text\", aes(label = paste(\"3rd Q:\", round(..y.., 2))), vjust = 1.5, hjust = -1.2, color = \"black\") +  # Label the 3rd quartile\n  labs(title = \"Boxplot of Total Drug Cases by Province\", y = \"Total Cases\", x = \"\") +\n  theme_minimal() +\n  coord_flip()  # Flip the boxplot to horizontal\n\n\n# Create boxplot for Total Density with data labels for quartiles and outliers\nboxplot_total_density &lt;- ggplot(thailand_province_df, aes(x = \"\", y = TotalDensity)) +\n  geom_boxplot(fill = \"lightgreen\", color = \"darkgreen\", outlier.color = \"red\") +\n  stat_summary(fun.min = min, geom = \"text\", aes(label = paste(\"Min:\", round(..y.., 2))), vjust = 1.5, color = \"black\") +  # Label the minimum\n  stat_summary(fun.max = max, geom = \"text\", aes(label = paste(\"Max:\", round(..y.., 2))), vjust = -1.5, color = \"black\") +  # Label the maximum\n  stat_summary(fun = function(y) quantile(y, 0.25), geom = \"text\", aes(label = paste(\"1st Q:\", round(..y.., 2))), vjust = -0.5, hjust = 1.2, color = \"black\") +  # Label the 1st quartile\n  stat_summary(fun = function(y) quantile(y, 0.75), geom = \"text\", aes(label = paste(\"3rd Q:\", round(..y.., 2))), vjust = 1.5, hjust = -1.2, color = \"black\") +  # Label the 3rd quartile\n  labs(title = \"Boxplot of Drug Case Density by Province\", y = \"Total Density (Cases per km²)\", x = \"\") +\n  theme_minimal() +\n  coord_flip()  # Flip the boxplot to horizontal\n\n# Arrange the boxplots horizontally (side by side)\ngrid.arrange(boxplot_total_cases, boxplot_total_density, nrow = 2)\n\n\n\n\n\n\n\n\nThe boxplots show significant disparities in drug cases across Thailand’s provinces.\n\nTotal cases: Most provinces have fewer than 13,651 cases, but a few outliers have much higher numbers, indicating concentrated drug problems.\nCase density: When adjusted for area, some provinces show high drug case densities, with outliers reaching over 40 cases per km², highlighting localized severity.\n\nThese findings suggest that while most provinces have moderate cases, specific regions face much higher drug activity, warranting focused interventions.\n\n\n5.1.2 Barchart to view the Total Drug Cases In Thailand by province\n\n# Create the first bar chart for Total Cases\ntotal_cases_plot &lt;- ggplot(thailand_province_df, aes(x = reorder(Province, -TotalCases), y = TotalCases)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_hline(aes(yintercept = mean(TotalCases)), color = \"red\", linetype = \"dashed\", size = 1) +\n  geom_hline(aes(yintercept = quantile(TotalCases, 0.25)), color = \"green\", linetype = \"dotted\", size = 1) +\n  geom_hline(aes(yintercept = quantile(TotalCases, 0.75)), color = \"green\", linetype = \"dotted\", size = 1) +\n  coord_flip() +\n  labs(title = \"Total Cases by Province with Quartiles\", x = \"Province\", y = \"Total Cases\") +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 7))  # Adjust the y-axis text size to fit\n\n# Create the second bar chart for Total Density\ntotal_density_plot &lt;- ggplot(thailand_province_df, aes(x = reorder(Province, -TotalDensity), y = TotalDensity)) +\n  geom_bar(stat = \"identity\", fill = \"darkorange\") +\n  geom_hline(aes(yintercept = mean(TotalDensity)), color = \"red\", linetype = \"dashed\", size = 1) +\n  geom_hline(aes(yintercept = quantile(TotalDensity, 0.25)), color = \"green\", linetype = \"dotted\", size = 1) +\n  geom_hline(aes(yintercept = quantile(TotalDensity, 0.75)), color = \"green\", linetype = \"dotted\", size = 1) +\n  coord_flip() +\n  labs(title = \"Total Density by Province with Quartiles\", x = \"Province\", y = \"Total Density (Cases per km²)\") +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 7))  # Adjust the y-axis text size to fit\n\n# Arrange the two plots side by side\ngrid.arrange(total_cases_plot, total_density_plot, ncol = 2)\n\n\n\n\n\n\n\n\nThe charts provide a visual comparison of total drug cases and drug case density across Thailand’s provinces:\n\nTotal Drug Cases (left chart):\n\nBangkok and Chon Buri have the highest number of drug cases, with Bangkok surpassing 60,000.\nMost provinces fall well below 20,000 cases, indicating that the drug issue is concentrated in a few key regions.\nThe provinces with fewer cases still reflect a significant variation, with many clustered around the median.\n\nDrug Case Density (Cases per km²) (right chart):\n\nBangkok shows the highest case density by a wide margin, highlighting its severe drug problem relative to its geographical size.\nOther provinces like Phuket, Samut Prakan, and Nonthaburi also show elevated case densities, though far less than Bangkok.\nMost provinces have densities below 10 cases per km², suggesting that while drug cases exist, their impact per area is much smaller compared to these key regions.\n\n\nThese insights indicate a heavy concentration of drug-related issues in Bangkok, both in total numbers and density, requiring focused attention on these urban hotspots."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#visualizing-trends-in-drug-abuse",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#visualizing-trends-in-drug-abuse",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "5.2 Visualizing Trends in Drug Abuse",
    "text": "5.2 Visualizing Trends in Drug Abuse\n5.2.1 Total Drug Abuse across Years By Province\n\n# Define the years\nyears &lt;- 2017:2022\nyear_columns &lt;- paste0(\"Drugs_Cases_\", years)\n\n# Create a list to store individual plots for each year\ncase_plots &lt;- list()\n\n# Loop through each year and create a bar plot for total cases (province on y-axis)\nfor (i in 1:length(years)) {\n  # Dynamically reference the column name using !!sym()\n  plot &lt;- ggplot(thailand_province_df, aes(y = reorder(Province, -!!sym(year_columns[i])), x = !!sym(year_columns[i]))) +\n    geom_bar(stat = \"identity\", fill = \"steelblue\") +\n    labs(title = paste(\"Total Drug Cases -\", years[i]), y = \"Province\", x = \"Total Cases\") +\n    theme_minimal() +\n    theme(axis.text.y = element_text(size = 7))\n  \n  case_plots[[i]] &lt;- plot\n}\n\n# Arrange the plots in a 3x2 grid\ngrid.arrange(grobs = case_plots, ncol = 3, nrow = 2)\n\n\n\n\n\n\n\n\nThese charts represent the total drug cases across Thailand’s provinces from 2017 to 2022. Here’s a brief analysis:\n\nConsistent trends: Bangkok consistently shows the highest number of drug cases across all years, indicating a persistent and significant drug problem in the capital. Chon Buri, Ubon Ratchathani, and Nakhon Si Thammarat also consistently rank high, suggesting these areas are heavily impacted.\nYearly fluctuations: While the rankings remain relatively stable, the total number of cases varies each year, with notable peaks in provinces like Bangkok and Chon Buri during certain years.\nProvincial concentration: A small number of provinces consistently account for the majority of drug cases, while most provinces report significantly fewer cases, reinforcing the idea that drug problems are concentrated in specific regions.\n\nThis trend indicates a need for focused intervention in the high-case provinces while monitoring fluctuations over time.\n\n5.1.2 Visualizing it across years on a map level\n\n# Define the years and corresponding column names\nyears &lt;- 2017:2022\nyear_columns &lt;- paste0(\"Drugs_Cases_\", years)\n\n# Create a list to store individual maps\nmap_list &lt;- list()\n\n# Loop through each year to create individual maps using tmap\nfor (i in 1:length(years)) {\n  map &lt;- tm_shape(thailand_province_final) +\n    tm_polygons(col = year_columns[i], \n                palette = \"Blues\",  # Use a blue color scale\n                style = \"quantile\", \n                title = paste(\"Drug Cases in\", years[i])) +\n    tm_borders() +\n    tm_layout(main.title = paste(\"Drug Cases in\", years[i]),  # Title outside and above each map\n              main.title.position = c(\"center\", \"top\"),  # Ensures the title is centered at the top\n              title.size = 1.5,  # Adjust title size if necessary\n              outer.margins = 0.05,  # Minimize margins\n              legend.position = c(\"right\", \"bottom\"))\n  \n  # Store each map in the list as a tmap object\n  map_list[[i]] &lt;- map\n}\n\n# Combine the maps into a 3x2 grid\nfinal_map &lt;- tmap_arrange(\n  map_list[[1]], map_list[[2]], map_list[[3]], \n  map_list[[4]], map_list[[5]], map_list[[6]], \n  ncol = 3, nrow = 2\n)\n\n# Display the map grid\nfinal_map\n\n\n\n\n\n\n\n\n\n\n5.1.3 Seeing it on an animation\n\nyears &lt;- 2017:2022\nyear_columns &lt;- paste0(\"Drugs_Cases_\", years)\n\n# Create a list to store individual maps for each year\nmap_list &lt;- list()\n# Loop through each year and create a map for total cases by year\nfor (i in 1:length(years)) {\n  map &lt;- tm_shape(thailand_province_final) +\n    tm_polygons(col = year_columns[i], \n                palette = \"Blues\",  # Use a blue color scale\n                style = \"quantile\", \n                title = paste(\"Drug Cases in\", years[i])) +\n    tm_borders() +\n    tm_layout(main.title = paste(\"Drug Cases in\", years[i]),  # Title outside and above each map\n              main.title.position = c(\"center\", \"top\"),  # Ensures the title is centered at the top\n              title.size = 1.5,  # Adjust title size if necessary\n              outer.margins = 0.05,  # Minimize margins\n              legend.position = c(\"right\", \"bottom\"))\n  \n  # Store each map in the list\n  map_list[[i]] &lt;- map\n}\n\n# Render the animated map by passing the list of maps\ntmap_animation(map_list, filename = \"thailand_drug_cases.gif\", delay = 100, width = 500, height = 500)\n\n\n5.2.1 Total Drug Abuse Density across Years By Province\n\n# Define the years\nyears &lt;- 2017:2022\ndensity_columns &lt;- paste0(\"Drugs_Cases_Per_Km2_\", years)\n\n# Create a list to store individual plots for each year (Density)\ndensity_plots &lt;- list()\n\n# Loop through each year and create a bar plot for density (province on y-axis)\nfor (i in 1:length(years)) {\n  plot &lt;- ggplot(thailand_province_df, aes(y = reorder(Province, -!!sym(density_columns[i])), x = !!sym(density_columns[i]))) +\n    geom_bar(stat = \"identity\", fill = \"darkorange\") +\n    labs(title = paste(\"Drug Case Density -\", years[i]), y = \"Province\", x = \"Density (Cases per km²)\") +\n    theme_minimal() +\n    theme(axis.text.y = element_text(size = 7))\n  \n  density_plots[[i]] &lt;- plot\n}\n\n# Arrange the plots in a 3x2 grid\ngrid.arrange(grobs = density_plots, ncol = 3, nrow = 2)\n\n\n\n\n\n\n\n\nThese charts visualize the drug case density (cases per km²) across Thailand’s provinces from 2017 to 2022. Here’s a brief summary:\n\nBangkok consistently has the highest density, with drug case density far exceeding other provinces each year, indicating that despite its smaller area, the capital remains a hotbed of drug-related issues.\nSamut Prakan, Nonthaburi, and Phuket frequently follow, with relatively high densities compared to other provinces, although still much lower than Bangkok.\nMost provinces have very low case density values, clustering near zero, which highlights that drug cases are more spread out and less concentrated geographically in those regions.\n\nThis pattern of concentration in a few urban provinces suggests that densely populated areas are facing more significant drug issues relative to their size, demanding focused urban interventions.\n\n\n5.2.2 Visualizing it across years on a map level\n\n# Define the years and corresponding column names\nyears &lt;- 2017:2022\nyear_columns &lt;- paste0(\"Drugs_Cases_Per_Km2_\", years)\n\n# Create a list to store individual maps\nmap_list &lt;- list()\n\n# Loop through each year to create individual maps using tmap\nfor (i in 1:length(years)) {\n  map &lt;- tm_shape(thailand_province_final) +\n    tm_polygons(col = year_columns[i], \n                palette = \"Oranges\",\n                style = \"quantile\", \n                title = paste(\"Drug Cases Density Km^2 in\", years[i])) +\n    tm_borders() +\n    tm_layout(main.title = paste(\"Drug Cases Density Km^2 in\", years[i]),  # Title outside and above each map\n              main.title.position = c(\"center\", \"top\"),  # Ensures the title is centered at the top\n              title.size = 1.5,  # Adjust title size if necessary\n              outer.margins = 0.05,  # Minimize margins\n              legend.position = c(\"right\", \"bottom\"))\n  \n  # Store each map in the list as a tmap object\n  map_list[[i]] &lt;- map\n}\n\n# Combine the maps into a 3x2 grid\nfinal_map &lt;- tmap_arrange(\n  map_list[[1]], map_list[[2]], map_list[[3]], \n  map_list[[4]], map_list[[5]], map_list[[6]], \n  ncol = 3, nrow = 2\n)\n\n# Display the map grid\nfinal_map\n\n\n\n\n\n\n\n\n\n\n5.2.3 Animation Across Years\n\n# Reshape data to long format for plotting rankings over time (Total Cases)\nrank_data_cases &lt;- thailand_province_df %&gt;%\n  select(Province, starts_with(\"Rank_No_Drug_Cases_\")) %&gt;%\n  pivot_longer(cols = matches(\"^Rank_No_Drug_Cases_\\\\d{4}$\"),  # Ensure only total cases rank columns are selected\n               names_to = \"Year\", \n               values_to = \"Rank\") %&gt;%\n  mutate(Year = gsub(\"Rank_No_Drug_Cases_\", \"\", Year))  # Clean Year values to keep only the year number\n\n# Function to add labels only at the start and end of the lines\nggplot(rank_data_cases, aes(x = Year, y = Rank, group = Province, color = Province)) +\n  geom_line(size = 1.2) +                                # Line to show rank movement\n  geom_point(size = 3) +                                 # Points for each rank\n  geom_text(data = rank_data_cases %&gt;% filter(Year == \"2017\"),  # Labels for the start (2017)\n            aes(label = Province), hjust = 1.1, size = 3) +\n  geom_text(data = rank_data_cases %&gt;% filter(Year == \"2022\"),  # Labels for the end (2022)\n            aes(label = Province), hjust = -0.1, size = 3) +\n  scale_y_reverse() +  # Reverse the y-axis to show better ranks at the top\n  labs(title = \"Ranking of Provinces by Total Drug Cases (2017-2022)\", \n       x = \"Year\", y = \"Rank (Lower is Better)\", color = \"Province\") +  \n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 10), legend.position = \"none\")  # Remove legend for clarity\n\n\n\n\n\n\n\n\nThis chart shows the ranking of Thailand’s provinces by total drug cases from 2017 to 2022. Key insights:\n\nBangkok consistently ranks at the top, indicating a persistent drug problem.\nUbon Ratchathani and Chon Buri also maintain high ranks throughout the years, showing consistent drug-related challenges.\nOther provinces like Chiang Mai, Rayong, and Nakhon Si Thammarat frequently move up and down in the rankings, indicating fluctuating drug case trends.\nThere is a lot of movement in the middle and lower rankings, suggesting changing dynamics in drug cases across the provinces over time.\n\nOverall, while certain provinces consistently face high drug case numbers, others experience more variability, reflecting shifting trends in drug enforcement or drug activity.\n\n# Reshape data to long format for plotting rankings over time (Density)\nrank_data_density &lt;- thailand_province_df %&gt;%\n  select(Province, starts_with(\"Rank_No_Drug_Cases_Per_Km2_\")) %&gt;%\n  pivot_longer(cols = matches(\"^Rank_No_Drug_Cases_Per_Km2_\\\\d{4}$\"),  # Ensure only density rank columns are selected\n               names_to = \"Year\", \n               values_to = \"Rank\") %&gt;%\n  mutate(Year = gsub(\"Rank_No_Drug_Cases_Per_Km2_\", \"\", Year))  # Clean Year values to keep only the year number\n\n# Function to add labels only at the start and end of the lines (for density)\nggplot(rank_data_density, aes(x = Year, y = Rank, group = Province, color = Province)) +\n  geom_line(size = 1.2) +                                # Line to show rank movement\n  geom_point(size = 3) +                                 # Points for each rank\n  geom_text(data = rank_data_density %&gt;% filter(Year == \"2017\"),  # Labels for the start (2017)\n            aes(label = Province), hjust = 1.1, size = 3) +\n  geom_text(data = rank_data_density %&gt;% filter(Year == \"2022\"),  # Labels for the end (2022)\n            aes(label = Province), hjust = -0.1, size = 3) +\n  scale_y_reverse() +  # Reverse the y-axis to show better ranks at the top\n  labs(title = \"Ranking of Provinces by Drug Case Density (2017-2022)\", \n       x = \"Year\", y = \"Rank (Lower is Better)\", color = \"Province\") +  \n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 10), legend.position = \"none\")  # Remove legend for clarity\n\n\n\n\n\n\n\n\nThis chart illustrates the ranking of Thailand’s provinces by drug case density (cases per km²) from 2017 to 2022. Key takeaways:\n\nBangkok consistently ranks at the top for drug case density, reflecting its severe drug problem relative to its small geographic size.\nRayong, Chon Buri, and Nonthaburi maintain high density rankings, indicating that these areas have concentrated drug cases despite their sizes.\nOther provinces, such as Samut Prakan, Samut Songkhram, and Nakhon Pathom, frequently appear near the top, signaling persistent issues with drug case density.\nThere is considerable variation in rankings for many mid-ranked provinces, suggesting fluctuating drug activity or law enforcement effectiveness over time.\n\nThis suggests that while certain urban areas maintain consistently high drug case density, other regions see more variability in the concentration of drug-related incidents."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#global-morans-i-for-aggregated-data-single-year",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#global-morans-i-for-aggregated-data-single-year",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "6.1 Global Moran’s I for Aggregated Data (Single Year)",
    "text": "6.1 Global Moran’s I for Aggregated Data (Single Year)\n\nMethod: Explanation of Global Moran’s I.\nResults: Moran’s I for a single year (e.g., the latest available year).\nInterpretation: How spatial dependency works for the overall drug abuse distribution."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#global-morans-i-over-multiple-years",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#global-morans-i-over-multiple-years",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "6.2 Global Moran’s I Over Multiple Years",
    "text": "6.2 Global Moran’s I Over Multiple Years\nThis analysis examines the Global Moran’s I and p-values from 2017 to 2022 to understand the spatial autocorrelation of drug cases in Thailand across several years. By analyzing these metrics over time, we gain insights into how drug-related incidents are distributed across provinces and whether their clustering is statistically significant.\nFirst get the results for each year and store it in a table\n\nyears &lt;- 2017:2022\nmoran_results &lt;- data.frame(Year = years, Moran_I = numeric(length(years)), P_Value = numeric(length(years)))\n\n# Loop through each year to calculate Moran's I and perform permutation tests\nfor (i in 1:length(years)) {\n  year_column &lt;- paste0(\"Drugs_Cases_Per_Km2_\", years[i])\n  \n  # Calculate Global Moran's I\n  moran_result &lt;- global_moran(thailand_province_final_sf[[year_column]], thailand_province_final_sf$nb, thailand_province_final_sf$wt)\n  \n  # Perform permutation test\n  perm_test_result &lt;- global_moran_perm(thailand_province_final_sf[[year_column]], thailand_province_final_sf$nb, thailand_province_final_sf$wt, nsim = 999)\n  \n  # Store results in the data frame\n  moran_results$Moran_I[i] &lt;- moran_result$I\n  moran_results$P_Value[i] &lt;- perm_test_result$p.value\n}\n\n# Print the results table\nprint(moran_results)\n\n  Year   Moran_I P_Value\n1 2017 0.1281893   0.000\n2 2018 0.3142248   0.000\n3 2019 0.3990897   0.002\n4 2020 0.2652932   0.002\n5 2021 0.2311792   0.018\n6 2022 0.4110562   0.000\n\n\nWe can plot the results with a line chart to compare across years\n\nmoran_plot_data &lt;- moran_results %&gt;%\n  pivot_longer(cols = c(Moran_I, P_Value), \n               names_to = \"Statistic\", \n               values_to = \"Value\")\n\n# Create the line chart\nggplot(moran_plot_data, aes(x = Year, y = Value, color = Statistic, group = Statistic)) +\n  geom_line(size = 1) +\n  geom_point(size = 3) +\n  scale_y_continuous(sec.axis = sec_axis(~ ., name = \"P-Value\")) +  # Secondary axis for p-values\n  labs(title = \"Global Moran's I and P-Values (2017-2022)\",\n       x = \"Year\",\n       y = \"Moran's I\",\n       color = \"Statistic\") +\n  theme_minimal() +\n  theme(legend.position = \"top\") +\n  scale_color_manual(values = c(\"Moran_I\" = \"blue\", \"P_Value\" = \"red\"))\n\n\n\n\n\n\n\n\nAnalysis Overview\n\nMoran’s I Values:\n\nThe line chart displays Moran’s I (in blue), which measures the degree of spatial autocorrelation. Higher values indicate a stronger clustering of drug cases.\nFrom the chart, we observe that Moran’s I values fluctuated, peaking in 2022, suggesting that spatial clustering of drug cases increased in recent years.\n\nP-Values:\n\nThe p-values (in red) indicate the statistical significance of the observed Moran’s I values. A low p-value (&lt; 0.05) suggests that the observed clustering is unlikely to have occurred by random chance.\nThe p-values remained low and stable throughout the period, indicating that the spatial clustering of drug cases is statistically significant across all years analyzed.\n\nTrends and Insights:\n\nThe upward trend in Moran’s I values over the years highlights increasing clustering of drug cases, particularly in 2022. This suggests that certain provinces may be experiencing more significant drug-related issues than others.\nThe stable low p-values reinforce the reliability of the findings, indicating consistent spatial autocorrelation throughout the study period."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#local-morans-i-for-aggregated-data-single-year",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#local-morans-i-for-aggregated-data-single-year",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "7.1 Local Moran’s I for Aggregated Data (Single Year)",
    "text": "7.1 Local Moran’s I for Aggregated Data (Single Year)\n\nMethod: Explanation of Local Moran’s I (LISA) to identify local clusters and outliers.\nResults: Visualizing clusters (high-high, low-low, etc.) for a single year on maps.\nInterpretation: Discussion of the clusters and outliers detected in that year."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#local-morans-i-over-multiple-years",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#local-morans-i-over-multiple-years",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "7.2 Local Moran’s I Over Multiple Years",
    "text": "7.2 Local Moran’s I Over Multiple Years\nWhile analyzing the total density of drug cases across provinces provides valuable insights, it’s also crucial to consider how these patterns change over time. By examining Local Moran’s I for each year from 2017 to 2022, we can uncover temporal trends in the clustering of drug cases, which may indicate emerging hotspots or shifts in drug-related activity across different periods.\nThe process for analyzing drug-related incidents over multiple years follows the same approach we used for the total density of cases. We calculate Local Moran’s I for each year individually, applying the same statistical consistency, and using the median to handle any skewness in the data. This ensures we maintain a robust analysis across different time frames.\n\n7.2.1 Prepping the data across.\nBy looping through each year from 2017 to 2022, we compute Local Moran’s I for each year’s drug cases per square kilometer. For each year, we extract the p_ii_sim values to determine the statistical significance of clusters and use the median to capture the central tendency of clustering patterns.\nThis step helps us track how spatial clustering of drug cases evolves over time. It enables us to answer key questions, such as whether the same regions consistently exhibit significant clustering (whether high-high or low-low), or if new hotspots have emerged in recent years. By focusing on p_ii_sim values and the median, we ensure consistency and reliability in the temporal analysis, which will allow us to plot time-based charts and compare year-on-year trends.\nUltimately, analyzing drug case clustering over time provides a more dynamic and comprehensive view of the drug situation in Thailand. It enables policymakers to not only respond to current hotspots but also to anticipate emerging trends and allocate resources accordingly to prevent escalation in regions showing increasing clustering patterns.\n\n# Define the years\nyears &lt;- 2017:2022\n# Loop through each year to calculate p_ii_sim and median\nfor (year in years) {\n  # Construct the year-specific variable names\n  year_column &lt;- paste0(\"Drugs_Cases_Per_Km2_\", year)\n  \n  # Calculate local Moran's I for the current year\n  LISA &lt;- thailand_province_final_sf %&gt;%\n    mutate(local_moran = local_moran(\n      !!sym(year_column),  # Use !!sym() to handle dynamic column names\n      nb,\n      wt,\n      nsim = 999\n    )) %&gt;%\n    unnest(local_moran)\n  \n  # Extract p_ii_sim and median from LISA\n  p_ii_sim_values &lt;- LISA$p_ii_sim  # Get all p_ii_sim values for the year\n  median_values &lt;- LISA$median       # Get all median values for the year \n  \n  # Add new columns to the existing LISA_TotalDensity data frame\n  LISA_TotalDensity &lt;- LISA_TotalDensity %&gt;%\n    mutate(!!paste0(\"p_ii_sim_\", year) := p_ii_sim_values,\n           !!paste0(\"median_\", year) := median_values)\n}\n# Print the resulting LISA_TotalDensity data frame\nprint(LISA_TotalDensity)\n\nSimple feature collection with 77 features and 57 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 325178.8 ymin: 620865.7 xmax: 1213656 ymax: 2263213\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 77 × 58\n   Province                TotalCases Area_km2 Drugs_Cases_2017 Drugs_Cases_2018\n * &lt;chr&gt;                        &lt;dbl&gt;    &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;\n 1 BANGKOK                      65522    1571.            11871            16480\n 2 SAMUT PRAKAN                 14721     949.              820             3015\n 3 NONTHABURI                    8881     636.              553             1661\n 4 PATHUM THANI                  9805    1517.              450             1823\n 5 PHRA NAKHON SI AYUTTHA…       8780    2553.              378             1123\n 6 ANG THONG                     3487     944.              208              660\n 7 LOP BURI                      9236    6493.              727             1850\n 8 SING BURI                     2596     818.              127              402\n 9 CHAI NAT                      3781    2485.              200              422\n10 SARABURI                      4229    3483.               69              628\n# ℹ 67 more rows\n# ℹ 53 more variables: Drugs_Cases_2019 &lt;dbl&gt;, Drugs_Cases_2020 &lt;dbl&gt;,\n#   Drugs_Cases_2021 &lt;dbl&gt;, Drugs_Cases_2022 &lt;dbl&gt;, TotalDensity &lt;dbl&gt;,\n#   Drugs_Cases_Per_Km2_2017 &lt;dbl&gt;, Drugs_Cases_Per_Km2_2018 &lt;dbl&gt;,\n#   Drugs_Cases_Per_Km2_2019 &lt;dbl&gt;, Drugs_Cases_Per_Km2_2020 &lt;dbl&gt;,\n#   Drugs_Cases_Per_Km2_2021 &lt;dbl&gt;, Drugs_Cases_Per_Km2_2022 &lt;dbl&gt;,\n#   Rank_TotalCases &lt;int&gt;, Rank_TotalDensity &lt;int&gt;, …\n\n\n\n\n7.2.2 Visualizing the chart Local Moran Across different years\n\n# Define the years\nyears &lt;- 2017:2022\n\n# Create an empty list to store individual maps\nmap_list &lt;- list()\n\n# Loop through each year to create maps for significant clusters\nfor (year in years) {\n  # Filter significant clusters for the current year\n  LISA_Sig &lt;- LISA_TotalDensity %&gt;%\n    filter(!!sym(paste0(\"p_ii_sim_\", year)) &lt; 0.05)  # Filter for significance\n\n  # Create the map for significant clusters for the current year\n  map &lt;- tm_shape(LISA_TotalDensity) +\n    tm_polygons() +\n    tm_borders(alpha = 0.5) +\n    tm_shape(LISA_Sig) +\n    tm_fill(paste0(\"median_\", year), alpha = 0.7) + \n    tm_borders(col = \"darkblue\", alpha = 0.4) +\n    tm_layout(main.title = paste(\"Significant Clusters of Local Moran's I -\", year),\n              main.title.size = 1.2,\n              legend.position = c(\"right\", \"bottom\")) +\n    tm_view(set.zoom.limits = c(6, 8))\n\n  # Store the current map in the list\n  map_list[[as.character(year)]] &lt;- map\n}\n\n# Combine all maps into one layout\ncombined_map &lt;- do.call(tmap_arrange, c(map_list, ncol = 3))\n\n# Print the combined map\nprint(combined_map)\n\n\n\n\n\n\n\n\nIn this analysis, we are generating a 3x2 grid of maps that will allow us to compare the significant clusters of Local Moran’s I across the years from 2017 to 2022. Each map will focus on displaying the provinces where drug-related incidents exhibit statistically significant spatial clustering patterns for that specific year, ensuring that only meaningful and significant data is highlighted.\nFor each year, we filter the data to include only clusters that have p-values less than 0.05, meaning they are statistically significant. This ensures that the clusters we observe represent genuine spatial patterns rather than random variations. By mapping these clusters across multiple years, we can visually compare the changes and consistency in spatial clustering over time.\n\nThe maps are arranged in a 3x2 layout to make it easy to view and compare the data for each year side by side. This layout helps us observe how the spatial distribution of drug cases evolves, whether the same regions continue to show significant clustering year after year, or if new areas emerge as hotspots.\nEach map will include visual indicators for the median values of Local Moran’s I, ensuring consistency in the method used to analyze and display the clustering data. This also helps us maintain uniformity in the interpretation across different years.\n\nThis comparative analysis is useful for policymakers, as it highlights temporal trends in drug-related incidents. By visualizing significant clusters over time, it becomes easier to pinpoint persistent problem areas or identify emerging regions of concern, helping to inform more targeted and timely interventions.\n\n7.2.2.1 Animation across years\n\n# Define the years\nyears &lt;- 2017:2022\n\n# Set tmap mode to plot (for static rendering)\ntmap_mode(\"plot\")\n\n# Create an empty list to store individual frames\nmap_list &lt;- list()\n\n# Loop through each year to create maps for significant clusters\nfor (year in years) {\n  # Filter significant clusters for the current year\n  LISA_Sig &lt;- LISA_TotalDensity %&gt;%\n    filter(!!sym(paste0(\"p_ii_sim_\", year)) &lt; 0.05)  # Filter for significance\n\n  # Create the map for the current year\n  map &lt;- tm_shape(LISA_TotalDensity) +\n    tm_polygons() +\n    tm_borders(alpha = 0.5) +\n    tm_shape(LISA_Sig) +\n    tm_fill(paste0(\"median_\", year), alpha = 0.7) + \n    tm_borders(col = \"darkblue\", alpha = 0.4) +\n    tm_layout(main.title = paste(\"Significant Clusters of Local Moran's I -\", year),\n              main.title.size = 0.8,\n              legend.position = c(\"right\", \"bottom\")) +\n    tm_view(set.zoom.limits = c(6, 8))\n\n  # Store the current map in the list\n  map_list[[as.character(year)]] &lt;- map\n}\n\n# Create an animated GIF by saving each map as a frame\ntmap_animation(\n  map_list, \n  filename = \"LISA_Animation.gif\", \n  delay = 100,  # Delay between frames in milliseconds\n  width = 800, \n  height = 600\n)\n\n\n\n\n\n7.2.3 Multi-Year Drug Case Density Analysis\n\n# Define the years\nyears &lt;- 2017:2022\n\n# Create an empty list to store individual bar charts\nplot_list &lt;- list()\n\n# Loop through each year to create a bar chart for significant clusters\nfor (year in years) {\n  # Filter data for the current year\n  LISA_Sig &lt;- LISA_TotalDensity %&gt;%\n    st_drop_geometry() %&gt;%  # Remove geometry column\n    filter(!!sym(paste0(\"p_ii_sim_\", year)) &lt; 0.05) %&gt;%  # Filter significant clusters\n    select(Province, \n           median = !!sym(paste0(\"median_\", year)), \n           Drugs_Cases_Per_Km2 = !!sym(paste0(\"Drugs_Cases_Per_Km2_\", year)))  # Select relevant columns\n\n  # Create a bar chart for the current year\n  plot &lt;- ggplot(LISA_Sig, aes(x = reorder(Province, -Drugs_Cases_Per_Km2), y = Drugs_Cases_Per_Km2, fill = as.factor(median))) +\n    geom_bar(stat = \"identity\") +\n    labs(\n      title = paste(\"Year:\", year),\n      x = \"Province\",\n      y = \"Drug Cases Per Km^2\",\n      fill = \"Cluster\"\n    ) +\n    theme_minimal() +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n  # Store the plot in the list\n  plot_list[[as.character(year)]] &lt;- plot\n}\n\n# Combine all the bar charts into a 3x2 layout\ncombined_plot &lt;- wrap_plots(plot_list, ncol = 3)\n\n# Print the combined plot\nprint(combined_plot)\n\n\n\n\n\n\n\n\nThis series of bar charts shows drug case density per Km² by province from 2017 to 2022, with clusters categorized as:\n\nHigh-High (blue/purple): High drug case density both within the province and surrounding areas.\nHigh-Low (green): High density in the province but low in neighboring regions.\nLow-Low (red): Low density both in the province and its surroundings.\n\nKey Trends:\n\nConsistent Urban Hotspots:\n\nBangkok, Samut Prakan, and Nonthaburi maintain High-High clusters throughout the years, indicating ongoing drug-related challenges in these urban areas.\n\nEmerging Shifts in 2022:\n\nA new purple color cluster emerges, suggesting shifts in clustering methods or data focus in 2022. Non-urban areas, such as Phuket, appear with high density in recent years, hinting at new or growing issues.\n\nStability of Low-Risk Areas:\n\nProvinces like Phichit, Tak, and Uttaradit remain consistently in the Low-Low category, reflecting well-maintained control over drug-related issues.\n\nFluctuating High-Low Clusters:\n\nKhon Kaen and Phrae oscillate between High-Low and Low-Low across the years, indicating instability in drug cases that require periodic monitoring.\n\n\nImplications:\n\nUrban Focus: Consistent high densities in metropolitan areas (Bangkok, Samut Prakan) suggest a need for sustained interventions.\nEmerging Concerns: Newly appearing provinces with significant clusters (e.g., Phuket in 2022) demand attention to prevent escalation.\nMonitoring Trends: Provinces switching between High-Low and Low-Low require close tracking for early interventions.\n\nThis multi-year analysis reveals the importance of tailored, region-specific strategies, with particular attention on urban centers and monitoring of new risk areas over time."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#ehsa-method-overview",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#ehsa-method-overview",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "8.1 EHSA Method Overview",
    "text": "8.1 EHSA Method Overview\n\nExplanation of Emerging Hot Spot Analysis (EHSA) and how it works to detect evolving hotspots over time."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#ehsa-results",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#ehsa-results",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "8.2 EHSA Results",
    "text": "8.2 EHSA Results\n\nVisualizing hotspots: Maps showing persistent, emerging, and dissipating hotspots.\nInterpretation: Discussion of the identified hot and cold spots over time, what trends are emerging, and what this could imply for interventions."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#temporal-trends-in-drug-abuse-across-key-provinces",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#temporal-trends-in-drug-abuse-across-key-provinces",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "9.1 Temporal Trends in Drug Abuse Across Key Provinces",
    "text": "9.1 Temporal Trends in Drug Abuse Across Key Provinces\n\nMethod: Tracking spatio-temporal trends by focusing on provinces identified as key clusters or hotspots.\nVisualization: Time-lapse maps or line charts showing the evolution of drug abuse rates in key provinces over multiple years.\nInterpretation: Analysis of how drug abuse patterns change across these key provinces, both spatially and temporally."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#comparative-analysis-of-spatio-temporal-patterns",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#comparative-analysis-of-spatio-temporal-patterns",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "9.2 Comparative Analysis of Spatio-Temporal Patterns",
    "text": "9.2 Comparative Analysis of Spatio-Temporal Patterns\n\nMethod: Comparing provinces with similar socio-economic factors (e.g., education, unemployment) to see if they exhibit similar spatio-temporal drug abuse patterns.\nVisualization: Comparative charts or maps of similar provinces to identify shared trends or diverging patterns."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#preparing-data-for-clustering",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#preparing-data-for-clustering",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "10.1 Preparing Data for Clustering",
    "text": "10.1 Preparing Data for Clustering"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#k-means-clustering",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#k-means-clustering",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "10.2 K-Means Clustering",
    "text": "10.2 K-Means Clustering"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#visualizing-clusters",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#visualizing-clusters",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "10.3 Visualizing Clusters",
    "text": "10.3 Visualizing Clusters"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#insights-from-clustering",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#insights-from-clustering",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "10.4 Insights from Clustering",
    "text": "10.4 Insights from Clustering"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to my IS415 Journey :) Jiale So here!",
    "section": "",
    "text": "Welcome to my website ! I’m a student currently enrolled in this course, where I’ll be diving deep into the world of geospatial analysis and geographic information systems (GIS). Through hands-on exercises, in-class activities, and take-home assignments, I’ll be exploring the practical applications of geospatial technologies.\n\n\nIS415-GAA is designed to introduce students to the key concepts and tools used in geospatial analysis. We will cover topics like spatial data collection, visualization, and analysis. By the end of the course, I aim to have a solid understanding of how to apply GIS principles to solve real-world problems.\n\n\n\nHands-On Exercises: This section includes practical exercises designed to apply what we learn in class. These exercises will help reinforce concepts and develop technical skills in GIS.\nIn-Class Exercises: These activities are done during class sessions to help us grasp key concepts quickly and collaboratively.\nTake-Home Exercises: Assignments to be completed independently, giving us the opportunity to dive deeper into specific topics at our own pace.\n\n\n\n\n\nI chose IS415-GAA because of its relevance in today’s data-driven world. Geospatial analysis is becoming increasingly important across many industries, and I’m excited to build the skills that can help me make data-driven decisions and contribute to meaningful projects.\n\n\n\nThroughout the course, I’ll be documenting my progress, reflecting on key learning points, and sharing interesting insights I discover along the way. Stay tuned as I embark on this exciting journey into the realm of geospatial analysis!\n\nTo navigate the site, use the links in the navigation bar at the top."
  },
  {
    "objectID": "index.html#about-this-module",
    "href": "index.html#about-this-module",
    "title": "Welcome to my IS415 Journey :) Jiale So here!",
    "section": "",
    "text": "IS415-GAA is designed to introduce students to the key concepts and tools used in geospatial analysis. We will cover topics like spatial data collection, visualization, and analysis. By the end of the course, I aim to have a solid understanding of how to apply GIS principles to solve real-world problems.\n\n\n\nHands-On Exercises: This section includes practical exercises designed to apply what we learn in class. These exercises will help reinforce concepts and develop technical skills in GIS.\nIn-Class Exercises: These activities are done during class sessions to help us grasp key concepts quickly and collaboratively.\nTake-Home Exercises: Assignments to be completed independently, giving us the opportunity to dive deeper into specific topics at our own pace."
  },
  {
    "objectID": "index.html#why-i-chose-this-module",
    "href": "index.html#why-i-chose-this-module",
    "title": "Welcome to my IS415 Journey :) Jiale So here!",
    "section": "",
    "text": "I chose IS415-GAA because of its relevance in today’s data-driven world. Geospatial analysis is becoming increasingly important across many industries, and I’m excited to build the skills that can help me make data-driven decisions and contribute to meaningful projects."
  },
  {
    "objectID": "index.html#what-to-expect",
    "href": "index.html#what-to-expect",
    "title": "Welcome to my IS415 Journey :) Jiale So here!",
    "section": "",
    "text": "Throughout the course, I’ll be documenting my progress, reflecting on key learning points, and sharing interesting insights I discover along the way. Stay tuned as I embark on this exciting journey into the realm of geospatial analysis!\n\nTo navigate the site, use the links in the navigation bar at the top."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#thai-drug-data-df",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#thai-drug-data-df",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "4.3 Thai Drug Data (DF)",
    "text": "4.3 Thai Drug Data (DF)\nStep 1: Filter Out Data that is Not Type “drug_use_cases”: - Keep only the relevant records for drug use cases\n\nthai_drug_data &lt;- thai_drug_data %&gt;%\n  filter(types_of_drug_offenses == \"drug_use_cases\")\n\nStep 3: Remove Useless Columns: Drop irrelevant columns for the analysis.\n\nthai_drug_data &lt;- thai_drug_data %&gt;%\n  select(province_en, no_cases, fiscal_year) %&gt;%\n  mutate(province_en = toupper(province_en))\n\nStep 4: Ensuring Data Check between against provinces from two data set,\n\n# Find provinces in thai_drug_data that are not in thailand_province\nprovinces_not_in_sf &lt;- thai_drug_data %&gt;%\n  anti_join(thailand_province, by = c(\"province_en\" = \"Province\")) %&gt;%\n  distinct(province_en)  # Only keep the distinct province names\n\n# Find provinces in thailand_province (sf) that are not in thai_drug_data\nprovinces_not_in_drug_data &lt;- thailand_province %&gt;%\n  anti_join(thai_drug_data, by = c(\"Province\" = \"province_en\")) %&gt;%\n  distinct(Province)  # Only keep the distinct province names\n\nProvinces in Thailand SF but not in Kaggle Drug Data:\n\nprint(provinces_not_in_drug_data$Province)\n\n[1] \"LOP BURI\"  \"BUENG KAN\"\n\n\nProvinces Not in Thailand SF but in Kaggle Drug Data:\n\nprint(provinces_not_in_sf$province_en)\n\n[1] \"LOBURI\"  \"BUOGKAN\"\n\n\nReplace “LOBURI” to “LOP BURI” and “BUOGKAN” as “BUENG KAN” to match the province data.\n\n# Replace specific values in the province_en column\nthai_drug_data &lt;- thai_drug_data %&gt;%\n  mutate(province_en = ifelse(province_en == \"LOBURI\", \"LOP BURI\", province_en),\n         province_en = ifelse(province_en == \"BUOGKAN\", \"BUENG KAN\", province_en))\n\nRename Columns for Consistency: - Rename province_name to Province, ensure it is in uppercase, and rename other columns.\n\nthai_drug_data &lt;- thai_drug_data %&gt;%\n  rename(\n    Province = province_en,\n    Year = fiscal_year,\n    Cases = no_cases\n  ) %&gt;%\n  mutate(Province = toupper(Province))\n\nView the Results\n\nhead(thai_drug_data)\n\n# A tibble: 6 × 3\n  Province                 Cases  Year\n  &lt;chr&gt;                    &lt;dbl&gt; &lt;dbl&gt;\n1 BANGKOK                  11871  2017\n2 CHAI NAT                   200  2017\n3 NONTHABURI                 553  2017\n4 PATHUM THANI               450  2017\n5 PHRA NAKHON SI AYUTTHAYA   378  2017\n6 LOP BURI                   727  2017"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#thai-province-data-sf",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#thai-province-data-sf",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "4.2 Thai Province Data (SF)",
    "text": "4.2 Thai Province Data (SF)\nStep 1: Change CRS to UTM Zone 47N (EPSG: 32647): - Transform the spatial data to the correct coordinate reference system.\n\nthailand_province &lt;- st_transform(thailand_province, crs = 32647)\nthailand_province\n\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 325178.8 ymin: 620860.6 xmax: 1213656 ymax: 2263241\nProjected CRS: WGS 84 / UTM zone 47N\nFirst 10 features:\n   Shape_Leng Shape_Area                  ADM1_EN       ADM1_TH ADM1_PCODE\n1    2.417227 0.13133873                  Bangkok  กรุงเทพมหานคร       TH10\n2    1.695100 0.07926199             Samut Prakan    สมุทรปราการ       TH11\n3    1.251111 0.05323766               Nonthaburi         นนทบุรี       TH12\n4    1.884945 0.12698345             Pathum Thani        ปทุมธานี       TH13\n5    3.041716 0.21393797 Phra Nakhon Si Ayutthaya พระนครศรีอยุธยา       TH14\n6    1.739908 0.07920961                Ang Thong        อ่างทอง       TH15\n7    5.693342 0.54578838                 Lop Buri          ลพบุรี       TH16\n8    1.778326 0.06872655                Sing Buri         สิงห์บุรี       TH17\n9    2.896316 0.20907828                 Chai Nat         ชัยนาท       TH18\n10   4.766446 0.29208711                 Saraburi         สระบุรี       TH19\n   ADM1_REF ADM1ALT1EN ADM1ALT2EN ADM1ALT1TH ADM1ALT2TH  ADM0_EN   ADM0_TH\n1      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n2      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n3      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n4      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n5      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n6      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n7      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n8      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n9      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n10     &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n   ADM0_PCODE       date    validOn    validTo                       geometry\n1          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((674339.8 15...\n2          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((687139.8 15...\n3          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((644817.9 15...\n4          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((704086 1575...\n5          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((662941.6 16...\n6          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((643472.8 16...\n7          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((751293.3 17...\n8          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((647136.1 16...\n9          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((620165.4 17...\n10         TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((757935.1 16...\n\n\nStep 2: Check if Geometries are Valid - Ensure the geometries are valid after the transformation.\n\nthailand_province &lt;- st_make_valid(thailand_province)\n\nStep 3: Remove Useless Columns: - Drop irrelevant columns for a cleaner dataset.\n\nthailand_province &lt;- thailand_province %&gt;% select(ADM1_EN, geometry)\n\nStep 4: Rename Columns: - Rename The columns and ensure naming Conventions\n\nthailand_province &lt;- thailand_province %&gt;%\n  rename(\n    Province = ADM1_EN,\n    geometry = geometry\n  ) %&gt;%\n  mutate(Province = toupper(Province))\n\nStep 5: Create a Reference DataFrame for Province Usage - Create a non-spatial DataFrame to use for referencing provinces.\n\nthailand_province_df &lt;- thailand_province %&gt;%\n  st_drop_geometry() %&gt;%\n  distinct(Province)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#combining-data",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#combining-data",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "4.3 Combining Data",
    "text": "4.3 Combining Data"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#creating-exploratory-data-analysis-aggregated-data",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#creating-exploratory-data-analysis-aggregated-data",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "4.4 Creating Exploratory Data Analysis Aggregated Data",
    "text": "4.4 Creating Exploratory Data Analysis Aggregated Data\nIn this section, we prepare the aggregated data for our Exploratory Data Analysis (EDA) by combining non-spatial drug case data with spatial province data in Thailand. The aim is to create a data frame that includes key variables such as total drug cases, yearly drug cases, province areas, and drug density (cases per square kilometer). Additionally, we will rank provinces based on these metrics for further analysis.\nStep 1: Calculate Province Area\nWe start by calculating the area of each province in square kilometers using the spatial geometry data. The areas are then stored as numeric values, and the geometry column is dropped from the data frame to focus on non-spatial attributes.\n\nthailand_province_df &lt;- thailand_province %&gt;%\n  mutate(Area_km2 = as.numeric(st_area(.) / 1e6)) %&gt;%\n  st_drop_geometry()\n\nThis gives us the area of each province, which is necessary for calculating drug case density (cases per square kilometer).\nStep 2: Aggregate Total Drug Cases per Province\nNext, we calculate the total number of drug cases for each province by grouping the data. The total cases are then merged with the province area data to prepare for further analysis.\n\nthailand_province_df &lt;- thai_drug_data %&gt;%\n  group_by(Province) %&gt;%\n  summarise(TotalCases = sum(Cases), .groups = 'drop') %&gt;%\n  left_join(thailand_province_df, by = \"Province\")  # Join with the spatial data (Area_km2)\n\nStep 3: Pivot Yearly Data into Wide Format\nWe pivot the yearly drug case data to create a column for each year, allowing us to store yearly drug case information in a wide format. This is useful for calculating yearly density and rankings.\n\ndrug_cases_by_year &lt;- thai_drug_data %&gt;%\n  group_by(Province, Year) %&gt;%\n  summarise(YearlyCases = sum(Cases), .groups = 'drop') %&gt;%\n  pivot_wider(names_from = Year, values_from = YearlyCases, names_prefix = \"Cases_\")\n\nStep 4: Merge Yearly Cases with Province Data\nWe merge the yearly drug case data with the existing province-level data to include both total cases and yearly cases in the same data frame.\n\nthailand_province_df &lt;- thailand_province_df %&gt;%\n  left_join(drug_cases_by_year, by = \"Province\")\n\nStep 5: Ensure Yearly Data Columns are Numeric\nTo facilitate further calculations, we ensure that all the yearly case columns are numeric, as they will be used in density calculations and rankings.\n\nthailand_province_df &lt;- thailand_province_df %&gt;%\n  mutate(across(starts_with(\"Cases_\"), as.numeric))\n\nStep 6: Calculate Total and Yearly Drug Density\nWe calculate the total drug case density (cases per square kilometer) by dividing the total number of drug cases by the area of each province. Similarly, we calculate yearly drug density for each year.\n\nthailand_province_df &lt;- thailand_province_df %&gt;%\n  mutate(TotalDensity = TotalCases / Area_km2)\n\n# Yearly drug density calculation (create new columns for each year)\nthailand_province_df &lt;- thailand_province_df %&gt;%\n  mutate(across(starts_with(\"Cases_\"), \n                ~ .x / Area_km2, \n                .names = \"Density_{.col}\"))\n\nStep 7: Rank Provinces by Total Cases, Density, and Yearly Cases\nWe generate rankings for provinces based on total drug cases, total drug density, and yearly drug cases and their respective densities. We use the dense_rank function, which assigns ranks while skipping gaps.\n\nyears &lt;- c(\"Cases_2017\", \"Cases_2018\", \"Cases_2019\", \"Cases_2020\", \"Cases_2021\", \"Cases_2022\")\n\n# Rank TotalCases and TotalDensity using dense_rank\nthailand_province_df &lt;- thailand_province_df %&gt;%\n  mutate(Rank_TotalCases = dense_rank(-TotalCases),  # Rank descending by TotalCases\n         Rank_TotalDensity = dense_rank(-TotalDensity))  # Rank descending by TotalDensity\n\n# Rank for each year's cases and density using dense_rank\nfor (year in years) {\n  thailand_province_df &lt;- thailand_province_df %&gt;%\n    mutate(!!paste0(\"Rank_\", year) := dense_rank(-get(year))) %&gt;%  # Rank yearly cases with dense_rank\n    mutate(!!paste0(\"Rank_Density_\", year) := dense_rank(-get(paste0(\"Density_\", year))))  # Rank yearly density with dense_rank\n}\n\nStep 8: Rename Columns for Consistency\nWe rename the columns for better readability and consistency, making sure all relevant metrics (cases, density, and ranks) are properly labeled.\n\nthailand_province_df &lt;- thailand_province_df %&gt;%\n  rename_with(~ gsub(\"^Cases_\", \"Drugs_Cases_\", .x), starts_with(\"Cases_\")) %&gt;%\n  rename_with(~ gsub(\"^Density_Cases_\", \"Drugs_Cases_Per_Km2_\", .x), starts_with(\"Density_Cases_\")) %&gt;%\n  rename_with(~ gsub(\"^Rank_Cases_\", \"Rank_No_Drug_Cases_\", .x), starts_with(\"Rank_Cases_\")) %&gt;%\n  rename_with(~ gsub(\"^Rank_Density_Cases_\", \"Rank_No_Drug_Cases_Per_Km2_\", .x), starts_with(\"Rank_Density_Cases_\"))\n\nStep 9: Final Data Overview\nWe now have a comprehensive data frame that includes:\n\nTotal and yearly drug cases\nProvince area\nDrug case density (total and yearly)\nRankings for cases and density\n\nThis data frame will serve as the foundation for further analysis, visualizations, and insights related to drug-related incidents across Thailand.\n\nhead(thailand_province_df)\n\n# A tibble: 6 × 30\n  Province      TotalCases Area_km2 Drugs_Cases_2017 Drugs_Cases_2018\n  &lt;chr&gt;              &lt;dbl&gt;    &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;\n1 AMNAT CHAROEN      11695    3291.             1734             2038\n2 ANG THONG           3487     944.              208              660\n3 BANGKOK            65522    1571.            11871            16480\n4 BUENG KAN           8921    4013.              900              824\n5 BURI RAM           16294   10096.             1265             2746\n6 CHACHOENGSAO       15516    5171.             2534             2199\n# ℹ 25 more variables: Drugs_Cases_2019 &lt;dbl&gt;, Drugs_Cases_2020 &lt;dbl&gt;,\n#   Drugs_Cases_2021 &lt;dbl&gt;, Drugs_Cases_2022 &lt;dbl&gt;, TotalDensity &lt;dbl&gt;,\n#   Drugs_Cases_Per_Km2_2017 &lt;dbl&gt;, Drugs_Cases_Per_Km2_2018 &lt;dbl&gt;,\n#   Drugs_Cases_Per_Km2_2019 &lt;dbl&gt;, Drugs_Cases_Per_Km2_2020 &lt;dbl&gt;,\n#   Drugs_Cases_Per_Km2_2021 &lt;dbl&gt;, Drugs_Cases_Per_Km2_2022 &lt;dbl&gt;,\n#   Rank_TotalCases &lt;int&gt;, Rank_TotalDensity &lt;int&gt;,\n#   Rank_No_Drug_Cases_2017 &lt;int&gt;, Rank_No_Drug_Cases_Per_Km2_2017 &lt;int&gt;, …\n\n\nStep 10: Merge Data Back with Geometry for Mapping\nNow that we have all the calculated data (cases, densities, and ranks), we merge this modified data frame back with the spatial geometry so that it can be used in mapping and further spatial analysis.\n\n# Merge the modified data (thailand_province_df) back with the geometry\nthailand_province_final &lt;- thailand_province %&gt;%\n  left_join(thailand_province_df, by = \"Province\")  # Merge on the 'Province' column\n\n\nthailand_province_final &lt;- thailand_province_final %&gt;%\n  st_simplify(dTolerance = 1000.0)  # Increase the tolerance value"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#interactive-choropleth-map",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#interactive-choropleth-map",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "5.3 Interactive Choropleth Map",
    "text": "5.3 Interactive Choropleth Map\n\n# Filter out unsupported columns (e.g., geometry columns)\npopup_vars &lt;- setdiff(colnames(thailand_province_final), attr(thailand_province_final, \"sf_column\"))\n\n# Remove underscores from the column names for the popups\npopup_vars_clean &lt;- gsub(\"_\", \" \", popup_vars)\n\n# Create a named list for popup.vars where the original columns are displayed with clean names\npopup_named_list &lt;- setNames(popup_vars, popup_vars_clean)\n\n# Create the Total Cases map layer\ntm_total_cases &lt;- tm_shape(thailand_province_final, name = \"Total Cases\") +  # Adding name for layer toggle\n  tm_polygons(\"TotalCases\", \n              style = \"cont\", \n              palette = \"YlOrRd\", \n              title = \"Total Cases\",\n              popup.vars = popup_named_list,  # Filtered columns as popup variables\n              id = \"Province\")\n\n# Create the Total Density map layer\ntm_total_density &lt;- tm_shape(thailand_province_final, name = \"Drug Case Density\") +  # Adding name for layer toggle\n  tm_polygons(\"TotalDensity\", \n              style = \"cont\", \n              palette = \"Blues\", \n              title = \"Drug Case Density\",\n              popup.vars = popup_named_list, \n              id = \"Province\")\n\n# Combine the two layers into one map with zoom limits\ntm_combined &lt;- tm_total_cases + tm_total_density +\n  tm_view(set.zoom.limits = c(6, 8)) + \n  tm_layout(title=\"Total Drug Cases and Density By Thailand Province\") \n\n# Show the combined map with two layers\ntm_combined"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#global-morans-i-for-aggregated-data-total",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#global-morans-i-for-aggregated-data-total",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "6.1 Global Moran’s I for Aggregated Data Total",
    "text": "6.1 Global Moran’s I for Aggregated Data Total\nIn this section, we calculate Global Moran’s I for the aggregated data on drug cases, which combines data from 2017 to 2022. By aggregating drug cases over these years, we aim to uncover whether provinces with high or low drug case numbers are spatially clustered over the entire study period. This analysis provides an overview of whether there is a persistent spatial pattern in the clustering of drug cases, allowing us to determine whether certain provinces consistently experience higher or lower concentrations of drug activity over time.\n\n6.1.1 Setting Queen Contiguity and Setting Neighbors\nTo compute Moran’s I, it is crucial to establish the spatial relationships between Thailand’s provinces. For this analysis, we use Queen’s contiguity, where two provinces are considered neighbors if they share either a boundary or a corner point. The next step involves calculating the neighbors for each province, which will define their spatial relationship with surrounding regions.\n\n# Ensure geometries are valid\ninvalid_geometries &lt;- !st_is_valid(thailand_province_final)\ncat(\"Invalid geometries: \", sum(invalid_geometries), \"\\n\")\n\nInvalid geometries:  0 \n\n# Fix invalid geometries (if any)\nthailand_province_final &lt;- st_make_valid(thailand_province_final)\n\n# Generate Queen's contiguity neighbors using sfdep\nnb_queen &lt;- st_contiguity(thailand_province_final, queen = TRUE)\n\n# Check if there are any provinces where the neighbor list contains only the value 0\nempty_neighbors &lt;- which(sapply(nb_queen, function(x) length(x) == 1 && x[[1]] == 0))\n\n# Print the indices of the provinces with no neighbors\ncat(\"Indices of provinces with no valid neighbors: \", empty_neighbors, \"\\n\")\n\nIndices of provinces with no valid neighbors:  67 \n\n# If there are any provinces with no valid neighbors, print their names using the correct index\nif (length(empty_neighbors) &gt; 0) {\n    cat(\"Provinces with no valid neighbors: \", thailand_province_final$Province[empty_neighbors], \"\\n\")\n} else {\n    cat(\"All provinces have valid neighbors.\\n\")\n}\n\nProvinces with no valid neighbors:  PHUKET \n\n\nSome provinces, such as Phuket (an island), do not have natural neighbors, so we manually assign neighboring provinces (e.g., Krabi and Phangnga) to ensure that each province is represented in the analysis. This step is essential to accurately compute spatial weights, which are required to calculate the Moran’s I statistic and identify potential clustering of drug cases across Thailand’s provinces.\n\n# Manually assign neighbors for Phuket (index 67), Krabi (index 65), and Phangnga (index 66)\n# Ensure the indices are integers\nnb_queen[[67]] &lt;- as.integer(c(65, 66))  # Convert to integers\n\n# Create weight matrix based on the neighbors\nwt_queen &lt;- st_weights(nb_queen, style = \"W\")\n\n# Add neighbors and weight matrix back to the thailand_province_final_sf object\nthailand_province_final_sf &lt;- thailand_province_final %&gt;%\n  mutate(nb = nb_queen, wt = wt_queen)\n\n# Check if there are any provinces where the neighbor list contains only the value 0\nempty_neighbors &lt;- which(sapply(nb_queen, function(x) length(x) == 1 && x[[1]] == 0))\n\n# Print the indices of the provinces with no neighbors\ncat(\"Indices of provinces with no valid neighbors: \", empty_neighbors, \"\\n\")\n\nIndices of provinces with no valid neighbors:   \n\n# If there are any provinces with no valid neighbors, print their names using the correct index\nif (length(empty_neighbors) &gt; 0) {\n  cat(\"Provinces with no valid neighbors: \", thailand_province_final$Province[empty_neighbors], \"\\n\")\n} else {\n  cat(\"All provinces have valid neighbors.\\n\")\n}\n\nAll provinces have valid neighbors.\n\n\n\n\n6.1.2 Getting Global’s Moran I\nIn this section, we are calculating the Global Moran’s I statistic to measure the degree of spatial autocorrelation in the aggregated drug case data across Thailand’s provinces. This statistic helps us understand whether provinces with similar numbers of drug cases are clustered together or dispersed across the region. To conduct this analysis, we rely on spatial weights based on Queen’s contiguity, which captures the spatial relationships between provinces.\nThe steps include:\n\nGlobal Moran’s I calculation: We calculate Global Moran’s I using the total number of drug cases across all provinces. The spatial relationships (neighbors) and spatial weights are used to determine the level of autocorrelation.\nPermutation test: To validate the significance of the Moran’s I statistic, we perform a permutation test with 1000 simulations. This tests whether the observed Moran’s I value is statistically significant or if the observed spatial clustering could have occurred by chance.\n\nThe code below performs the calculation and checks the structure of the results.\n\n\n\n\n\n\nNote\n\n\n\nWhy Use Density Instead of Total Cases?\nUsing density normalizes drug cases by population or area, allowing for fairer comparisons between regions. Total cases alone can mislead, as larger provinces naturally have more cases due to size. Density highlights areas with higher concentrations of drug cases, providing a clearer, more accurate analysis of hotspots, regardless of region size.\n\n\n\n# Global Moran's I for TotalCases\nglobal_moranI_total &lt;- global_moran(thailand_province_final_sf$TotalDensity, thailand_province_final_sf$nb, thailand_province_final_sf$wt)\n# Perform Permutation test for TotalCases\nglobal_moranI_total_perm_test &lt;- global_moran_perm(thailand_province_final_sf$TotalDensity, thailand_province_final_sf$nb, thailand_province_final_sf$wt, nsim = 999)\n\n# Check the structure of the result\nprint(global_moranI_total)\n\n$I\n[1] 0.3379632\n\n$K\n[1] 37.1161\n\nprint(global_moranI_total_perm_test)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.33796, observed rank = 1000, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\nThe global_moran() function calculates the Moran’s I statistic for the total drug cases based on the defined spatial relationships and weights.\nThe global_moran_perm() function performs a permutation test with 1000 random simulations to determine whether the observed Moran’s I value is significant.\nFinally, we print the results to review the Moran’s I value and assess its significance based on the permutation test output.\n\n\n\n6.1.3 Analysis and Interpretation\nThe histogram helps visualize the distribution of simulated Moran’s I values from the permutation test. By comparing the observed Moran’s I (red line) to this distribution, we can quickly assess how unusual or significant the observed spatial autocorrelation is.\n\nhist(global_moranI_total_perm_test$res, breaks = 20, main = \"Permutation Distribution of Moran's I\", \n     xlab = \"Simulated Moran's I Values\", col = \"lightblue\")\nabline(v = global_moranI_total_perm_test$statistic, col = \"red\", lwd = 2)\nlegend(\"topright\", legend = c(\"Observed Moran's I\"), col = c(\"red\"), lwd = 2)\n\n\n\n\n\n\n\n\nThe results of the Global Moran’s I statistic and the Monte Carlo permutation test provide insight into the spatial autocorrelation of drug cases across Thailand’s provinces. Let’s break down the results and further analyze the implications.\n\nInterpretation of the Moran’s I Value: The Moran’s I value is 0.315, which indicates moderate positive spatial autocorrelation. This means provinces with similar numbers of drug cases (whether high or low) tend to cluster together, showing a stronger spatial pattern than random distribution.\nSignificance of the Results (Permutation Test): The Monte Carlo simulation, with 1000 random permutations, gives a p-value of &lt; 2.2e-16, indicating the Moran’s I value is highly significant. The observed rank of 1,000 confirms that none of the random permutations produced a higher Moran’s I value. This strongly supports the presence of spatial clustering in drug cases.\nThe histogram shows that the observed Moran’s I value (in red) is far to the right of the distribution of simulated values, indicating strong spatial autocorrelation. The significant difference between the observed value and the simulated values confirms that the clustering of drug cases is not random, but statistically significant, with a p-value &lt; 2.2e-16.\nImplications and Next Steps: The significant and moderate Moran’s I value suggests that drug cases are not randomly distributed but are spatially clustered across provinces. This finding points to specific areas that may require targeted interventions. Further analysis using local spatial statistics could help identify precise clusters for more effective policy measures."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#conclusion",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#conclusion",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "6.3 Conclusion",
    "text": "6.3 Conclusion\nAnalyzing the Global Moran’s I and p-values over the years reveals clear trends in the spatial distribution of drug cases. The consistent significance of clustering indicates that certain provinces are experiencing concentrated drug-related incidents. This insight is valuable for policymakers and public health officials, as it highlights the need to focus interventions on these hotspot areas. The persistent significance underscores the importance of continuous monitoring and strategic allocation of resources to combat drug-related issues in these regions effectively."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#local-morans-i-for-aggregated-data-total",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#local-morans-i-for-aggregated-data-total",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "7.1 Local Moran’s I for Aggregated Data (Total)",
    "text": "7.1 Local Moran’s I for Aggregated Data (Total)\nTo further investigate the spatial distribution of drug cases in Thailand, we now shift our focus from global to local spatial autocorrelation. Local Moran’s I helps identify clusters of high or low drug-related incidents at a more granular level, revealing hotspots and cold spots that might be masked in the aggregated data.\nIn this step, we calculate Local Moran’s I for the total density of drug cases across provinces, enabling us to detect local clusters of drug activity. This local analysis allows policymakers to focus resources more efficiently on regions that require immediate attention.\n\n7.1.1 Preparing the Data\n\nLISA_TotalDensity &lt;- thailand_province_final_sf %&gt;%\n  mutate(local_moran = local_moran(\n    TotalDensity, \n    nb, \n    wt, \n    nsim = 999\n  )) %&gt;%\n  unnest(local_moran)\nLISA_TotalDensity\n\nSimple feature collection with 77 features and 44 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 325178.8 ymin: 620865.7 xmax: 1213656 ymax: 2263213\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 77 × 45\n   Province                TotalCases Area_km2 Drugs_Cases_2017 Drugs_Cases_2018\n   &lt;chr&gt;                        &lt;dbl&gt;    &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;\n 1 BANGKOK                      65522    1571.            11871            16480\n 2 SAMUT PRAKAN                 14721     949.              820             3015\n 3 NONTHABURI                    8881     636.              553             1661\n 4 PATHUM THANI                  9805    1517.              450             1823\n 5 PHRA NAKHON SI AYUTTHA…       8780    2553.              378             1123\n 6 ANG THONG                     3487     944.              208              660\n 7 LOP BURI                      9236    6493.              727             1850\n 8 SING BURI                     2596     818.              127              402\n 9 CHAI NAT                      3781    2485.              200              422\n10 SARABURI                      4229    3483.               69              628\n# ℹ 67 more rows\n# ℹ 40 more variables: Drugs_Cases_2019 &lt;dbl&gt;, Drugs_Cases_2020 &lt;dbl&gt;,\n#   Drugs_Cases_2021 &lt;dbl&gt;, Drugs_Cases_2022 &lt;dbl&gt;, TotalDensity &lt;dbl&gt;,\n#   Drugs_Cases_Per_Km2_2017 &lt;dbl&gt;, Drugs_Cases_Per_Km2_2018 &lt;dbl&gt;,\n#   Drugs_Cases_Per_Km2_2019 &lt;dbl&gt;, Drugs_Cases_Per_Km2_2020 &lt;dbl&gt;,\n#   Drugs_Cases_Per_Km2_2021 &lt;dbl&gt;, Drugs_Cases_Per_Km2_2022 &lt;dbl&gt;,\n#   Rank_TotalCases &lt;int&gt;, Rank_TotalDensity &lt;int&gt;, …\n\n\nIn our analysis, we rely on the P_ii_sim (simulated p-values) because they provide a robust measure of the statistical significance of local clusters. These simulated p-values help us determine whether observed clusters are significant or could have occurred by random chance. This is especially important when running multiple simulations (in this case, 1000) to ensure the reliability of our results.\n\n\n\n\n\n\nNote\n\n\n\nWhen to use median and mean?\nIn our analysis, we rely on the P_ii_sim (simulated p-values) because they provide a robust measure of the statistical significance of local clusters. These simulated p-values help us determine whether observed clusters are significant or could have occurred by random chance. This is especially important when running multiple simulations (in this case, 1000) to ensure the reliability of our results. Hence we check for the skewness and use median.\n\n\n\n# Assuming LISA_TotalDensity contains a column named 'skewness'\n# Create a histogram of the skewness values\nggplot(LISA_TotalDensity, aes(x = skewness)) +\n  geom_histogram(bins = 30, fill = \"blue\", alpha = 0.7) +\n  labs(title = \"Histogram of Skewness Values\", x = \"Skewness\", y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Calculate mean and median of the skewness values\nmean_skewness &lt;- mean(LISA_TotalDensity$skewness, na.rm = TRUE)\nmedian_skewness &lt;- median(LISA_TotalDensity$skewness, na.rm = TRUE)\n\n# Display the mean and median skewness\ncat(\"Mean Skewness: \", mean_skewness, \"\\n\")\n\nMean Skewness:  -1.24739 \n\ncat(\"Median Skewness: \", median_skewness, \"\\n\")\n\nMedian Skewness:  -2.188325 \n\n# Determine which measure to use for clustering\nif (abs(median_skewness) &gt; 0.1) {\n  cat(\"Use Median for clustering based on skewness.\\n\")\n} else {\n  cat(\"Use Mean for clustering based on skewness.\\n\")\n}\n\nUse Median for clustering based on skewness.\n\n\n\n\n7.1.2 Visualizing the clusters\nIn this part of the analysis, we are examining Local Moran’s I, which helps us identify where drug-related incidents in Thailand are spatially clustered at the local level. Unlike Global Moran’s I, which gives us an overall sense of spatial autocorrelation across the entire dataset, Local Moran’s I zooms in on individual provinces. It reveals whether specific provinces are surrounded by others with similar (high-high or low-low) or dissimilar (high-low or low-high) patterns of drug cases.\n\nHigh-High and Low-Low Clustering\n\nHigh-High Clusters: These are provinces where a high number of drug-related incidents are clustered with neighboring provinces that also have high numbers. This indicates hotspots of drug activity, which are critical for public health officials and policymakers to target interventions. These areas are experiencing a concentrated issue that may require urgent attention, such as increased law enforcement or public health campaigns.\nLow-Low Clusters: On the other hand, low-low clusters occur where provinces with low drug-related incidents are surrounded by others that also report low numbers. These areas are typically not a cause for immediate concern but might reflect regions that could benefit from maintaining current preventive measures.\nHigh-Low and Low-High: These are areas where the province’s drug case count contrasts with its neighbors (e.g., a high number of incidents surrounded by low-incident provinces). These outliers may indicate regions where drug problems are emerging or where prevention strategies are not uniform across regions.\n\n\n\nThe Importance of Statistical Significance (P_ii_sim)\nThe significance value, represented by P_ii_sim, plays a crucial role in determining whether these local clusters are statistically significant or just random noise. In our case, we are considering clusters as significant if their p-value is less than 0.05.\n\nSignificant Clusters: If a cluster is significant, it means that the observed spatial pattern (whether it’s high-high, low-low, etc.) is unlikely to have occurred by chance. These are the clusters that demand the most attention, as they reflect genuine patterns in the spatial distribution of drug cases.\nNon-Significant Clusters: These clusters, on the other hand, may not represent real patterns and could have occurred randomly. They are less important for immediate action and should be interpreted with caution.\n\nBy visualizing both the Local Moran’s I and the corresponding p-values, we can visually assess which provinces exhibit significant spatial patterns of clustering. The side-by-side maps allow us to see:\n\nWhere high-high and low-low clusters are happening (Local Moran’s I map).\nWhich of these clusters are statistically significant (P-value map).\n\nThis combination of local spatial autocorrelation and significance testing helps us prioritize where to focus resources and interventions. It enables policymakers to target areas with strong evidence of clustering and take proactive measures in provinces where drug-related issues are concentrated.\n\nLISA_TotalDensity &lt;- LISA_TotalDensity %&gt;%\n  mutate(significant = ifelse(p_ii_sim &lt; 0.05, \"Significant\", \"Not Significant\"))\n\n# Set tmap mode to plot\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n# Assuming LISA_TotalDensity is your spatial data frame containing the relevant columns\n\n# Create map for local Moran's I\nmap1 &lt;- tm_shape(LISA_TotalDensity) +  # Use the spatial data frame\n  tm_fill(\"median\", title = \"Local Moran's I\") +  # Change to the relevant column for local Moran's I\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6, 8)) +\n  tm_layout(main.title = \"Local Moran's I of TotalDensity\",\n            main.title.size = 0.8)\n\n# Create map for p-value of local Moran's I\nmap2 &lt;- tm_shape(LISA_TotalDensity) +\n  tm_fill(\"p_ii_sim\",  # Change to your p-value column\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"),\n          title = \"P-Value of Local Moran's I\") + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"P-Value of Local Moran's I\",\n            main.title.size = 0.8)\n\n# Arrange the maps side by side\ntmap_arrange(map1, map2, ncol = 2)\n\n\n\n\n\n\n\n\nThe side-by-side maps display the Local Moran’s I clustering (left) and the corresponding p-values for significance (right) of drug-related incidents across provinces in Thailand.\nOn the Local Moran’s I map, we can observe areas of high-high clustering, such as in the eastern regions, indicating provinces where drug cases are concentrated and surrounded by similarly affected provinces. Conversely, low-low clusters, seen in some northern and southern regions, suggest areas with low drug case densities surrounded by similarly low-density provinces. There are also some high-low and low-high outliers, which might represent emerging drug-related issues or unusual distribution patterns.\nHowever, the P-value map reveals that many of these clusters are marked as not significant (in darker orange). This suggests that although spatial patterns appear in the Local Moran’s I map, they may not be statistically significant. To focus the analysis on reliable clusters, it would be useful to filter out these non-significant areas and concentrate only on the significant clusters (those with p-values below 0.05), which will provide a clearer picture of where interventions are truly needed.\nBy filtering out the non-significant areas, we can better prioritize the regions where statistically significant spatial clustering of drug cases occurs, allowing for more targeted and data-driven policy measures.\n\n# Set tmap mode to view for interactive mapping\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n# Filter significant local Moran's I results\nLISA_TotalDensity_Sig &lt;- LISA_TotalDensity %&gt;%\n  filter(p_ii_sim &lt; 0.05)\n\n# Create the map\nmap &lt;- tm_shape(LISA_TotalDensity) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  tm_shape(LISA_TotalDensity_Sig) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_fill(\"median\") + \n  tm_borders(alpha = 0.4)\n\n# Print the map\nprint(map)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nThis map highlights the significant clusters of Local Moran’s I after filtering out the non-significant regions. The provinces that remain on this map are those where the spatial clustering of drug-related incidents is statistically significant, meaning that these areas demonstrate true spatial patterns that are not likely to have occurred by chance.\n\nChiang Mai and a few neighboring provinces in the north exhibit low-low clustering (green), suggesting these regions have lower densities of drug-related cases and are surrounded by similarly low-case provinces. This could indicate effective control measures or a less severe drug issue in this part of the country.\nBangkok and surrounding provinces (in red) show high-high clustering, indicating that these areas are experiencing significantly higher concentrations of drug-related cases, and they are surrounded by similarly affected provinces. These regions are likely hotspots and would be priority areas for intervention strategies, such as increased law enforcement or public health outreach.\nA few provinces in the northeastern and northern regions (yellow) display low-high clusters, where relatively low case densities are adjacent to provinces with higher case densities. These areas could represent transitional zones or emerging problem areas, which may require monitoring to prevent future escalation.\n\nThis focused map allows policymakers to concentrate on the most critical regions, ensuring that resources are directed to areas where drug-related clustering is a statistically significant concern."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#conclusion-1",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#conclusion-1",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "7.3 Conclusion",
    "text": "7.3 Conclusion\nThe 3x2 grid of maps showcases the significant clusters of Local Moran’s I across the years 2017 to 2022, highlighting where drug-related incidents have shown consistent spatial clustering over time. Here’s the key analysis based on the visualization:\nConsistent Clustering Patterns:\n\nBangkok and surrounding areas have consistently shown high-high clustering across all years from 2017 to 2022. This suggests that this region remains a persistent hotspot for drug-related incidents, indicating that the problem has not been mitigated over time. The significance of these clusters each year emphasizes the importance of sustained intervention in these regions.\nNorthern and central provinces show low-low clustering consistently throughout the years. These provinces have lower drug-related incidents compared to their neighbors, and the stability of this pattern over time suggests that these areas have not experienced a significant increase in drug activity.\n\nPotential Anomalies in 2021:\n\nIn 2021, we observe some slight changes in the clustering patterns, where fewer regions appear significant compared to other years. This could potentially be linked to the effects of COVID-19, where disruptions in law enforcement, reporting, or drug activities might have led to temporary fluctuations in spatial patterns. However, this change seems to be short-lived, as the patterns return to similar levels in 2022.\n\nConcerning Stability of Active Regions:\n\nThe fact that the same provinces (both high-high and low-low) remain significant across multiple years is concerning. This persistence suggests that certain regions have been continuously affected by either a concentration of drug-related problems or consistently low incident rates. For areas showing high-high clustering, this implies a failure to effectively address the issue over time.\n\nPolicy Implications:\nThe lack of significant change in clustering patterns year after year highlights the need for long-term strategies and possibly new approaches to mitigate drug-related incidents in regions like Bangkok and its surrounding areas. Meanwhile, for regions with low-low clustering, efforts should continue to maintain preventive measures, ensuring that these areas remain under control.\nThis analysis underscores the importance of regularly monitoring spatial clustering to track the effectiveness of policy interventions and to identify emerging trends that may require attention."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#ehsa-total-density",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#ehsa-total-density",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "8.1 EHSA Total Density",
    "text": "8.1 EHSA Total Density\n\n8.1.1 Creating the Weights\nIn the provided code snippet, we prepare the data by constructing a neighborhood structure for each province and calculating the weights necessary for the EHSA.\n\nthailand_idw &lt;- thailand_province_final_sf %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         geometry_centroid = st_centroid(geometry), # Convert polygons to centroids\n         wts = st_inverse_distance(nb, \n                                   geometry_centroid, # Use centroids for inverse distance\n                                   scale = 1,\n                                   alpha = 1))\n\nExplanation:\n\nNeighborhood Structure (nb): The include_self(st_contiguity(geometry)) creates a spatial contiguity matrix where each province is considered to be a neighbor of itself. This ensures that when calculating clustering metrics, the province is included in its own analysis.\nWeights (wts): The weights are calculated using the inverse distance method, which gives more weight to closer neighbors and less weight to farther ones. The parameters scale = 1 and alpha = 1 control the scaling factor and decay rate of the distance weighting. The use of these inverse-distance weights is important because it reflects how incidents in nearby areas have a greater impact on the clustering of a province.\n\nAfter the neighborhood structure and weights are established, we calculate the Local Gi statistic* to identify local hotspots using the following code:\n\nHCSA_Total &lt;- thailand_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    TotalDensity, nb, wts, nsim = 999)) %&gt;%\n  unnest(local_Gi)\nHCSA_Total\n\nSimple feature collection with 77 features and 43 fields\nActive geometry column: geometry\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 325178.8 ymin: 620865.7 xmax: 1213656 ymax: 2263213\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 77 × 45\n   Province                TotalCases Area_km2 Drugs_Cases_2017 Drugs_Cases_2018\n   &lt;chr&gt;                        &lt;dbl&gt;    &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;\n 1 BANGKOK                      65522    1571.            11871            16480\n 2 SAMUT PRAKAN                 14721     949.              820             3015\n 3 NONTHABURI                    8881     636.              553             1661\n 4 PATHUM THANI                  9805    1517.              450             1823\n 5 PHRA NAKHON SI AYUTTHA…       8780    2553.              378             1123\n 6 ANG THONG                     3487     944.              208              660\n 7 LOP BURI                      9236    6493.              727             1850\n 8 SING BURI                     2596     818.              127              402\n 9 CHAI NAT                      3781    2485.              200              422\n10 SARABURI                      4229    3483.               69              628\n# ℹ 67 more rows\n# ℹ 40 more variables: Drugs_Cases_2019 &lt;dbl&gt;, Drugs_Cases_2020 &lt;dbl&gt;,\n#   Drugs_Cases_2021 &lt;dbl&gt;, Drugs_Cases_2022 &lt;dbl&gt;, TotalDensity &lt;dbl&gt;,\n#   Drugs_Cases_Per_Km2_2017 &lt;dbl&gt;, Drugs_Cases_Per_Km2_2018 &lt;dbl&gt;,\n#   Drugs_Cases_Per_Km2_2019 &lt;dbl&gt;, Drugs_Cases_Per_Km2_2020 &lt;dbl&gt;,\n#   Drugs_Cases_Per_Km2_2021 &lt;dbl&gt;, Drugs_Cases_Per_Km2_2022 &lt;dbl&gt;,\n#   Rank_TotalCases &lt;int&gt;, Rank_TotalDensity &lt;int&gt;, …\n\n\n\nlocal_Gi Calculation: Here, we are calculating the Local Gi statistic* using a permutation approach (local_gstar_perm). This statistic measures local hotspots and coldspots based on the density of drug cases (TotalDensity) and the spatial relationships (nb and wts). The number of simulations (nsim = 999) ensures that we have a robust estimate of the significance of clustering.\n\nThe local_Gi statistic helps in identifying whether a province is part of a hotspot (higher-than-expected incidents of drug cases) or a coldspot (lower-than-expected incidents). By applying this statistic over multiple time periods, we can track whether hotspots are emerging, dissipating, or remaining stable over time, making this a powerful tool for understanding the evolving nature of drug-related incidents.\nThe results of EHSA, combined with statistical measures like Local Gi*, allow us to visualize which provinces are experiencing significant changes in drug-related activity, helping to inform more timely and localized interventions. This makes it an essential tool for long-term strategic planning in addressing the drug problem in Thailand.\n\n\n8.1.2 Visualising the HotSpot Areas\nTo visualize the results of the Emerging Hot Spot Analysis (EHSA), we follow a similar process to what we did for Local Moran’s I, but this time we are focusing on the Gi statistic* (also known as Getis-Ord Gi*) and its corresponding p-values.\nThe goal here is to display the hotspots (areas with higher-than-expected drug-related incidents) and coldspots (areas with lower-than-expected incidents) alongside the statistical significance of these patterns, just like in the Local Moran’s I analysis.\n\n\n\n\n\n\nNote\n\n\n\nWhy Visualize the Gi* Statistic and p-values?\nBy visualizing both the Gi statistic* and its p-values, we can understand not only where clustering occurs but also which clusters are statistically significant. This allows us to differentiate between areas that may show some clustering patterns but are not significant from those that have a strong statistical basis for further investigation or intervention.\nVisualizing these charts is crucial for understanding which provinces have stable or emerging hotspots of drug activity, helping authorities make informed, data-driven decisions.\n\n\n\n8.1.2.1 Visualizing the Gi* Statistic and p-values\nThe first map (map1) shows the Gi* clustering for density, where the color-coding indicates whether a region is part of a high-high cluster (hotspot) or a low-low cluster (coldspot). The second map (map2) focuses on the p-values, showing which clusters are statistically significant (with a p-value less than 0.05) and thus are more likely to represent real patterns rather than random noise.\n\nmap1 &lt;- tm_shape(HCSA_Total) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Density\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(HCSA_Total) +\n  tm_fill(\"p_sim\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n8.1.2.2 Filtering Out for Significant Clusters\nTo ensure we only focus on meaningful results, we filter the dataset to include only significant clusters (p-values &lt; 0.05) and visualize these clusters again:\n\nHCSA_total_sig &lt;- HCSA_Total %&gt;%\n  filter(p_sim &lt; 0.05)\n\ntm_shape(HCSA_Total) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  tm_layout(title = \"Significant Clusters of HSCA by Thailand Province\",\n            title.size = 0.8) +  # Add + here\ntm_shape(HCSA_total_sig) +\n  tm_fill(\"cluster\", \n          popup.vars = c(\"Province\" = \"Province\", \"P-Value\" = \"p_sim\", \"Cluster\" = \"cluster\", \"Drug Case Density (Km^2)\" = \"TotalDensity\")) +  # Set popup variables order\n  tm_borders(alpha = 0.4) +\n  tm_view(set.zoom.limits = c(6, 8))\n\n\n\n\n\nThe map displays the results of the Emerging Hot Spot Analysis (EHSA), specifically highlighting the significant clusters of drug-related incidents in Thailand. The regions are color-coded based on whether they represent high or low clusters of drug-related activity:\n\nYellow regions represent high clusters (hotspots), where drug-related incidents are higher than expected. These areas, centered around Bangkok and its surrounding provinces, indicate persistent hotspots of drug activity. This suggests a concentration of drug-related issues that have continued to be significant over time, signaling the need for sustained intervention in these areas.\nGreen regions indicate low clusters (coldspots), where drug-related incidents are lower than expected. These are regions primarily in the northern and central parts of Thailand, where drug activity appears to be under better control compared to the surrounding areas. The consistency of these low clusters suggests that these provinces have relatively fewer drug-related problems and may serve as areas with effective preventive measures.\n\n\n\n8.1.2.3 Analysis On Total Density By Province With Significant clusters.\n\n# Drop geometry, sort by TotalDensity, and select relevant columns\nHCSA_total_sig &lt;- HCSA_total_sig %&gt;%\n  st_drop_geometry() %&gt;%  # Remove geometry\n  select(Province, p_sim, cluster, TotalDensity) %&gt;%\n  arrange(desc(TotalDensity))  # Sort by TotalDensity\n\n# Create the bar chart\nggplot(HCSA_total_sig, aes(x = reorder(Province, -TotalDensity), y = TotalDensity, fill = as.factor(cluster))) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    title = \"Total Drug Case Density by Province with Signficant HSCA Clusters\",\n    x = \"Province\",\n    y = \"Drug Case Density (Km^2)\",\n    fill = \"Cluster\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nAnalysis of Total Drug Case Density by Province with Significant HSCA Clusters\nThis chart shows the drug case density (per Km²) by province, with clusters categorized as High (teal) and Low (red), reflecting the HSCA (Hot Spot Cluster Analysis) results.\nKey Observations:\n\nUrban Hotspots (High Cluster):\n\nBangkok, Samut Prakan, and Nonthaburi display the highest drug case densities, highlighting persistent drug-related issues in major urban centers.\nThese areas likely face challenges due to population density, social factors, and higher substance availability.\n\nModerate Risk Provinces:\n\nProvinces such as Pathum Thani and Chachoengsao are also in the high cluster but with lower densities compared to Bangkok. They indicate spillover effects from nearby urban areas.\n\nLow Clusters (Red):\n\nSeveral provinces, including Khon Kaen, Phichit, and Uttaradit, show low-density clusters, reflecting fewer drug-related incidents.\nThis suggests these areas have fewer drug problems or effective control measures in place.\n\nDistribution Trend:\n\nThe drug case density drops sharply after the first few high-risk provinces, with most of the remaining provinces showing minimal cases.\n\n\nImplications:\n\nFocused Intervention: Urban areas like Bangkok and surrounding provinces need targeted policies, such as increased monitoring, prevention programs, and rehabilitation efforts.\nPreventive Action in Low-Risk Areas: The low-cluster provinces should continue preventive measures to maintain their low-density status.\nSpillover Monitoring: Moderate-risk provinces (e.g., Pathum Thani) could benefit from monitoring efforts to prevent escalation from neighboring high-risk areas."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#visualising-the-charts",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#visualising-the-charts",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "8.1.2 Visualising the charts",
    "text": "8.1.2 Visualising the charts\nTo visualize the results of the Emerging Hot Spot Analysis (EHSA), we follow a similar process to what we did for Local Moran’s I, but this time we are focusing on the Gi statistic* (also known as Getis-Ord Gi*) and its corresponding p-values.\nThe goal here is to display the hotspots (areas with higher-than-expected drug-related incidents) and coldspots (areas with lower-than-expected incidents) alongside the statistical significance of these patterns, just like in the Local Moran’s I analysis.\n\nWhy Visualize the Gi* Statistic and p-values?\nBy visualizing both the Gi statistic* and its p-values, we can understand not only where clustering occurs but also which clusters are statistically significant. This allows us to differentiate between areas that may show some clustering patterns but are not significant from those that have a strong statistical basis for further investigation or intervention.\nVisualizing these charts is crucial for understanding which provinces have stable or emerging hotspots of drug activity, helping authorities make informed, data-driven decisions.\n\n\nVisualizing the Gi* Statistic and p-values\nThe first map (map1) shows the Gi* clustering for density, where the color-coding indicates whether a region is part of a high-high cluster (hotspot) or a low-low cluster (coldspot). The second map (map2) focuses on the p-values, showing which clusters are statistically significant (with a p-value less than 0.05) and thus are more likely to represent real patterns rather than random noise.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmap1 &lt;- tm_shape(HCSA_Total) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Density\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(HCSA_Total) +\n  tm_fill(\"p_sim\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\n\n\n\n\n\n\n\n\n\nFiltering Significant Clusters\nTo ensure we only focus on meaningful results, we filter the dataset to include only significant clusters (p-values &lt; 0.05) and visualize these clusters again:\n\nHCSA_total_sig &lt;- HCSA_Total  %&gt;%\n  filter(p_sim &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA_Total) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = paste(\"Significant Clusters of HSCA\"),\n              main.title.size = 0.8,\n              legend.position = c(\"right\", \"bottom\")) +\ntm_shape(HCSA_total_sig) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\nThe map displays the results of the Emerging Hot Spot Analysis (EHSA), specifically highlighting the significant clusters of drug-related incidents in Thailand. The regions are color-coded based on whether they represent high or low clusters of drug-related activity:\n\nYellow regions represent high clusters (hotspots), where drug-related incidents are higher than expected. These areas, centered around Bangkok and its surrounding provinces, indicate persistent hotspots of drug activity. This suggests a concentration of drug-related issues that have continued to be significant over time, signaling the need for sustained intervention in these areas.\nGreen regions indicate low clusters (coldspots), where drug-related incidents are lower than expected. These are regions primarily in the northern and central parts of Thailand, where drug activity appears to be under better control compared to the surrounding areas. The consistency of these low clusters suggests that these provinces have relatively fewer drug-related problems and may serve as areas with effective preventive measures.\n\nKey Analysis:\n\nThe clustering of high drug activity in Bangkok and its neighboring provinces is concerning because it has remained significant across the analysis. This persistent issue points to the need for intensified policy measures and interventions to address the ongoing drug-related challenges in these areas.\nThe northern and central regions, which form the low clusters, appear to be stable in terms of drug-related incidents. These regions likely have lower drug activity, but this doesn’t mean that preventive efforts should be relaxed. Continued monitoring is essential to ensure that these regions remain under control and do not experience an uptick in incidents in the future.\n\nThis analysis suggests that while some areas have remained relatively stable, certain regions—particularly around Bangkok—continue to be drug-related hotspots, indicating the need for focused resource allocation and public health initiatives to mitigate the problem effectively."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#ehsa-across-the-years",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#ehsa-across-the-years",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "8.2 EHSA Across the years",
    "text": "8.2 EHSA Across the years\n\n8.2.1 Visualizing the Province by Significant ESHA cluster\nAnalyzing the Emerging Hot Spot Analysis (EHSA) across multiple years allows us to track temporal trends in drug-related incidents. By comparing significant clusters each year, we can identify whether certain provinces remain consistent hotspots or if new areas emerge as concerns. This helps in determining if interventions are working effectively over time or if new strategies are needed to address emerging regions.\nBy performing this analysis year by year, we can:\n\nMonitor Stability: Identify provinces that consistently show significant clustering, which may indicate areas where drug-related activities are deeply rooted or interventions have not been effective.\nDetect Emerging Hotspots: Identify regions where clustering is becoming significant over time, signaling an increase in drug-related incidents that may require new policies or interventions.\nMeasure Policy Effectiveness: Track changes in significant clusters, which helps to evaluate whether implemented strategies in previous years have succeeded in reducing drug-related cases in problem areas.\n\n\n# Define the years\nyears &lt;- 2017:2022\n# Loop through each year to calculate p_ii_sim and median\nfor (year in years) {\n  # Construct the year-specific variable names\n  year_column &lt;- paste0(\"Drugs_Cases_Per_Km2_\", year)\n  # Calculate local Moran's I for the current year\n  HSCA &lt;- thailand_idw %&gt;%\n    mutate(local_Gi = local_gstar_perm(\n      !!sym(year_column),  # Use !!sym() to handle dynamic column names\n      nb,\n      wts,\n      nsim = 999)\n    ,.before = 1) %&gt;%\n    unnest(local_Gi)\n  \n  \n  # Extract p_ii_sim and median from LISA\n  p_sim_values &lt;- HSCA$p_sim  # Get all p_ii_sim values for the year\n  cluster_values &lt;- HSCA$cluster       # Get all median values for the year \n  \n  # Add new columns to the existing LISA_TotalDensity data frame\n  HCSA_Total &lt;- HCSA_Total %&gt;%\n    mutate(!!paste0(\"p_sim_\", year) := p_sim_values,\n           !!paste0(\"cluster_\", year) := cluster_values)\n}\n\n# Print the resulting LISA_TotalDensity data frame\nprint(HCSA_Total)\n\nSimple feature collection with 77 features and 55 fields\nActive geometry column: geometry\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 325178.8 ymin: 620865.7 xmax: 1213656 ymax: 2263213\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 77 × 57\n   Province                TotalCases Area_km2 Drugs_Cases_2017 Drugs_Cases_2018\n * &lt;chr&gt;                        &lt;dbl&gt;    &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;\n 1 BANGKOK                      65522    1571.            11871            16480\n 2 SAMUT PRAKAN                 14721     949.              820             3015\n 3 NONTHABURI                    8881     636.              553             1661\n 4 PATHUM THANI                  9805    1517.              450             1823\n 5 PHRA NAKHON SI AYUTTHA…       8780    2553.              378             1123\n 6 ANG THONG                     3487     944.              208              660\n 7 LOP BURI                      9236    6493.              727             1850\n 8 SING BURI                     2596     818.              127              402\n 9 CHAI NAT                      3781    2485.              200              422\n10 SARABURI                      4229    3483.               69              628\n# ℹ 67 more rows\n# ℹ 52 more variables: Drugs_Cases_2019 &lt;dbl&gt;, Drugs_Cases_2020 &lt;dbl&gt;,\n#   Drugs_Cases_2021 &lt;dbl&gt;, Drugs_Cases_2022 &lt;dbl&gt;, TotalDensity &lt;dbl&gt;,\n#   Drugs_Cases_Per_Km2_2017 &lt;dbl&gt;, Drugs_Cases_Per_Km2_2018 &lt;dbl&gt;,\n#   Drugs_Cases_Per_Km2_2019 &lt;dbl&gt;, Drugs_Cases_Per_Km2_2020 &lt;dbl&gt;,\n#   Drugs_Cases_Per_Km2_2021 &lt;dbl&gt;, Drugs_Cases_Per_Km2_2022 &lt;dbl&gt;,\n#   Rank_TotalCases &lt;int&gt;, Rank_TotalDensity &lt;int&gt;, …\n\n\n\n# Define the years\nyears &lt;- 2017:2022\n\n# Create an empty list to store individual maps\nmap_list &lt;- list()\n\n# Loop through each year to create maps for significant clusters\nfor (year in years) {\n  # Filter significant clusters for the current year\n  HSCA_Sig &lt;- HCSA_Total %&gt;%\n    filter(!!sym(paste0(\"p_sim_\", year)) &lt; 0.05)  # Filter for significance\n\n  # Create the map for significant clusters for the current year\n  map_HSCA &lt;- tm_shape(HCSA_Total) +\n    tm_polygons() +\n    tm_borders(alpha = 0.5) +\n    tm_shape(HSCA_Sig) +\n    tm_fill(paste0(\"cluster_\", year), alpha = 0.7) + \n    tm_borders(col = \"darkblue\", alpha = 0.4) +\n    tm_layout(main.title = paste(\"Significant Clusters of HSCA -\", year),\n              main.title.size = 1.2,\n              legend.position = c(\"right\", \"bottom\")) +\n    tm_view(set.zoom.limits = c(6, 8))\n\n  # Store the current map in the list\n  map_list[[as.character(year)]] &lt;- map_HSCA\n}\n\n# Combine all maps into one layout\ncombined_map &lt;- do.call(tmap_arrange, c(map_list, ncol = 3))\nprint(combined_map)\n\n\n\n\n\n\n\n\nThe maps above depict the significant clusters of drug-related incidents across Thailand from 2017 to 2022, showing both high clusters (hotspots) and low clusters (coldspots).\n\n2017-2022 Consistency:\n\nHotspots in Bangkok and surrounding provinces are consistent across the years. This persistent high clustering in central Thailand indicates that drug-related activities remain concentrated in this area. Despite any potential interventions, these regions continue to display significant hotspots, signaling a need for stronger or alternative policies to address this issue.\nLow clusters in northern provinces such as Chiang Mai are also consistent over the years. These areas have maintained a lower-than-expected rate of drug incidents, which could indicate successful long-term preventive measures or generally lower drug-related activities.\n\nEmerging Patterns:\n\nIn 2020, the clustering patterns remain similar to previous years, with no significant changes, suggesting that the drug activity hotspots and coldspots are stable.\nIn 2021, there is some slight variation in the clustering patterns, though the changes are minimal. The continued high clustering in the central provinces emphasizes that the core problem areas have not shifted substantially.\n\nKey Observations:\n\nThe regions around Bangkok remain significant hotspots throughout the six years, indicating that drug-related incidents are entrenched in this area.\nNorthern and central provinces consistently show low clustering, which suggests effective long-term measures or inherently lower drug activities.\nThere are no new emerging hotspots in other regions, suggesting that the drug issue has remained largely concentrated in these identified provinces over time.\n\n\n\n8.2.1.2 Animation across the years ESHA\n\n# Define the years\nyears &lt;- 2017:2022\n\n# Create an empty list to store individual maps\nmap_list &lt;- list()\n\n# Loop through each year to create maps for significant clusters\nfor (year in years) {\n  # Filter significant clusters for the current year\n  HSCA_Sig &lt;- HCSA_Total %&gt;%\n    filter(!!sym(paste0(\"p_sim_\", year)) &lt; 0.05)  # Filter for significance\n\n  # Create the map for significant clusters for the current year\n  map_HSCA &lt;- tm_shape(HCSA_Total) +\n    tm_polygons() +\n    tm_borders(alpha = 0.5) +\n    tm_shape(HSCA_Sig) +\n    tm_fill(paste0(\"cluster_\", year), alpha = 0.7) + \n    tm_borders(col = \"darkblue\", alpha = 0.4) +\n    tm_layout(\n      main.title = paste(\"Significant Clusters of HSCA -\", year),\n      main.title.size = 0.8,\n      legend.position = c(\"right\", \"bottom\")\n    ) +\n    tm_view(set.zoom.limits = c(6, 8))\n\n  # Store the current map in the list\n  map_list[[as.character(year)]] &lt;- map_HSCA\n}\n\n# Create an animated GIF by stitching the maps together\ntmap_animation(\n  map_list,\n  filename = \"HSCA_Animation.gif\",  # Output GIF file\n  delay = 1000,  # Delay between frames in milliseconds (1 second)\n  width = 800, \n  height = 600\n)\n\n\n\n\n\n8.2.2 Analysis of the EHSA Maps (2017-2022)\n\n# Define the years\nyears &lt;- 2017:2022\n\n# Create an empty list to store individual bar charts\nplot_list &lt;- list()\n\n# Loop through each year to create a bar chart for significant HSCA clusters\nfor (year in years) {\n  # Filter data for the current year\n  HCSA_Sig &lt;- HCSA_Total %&gt;%\n    st_drop_geometry() %&gt;%  # Remove geometry column\n    filter(!!sym(paste0(\"p_sim_\", year)) &lt; 0.05) %&gt;%  # Filter significant clusters\n    select(\n      Province,\n      cluster = !!sym(paste0(\"cluster_\", year)),\n      Density = !!sym(paste0(\"Drugs_Cases_Per_Km2_\", year))  # Use year-specific density\n    ) %&gt;%\n    arrange(desc(Density))  # Sort by that year's density\n\n  # Create a bar chart for the current year\n  plot &lt;- ggplot(HCSA_Sig, aes(x = reorder(Province, -Density), y = Density, fill = as.factor(cluster))) +\n    geom_bar(stat = \"identity\") +\n    labs(\n      title = paste(\"Year:\", year),\n      x = \"Province\",\n      y = \"Drug Cases Per Km²\",\n      fill = \"Cluster\"\n    ) +\n    theme_minimal() +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n  # Store the plot in the list\n  plot_list[[as.character(year)]] &lt;- plot\n}\n\n# Combine all the bar charts into a 3x2 layout\ncombined_plot &lt;- wrap_plots(plot_list, ncol = 3)\n\n# Print the combined plot\nprint(combined_plot)\n\n\n\n\n\n\n\n\nThis series of bar charts shows the drug case density (per Km²) by province across the years 2017-2022, with clusters categorized as:\n\nHigh (teal): Provinces with high drug case density.\nLow (red): Provinces with lower drug case density.\n\nKey Observations:\n\nConsistent Urban Hotspots:\n\nBangkok, Samut Prakan, and Nonthaburi maintain high drug case density across all years. These urban areas are consistently identified as high-risk zones, requiring sustained interventions.\n\nGrowth and Decline Patterns:\n\nSamut Prakan shows a rise in density by 2022, becoming the leading hotspot.\nDrug density in other provinces, such as Bangkok, fluctuates but remains high throughout the period, showing persistent challenges.\n\nEmerging Risks:\n\nPhrae and Khon Kaen occasionally appear with high density in some years, suggesting emerging or localized risks that require periodic monitoring.\n\nStable Low-Density Provinces:\n\nProvinces such as Tak, Sukhothai, and Phitsanulok remain consistently low-risk, indicating effective control or minimal drug-related issues.\n\n\nTrends Over Time:\n\nUrban Spread: Drug cases remain concentrated in metropolitan areas, with little spread to rural provinces.\nShift in Focus in 2022: The dominance of Samut Prakan in 2022 suggests a shift in hotspot dynamics, possibly requiring resource reallocation.\n\nImplications:\n\nTargeted Interventions in Urban Centers: Consistent high-density areas (e.g., Bangkok, Samut Prakan) demand focused strategies, including prevention, treatment, and law enforcement.\nMonitoring Emerging Risks: Provinces like Khon Kaen and Phrae need to be monitored closely to prevent escalation.\nMaintain Stability in Low-Risk Areas: Continued preventive efforts are necessary in low-risk provinces to avoid future outbreaks."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#conclusion-2",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#conclusion-2",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "8.3 Conclusion:",
    "text": "8.3 Conclusion:\nThe analysis of significant clusters across the years reveals a stable spatial distribution of drug-related incidents. The persistent hotspots in Bangkok and surrounding areas are concerning and point to the need for continued or enhanced interventions. The low clustering in northern provinces is a positive indicator of stable regions with lower drug incidents, but monitoring should continue to ensure these areas remain under control."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#global-local-and-temporal-integration-overview",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#global-local-and-temporal-integration-overview",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "9.1 Global, Local, and Temporal Integration Overview",
    "text": "9.1 Global, Local, and Temporal Integration Overview\n\nGlobal Moran’s I provides an overall indication of whether drug-related incidents are clustered or dispersed across the entire country. This is a macro-level measure that tells us whether there is significant spatial autocorrelation in the data as a whole.\nLocal Moran’s I allows us to zoom into specific provinces and examine whether individual regions are part of high-high or low-low clusters. This helps identify specific hotspots or coldspots within the broader trends detected by Global Moran’s I.\nEmerging Hot Spot Analysis (EHSA) adds a temporal dimension to the analysis, revealing whether hotspots are stable, emerging, or dissipating over time. This allows us to track how patterns change across years and identify regions where drug-related issues are growing."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#merging-insights-for-holistic-understanding",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#merging-insights-for-holistic-understanding",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "9.2 Merging Insights for Holistic Understanding",
    "text": "9.2 Merging Insights for Holistic Understanding\n\n9.2.1 Spatial and Temporal Consistency\n\nGlobal Moran’s I shows persistent clustering, suggesting entrenched spatial patterns of drug-related issues.\nLISA confirms Bangkok and neighboring provinces form high-high clusters, while northern provinces like Chiang Mai remain low-risk.\nHSCA analysis supports this, with urban centers in central Thailand reporting sustained drug activity from 2017 to 2022, while northern regions maintain stable, low-risk conditions.\n\n\n\n9.2.2 Emerging Hotspots and Coldspots\n\nNo new hotspots have emerged outside of known high-risk areas, with activity concentrated near Bangkok.\nNorthern provinces show stable low incident rates, confirming the effectiveness of their preventive strategies."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#visualizing-the-combined-insights",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#visualizing-the-combined-insights",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "9.3 Visualizing the Combined Insights",
    "text": "9.3 Visualizing the Combined Insights\nBy visualizing the results of Global Moran’s I, Local Moran’s I, and EHSA together, we can create a composite map that highlights the regions that are both spatially and temporally significant. This composite map would allow us to see:\n\nPersistent hotspots (regions with high-high clustering and significant hot spots over time).\nStable coldspots (regions with low-low clustering and stable cold spots).\nEmerging trends (areas where clustering patterns are changing over time)."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#conclusion-and-next-steps",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#conclusion-and-next-steps",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "9.4 Conclusion and Next Steps",
    "text": "9.4 Conclusion and Next Steps\nThe integration of these three spatial analysis methods provides a holistic view of the drug-related problem in Thailand. This combined approach allows us to understand not just where the issues are, but also how they have evolved over time and whether current policies are having the desired effect. By continuing to monitor these patterns and adjusting interventions accordingly, policymakers can more effectively address drug-related problems in the country. The next step would be to delve deeper into the specific socio-economic or structural factors driving these persistent hotspots and identify ways to mitigate their impact over time.\nThis comprehensive analysis equips stakeholders with the information they need to implement more targeted, data-driven interventions that address both spatial and temporal trends in drug-related incidents."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#drug-abuse-data-kaggle-dataset",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#drug-abuse-data-kaggle-dataset",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "3.1 Drug Abuse Data (Kaggle Dataset):",
    "text": "3.1 Drug Abuse Data (Kaggle Dataset):\n\nThis dataset contains provincial-level information on drug abuse rates across multiple years.\n\n\nthai_drug_data &lt;- read_csv(\"data/raw/aspatial/thai_drug_offenses_2017_2022.csv\") \n\nRows: 7392 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): types_of_drug_offenses, province_th, province_en\ndbl (2): fiscal_year, no_cases\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nDrug Abuse Data Columns and Values\n\n\nFiscal Year The year in which the drug-related offenses were recorded, corresponding to the fiscal period of the data collection (e.g., 2017, 2018, 2019, 2020, 2021, 2022).\nType Of Drug Offenses The classification or type of drug offense committed (e.g., possession, trafficking, manufacturing), detailing the specific nature of the drug-related crime.\n\nType Includes\n\ndrug_use_cases\nsuspects_in_drug_use_cases\npossession_cases\nsuspects_in_possession_cases\npossession_with_intent_to_distribute_cases\nsuspects_in_possession_with_intent_to_distribute_cases\ntrafficking_cases\nsuspects_in_trafficking_cases\nproduction_cases\nsuspects_in_production_cases\nimport_cases\nsuspects_in_import_cases\nexport_cases\nsuspects_in_export_cases\nconspiracy_cases\nsuspects_in_conspiracy_cases\n\n\nNo Of Case The total number of drug-related cases reported for a given province and fiscal year, representing the count of offenses recorded.\nProvince_th The name of the province in Thai, used to identify the location of the reported drug offenses.\nProvince_en The name of the province in English, providing a translated version of the province for non-Thai speakers or international reference."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#thailand-province-spatial-data-hdx-link",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#thailand-province-spatial-data-hdx-link",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "3.2 Thailand Province Spatial Data (HDX Link):",
    "text": "3.2 Thailand Province Spatial Data (HDX Link):\nThe shapefile dataset contains the geographical boundaries of Thailand’s provinces, including Bangkok. Each polygon represents a province, allowing us to visualize the spatial distribution of drug abuse and analyze spatial patterns effectively.\n\nthailand_province &lt;- st_read(dsn = \"data/raw/geospatial\", layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Take_Home_Exercises\\Take_Home_Exercise_2\\data\\raw\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\n\n\nHDX Thai Shape file data\n\nThese are the columns within the Shape File:\n\nShape_Leng: The length of the boundary (perimeter) of the province’s polygon in the shapefile, typically measured in meters or kilometers.\nShape_Area: The area of the province’s polygon in the shapefile, usually measured in square meters or square kilometers.\nADMIN1_EN: The name of the province in English. This is a key identifier used to reference each province in the dataset.\nADM1_TH: The name of the province in Thai. This is the local language representation of the province name.\nADM1_PCODE The administrative code (or postal code) for the province. This is a standardized reference code for the administrative region.\nADM1_REF: A reference code or ID specific to the administrative level (province), typically used internally for referencing within GIS systems.\nADM1ALT1EN: An alternative English name for the province, if available. This might represent an old or variant name for the province in English.\nADM1ALT2EN: A second alternative English name for the province, if applicable. This could reflect historical or other variant names.\nADM1ALT1TH: An alternative Thai name for the province. This could reflect a regional or historical name in the local language.\nADM1ALT2TH A second alternative Thai name for the province, used if there are additional variants in the local language.\nADM0_EN: The name of the country (Thailand) in English. This is a reference to the country level of administration.\nADM0_TH The name of the country (Thailand) in Thai. This is the local language representation of the country name.\nADM0_PCODE The administrative code for the country (Thailand). This is a standardized reference code at the national level.\ndate The date when the data was collected or last updated. This indicates when the shapefile’s data was created or validated.\nvalidOn The date when the data became valid or effective. It’s typically used to track the validity of administrative boundaries.\nvalidTo The date when the data is no longer valid. This is useful for tracking changes in administrative boundaries over time (e.g., if a province’s borders were changed or merged with another).\ngeometry The spatial geometry of the province, represented as polygons in the shapefile. This field stores the geographical coordinates that define the boundaries of each province."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#steps-for-data-wrangling-exploration",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#steps-for-data-wrangling-exploration",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "4.1 Steps for Data Wrangling Exploration",
    "text": "4.1 Steps for Data Wrangling Exploration\nBefore we begin the spatial analysis, it is essential to explore and prepare the datasets to ensure they are ready for analysis. This includes checking for missing values, merging datasets, and creating visualizations to understand the general patterns of drug abuse across provinces.\n\nPreviewing the Spatial Data: We start by loading the shapefile to confirm that all provinces are represented and the boundaries are correct. This spatial dataset will form the backbone of the analysis, providing the geographical context for our study.\nCleaning and Aggregating: Any missing or erroneous data is cleaned, and the data is aggregated at the province level if needed. This ensures that the dataset is consistent and ready for analysis.\nSummary Statistics: We generate summary statistics for key variables, such as the average drug abuse rate across provinces, the distribution of education levels, and unemployment rates. This gives us a preliminary understanding of the data distribution before we move into more detailed spatial analysis."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#visualizing-trends-in-drug-abuse-on-year-level-by-province",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#visualizing-trends-in-drug-abuse-on-year-level-by-province",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "5.2 Visualizing Trends in Drug Abuse On Year Level By Province",
    "text": "5.2 Visualizing Trends in Drug Abuse On Year Level By Province\nVisualizing drug abuse trends across years at the provincial level provides crucial insights into the spatial and temporal dynamics of the issue. By examining how drug abuse varies from year to year within specific provinces, we can identify patterns, emerging hotspots, and areas that require immediate intervention. This analysis helps policymakers, law enforcement, and public health officials prioritize resource allocation, implement targeted prevention strategies, and assess the effectiveness of ongoing programs. Moreover, this approach can highlight regions where drug abuse is decreasing, serving as models for successful interventions.\n\n5.2.1 Total Drug Abuse across Years By Province\n\n# Define the years\nyears &lt;- 2017:2022\nyear_columns &lt;- paste0(\"Drugs_Cases_\", years)\n\n# Create a list to store individual plots for each year\ncase_plots &lt;- list()\n\n# Loop through each year and create a bar plot for total cases (province on y-axis)\nfor (i in 1:length(years)) {\n  # Dynamically reference the column name using !!sym()\n  plot &lt;- ggplot(thailand_province_df, aes(y = reorder(Province, -!!sym(year_columns[i])), x = !!sym(year_columns[i]))) +\n    geom_bar(stat = \"identity\", fill = \"steelblue\") +\n    labs(title = paste(\"Total Drug Cases -\", years[i]), y = \"Province\", x = \"Total Cases\") +\n    theme_minimal() +\n    theme(axis.text.y = element_text(size = 7))\n  \n  case_plots[[i]] &lt;- plot\n}\n\n# Arrange the plots in a 3x2 grid\ngrid.arrange(grobs = case_plots, ncol = 3, nrow = 2)\n\n\n\n\n\n\n\n\n\n5.2.1.1 Visualizing it across years on a map level\n\n# Define the years and corresponding column names\nyears &lt;- 2017:2022\nyear_columns &lt;- paste0(\"Drugs_Cases_\", years)\n\n# Create a list to store individual maps\nmap_list &lt;- list()\n\n# Loop through each year to create individual maps using tmap\nfor (i in 1:length(years)) {\n  map &lt;- tm_shape(thailand_province_final) +\n    tm_polygons(col = year_columns[i], \n                palette = \"Blues\",  # Use a blue color scale\n                style = \"quantile\", \n                title = paste(\"Drug Cases in\", years[i])) +\n    tm_borders() +\n    tm_layout(main.title = paste(\"Drug Cases in\", years[i]),  # Title outside and above each map\n              main.title.position = c(\"center\", \"top\"),  # Ensures the title is centered at the top\n              title.size = 1.5,  # Adjust title size if necessary\n              outer.margins = 0.05,  # Minimize margins\n              legend.position = c(\"right\", \"bottom\"))\n  \n  # Store each map in the list as a tmap object\n  map_list[[i]] &lt;- map\n}\n\n# Combine the maps into a 3x2 grid\nfinal_map &lt;- tmap_arrange(\n  map_list[[1]], map_list[[2]], map_list[[3]], \n  map_list[[4]], map_list[[5]], map_list[[6]], \n  ncol = 3, nrow = 2\n)\n\n# Display the map grid\nfinal_map\n\n\n\n\n\n\n\n\n\n\n5.2.1.2 Seeing it on an animation\n\nyears &lt;- 2017:2022\nyear_columns &lt;- paste0(\"Drugs_Cases_\", years)\n\n# Create a list to store individual maps for each year\nmap_list &lt;- list()\n# Loop through each year and create a map for total cases by year\nfor (i in 1:length(years)) {\n  map &lt;- tm_shape(thailand_province_final) +\n    tm_polygons(col = year_columns[i], \n                palette = \"Blues\",  # Use a blue color scale\n                style = \"quantile\", \n                title = paste(\"Drug Cases in\", years[i])) +\n    tm_borders() +\n    tm_layout(main.title = paste(\"Drug Cases in\", years[i]),  # Title outside and above each map\n              main.title.position = c(\"center\", \"top\"),  # Ensures the title is centered at the top\n              title.size = 1.5,  # Adjust title size if necessary\n              outer.margins = 0.05,  # Minimize margins\n              legend.position = c(\"right\", \"bottom\"))\n  \n  # Store each map in the list\n  map_list[[i]] &lt;- map\n}\n\n# Render the animated map by passing the list of maps\ntmap_animation(map_list, filename = \"thailand_drug_cases.gif\", delay = 100, width = 500, height = 500)\n\n\n\n\n5.2.2.3 Analysis found on total drug cases in Thailand across years by province.\nThese charts represent the total drug cases across Thailand’s provinces from 2017 to 2022.\n\nConsistent trends: Bangkok consistently shows the highest number of drug cases across all years, indicating a persistent and significant drug problem in the capital. Chon Buri, Ubon Ratchathani, and Nakhon Si Thammarat also consistently rank high, suggesting these areas are heavily impacted.\nYearly fluctuations: While the rankings remain relatively stable, the total number of cases varies each year, with notable peaks in provinces like Bangkok and Chon Buri during certain years.\nProvincial concentration: A small number of provinces consistently account for the majority of drug cases, while most provinces report significantly fewer cases, reinforcing the idea that drug problems are concentrated in specific regions.\n\nThis trend indicates a need for focused intervention in the high-case provinces while monitoring fluctuations over time.\n\n\n\n5.2.2 Total Drug Abuse Density across Years By Province\n\n# Define the years\nyears &lt;- 2017:2022\ndensity_columns &lt;- paste0(\"Drugs_Cases_Per_Km2_\", years)\n\n# Create a list to store individual plots for each year (Density)\ndensity_plots &lt;- list()\n\n# Loop through each year and create a bar plot for density (province on y-axis)\nfor (i in 1:length(years)) {\n  plot &lt;- ggplot(thailand_province_df, aes(y = reorder(Province, -!!sym(density_columns[i])), x = !!sym(density_columns[i]))) +\n    geom_bar(stat = \"identity\", fill = \"darkorange\") +\n    labs(title = paste(\"Drug Case Density -\", years[i]), y = \"Province\", x = \"Density (Cases per km²)\") +\n    theme_minimal() +\n    theme(axis.text.y = element_text(size = 7))\n  \n  density_plots[[i]] &lt;- plot\n}\n\n# Arrange the plots in a 3x2 grid\ngrid.arrange(grobs = density_plots, ncol = 3, nrow = 2)\n\n\n\n\n\n\n\n\n\n5.2.2.1 Visualizing it across years on a map level\n\n# Define the years and corresponding column names\nyears &lt;- 2017:2022\nyear_columns &lt;- paste0(\"Drugs_Cases_Per_Km2_\", years)\n\n# Create a list to store individual maps\nmap_list &lt;- list()\n\n# Loop through each year to create individual maps using tmap\nfor (i in 1:length(years)) {\n  map &lt;- tm_shape(thailand_province_final) +\n    tm_polygons(col = year_columns[i], \n                palette = \"Oranges\",\n                style = \"quantile\", \n                title = paste(\"Drug Cases Density Km^2 in\", years[i])) +\n    tm_borders() +\n    tm_layout(main.title = paste(\"Drug Cases Density Km^2 in\", years[i]),  # Title outside and above each map\n              main.title.position = c(\"center\", \"top\"),  # Ensures the title is centered at the top\n              title.size = 1.5,  # Adjust title size if necessary\n              outer.margins = 0.05,  # Minimize margins\n              legend.position = c(\"right\", \"bottom\"))\n  \n  # Store each map in the list as a tmap object\n  map_list[[i]] &lt;- map\n}\n\n# Combine the maps into a 3x2 grid\nfinal_map &lt;- tmap_arrange(\n  map_list[[1]], map_list[[2]], map_list[[3]], \n  map_list[[4]], map_list[[5]], map_list[[6]], \n  ncol = 3, nrow = 2\n)\n\n# Display the map grid\nfinal_map\n\n\n\n\n\n\n\n\n\n\n5.2.1.2 Animation Across Years\n\nyears &lt;- 2017:2022\nyear_columns &lt;- paste0(\"Drugs_Cases_Per_Km2_\", years)\n\n# Create a list to store individual maps for each year\nmap_list &lt;- list()\n# Loop through each year and create a map for total cases by year\nfor (i in 1:length(years)) {\n  map &lt;- tm_shape(thailand_province_final) +\n    tm_polygons(col = year_columns[i], \n                palette = \"Oranges\",  # Use a blue color scale\n                style = \"quantile\", \n                title = paste(\"Drug Cases Density Km^2 in\", years[i])) +\n    tm_borders() +\n    tm_layout(main.title = paste(\"Drug Cases Density Km^2 in\", years[i]),  # Title outside and above each map\n              main.title.position = c(\"center\", \"top\"),  # Ensures the title is centered at the top\n              main.title.size = 0.8,  # Adjust title size if necessary\n              outer.margins = 0.05,  # Minimize margins\n              legend.position = c(\"right\", \"bottom\"))\n  \n  # Store each map in the list\n  map_list[[i]] &lt;- map\n}\n\n# Render the animated map by passing the list of maps\ntmap_animation(map_list, filename = \"thailand_drug_cases_density.gif\", delay = 100, width = 500, height = 500)\n\n\n\n\n5.2.2.3 Analysis found on Density across Thailand provinces\nThese charts visualize the drug case density (cases per km²) across Thailand’s provinces from 2017 to 2022.\n\nBangkok consistently has the highest density, with drug case density far exceeding other provinces each year, indicating that despite its smaller area, the capital remains a hotbed of drug-related issues.\nSamut Prakan, Nonthaburi, and Phuket frequently follow, with relatively high densities compared to other provinces, although still much lower than Bangkok.\nMost provinces have very low case density values, clustering near zero, which highlights that drug cases are more spread out and less concentrated geographically in those regions.\n\nThis pattern of concentration in a few urban provinces suggests that densely populated areas are facing more significant drug issues relative to their size, demanding focused urban interventions.\n\n\n\n5.2.3 Rank Chart for Total Drug Cases and Density Across years.\nA rank chart is used to display the relative positions of provinces based on their total number of drug cases or the density of drug abuse over time. It helps to visualize how provinces compare to one another and how their ranks shift across different years.\n\n5.2.3.1 Rank Chart for Total Drug Cases Across Years\n\n# Reshape data to long format for plotting rankings over time (Total Cases)\nrank_data_cases &lt;- thailand_province_df %&gt;%\n  select(Province, starts_with(\"Rank_No_Drug_Cases_\")) %&gt;%\n  pivot_longer(cols = matches(\"^Rank_No_Drug_Cases_\\\\d{4}$\"),  # Ensure only total cases rank columns are selected\n               names_to = \"Year\", \n               values_to = \"Rank\") %&gt;%\n  mutate(Year = gsub(\"Rank_No_Drug_Cases_\", \"\", Year))  # Clean Year values to keep only the year number\n\n# Function to add labels only at the start and end of the lines\nggplot(rank_data_cases, aes(x = Year, y = Rank, group = Province, color = Province)) +\n  geom_line(size = 1.2) +                                # Line to show rank movement\n  geom_point(size = 3) +                                 # Points for each rank\n  geom_text(data = rank_data_cases %&gt;% filter(Year == \"2017\"),  # Labels for the start (2017)\n            aes(label = Province), hjust = 1.1, size = 3) +\n  geom_text(data = rank_data_cases %&gt;% filter(Year == \"2022\"),  # Labels for the end (2022)\n            aes(label = Province), hjust = -0.1, size = 3) +\n  scale_y_reverse() +  # Reverse the y-axis to show better ranks at the top\n  labs(title = \"Ranking of Provinces by Total Drug Cases (2017-2022)\", \n       x = \"Year\", y = \"Rank (Lower is Better)\", color = \"Province\") +  \n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 10), legend.position = \"none\")  # Remove legend for clarity\n\n\n\n\n\n\n\n\nThis chart shows the ranking of Thailand’s provinces by total drug cases from 2017 to 2022. Key insights:\n\nBangkok consistently ranks at the top, indicating a persistent drug problem.\nUbon Ratchathani and Chon Buri also maintain high ranks throughout the years, showing consistent drug-related challenges.\nOther provinces like Chiang Mai, Rayong, and Nakhon Si Thammarat frequently move up and down in the rankings, indicating fluctuating drug case trends.\nThere is a lot of movement in the middle and lower rankings, suggesting changing dynamics in drug cases across the provinces over time.\n\nOverall, while certain provinces consistently face high drug case numbers, others experience more variability, reflecting shifting trends in drug enforcement or drug activity.\n\n\n5.2.3.2 Rank Chart for Drug Cases Density Across Years\n\n# Reshape data to long format for plotting rankings over time (Density)\nrank_data_density &lt;- thailand_province_df %&gt;%\n  select(Province, starts_with(\"Rank_No_Drug_Cases_Per_Km2_\")) %&gt;%\n  pivot_longer(cols = matches(\"^Rank_No_Drug_Cases_Per_Km2_\\\\d{4}$\"),  # Ensure only density rank columns are selected\n               names_to = \"Year\", \n               values_to = \"Rank\") %&gt;%\n  mutate(Year = gsub(\"Rank_No_Drug_Cases_Per_Km2_\", \"\", Year))  # Clean Year values to keep only the year number\n\n# Function to add labels only at the start and end of the lines (for density)\nggplot(rank_data_density, aes(x = Year, y = Rank, group = Province, color = Province)) +\n  geom_line(size = 1.2) +                                # Line to show rank movement\n  geom_point(size = 3) +                                 # Points for each rank\n  geom_text(data = rank_data_density %&gt;% filter(Year == \"2017\"),  # Labels for the start (2017)\n            aes(label = Province), hjust = 1.1, size = 3) +\n  geom_text(data = rank_data_density %&gt;% filter(Year == \"2022\"),  # Labels for the end (2022)\n            aes(label = Province), hjust = -0.1, size = 3) +\n  scale_y_reverse() +  # Reverse the y-axis to show better ranks at the top\n  labs(title = \"Ranking of Provinces by Drug Case Density (2017-2022)\", \n       x = \"Year\", y = \"Rank (Lower is Better)\", color = \"Province\") +  \n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 10), legend.position = \"none\")  # Remove legend for clarity\n\n\n\n\n\n\n\n\nThis chart illustrates the ranking of Thailand’s provinces by drug case density (cases per km²) from 2017 to 2022. Key takeaways:\n\nBangkok consistently ranks at the top for drug case density, reflecting its severe drug problem relative to its small geographic size.\nRayong, Chon Buri, and Nonthaburi maintain high density rankings, indicating that these areas have concentrated drug cases despite their sizes.\nOther provinces, such as Samut Prakan, Samut Songkhram, and Nakhon Pathom, frequently appear near the top, signaling persistent issues with drug case density.\nThere is considerable variation in rankings for many mid-ranked provinces, suggesting fluctuating drug activity or law enforcement effectiveness over time.\n\nThis suggests that while certain urban areas maintain consistently high drug case density, other regions see more variability in the concentration of drug-related incidents."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#local-morans-i-for-aggregated-data-total-cases-across-years",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#local-morans-i-for-aggregated-data-total-cases-across-years",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "7.1 Local Moran’s I for Aggregated Data Total Cases Across Years",
    "text": "7.1 Local Moran’s I for Aggregated Data Total Cases Across Years\nTo further investigate the spatial distribution of drug cases in Thailand, we now shift our focus from global to local spatial autocorrelation. Local Moran’s I helps identify clusters of high or low drug-related incidents at a more granular level, revealing hotspots and cold spots that might be masked in the aggregated data.\nIn this step, we calculate Local Moran’s I for the total density of drug cases across provinces, enabling us to detect local clusters of drug activity. This local analysis allows policymakers to focus resources more efficiently on regions that require immediate attention.\n\n7.1.1 Preparing the Data\n\nLISA_TotalDensity &lt;- thailand_province_final_sf %&gt;%\n  mutate(local_moran = local_moran(\n    TotalDensity, \n    nb, \n    wt, \n    nsim = 999\n  )) %&gt;%\n  unnest(local_moran)\nLISA_TotalDensity\n\nSimple feature collection with 77 features and 44 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 325178.8 ymin: 620865.7 xmax: 1213656 ymax: 2263213\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 77 × 45\n   Province                TotalCases Area_km2 Drugs_Cases_2017 Drugs_Cases_2018\n   &lt;chr&gt;                        &lt;dbl&gt;    &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;\n 1 BANGKOK                      65522    1571.            11871            16480\n 2 SAMUT PRAKAN                 14721     949.              820             3015\n 3 NONTHABURI                    8881     636.              553             1661\n 4 PATHUM THANI                  9805    1517.              450             1823\n 5 PHRA NAKHON SI AYUTTHA…       8780    2553.              378             1123\n 6 ANG THONG                     3487     944.              208              660\n 7 LOP BURI                      9236    6493.              727             1850\n 8 SING BURI                     2596     818.              127              402\n 9 CHAI NAT                      3781    2485.              200              422\n10 SARABURI                      4229    3483.               69              628\n# ℹ 67 more rows\n# ℹ 40 more variables: Drugs_Cases_2019 &lt;dbl&gt;, Drugs_Cases_2020 &lt;dbl&gt;,\n#   Drugs_Cases_2021 &lt;dbl&gt;, Drugs_Cases_2022 &lt;dbl&gt;, TotalDensity &lt;dbl&gt;,\n#   Drugs_Cases_Per_Km2_2017 &lt;dbl&gt;, Drugs_Cases_Per_Km2_2018 &lt;dbl&gt;,\n#   Drugs_Cases_Per_Km2_2019 &lt;dbl&gt;, Drugs_Cases_Per_Km2_2020 &lt;dbl&gt;,\n#   Drugs_Cases_Per_Km2_2021 &lt;dbl&gt;, Drugs_Cases_Per_Km2_2022 &lt;dbl&gt;,\n#   Rank_TotalCases &lt;int&gt;, Rank_TotalDensity &lt;int&gt;, …\n\n\nIn our analysis, we rely on the P_ii_sim (simulated p-values) because they provide a robust measure of the statistical significance of local clusters. These simulated p-values help us determine whether observed clusters are significant or could have occurred by random chance. This is especially important when running multiple simulations (in this case, 1000) to ensure the reliability of our results.\n\n\n\n\n\n\nNote\n\n\n\nWhen to use median and mean?\nIn our analysis, we rely on the P_ii_sim (simulated p-values) because they provide a robust measure of the statistical significance of local clusters. These simulated p-values help us determine whether observed clusters are significant or could have occurred by random chance. This is especially important when running multiple simulations (in this case, 1000) to ensure the reliability of our results. Hence we check for the skewness and use median.\n\n\n\n# Assuming LISA_TotalDensity contains a column named 'skewness'\n# Create a histogram of the skewness values\nggplot(LISA_TotalDensity, aes(x = skewness)) +\n  geom_histogram(bins = 30, fill = \"blue\", alpha = 0.7) +\n  labs(title = \"Histogram of Skewness Values\", x = \"Skewness\", y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Calculate mean and median of the skewness values\nmean_skewness &lt;- mean(LISA_TotalDensity$skewness, na.rm = TRUE)\nmedian_skewness &lt;- median(LISA_TotalDensity$skewness, na.rm = TRUE)\n\n# Display the mean and median skewness\ncat(\"Mean Skewness: \", mean_skewness, \"\\n\")\n\nMean Skewness:  -1.24739 \n\ncat(\"Median Skewness: \", median_skewness, \"\\n\")\n\nMedian Skewness:  -2.188325 \n\n# Determine which measure to use for clustering\nif (abs(median_skewness) &gt; 0.1) {\n  cat(\"Use Median for clustering based on skewness.\\n\")\n} else {\n  cat(\"Use Mean for clustering based on skewness.\\n\")\n}\n\nUse Median for clustering based on skewness.\n\n\nSince there is a huge skewness, we will use median and not mean for analysis!\n\n\n7.1.2 Visualizing the clusters\nIn this part of the analysis, we are examining Local Moran’s I, which helps us identify where drug-related incidents in Thailand are spatially clustered at the local level. Unlike Global Moran’s I, which gives us an overall sense of spatial autocorrelation across the entire dataset, Local Moran’s I zooms in on individual provinces. It reveals whether specific provinces are surrounded by others with similar (high-high or low-low) or dissimilar (high-low or low-high) patterns of drug cases.\nHigh-High and Low-Low Clustering\n\nHigh-High Clusters: These are provinces where a high number of drug-related incidents are clustered with neighboring provinces that also have high numbers. This indicates hotspots of drug activity, which are critical for public health officials and policymakers to target interventions. These areas are experiencing a concentrated issue that may require urgent attention, such as increased law enforcement or public health campaigns.\nLow-Low Clusters: On the other hand, low-low clusters occur where provinces with low drug-related incidents are surrounded by others that also report low numbers. These areas are typically not a cause for immediate concern but might reflect regions that could benefit from maintaining current preventive measures.\nHigh-Low and Low-High: These are areas where the province’s drug case count contrasts with its neighbors (e.g., a high number of incidents surrounded by low-incident provinces). These outliers may indicate regions where drug problems are emerging or where prevention strategies are not uniform across regions.\n\nThe Importance of Statistical Significance (P_ii_sim)\nThe significance value, represented by P_ii_sim, plays a crucial role in determining whether these local clusters are statistically significant or just random noise. In our case, we are considering clusters as significant if their p-value is less than 0.05.\n\nSignificant Clusters: If a cluster is significant, it means that the observed spatial pattern (whether it’s high-high, low-low, etc.) is unlikely to have occurred by chance. These are the clusters that demand the most attention, as they reflect genuine patterns in the spatial distribution of drug cases.\nNon-Significant Clusters: These clusters, on the other hand, may not represent real patterns and could have occurred randomly. They are less important for immediate action and should be interpreted with caution.\n\nBy visualizing both the Local Moran’s I and the corresponding p-values, we can visually assess which provinces exhibit significant spatial patterns of clustering. The side-by-side maps allow us to see:\n\nWhere high-high and low-low clusters are happening (Local Moran’s I map).\nWhich of these clusters are statistically significant (P-value map).\n\nThis combination of local spatial autocorrelation and significance testing helps us prioritize where to focus resources and interventions. It enables policymakers to target areas with strong evidence of clustering and take proactive measures in provinces where drug-related issues are concentrated.\n\nLISA_TotalDensity &lt;- LISA_TotalDensity %&gt;%\n  mutate(significant = ifelse(p_ii_sim &lt; 0.05, \"Significant\", \"Not Significant\"))\n\n# Create map for local Moran's \nmap1 &lt;- tm_shape(LISA_TotalDensity) +  # Use the spatial data frame\n  tm_fill(\"median\", title = \"Local Moran's I\") +  # Change to the relevant column for local Moran's I\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6, 8)) +\n  tm_layout(main.title = \"Local Moran's I of TotalDensity\",\n            main.title.size = 0.8)\n\n# Create map for p-value of local Moran's I\nmap2 &lt;- tm_shape(LISA_TotalDensity) +\n  tm_fill(\"p_ii_sim\",  # Change to your p-value column\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"),\n          title = \"P-Value of Local Moran's I\") + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"P-Value of Local Moran's I\",\n            main.title.size = 0.8)\n\n# Arrange the maps side by side\ntmap_arrange(map1, map2, ncol = 2)\n\n\n\n\n\n\n\n\nThe side-by-side maps display the Local Moran’s I clustering (left) and the corresponding p-values for significance (right) of drug-related incidents across provinces in Thailand.\nOn the Local Moran’s I map, we can observe areas of high-high clustering, such as in the eastern regions, indicating provinces where drug cases are concentrated and surrounded by similarly affected provinces. Conversely, low-low clusters, seen in some northern and southern regions, suggest areas with low drug case densities surrounded by similarly low-density provinces. There are also some high-low and low-high outliers, which might represent emerging drug-related issues or unusual distribution patterns.\nHowever, the P-value map reveals that many of these clusters are marked as not significant (in darker orange). This suggests that although spatial patterns appear in the Local Moran’s I map, they may not be statistically significant. To focus the analysis on reliable clusters, it would be useful to filter out these non-significant areas and concentrate only on the significant clusters (those with p-values below 0.05), which will provide a clearer picture of where interventions are truly needed.\nBy filtering out the non-significant areas, we can better prioritize the regions where statistically significant spatial clustering of drug cases occurs, allowing for more targeted and data-driven policy measures.\n\n# Filter significant local Moran's I results\nLISA_TotalDensity_Sig &lt;- LISA_TotalDensity %&gt;%\n  filter(p_ii_sim &lt; 0.05)\n\n# Create the map\nmap &lt;- tm_shape(LISA_TotalDensity) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  tm_shape(LISA_TotalDensity_Sig) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_fill(\"median\", \n          popup.vars = c(\"Province\" = \"Province\", \"P-value\" = \"p_ii_sim\", \"Cluster\" = \"median\",\"Drug Case Density (Km^2)\" = \"TotalDensity\")) +  # Corrected popup.vars\n  tm_borders(alpha = 0.4) +\n  tm_layout(title=\"Drug Use Per Density of Thailand Province with Significant Clusters\")\n\n# Print the map\nmap\n\n\n\n\n\nThis map highlights the significant clusters of Local Moran’s I after filtering out the non-significant regions. The provinces that remain on this map are those where the spatial clustering of drug-related incidents is statistically significant, meaning that these areas demonstrate true spatial patterns that are not likely to have occurred by chance.\n\nChiang Mai and a few neighboring provinces in the north exhibit low-low clustering (green), suggesting these regions have lower densities of drug-related cases and are surrounded by similarly low-case provinces. This could indicate effective control measures or a less severe drug issue in this part of the country.\nBangkok and surrounding provinces (in red) show high-high clustering, indicating that these areas are experiencing significantly higher concentrations of drug-related cases, and they are surrounded by similarly affected provinces. These regions are likely hotspots and would be priority areas for intervention strategies, such as increased law enforcement or public health outreach.\nA few provinces in the northeastern and northern regions (yellow) display low-high clusters, where relatively low case densities are adjacent to provinces with higher case densities. These areas could represent transitional zones or emerging problem areas, which may require monitoring to prevent future escalation.\n\nThis focused map allows policymakers to concentrate on the most critical regions, ensuring that resources are directed to areas where drug-related clustering is a statistically significant concern.\n\n\n7.1.3 Analysis On Province with Signifcant Clusters\n\n# Drop the geometry and keep only the relevant columns\nLISA_TotalDensity_Sig_Table &lt;- LISA_TotalDensity_Sig %&gt;%\n  st_drop_geometry() %&gt;%  # This removes the geometry column\n  select(Province, p_ii_sim, median, TotalDensity)  # Select the required columns\n\n# Print the resulting table\n# Create the bar chart\nggplot(LISA_TotalDensity_Sig_Table, aes(x = reorder(Province, -TotalDensity), y = TotalDensity, fill = as.factor(median))) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    title = \"Total Drug Case Density by Province with Clusters\",\n    x = \"Province\",\n    y = \"Drug Case Density (Km^2)\",\n    fill = \"Cluster\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nThe bar chart visualizes Drug Case Density (Km²) by Province, with clusters categorized as High-High (blue), High-Low (green), and Low-Low (red).\nKey Insights:\n\nUrban Hotspots (High-High):\n\nProvinces like Bangkok, Samut Prakan, and Nonthaburi exhibit the highest drug case densities, suggesting a concentration of drug-related issues in highly urbanized areas.\n\nLocalized Issues (High-Low):\n\nKhon Kaen and Phrae show elevated drug cases despite being surrounded by lower-risk areas, indicating potential localized problems or emerging threats.\n\nWidespread Low Risk (Low-Low):\n\nMost provinces (e.g., Phichit, Uttaradit, Tak) report low drug case density, reflecting minimal or well-controlled drug-related activities.\n\n\nImplications:\n\nTargeted Interventions: Focus efforts in Bangkok and neighboring urban areas to address high-risk zones.\nMonitoring Emerging Issues: Keep an eye on High-Low clusters to prevent escalation in localized areas.\nPreventive Measures: Maintain efforts in Low-Low provinces to sustain low drug activity levels.\n\nThis chart underscores the need for geographically tailored strategies, with a stronger focus on urban centers and potential early interventions in emerging high-risk areas."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#ehsa-conclusion",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#ehsa-conclusion",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "8.3 EHSA Conclusion",
    "text": "8.3 EHSA Conclusion\nThe analysis of significant clusters across the years reveals a stable spatial distribution of drug-related incidents. The persistent hotspots in Bangkok and surrounding areas are concerning and point to the need for continued or enhanced interventions. The low clustering in northern provinces is a positive indicator of stable regions with lower drug incidents, but monitoring should continue to ensure these areas remain under control."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#global-local-temporal-integration-overview",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#global-local-temporal-integration-overview",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "9.1 Global-Local-Temporal Integration Overview",
    "text": "9.1 Global-Local-Temporal Integration Overview\n\n\n\n\n\n\n\nMethod\nPurpose\n\n\n\n\nGlobal Moran’s I\nMeasures overall clustering to reveal if drug cases are dispersed or concentrated.\n\n\nLISA (Local Moran’s I)\nIdentifies clusters and outliers, highlighting provinces with high or low activity.\n\n\nHSCA\nClassifies regions into high-high hotspots or low-low stable areas and tracks shifts over time.\n\n\n\nThese methods together answer:\n\nGlobal Trends: Are drug cases concentrated or spread out across Thailand?\nLocal Insights: Which provinces are contributing to these patterns?\nTemporal Dynamics: How are these trends shifting over time?"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#high-risk-provinces-identified",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#high-risk-provinces-identified",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "9.3 High-Risk Provinces Identified",
    "text": "9.3 High-Risk Provinces Identified\n\n\n\n\n\n\n\n\nCategory\nProvinces\nDescription\n\n\n\n\nPersistent Hotspots\nBangkok, Samut Prakan, Nonthaburi\nHigh-risk areas with consistent drug activity flagged by both LISA and HSCA.\n\n\nEmerging Risks\nPathum Thani, Chachoengsao, Khon Kaen, Phrae\nAreas showing fluctuating or increasing drug density, needing monitoring.\n\n\nStable Low-Risk Areas\nPhichit, Tak, Sukhothai\nConsistently low-risk, serving as models for prevention strategies."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#conclusion-and-next-steps-for-thailand",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#conclusion-and-next-steps-for-thailand",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "9.4 Conclusion and Next Steps for Thailand",
    "text": "9.4 Conclusion and Next Steps for Thailand\nBangkok and Samut Prakan remain central to Thailand’s drug-related challenges, with new risks emerging in Khon Kaen and Phrae. Immediate interventions and proactive monitoring are essential.\n\n9.4.1. Key Recommendations\n\n\n\n\n\n\n\nAction\nDetails\n\n\n\n\nUrban Hotspot Interventions\nStrengthen law enforcement, raise awareness, and expand treatment programs in Bangkok, Samut Prakan, and Nonthaburi.\n\n\nMonitoring Emerging Risks\nDeploy early interventions in Pathum Thani and Khon Kaen to prevent escalation.\n\n\nSustaining Prevention Strategies\nMaintain existing strategies in Phichit and Tak to avoid future outbreaks.\n\n\nDynamic Policy Adjustments\nUse real-time data to continuously refine policies and ensure efficient resource allocation."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#below-is-a-refined-version-of-your-content-using-tables-and-concise-paragraphs-to-reduce-redundancy-while-maintaining-clarity.",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#below-is-a-refined-version-of-your-content-using-tables-and-concise-paragraphs-to-reduce-redundancy-while-maintaining-clarity.",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Below is a refined version of your content, using tables and concise paragraphs to reduce redundancy while maintaining clarity.",
    "text": "Below is a refined version of your content, using tables and concise paragraphs to reduce redundancy while maintaining clarity."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#merging-global-local-and-temporal-analysis-for-comprehensive-insights-1",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#merging-global-local-and-temporal-analysis-for-comprehensive-insights-1",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "9.0 Merging Global, Local, and Temporal Analysis for Comprehensive Insights",
    "text": "9.0 Merging Global, Local, and Temporal Analysis for Comprehensive Insights\nComprehensive insight into drug-related issues in Thailand requires the integration of Global Moran’s I, Local Indicators of Spatial Association (LISA), and Hot Spot Cluster Analysis (HSCA). This combined approach captures both macro- and micro-level trends while identifying temporal shifts and emerging risks."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#global-local-temporal-integration-overview-1",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#global-local-temporal-integration-overview-1",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "9.1 Global-Local-Temporal Integration Overview",
    "text": "9.1 Global-Local-Temporal Integration Overview\n\n\n\n\n\n\n\nMethod\nPurpose\n\n\n\n\nGlobal Moran’s I\nMeasures overall clustering to reveal if drug cases are dispersed or concentrated.\n\n\nLISA (Local Moran’s I)\nIdentifies clusters and outliers, highlighting provinces with high or low activity.\n\n\nHSCA\nClassifies regions into high-high hotspots or low-low stable areas and tracks shifts over time.\n\n\n\nThese methods together answer:\n\nGlobal Trends: Are drug cases concentrated or spread out across Thailand?\nLocal Insights: Which provinces are contributing to these patterns?\nTemporal Dynamics: How are these trends shifting over time?"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#merging-insights-for-holistic-understanding-1",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#merging-insights-for-holistic-understanding-1",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "9.2 Merging Insights for Holistic Understanding",
    "text": "9.2 Merging Insights for Holistic Understanding\n\n9.2.1 Spatial and Temporal Consistency\n\nGlobal Moran’s I shows persistent clustering, suggesting entrenched spatial patterns of drug-related issues.\nLISA confirms Bangkok and neighboring provinces form high-high clusters, while northern provinces like Chiang Mai remain low-risk.\nHSCA analysis supports this, with urban centers in central Thailand reporting sustained drug activity from 2017 to 2022, while northern regions maintain stable, low-risk conditions.\n\n\n\n9.2.2 Emerging Hotspots and Coldspots\n\nNo new hotspots have emerged outside of known high-risk areas, with activity concentrated near Bangkok.\nNorthern provinces show stable low incident rates, confirming the effectiveness of their preventive strategies."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#high-risk-provinces-identified-1",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise2.html#high-risk-provinces-identified-1",
    "title": "Take Home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "9.3 High-Risk Provinces Identified",
    "text": "9.3 High-Risk Provinces Identified\n\n\n\n\n\n\n\n\nCategory\nProvinces\nDescription\n\n\n\n\nPersistent Hotspots\nBangkok, Samut Prakan, Nonthaburi\nHigh-risk areas with consistent drug activity flagged by both LISA and HSCA.\n\n\nEmerging Risks\nPathum Thani, Chachoengsao, Khon Kaen, Phrae\nAreas showing fluctuating or increasing drug density, needing monitoring.\n\n\nStable Low-Risk Areas\nPhichit, Tak, Sukhothai\nConsistently low-risk, serving as models for prevention strategies."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_9/Hands_On_Exercise9.html",
    "href": "Hands_On_Exercises/Hands_On_Exercise_9/Hands_On_Exercise9.html",
    "title": "Hands-On Exercise 9",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on how to delineate homogeneous region by using geographically referenced multivariate data. There are two major analysis, namely:\n\nhierarchical cluster analysis; and\nspatially constrained cluster analysis.\n\n\n\nBy the end of this hands-on exercise, you will able:\n\nto convert GIS polygon data into R’s simple feature data.frame by using appropriate functions of sf package of R;\nto convert simple feature data.frame into R’s SpatialPolygonDataFrame object by using appropriate sf of package of R;\nto perform custer analysis by using hclust() of Base R;\nto perform spatially constrained cluster analysis using skater() of Base R; and\nto visualise the analysis output by using ggplot2 and tmap package.\n\n\n\n\n\n\n\nIn geobusiness and spatial policy, it is a common practice to delineate the market or planning area into homogeneous regions by using multivariate data. In this hands-on exercise, we are interested to delineate Shan State, Myanmar into homogeneous regions by using multiple Information and Communication technology (ICT) measures, namely: Radio, Television, Land line phone, Mobile phone, Computer, and Internet at home.\n\n\n\n\nTwo data sets will be used in this study. They are:\n\nMyanmar Township Boundary Data (i.e. myanmar_township_boundaries) : This is a GIS data in ESRI shapefile format. It consists of township boundary information of Myanmar. The spatial data are captured in polygon features.\nShan-ICT.csv: This is an extract of The 2014 Myanmar Population and Housing Census Myanmar at the township level.\n\n\n\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\nThe R packages needed for this exercise are as follows:\n\nSpatial data handling\n\nsf, rgdal and spdep\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\nMultivariate data visualisation and analysis\n\ncoorplot, ggpubr, and heatmaply\n\nCluster analysis\n\ncluster\nClustGeo\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)\n\nNote: With tidyverse, we do not have to install readr, ggplot2 and dplyr packages separately. In fact, tidyverse also installs other very useful R packages such as tidyr.\n\n\n\n\n\n\nIn this section, you will import Myanmar Township Boundary GIS data and its associated attrbiute table into R environment.\nThe Myanmar Township Boundary GIS data is in ESRI shapefile format. It will be imported into R environment by using the st_read() function of sf.\nThe code chunks used are shown below:\n\nshan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"myanmar_township_boundaries\") %&gt;%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_9\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\nThe imported township boundary object is called shan_sf. It is saved in simple feature data.frame format. We can view the content of the newly created shan_sf simple features data.frame by using the code chunk below.\n\nshan_sf\n\nSimple feature collection with 55 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n             ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1  Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2  Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3  Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4  Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5  Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6  Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7  Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8  Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9  Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                         geometry\n1  MULTIPOLYGON (((96.96001 23...\n2  MULTIPOLYGON (((96.7731 21....\n3  MULTIPOLYGON (((96.78483 21...\n4  MULTIPOLYGON (((96.49518 20...\n5  MULTIPOLYGON (((96.66306 24...\n6  MULTIPOLYGON (((96.49518 20...\n7  MULTIPOLYGON (((97.14738 19...\n8  MULTIPOLYGON (((96.94981 22...\n9  MULTIPOLYGON (((96.75648 22...\n10 MULTIPOLYGON (((96.95498 22...\n\n\nNotice that sf.data.frame is conformed to Hardy Wickham’s tidy framework.\nSince shan_sf is conformed to tidy framework, we can also glimpse() to reveal the data type of it’s fields.\n\nglimpse(shan_sf)\n\nRows: 55\nColumns: 7\n$ ST       &lt;chr&gt; \"Shan (North)\", \"Shan (South)\", \"Shan (South)\", \"Shan (South)…\n$ ST_PCODE &lt;chr&gt; \"MMR015\", \"MMR014\", \"MMR014\", \"MMR014\", \"MMR015\", \"MMR014\", \"…\n$ DT       &lt;chr&gt; \"Mongmit\", \"Taunggyi\", \"Taunggyi\", \"Taunggyi\", \"Mongmit\", \"Ta…\n$ DT_PCODE &lt;chr&gt; \"MMR015D008\", \"MMR014D001\", \"MMR014D001\", \"MMR014D001\", \"MMR0…\n$ TS       &lt;chr&gt; \"Mongmit\", \"Pindaya\", \"Ywangan\", \"Pinlaung\", \"Mabein\", \"Kalaw…\n$ TS_PCODE &lt;chr&gt; \"MMR015017\", \"MMR014006\", \"MMR014007\", \"MMR014009\", \"MMR01501…\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((96.96001 23..., MULTIPOLYGON (((…\n\n\n\n\n\nThe csv file will be import using read_csv function of readr package.\nThe code chunks used are shown below:\n\nict &lt;- read_csv (\"data/aspatial/Shan-ICT.csv\")\n\nRows: 55 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): District Pcode, District Name, Township Pcode, Township Name\ndbl (7): Total households, Radio, Television, Land line phone, Mobile phone,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe imported InfoComm variables are extracted from The 2014 Myanmar Population and Housing Census Myanmar. The attribute data set is called ict. It is saved in R’s * tibble data.frame* format.\nThe code chunk below reveal the summary statistics of ict data.frame.\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\nThere are a total of eleven fields and 55 observation in the tibble data.frame.\n\n\n\nThe unit of measurement of the values are number of household. Using these values directly will be bias by the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\nIn order to overcome this problem, we will derive the penetration rate of each ICT variable by using the code chunk below.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nLet us review the summary statistics of the newly derived penetration rates using the code chunk below.\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985  \n\n\nNotice that six new fields have been added into the data.frame. They are RADIO_PR, TV_PR, LLPHONE_PR, MPHONE_PR, COMPUTER_PR, and INTERNET_PR.\n\n\n\n\n\n\nWe can plot the distribution of the variables (i.e. Number of households with radio) by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\nHistogram is useful to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution)\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\n\n\n\nBoxplot is useful to detect if there are outliers.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\n\n\n\n\nNext, we will also plotting the distribution of the newly derived variables (i.e. Radio penetration rate) by using the code chunk below.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\n\n\n\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\n\n\n\n\nIn the figure below, multiple histograms are plotted to reveal the distribution of the selected variables in the ict_derived data.frame.\n\n\n\n\n\n\nNote\n\n\n\n**What can you observed from the distributions reveal in the histogram and boxplot.\nHistogram Observations:**\n\nDistribution Shape: The histogram appears slightly right-skewed, meaning there are more data points concentrated towards the lower values, with fewer higher values extending towards the right tail.\nModal Range: The most frequent observations lie between 200 and 300, indicating that this range contains the majority of the data points.\nSpread: There is a relatively wide spread, with values ranging approximately from 0 to 500.\nPotential Outliers: The presence of a few bars towards the higher end (above 400) suggests there might be some extreme values, though these are less frequent.\n\nBoxplot Observations:\n\nCentral Tendency: The median (thick horizontal line in the box) lies around 200, indicating that half of the data points are below this value.\nInterquartile Range (IQR): The box represents the IQR, with most data points lying between approximately 150 and 300.\nOutlier: The black dot beyond the whisker on the right side indicates a potential outlier—a value that is significantly higher than the rest of the distribution.\nSymmetry: The boxplot suggests the data is right-skewed, with a longer whisker on the right side, matching the histogram’s indication of higher values being less frequent but present.\n\nSummary:\nThe RADIO_PR variable shows a right-skewed distribution with a majority of values centered around 200-300. The boxplot confirms the presence of at least one outlier and indicates that the data might not be perfectly symmetrical, with some values extending further towards the higher range. This suggests that while most observations are within a typical range, there are a few exceptionally high values worth investigating further.\n\n\nIn the figure below, multiple histograms are plotted to reveal the distribution of the selected variables in the ict_derived data.frame.\n\nradio &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv &lt;- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone &lt;- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone &lt;- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer &lt;- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet &lt;- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore we can prepare the choropleth map, we need to combine both the geospatial data object (i.e. shan_sf) and aspatial data.frame object (i.e. ict_derived) into one. This will be performed by using the left_join function of dplyr package. The shan_sf simple feature data.frame will be used as the base data object and the ict_derived data.frame will be used as the join table.\nThe code chunks below is used to perform the task. The unique identifier used to join both data objects is TS_PCODE.\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \nwrite_rds(shan_sf, \"data/rds/shan_sf.rds\")\n\nthe message above shows that TS_CODE field is the common field used to perform the left-join.\nIt is important to note that there is no new output data been created. Instead, the data fields from ict_derived data frame are now updated into the data frame of shan_sf.\n\nshan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\n\n\n\n\nTo have a quick look at the distribution of Radio penetration rate of Shan State at township level, a choropleth map will be prepared.\nThe code chunks below are used to prepare the choroplethby using the qtm() function of tmap package.\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\n\n\n\n\nIn order to reveal the distribution shown in the choropleth map above are bias to the underlying total number of households at the townships, we will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) by using the code chunk below.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\n\n\n\n\n\n\n\nNotice that the choropleth maps above clearly show that townships with relatively larger number ot households are also showing relatively higher number of radio ownership.\nNow let us plot the choropleth maps showing the dsitribution of total number of households and Radio penetration rate by using the code chunk below.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat is the difference between the two maps?\nKey Differences:\n\n\n\n\n\n\n\n\nAspect\n1st Code Block (tmap_arrange)\n2nd Code Block (tm_facets)\n\n\n\n\nLayout\nTwo independent maps side-by-side\nSynchronized maps in facets\n\n\nInteractivity\nNo interaction between maps\nMaps share zoom and pan behavior\n\n\nLegends\nSeparate for each map\nSingle, unified legend placement\n\n\nCode Complexity\nRequires creating individual maps\nSingle map object with multiple facets\n\n\nUse Case\nGood for static side-by-side comparison\nIdeal for interactive exploration\n\n\n\nWhen to Use Which?\n\ntmap_arrange(): Use when you want two independent maps for comparison, each with its own settings and legends.\ntm_facets(): Use when you need synchronized maps with a unified experience, such as for interactive dashboards.\n\n\n\n\n\n\n\n\nBefore we perform cluster analysis, it is important for us to ensure that the cluster variables are not highly correlated.\nIn this section, you will learn how to use corrplot.mixed() function of corrplot package to visualise and analyse the correlation of the input variables.\n\ncluster_vars.cor = cor(ict_derived[,12:17])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nThe correlation plot above shows that COMPUTER_PR and INTERNET_PR are highly correlated. This suggest that only one of them should be used in the cluster analysis instead of both.\n\n\n\nIn this section, you will learn how to perform hierarchical cluster analysis. The analysis consists of four major steps:\n\n\nThe code chunk below will be used to extract the clustering variables from the shan_sf simple feature object into data.frame.\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the final clustering variables list does not include variable INTERNET_PR because it is highly correlated with variable COMPUTER_PR.\nNext, we need to change the rows by township name instead of row number by using the code chunk below\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the row number has been replaced into the township name.\nNow, we will delete the TS.x field by using the code chunk below.\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n\n\nIn general, multiple variables will be used in cluster analysis. It is not unusual their values range are different. In order to avoid the cluster analysis result is baised to clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis.\n\n\n\nIn the code chunk below, normalize() of heatmaply package is used to stadardisation the clustering variables by using Min-Max method. The summary() is then used to display the summary statistics of the standardised clustering variables.\n\nshan_ict.std &lt;- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\nNotice that the values range of the Min-max standardised clustering variables are 0-1 now.\n\n\n\nZ-score standardisation can be performed easily by using scale() of Base R. The code chunk below will be used to stadardisation the clustering variables by using Z-score method.\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\nNotice the mean and standard deviation of the Z-score standardised clustering variables are 0 and 1 respectively.\nNote: describe() of psych package is used here instead of summary() of Base R because the earlier provides standard deviation.\nWarning: Z-score standardisation method should only be used if we would assume all variables come from some normal distribution.\n\n\n\nBeside reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphical.\nThe code chunk below plot the scaled Radio_PR field.\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nWhat statistical conclusion can you draw from the histograms above?\n1. Raw Values without Standardization (Left Histogram):\n\nThe distribution of the raw values is right-skewed, with more observations concentrated towards the lower values and fewer observations at the higher end (above 400).\nThe spread is large, with values ranging between 0 and 500, suggesting that the raw data may contain large variability or outliers.\n\n2. Min-Max Standardization (Center Histogram):\n\nMin-Max standardization scales the data to a range between 0 and 1.\nThe shape of the distribution remains similar to the original (right-skewed), but the values are now confined within the standardized range.\nThis transformation preserves the relative spacing between data points but makes it easier to compare across datasets that might have different ranges.\n\n3. Z-Score Standardization (Right Histogram):\n\nZ-score standardization centers the data around a mean of 0 and standard deviation of 1.\nThe distribution is now scaled such that most values fall between -2 and 2.\nThe shape of the distribution is again maintained, but this transformation highlights how far observations deviate from the mean, making it easier to detect outliers or extreme values (e.g., the rightmost bar suggests potential outliers).\n\n\n\n\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\nIn R, many packages provide functions to calculate distance matrix. We will compute the proximity matrix by using dist() of R.\ndist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using euclidean method.\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\n\nThe code chunk below can then be used to list the content of proxmat for visual inspection.\n\nproxmat\n\n             Mongmit   Pindaya   Ywangan  Pinlaung    Mabein     Kalaw\nPindaya    171.86828                                                  \nYwangan    381.88259 257.31610                                        \nPinlaung    57.46286 208.63519 400.05492                              \nMabein     263.37099 313.45776 529.14689 312.66966                    \nKalaw      160.05997 302.51785 499.53297 181.96406 198.14085          \nPekon       59.61977 117.91580 336.50410  94.61225 282.26877 211.91531\nLawksawk   140.11550 204.32952 432.16535 192.57320 130.36525 140.01101\nNawnghkio   89.07103 180.64047 377.87702 139.27495 204.63154 127.74787\nKyaukme    144.02475 311.01487 505.89191 139.67966 264.88283  79.42225\nMuse       563.01629 704.11252 899.44137 571.58335 453.27410 412.46033\nLaihka     141.87227 298.61288 491.83321 101.10150 345.00222 197.34633\nMongnai    115.86190 258.49346 422.71934  64.52387 358.86053 200.34668\nMawkmai    434.92968 437.99577 397.03752 398.11227 693.24602 562.59200\nKutkai      97.61092 212.81775 360.11861  78.07733 340.55064 204.93018\nMongton    192.67961 283.35574 361.23257 163.42143 425.16902 267.87522\nMongyai    256.72744 287.41816 333.12853 220.56339 516.40426 386.74701\nMongkaing  503.61965 481.71125 364.98429 476.29056 747.17454 625.24500\nLashio     251.29457 398.98167 602.17475 262.51735 231.28227 106.69059\nMongpan    193.32063 335.72896 483.68125 192.78316 301.52942 114.69105\nMatman     401.25041 354.39039 255.22031 382.40610 637.53975 537.63884\nTachileik  529.63213 635.51774 807.44220 555.01039 365.32538 373.64459\nNarphan    406.15714 474.50209 452.95769 371.26895 630.34312 463.53759\nMongkhet   349.45980 391.74783 408.97731 305.86058 610.30557 465.52013\nHsipaw     118.18050 245.98884 388.63147  76.55260 366.42787 212.36711\nMonghsat   214.20854 314.71506 432.98028 160.44703 470.48135 317.96188\nMongmao    242.54541 402.21719 542.85957 217.58854 384.91867 195.18913\nNansang    104.91839 275.44246 472.77637  85.49572 287.92364 124.30500\nLaukkaing  568.27732 726.85355 908.82520 563.81750 520.67373 427.77791\nPangsang   272.67383 428.24958 556.82263 244.47146 418.54016 224.03998\nNamtu      179.62251 225.40822 444.66868 170.04533 366.16094 307.27427\nMonghpyak  177.76325 221.30579 367.44835 222.20020 212.69450 167.08436\nKonkyan    403.39082 500.86933 528.12533 365.44693 613.51206 444.75859\nMongping   265.12574 310.64850 337.94020 229.75261 518.16310 375.64739\nHopong     136.93111 223.06050 352.85844  98.14855 398.00917 264.16294\nNyaungshwe  99.38590 216.52463 407.11649 138.12050 210.21337  95.66782\nHsihseng   131.49728 172.00796 342.91035 111.61846 381.20187 287.11074\nMongla     384.30076 549.42389 728.16301 372.59678 406.09124 260.26411\nHseni      189.37188 337.98982 534.44679 204.47572 213.61240  38.52842\nKunlong    224.12169 355.47066 531.63089 194.76257 396.61508 273.01375\nHopang     281.05362 443.26362 596.19312 265.96924 368.55167 185.14704\nNamhkan    386.02794 543.81859 714.43173 382.78835 379.56035 246.39577\nKengtung   246.45691 385.68322 573.23173 263.48638 219.47071  88.29335\nLangkho    164.26299 323.28133 507.78892 168.44228 253.84371  67.19580\nMonghsu    109.15790 198.35391 340.42789  80.86834 367.19820 237.34578\nTaunggyi   399.84278 503.75471 697.98323 429.54386 226.24011 252.26066\nPangwaun   381.51246 512.13162 580.13146 356.37963 523.44632 338.35194\nKyethi     202.92551 175.54012 287.29358 189.47065 442.07679 360.17247\nLoilen     145.48666 293.61143 469.51621  91.56527 375.06406 217.19877\nManton     430.64070 402.42888 306.16379 405.83081 674.01120 560.16577\nMongyang   309.51302 475.93982 630.71590 286.03834 411.88352 233.56349\nKunhing    173.50424 318.23811 449.67218 141.58836 375.82140 197.63683\nMongyawng  214.21738 332.92193 570.56521 235.55497 193.49994 173.43078\nTangyan    195.92520 208.43740 324.77002 169.50567 448.59948 348.06617\nNamhsan    237.78494 228.41073 286.16305 214.33352 488.33873 385.88676\n               Pekon  Lawksawk Nawnghkio   Kyaukme      Muse    Laihka\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk   157.51129                                                  \nNawnghkio  113.15370  90.82891                                        \nKyaukme    202.12206 186.29066 157.04230                              \nMuse       614.56144 510.13288 533.68806 434.75768                    \nLaihka     182.23667 246.74469 211.88187 128.24979 526.65211          \nMongnai    151.60031 241.71260 182.21245 142.45669 571.97975 100.53457\nMawkmai    416.00669 567.52693 495.15047 512.02846 926.93007 429.96554\nKutkai     114.98048 224.64646 147.44053 170.93318 592.90743 144.67198\nMongton    208.14888 311.07742 225.81118 229.28509 634.71074 212.07320\nMongyai    242.52301 391.26989 319.57938 339.27780 763.91399 264.13364\nMongkaing  480.23965 625.18712 546.69447 586.05094 995.66496 522.96309\nLashio     303.80011 220.75270 230.55346 129.95255 313.15288 238.64533\nMongpan    243.30037 228.54223 172.84425 110.37831 447.49969 210.76951\nMatman     368.25761 515.39711 444.05061 505.52285 929.11283 443.25453\nTachileik  573.39528 441.82621 470.45533 429.15493 221.19950 549.08985\nNarphan    416.84901 523.69580 435.59661 420.30003 770.40234 392.32592\nMongkhet   342.08722 487.41102 414.10280 409.03553 816.44931 324.97428\nHsipaw     145.37542 249.35081 176.09570 163.95741 591.03355 128.42987\nMonghsat   225.64279 352.31496 289.83220 253.25370 663.76026 158.93517\nMongmao    293.70625 314.64777 257.76465 146.09228 451.82530 185.99082\nNansang    160.37607 188.78869 151.13185  60.32773 489.35308  78.78999\nLaukkaing  624.82399 548.83928 552.65554 428.74978 149.26996 507.39700\nPangsang   321.81214 345.91486 287.10769 175.35273 460.24292 214.19291\nNamtu      165.02707 260.95300 257.52713 270.87277 659.16927 185.86794\nMonghpyak  190.93173 142.31691  93.03711 217.64419 539.43485 293.22640\nKonkyan    421.48797 520.31264 439.34272 393.79911 704.86973 351.75354\nMongping   259.68288 396.47081 316.14719 330.28984 744.44948 272.82761\nHopong     138.86577 274.91604 204.88286 218.84211 648.68011 157.48857\nNyaungshwe 139.31874 104.17830  43.26545 126.50414 505.88581 201.71653\nHsihseng   105.30573 257.11202 209.88026 250.27059 677.66886 175.89761\nMongla     441.20998 393.18472 381.40808 241.58966 256.80556 315.93218\nHseni      243.98001 171.50398 164.05304  81.20593 381.30567 204.49010\nKunlong    249.36301 318.30406 285.04608 215.63037 547.24297 122.68682\nHopang     336.38582 321.16462 279.84188 154.91633 377.44407 230.78652\nNamhkan    442.77120 379.41126 367.33575 247.81990 238.67060 342.43665\nKengtung   297.67761 209.38215 208.29647 136.23356 330.08211 258.23950\nLangkho    219.21623 190.30257 156.51662  51.67279 413.64173 160.94435\nMonghsu    113.84636 242.04063 170.09168 200.77712 633.21624 163.28926\nTaunggyi   440.66133 304.96838 344.79200 312.60547 250.81471 425.36916\nPangwaun   423.81347 453.02765 381.67478 308.31407 541.97887 351.78203\nKyethi     162.43575 317.74604 267.21607 328.14177 757.16745 255.83275\nLoilen     181.94596 265.29318 219.26405 146.92675 560.43400  59.69478\nManton     403.82131 551.13000 475.77296 522.86003 941.49778 458.30232\nMongyang   363.58788 363.37684 323.32123 188.59489 389.59919 229.71502\nKunhing    213.46379 278.68953 206.15773 145.00266 533.00162 142.03682\nMongyawng  248.43910 179.07229 220.61209 181.55295 422.37358 211.99976\nTangyan    167.79937 323.14701 269.07880 306.78359 736.93741 224.29176\nNamhsan    207.16559 362.84062 299.74967 347.85944 778.52971 273.79672\n             Mongnai   Mawkmai    Kutkai   Mongton   Mongyai Mongkaing\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai    374.50873                                                  \nKutkai      91.15307 364.95519                                        \nMongton    131.67061 313.35220 107.06341                              \nMongyai    203.23607 178.70499 188.94166 159.79790                    \nMongkaing  456.00842 133.29995 428.96133 365.50032 262.84016          \nLashio     270.86983 638.60773 289.82513 347.11584 466.36472 708.65819\nMongpan    178.09554 509.99632 185.18173 200.31803 346.39710 563.56780\nMatman     376.33870 147.83545 340.86349 303.04574 186.95158 135.51424\nTachileik  563.95232 919.38755 568.99109 608.76740 750.29555 967.14087\nNarphan    329.31700 273.75350 314.27683 215.97925 248.82845 285.65085\nMongkhet   275.76855 115.58388 273.91673 223.22828 104.98924 222.60577\nHsipaw      52.68195 351.34601  51.46282  90.69766 177.33790 423.77868\nMonghsat   125.25968 275.09705 154.32012 150.98053 127.35225 375.60376\nMongmao    188.29603 485.52853 204.69232 206.57001 335.61300 552.31959\nNansang     92.79567 462.41938 130.04549 199.58124 288.55962 542.16609\nLaukkaing  551.56800 882.51110 580.38112 604.66190 732.68347 954.11795\nPangsang   204.25746 484.14757 228.33583 210.77938 343.30638 548.40662\nNamtu      209.35473 427.95451 225.28268 308.71751 278.02761 525.04057\nMonghpyak  253.26470 536.71695 206.61627 258.04282 370.01575 568.21089\nKonkyan    328.82831 339.01411 310.60810 248.25265 287.87384 380.92091\nMongping   202.99615 194.31049 182.75266 119.86993  65.38727 257.18572\nHopong      91.53795 302.84362  73.45899 106.21031 124.62791 379.37916\nNyaungshwe 169.63695 502.99026 152.15482 219.72196 327.13541 557.32112\nHsihseng   142.36728 329.29477 128.21054 194.64317 162.27126 411.59788\nMongla     354.10985 686.88950 388.40984 411.06668 535.28615 761.48327\nHseni      216.81639 582.53670 229.37894 286.75945 408.23212 648.04408\nKunlong    202.92529 446.53763 204.54010 270.02165 299.36066 539.91284\nHopang     243.00945 561.24281 263.31986 273.50305 408.73288 626.17673\nNamhkan    370.05669 706.47792 392.48568 414.53594 550.62819 771.39688\nKengtung   272.28711 632.54638 279.19573 329.38387 460.39706 692.74693\nLangkho    174.67678 531.08019 180.51419 236.70878 358.95672 597.42714\nMonghsu     84.11238 332.07962  62.60859 107.04894 154.86049 400.71816\nTaunggyi   448.55282 810.74692 450.33382 508.40925 635.94105 866.21117\nPangwaun   312.13429 500.68857 321.80465 257.50434 394.07696 536.95736\nKyethi     210.50453 278.85535 184.23422 222.52947 137.79420 352.06533\nLoilen      58.41263 388.73386 131.56529 176.16001 224.79239 482.18190\nManton     391.54062 109.08779 361.82684 310.20581 195.59882  81.75337\nMongyang   260.39387 558.83162 285.33223 295.60023 414.31237 631.91325\nKunhing    110.55197 398.43973 108.84990 114.03609 238.99570 465.03971\nMongyawng  275.77546 620.04321 281.03383 375.22688 445.78964 700.98284\nTangyan    180.37471 262.66006 166.61820 198.88460 109.08506 348.56123\nNamhsan    218.10003 215.19289 191.32762 196.76188  77.35900 288.66231\n              Lashio   Mongpan    Matman Tachileik   Narphan  Mongkhet\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan    172.33279                                                  \nMatman     628.11049 494.81014                                        \nTachileik  311.95286 411.03849 890.12935                              \nNarphan    525.63854 371.13393 312.05193 760.29566                    \nMongkhet   534.44463 412.17123 203.02855 820.50164 217.28718          \nHsipaw     290.86435 179.52054 344.45451 576.18780 295.40170 253.80950\nMonghsat   377.86793 283.30992 313.59911 677.09508 278.21548 167.98445\nMongmao    214.23677 131.59966 501.59903 472.95568 331.42618 375.35820\nNansang    184.47950 144.77393 458.06573 486.77266 398.13308 360.99219\nLaukkaing  334.65738 435.58047 903.72094 325.06329 708.82887 769.06406\nPangsang   236.72516 140.23910 506.29940 481.31907 316.30314 375.58139\nNamtu      365.88437 352.91394 416.65397 659.56458 494.36143 355.99713\nMonghpyak  262.09281 187.85699 470.46845 444.04411 448.40651 462.63265\nKonkyan    485.51312 365.87588 392.40306 730.92980 158.82353 254.24424\nMongping   454.52548 318.47482 201.65224 727.08969 188.64567 113.80917\nHopong     345.31042 239.43845 291.84351 632.45718 294.40441 212.99485\nNyaungshwe 201.58191 137.29734 460.91883 445.81335 427.94086 417.08639\nHsihseng   369.00833 295.87811 304.02806 658.87060 377.52977 256.70338\nMongla     179.95877 253.20001 708.17595 347.33155 531.46949 574.40292\nHseni       79.41836 120.66550 564.64051 354.90063 474.12297 481.88406\nKunlong    295.23103 288.03320 468.27436 595.70536 413.07823 341.68641\nHopang     170.63913 135.62913 573.55355 403.82035 397.85908 451.51070\nNamhkan    173.27153 240.34131 715.42102 295.91660 536.85519 596.19944\nKengtung    59.85893 142.21554 613.01033 295.90429 505.40025 531.35998\nLangkho    115.18145  94.98486 518.86151 402.33622 420.65204 428.08061\nMonghsu    325.71557 216.25326 308.13805 605.02113 311.92379 247.73318\nTaunggyi   195.14541 319.81385 778.45810 150.84117 684.20905 712.80752\nPangwaun   362.45608 232.52209 523.43600 540.60474 264.64997 407.02947\nKyethi     447.10266 358.89620 233.83079 728.87329 374.90376 233.25039\nLoilen     268.92310 207.25000 406.56282 573.75476 354.79137 284.76895\nManton     646.66493 507.96808  59.52318 910.23039 280.26395 181.33894\nMongyang   209.33700 194.93467 585.61776 448.79027 401.39475 445.40621\nKunhing    255.10832 137.85278 403.66587 532.26397 281.62645 292.49814\nMongyawng  172.70139 275.15989 601.80824 432.10118 572.76394 522.91815\nTangyan    429.84475 340.39128 242.78233 719.84066 348.84991 201.49393\nNamhsan    472.04024 364.77086 180.09747 754.03913 316.54695 170.90848\n              Hsipaw  Monghsat   Mongmao   Nansang Laukkaing  Pangsang\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat   121.78922                                                  \nMongmao    185.99483 247.17708                                        \nNansang    120.24428 201.92690 164.99494                              \nLaukkaing  569.06099 626.44910 404.00848 480.60074                    \nPangsang   205.04337 256.37933  57.60801 193.36162 408.04016          \nNamtu      229.44658 231.78673 365.03882 217.61884 664.06286 392.97391\nMonghpyak  237.67919 356.84917 291.88846 227.52638 565.84279 315.11651\nKonkyan    296.74316 268.25060 281.87425 374.70456 635.92043 274.81900\nMongping   168.92101 140.95392 305.57166 287.36626 708.13447 308.33123\nHopong      62.86179 100.45714 244.16253 167.66291 628.48557 261.51075\nNyaungshwe 169.92664 286.37238 230.45003 131.18943 520.24345 257.77823\nHsihseng   136.54610 153.49551 311.98001 193.53779 670.74564 335.52974\nMongla     373.47509 429.00536 216.24705 289.45119 202.55831 217.88123\nHseni      231.48538 331.22632 184.67099 136.45492 391.74585 214.66375\nKunlong    205.10051 202.31862 224.43391 183.01388 521.88657 258.49342\nHopang     248.72536 317.64824  78.29342 196.47091 331.67199  92.57672\nNamhkan    382.79302 455.10875 223.32205 302.89487 196.46063 231.38484\nKengtung   284.08582 383.72138 207.58055 193.67980 351.48520 229.85484\nLangkho    183.05109 279.52329 134.50170  99.39859 410.41270 167.65920\nMonghsu     58.55724 137.24737 242.43599 153.59962 619.01766 260.52971\nTaunggyi   462.31183 562.88102 387.33906 365.04897 345.98041 405.59730\nPangwaun   298.12447 343.53898 187.40057 326.12960 470.63605 157.48757\nKyethi     195.17677 190.50609 377.89657 273.02385 749.99415 396.89963\nLoilen      98.04789 118.65144 190.26490  94.23028 535.57527 207.94433\nManton     359.60008 317.15603 503.79786 476.55544 907.38406 504.75214\nMongyang   267.10497 312.64797  91.06281 218.49285 326.19219 108.37735\nKunhing     90.77517 165.38834 103.91040 128.20940 500.41640 123.18870\nMongyawng  294.70967 364.40429 296.40789 191.11990 454.80044 336.16703\nTangyan    167.69794 144.59626 347.14183 249.70235 722.40954 364.76893\nNamhsan    194.47928 169.56962 371.71448 294.16284 760.45960 385.65526\n               Namtu Monghpyak   Konkyan  Mongping    Hopong Nyaungshwe\nPindaya                                                                \nYwangan                                                                \nPinlaung                                                               \nMabein                                                                 \nKalaw                                                                  \nPekon                                                                  \nLawksawk                                                               \nNawnghkio                                                              \nKyaukme                                                                \nMuse                                                                   \nLaihka                                                                 \nMongnai                                                                \nMawkmai                                                                \nKutkai                                                                 \nMongton                                                                \nMongyai                                                                \nMongkaing                                                              \nLashio                                                                 \nMongpan                                                                \nMatman                                                                 \nTachileik                                                              \nNarphan                                                                \nMongkhet                                                               \nHsipaw                                                                 \nMonghsat                                                               \nMongmao                                                                \nNansang                                                                \nLaukkaing                                                              \nPangsang                                                               \nNamtu                                                                  \nMonghpyak  346.57799                                                   \nKonkyan    478.37690 463.39594                                         \nMongping   321.66441 354.76537 242.02901                               \nHopong     206.82668 267.95563 304.49287 134.00139                     \nNyaungshwe 271.41464 103.97300 432.35040 319.32583 209.32532           \nHsihseng   131.89940 285.37627 383.49700 199.64389  91.65458  225.80242\nMongla     483.49434 408.03397 468.09747 512.61580 432.31105  347.60273\nHseni      327.41448 200.26876 448.84563 395.58453 286.41193  130.86310\nKunlong    233.60474 357.44661 329.11433 309.05385 219.06817  285.13095\nHopang     408.24516 304.26577 348.18522 379.27212 309.77356  247.19891\nNamhkan    506.32466 379.50202 481.59596 523.74815 444.13246  333.32428\nKengtung   385.33554 221.47613 474.82621 442.80821 340.47382  177.75714\nLangkho    305.03473 200.27496 386.95022 343.96455 239.63685  128.26577\nMonghsu    209.64684 232.17823 331.72187 158.90478  43.40665  173.82799\nTaunggyi   518.72748 334.17439 650.56905 621.53039 513.76415  325.09619\nPangwaun   517.03554 381.95144 263.97576 340.37881 346.00673  352.92324\nKyethi     186.90932 328.16234 400.10989 187.43974 136.49038  288.06872\nLoilen     194.24075 296.99681 334.19820 231.99959 124.74445  206.40432\nManton     448.58230 502.20840 366.66876 200.48082 310.58885  488.79874\nMongyang   413.26052 358.17599 329.39338 387.80686 323.35704  294.29500\nKunhing    296.43996 250.74435 253.74202 212.59619 145.15617  189.97131\nMongyawng  262.24331 285.56475 522.38580 455.59190 326.59925  218.12104\nTangyan    178.69483 335.26416 367.46064 161.67411 106.82328  284.14692\nNamhsan    240.95555 352.70492 352.20115 130.23777 132.70541  315.91750\n            Hsihseng    Mongla     Hseni   Kunlong    Hopang   Namhkan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla     478.66210                                                  \nHseni      312.74375 226.82048                                        \nKunlong    231.85967 346.46200 276.19175                              \nHopang     370.01334 147.02444 162.80878 271.34451                    \nNamhkan    492.09476  77.21355 212.11323 375.73885 146.18632          \nKengtung   370.72441 202.45004  66.12817 317.14187 164.29921 175.63015\nLangkho    276.27441 229.01675  66.66133 224.52741 134.24847 224.40029\nMonghsu     97.82470 424.51868 262.28462 239.89665 301.84458 431.32637\nTaunggyi   528.14240 297.09863 238.19389 471.29032 329.95252 257.29147\nPangwaun   433.06326 319.18643 330.70182 392.45403 206.98364 310.44067\nKyethi      84.04049 556.02500 388.33498 298.55859 440.48114 567.86202\nLoilen     158.84853 338.67408 227.10984 166.53599 242.89326 364.90647\nManton     334.87758 712.51416 584.63341 479.76855 577.52046 721.86149\nMongyang   382.59743 146.66661 210.19929 247.22785  69.25859 167.72448\nKunhing    220.15490 306.47566 206.47448 193.77551 172.96164 314.92119\nMongyawng  309.51462 315.57550 173.86004 240.39800 290.51360 321.21112\nTangyan     70.27241 526.80849 373.07575 268.07983 412.22167 542.64078\nNamhsan    125.74240 564.02740 411.96125 310.40560 440.51555 576.42717\n            Kengtung   Langkho   Monghsu  Taunggyi  Pangwaun    Kyethi\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho    107.16213                                                  \nMonghsu    316.91914 221.84918                                        \nTaunggyi   186.28225 288.27478 486.91951                              \nPangwaun   337.48335 295.38434 343.38498 497.61245                    \nKyethi     444.26274 350.91512 146.61572 599.57407 476.62610          \nLoilen     282.22935 184.10672 131.55208 455.91617 331.69981 232.32965\nManton     631.99123 535.95620 330.76503 803.08034 510.79265 272.03299\nMongyang   217.08047 175.35413 323.95988 374.58247 225.25026 453.86726\nKunhing    245.95083 146.38284 146.78891 429.98509 229.09986 278.95182\nMongyawng  203.87199 186.11584 312.85089 287.73864 475.33116 387.71518\nTangyan    429.95076 332.02048 127.42203 592.65262 447.05580  47.79331\nNamhsan    466.20497 368.20978 153.22576 631.49232 448.58030  68.67929\n              Loilen    Manton  Mongyang   Kunhing Mongyawng   Tangyan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho                                                               \nMonghsu                                                               \nTaunggyi                                                              \nPangwaun                                                              \nKyethi                                                                \nLoilen                                                                \nManton     419.06087                                                  \nMongyang   246.76592 585.70558                                        \nKunhing    130.39336 410.49230 188.89405                              \nMongyawng  261.75211 629.43339 304.21734 295.35984                    \nTangyan    196.60826 271.82672 421.06366 249.74161 377.52279          \nNamhsan    242.15271 210.48485 450.97869 270.79121 430.02019  63.67613\n\n\n\n\n\nIn R, there are several packages provide hierarchical clustering function. In this hands-on exercise, hclust() of R stats will be used.\nhclust() employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).\nThe code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class hclust which describes the tree produced by the clustering process.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\nWe can then plot the tree by using plot() of R Graphics as shown in the code chunk below.\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be solved by using use agnes() function of cluster package. It functions like hclus(), however, with the agnes() function you can also get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\nWith reference to the output above, we can see that Ward’s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used.\n\n\n\nAnother technical challenge face by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\n\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used.\n\nset.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nAlso note that the hcut function used is from factoextra package.\nNext, we can visualise the plot by using fviz_gap_stat() of factoextra package\n\nfviz_gap_stat(gap_stat)\n\n\n\n\n\n\n\n\nWith reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.\nNote: In addition to these commonly used approaches, the NbClust package, published by Charrad et al., 2014, provides 30 indices for determining the relevant number of clusters and proposes to users the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods.\n\n\n\n\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument border is used to specify the border colors for the rectangles.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will learn how to perform visually-driven hiearchical clustering analysis by using heatmaply package.\nWith heatmaply, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform shan_ict data frame into a data matrix.\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\n\n\nIn the code chunk below, the heatmaply() of heatmaply package is used to build an interactive cluster heatmap.\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\n\n\n\n\nWith closed examination of the dendragram above, we have decided to retain six clusters.\ncutree() of R Base will be used in the code chunk below to derive a 6-cluster model.\n\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\nThe output is called groups. It is a list object.\nIn order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.\nThe code chunk below form the join in three steps:\n\nthe groups list object will be converted into a matrix;\ncbind() is used to append groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster; and\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nNext, qtm() of tmap package is used to plot the choropleth map showing the cluster formed.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used.\nSaving it for next hands on 10\n\nwrite_rds(shan_ict, \"data/rds/shan_ict.rds\")\nwrite_rds(shan_sf_cluster, \"data/rds/shan_sf_cluster.rds\")\nwrite_rds(proxmat, \"data/rds/proxmat.rds\")"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_9/Hands_On_Exercise9.html#overview",
    "href": "Hands_On_Exercises/Hands_On_Exercise_9/Hands_On_Exercise9.html#overview",
    "title": "Hands-On Exercise 9",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on how to delineate homogeneous region by using geographically referenced multivariate data. There are two major analysis, namely:\n\nhierarchical cluster analysis; and\nspatially constrained cluster analysis.\n\n\n\nBy the end of this hands-on exercise, you will able:\n\nto convert GIS polygon data into R’s simple feature data.frame by using appropriate functions of sf package of R;\nto convert simple feature data.frame into R’s SpatialPolygonDataFrame object by using appropriate sf of package of R;\nto perform custer analysis by using hclust() of Base R;\nto perform spatially constrained cluster analysis using skater() of Base R; and\nto visualise the analysis output by using ggplot2 and tmap package."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_9/Hands_On_Exercise9.html#getting-started",
    "href": "Hands_On_Exercises/Hands_On_Exercise_9/Hands_On_Exercise9.html#getting-started",
    "title": "Hands-On Exercise 9",
    "section": "",
    "text": "In geobusiness and spatial policy, it is a common practice to delineate the market or planning area into homogeneous regions by using multivariate data. In this hands-on exercise, we are interested to delineate Shan State, Myanmar into homogeneous regions by using multiple Information and Communication technology (ICT) measures, namely: Radio, Television, Land line phone, Mobile phone, Computer, and Internet at home."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_9/Hands_On_Exercise9.html#the-data",
    "href": "Hands_On_Exercises/Hands_On_Exercise_9/Hands_On_Exercise9.html#the-data",
    "title": "Hands-On Exercise 9",
    "section": "",
    "text": "Two data sets will be used in this study. They are:\n\nMyanmar Township Boundary Data (i.e. myanmar_township_boundaries) : This is a GIS data in ESRI shapefile format. It consists of township boundary information of Myanmar. The spatial data are captured in polygon features.\nShan-ICT.csv: This is an extract of The 2014 Myanmar Population and Housing Census Myanmar at the township level.\n\n\n\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\nThe R packages needed for this exercise are as follows:\n\nSpatial data handling\n\nsf, rgdal and spdep\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\nMultivariate data visualisation and analysis\n\ncoorplot, ggpubr, and heatmaply\n\nCluster analysis\n\ncluster\nClustGeo\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)\n\nNote: With tidyverse, we do not have to install readr, ggplot2 and dplyr packages separately. In fact, tidyverse also installs other very useful R packages such as tidyr."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_9/Hands_On_Exercise9.html#data-import-and-prepatation",
    "href": "Hands_On_Exercises/Hands_On_Exercise_9/Hands_On_Exercise9.html#data-import-and-prepatation",
    "title": "Hands-On Exercise 9",
    "section": "",
    "text": "In this section, you will import Myanmar Township Boundary GIS data and its associated attrbiute table into R environment.\nThe Myanmar Township Boundary GIS data is in ESRI shapefile format. It will be imported into R environment by using the st_read() function of sf.\nThe code chunks used are shown below:\n\nshan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"myanmar_township_boundaries\") %&gt;%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_9\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\nThe imported township boundary object is called shan_sf. It is saved in simple feature data.frame format. We can view the content of the newly created shan_sf simple features data.frame by using the code chunk below.\n\nshan_sf\n\nSimple feature collection with 55 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n             ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1  Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2  Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3  Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4  Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5  Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6  Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7  Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8  Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9  Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                         geometry\n1  MULTIPOLYGON (((96.96001 23...\n2  MULTIPOLYGON (((96.7731 21....\n3  MULTIPOLYGON (((96.78483 21...\n4  MULTIPOLYGON (((96.49518 20...\n5  MULTIPOLYGON (((96.66306 24...\n6  MULTIPOLYGON (((96.49518 20...\n7  MULTIPOLYGON (((97.14738 19...\n8  MULTIPOLYGON (((96.94981 22...\n9  MULTIPOLYGON (((96.75648 22...\n10 MULTIPOLYGON (((96.95498 22...\n\n\nNotice that sf.data.frame is conformed to Hardy Wickham’s tidy framework.\nSince shan_sf is conformed to tidy framework, we can also glimpse() to reveal the data type of it’s fields.\n\nglimpse(shan_sf)\n\nRows: 55\nColumns: 7\n$ ST       &lt;chr&gt; \"Shan (North)\", \"Shan (South)\", \"Shan (South)\", \"Shan (South)…\n$ ST_PCODE &lt;chr&gt; \"MMR015\", \"MMR014\", \"MMR014\", \"MMR014\", \"MMR015\", \"MMR014\", \"…\n$ DT       &lt;chr&gt; \"Mongmit\", \"Taunggyi\", \"Taunggyi\", \"Taunggyi\", \"Mongmit\", \"Ta…\n$ DT_PCODE &lt;chr&gt; \"MMR015D008\", \"MMR014D001\", \"MMR014D001\", \"MMR014D001\", \"MMR0…\n$ TS       &lt;chr&gt; \"Mongmit\", \"Pindaya\", \"Ywangan\", \"Pinlaung\", \"Mabein\", \"Kalaw…\n$ TS_PCODE &lt;chr&gt; \"MMR015017\", \"MMR014006\", \"MMR014007\", \"MMR014009\", \"MMR01501…\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((96.96001 23..., MULTIPOLYGON (((…\n\n\n\n\n\nThe csv file will be import using read_csv function of readr package.\nThe code chunks used are shown below:\n\nict &lt;- read_csv (\"data/aspatial/Shan-ICT.csv\")\n\nRows: 55 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): District Pcode, District Name, Township Pcode, Township Name\ndbl (7): Total households, Radio, Television, Land line phone, Mobile phone,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe imported InfoComm variables are extracted from The 2014 Myanmar Population and Housing Census Myanmar. The attribute data set is called ict. It is saved in R’s * tibble data.frame* format.\nThe code chunk below reveal the summary statistics of ict data.frame.\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\nThere are a total of eleven fields and 55 observation in the tibble data.frame.\n\n\n\nThe unit of measurement of the values are number of household. Using these values directly will be bias by the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\nIn order to overcome this problem, we will derive the penetration rate of each ICT variable by using the code chunk below.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nLet us review the summary statistics of the newly derived penetration rates using the code chunk below.\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985  \n\n\nNotice that six new fields have been added into the data.frame. They are RADIO_PR, TV_PR, LLPHONE_PR, MPHONE_PR, COMPUTER_PR, and INTERNET_PR."
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_8/In_Class_Exercise8.html",
    "href": "In_Class_Exercises/In_Class_Exercise_8/In_Class_Exercise8.html",
    "title": "In Class Exercise 8: Geospatial Data Science",
    "section": "",
    "text": "There’s no In Class Exercise 8, so here’s a picture of a cat."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_8/Hands_On_Exercise8.html",
    "href": "Hands_On_Exercises/Hands_On_Exercise_8/Hands_On_Exercise8.html",
    "title": "Hands-On Exercise 8",
    "section": "",
    "text": "There’s no In Hands On Exercise 8, so here’s a picture of a cat."
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_7/In_Class_Exercise7.html",
    "href": "In_Class_Exercises/In_Class_Exercise_7/In_Class_Exercise7.html",
    "title": "In Class Exercise 7: Shiny App",
    "section": "",
    "text": "View in class 7 here: https://jialeso.shinyapps.io/GAShiny/"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_9/Hands_On_Exercise9.html#exploratory-data-analysis-eda",
    "href": "Hands_On_Exercises/Hands_On_Exercise_9/Hands_On_Exercise9.html#exploratory-data-analysis-eda",
    "title": "Hands-On Exercise 9",
    "section": "",
    "text": "We can plot the distribution of the variables (i.e. Number of households with radio) by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\nHistogram is useful to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution)\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\n\n\n\nBoxplot is useful to detect if there are outliers.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\n\n\n\n\nNext, we will also plotting the distribution of the newly derived variables (i.e. Radio penetration rate) by using the code chunk below.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\n\n\n\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\n\n\n\n\nIn the figure below, multiple histograms are plotted to reveal the distribution of the selected variables in the ict_derived data.frame.\n\n\n\n\n\n\nNote\n\n\n\n**What can you observed from the distributions reveal in the histogram and boxplot.\nHistogram Observations:**\n\nDistribution Shape: The histogram appears slightly right-skewed, meaning there are more data points concentrated towards the lower values, with fewer higher values extending towards the right tail.\nModal Range: The most frequent observations lie between 200 and 300, indicating that this range contains the majority of the data points.\nSpread: There is a relatively wide spread, with values ranging approximately from 0 to 500.\nPotential Outliers: The presence of a few bars towards the higher end (above 400) suggests there might be some extreme values, though these are less frequent.\n\nBoxplot Observations:\n\nCentral Tendency: The median (thick horizontal line in the box) lies around 200, indicating that half of the data points are below this value.\nInterquartile Range (IQR): The box represents the IQR, with most data points lying between approximately 150 and 300.\nOutlier: The black dot beyond the whisker on the right side indicates a potential outlier—a value that is significantly higher than the rest of the distribution.\nSymmetry: The boxplot suggests the data is right-skewed, with a longer whisker on the right side, matching the histogram’s indication of higher values being less frequent but present.\n\nSummary:\nThe RADIO_PR variable shows a right-skewed distribution with a majority of values centered around 200-300. The boxplot confirms the presence of at least one outlier and indicates that the data might not be perfectly symmetrical, with some values extending further towards the higher range. This suggests that while most observations are within a typical range, there are a few exceptionally high values worth investigating further.\n\n\nIn the figure below, multiple histograms are plotted to reveal the distribution of the selected variables in the ict_derived data.frame.\n\nradio &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv &lt;- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone &lt;- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone &lt;- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer &lt;- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet &lt;- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore we can prepare the choropleth map, we need to combine both the geospatial data object (i.e. shan_sf) and aspatial data.frame object (i.e. ict_derived) into one. This will be performed by using the left_join function of dplyr package. The shan_sf simple feature data.frame will be used as the base data object and the ict_derived data.frame will be used as the join table.\nThe code chunks below is used to perform the task. The unique identifier used to join both data objects is TS_PCODE.\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \nwrite_rds(shan_sf, \"data/rds/shan_sf.rds\")\n\nthe message above shows that TS_CODE field is the common field used to perform the left-join.\nIt is important to note that there is no new output data been created. Instead, the data fields from ict_derived data frame are now updated into the data frame of shan_sf.\n\nshan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\n\n\n\n\nTo have a quick look at the distribution of Radio penetration rate of Shan State at township level, a choropleth map will be prepared.\nThe code chunks below are used to prepare the choroplethby using the qtm() function of tmap package.\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\n\n\n\n\nIn order to reveal the distribution shown in the choropleth map above are bias to the underlying total number of households at the townships, we will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) by using the code chunk below.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\n\n\n\n\n\n\n\nNotice that the choropleth maps above clearly show that townships with relatively larger number ot households are also showing relatively higher number of radio ownership.\nNow let us plot the choropleth maps showing the dsitribution of total number of households and Radio penetration rate by using the code chunk below.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat is the difference between the two maps?\nKey Differences:\n\n\n\n\n\n\n\n\nAspect\n1st Code Block (tmap_arrange)\n2nd Code Block (tm_facets)\n\n\n\n\nLayout\nTwo independent maps side-by-side\nSynchronized maps in facets\n\n\nInteractivity\nNo interaction between maps\nMaps share zoom and pan behavior\n\n\nLegends\nSeparate for each map\nSingle, unified legend placement\n\n\nCode Complexity\nRequires creating individual maps\nSingle map object with multiple facets\n\n\nUse Case\nGood for static side-by-side comparison\nIdeal for interactive exploration\n\n\n\nWhen to Use Which?\n\ntmap_arrange(): Use when you want two independent maps for comparison, each with its own settings and legends.\ntm_facets(): Use when you need synchronized maps with a unified experience, such as for interactive dashboards."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_9/Hands_On_Exercise9.html#correlation-analysis",
    "href": "Hands_On_Exercises/Hands_On_Exercise_9/Hands_On_Exercise9.html#correlation-analysis",
    "title": "Hands-On Exercise 9",
    "section": "",
    "text": "Before we perform cluster analysis, it is important for us to ensure that the cluster variables are not highly correlated.\nIn this section, you will learn how to use corrplot.mixed() function of corrplot package to visualise and analyse the correlation of the input variables.\n\ncluster_vars.cor = cor(ict_derived[,12:17])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nThe correlation plot above shows that COMPUTER_PR and INTERNET_PR are highly correlated. This suggest that only one of them should be used in the cluster analysis instead of both."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_9/Hands_On_Exercise9.html#hierarchy-cluster-analysis",
    "href": "Hands_On_Exercises/Hands_On_Exercise_9/Hands_On_Exercise9.html#hierarchy-cluster-analysis",
    "title": "Hands-On Exercise 9",
    "section": "",
    "text": "In this section, you will learn how to perform hierarchical cluster analysis. The analysis consists of four major steps:\n\n\nThe code chunk below will be used to extract the clustering variables from the shan_sf simple feature object into data.frame.\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the final clustering variables list does not include variable INTERNET_PR because it is highly correlated with variable COMPUTER_PR.\nNext, we need to change the rows by township name instead of row number by using the code chunk below\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the row number has been replaced into the township name.\nNow, we will delete the TS.x field by using the code chunk below.\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n\n\nIn general, multiple variables will be used in cluster analysis. It is not unusual their values range are different. In order to avoid the cluster analysis result is baised to clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis.\n\n\n\nIn the code chunk below, normalize() of heatmaply package is used to stadardisation the clustering variables by using Min-Max method. The summary() is then used to display the summary statistics of the standardised clustering variables.\n\nshan_ict.std &lt;- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\nNotice that the values range of the Min-max standardised clustering variables are 0-1 now.\n\n\n\nZ-score standardisation can be performed easily by using scale() of Base R. The code chunk below will be used to stadardisation the clustering variables by using Z-score method.\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\nNotice the mean and standard deviation of the Z-score standardised clustering variables are 0 and 1 respectively.\nNote: describe() of psych package is used here instead of summary() of Base R because the earlier provides standard deviation.\nWarning: Z-score standardisation method should only be used if we would assume all variables come from some normal distribution.\n\n\n\nBeside reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphical.\nThe code chunk below plot the scaled Radio_PR field.\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nWhat statistical conclusion can you draw from the histograms above?\n1. Raw Values without Standardization (Left Histogram):\n\nThe distribution of the raw values is right-skewed, with more observations concentrated towards the lower values and fewer observations at the higher end (above 400).\nThe spread is large, with values ranging between 0 and 500, suggesting that the raw data may contain large variability or outliers.\n\n2. Min-Max Standardization (Center Histogram):\n\nMin-Max standardization scales the data to a range between 0 and 1.\nThe shape of the distribution remains similar to the original (right-skewed), but the values are now confined within the standardized range.\nThis transformation preserves the relative spacing between data points but makes it easier to compare across datasets that might have different ranges.\n\n3. Z-Score Standardization (Right Histogram):\n\nZ-score standardization centers the data around a mean of 0 and standard deviation of 1.\nThe distribution is now scaled such that most values fall between -2 and 2.\nThe shape of the distribution is again maintained, but this transformation highlights how far observations deviate from the mean, making it easier to detect outliers or extreme values (e.g., the rightmost bar suggests potential outliers).\n\n\n\n\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\nIn R, many packages provide functions to calculate distance matrix. We will compute the proximity matrix by using dist() of R.\ndist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using euclidean method.\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\n\nThe code chunk below can then be used to list the content of proxmat for visual inspection.\n\nproxmat\n\n             Mongmit   Pindaya   Ywangan  Pinlaung    Mabein     Kalaw\nPindaya    171.86828                                                  \nYwangan    381.88259 257.31610                                        \nPinlaung    57.46286 208.63519 400.05492                              \nMabein     263.37099 313.45776 529.14689 312.66966                    \nKalaw      160.05997 302.51785 499.53297 181.96406 198.14085          \nPekon       59.61977 117.91580 336.50410  94.61225 282.26877 211.91531\nLawksawk   140.11550 204.32952 432.16535 192.57320 130.36525 140.01101\nNawnghkio   89.07103 180.64047 377.87702 139.27495 204.63154 127.74787\nKyaukme    144.02475 311.01487 505.89191 139.67966 264.88283  79.42225\nMuse       563.01629 704.11252 899.44137 571.58335 453.27410 412.46033\nLaihka     141.87227 298.61288 491.83321 101.10150 345.00222 197.34633\nMongnai    115.86190 258.49346 422.71934  64.52387 358.86053 200.34668\nMawkmai    434.92968 437.99577 397.03752 398.11227 693.24602 562.59200\nKutkai      97.61092 212.81775 360.11861  78.07733 340.55064 204.93018\nMongton    192.67961 283.35574 361.23257 163.42143 425.16902 267.87522\nMongyai    256.72744 287.41816 333.12853 220.56339 516.40426 386.74701\nMongkaing  503.61965 481.71125 364.98429 476.29056 747.17454 625.24500\nLashio     251.29457 398.98167 602.17475 262.51735 231.28227 106.69059\nMongpan    193.32063 335.72896 483.68125 192.78316 301.52942 114.69105\nMatman     401.25041 354.39039 255.22031 382.40610 637.53975 537.63884\nTachileik  529.63213 635.51774 807.44220 555.01039 365.32538 373.64459\nNarphan    406.15714 474.50209 452.95769 371.26895 630.34312 463.53759\nMongkhet   349.45980 391.74783 408.97731 305.86058 610.30557 465.52013\nHsipaw     118.18050 245.98884 388.63147  76.55260 366.42787 212.36711\nMonghsat   214.20854 314.71506 432.98028 160.44703 470.48135 317.96188\nMongmao    242.54541 402.21719 542.85957 217.58854 384.91867 195.18913\nNansang    104.91839 275.44246 472.77637  85.49572 287.92364 124.30500\nLaukkaing  568.27732 726.85355 908.82520 563.81750 520.67373 427.77791\nPangsang   272.67383 428.24958 556.82263 244.47146 418.54016 224.03998\nNamtu      179.62251 225.40822 444.66868 170.04533 366.16094 307.27427\nMonghpyak  177.76325 221.30579 367.44835 222.20020 212.69450 167.08436\nKonkyan    403.39082 500.86933 528.12533 365.44693 613.51206 444.75859\nMongping   265.12574 310.64850 337.94020 229.75261 518.16310 375.64739\nHopong     136.93111 223.06050 352.85844  98.14855 398.00917 264.16294\nNyaungshwe  99.38590 216.52463 407.11649 138.12050 210.21337  95.66782\nHsihseng   131.49728 172.00796 342.91035 111.61846 381.20187 287.11074\nMongla     384.30076 549.42389 728.16301 372.59678 406.09124 260.26411\nHseni      189.37188 337.98982 534.44679 204.47572 213.61240  38.52842\nKunlong    224.12169 355.47066 531.63089 194.76257 396.61508 273.01375\nHopang     281.05362 443.26362 596.19312 265.96924 368.55167 185.14704\nNamhkan    386.02794 543.81859 714.43173 382.78835 379.56035 246.39577\nKengtung   246.45691 385.68322 573.23173 263.48638 219.47071  88.29335\nLangkho    164.26299 323.28133 507.78892 168.44228 253.84371  67.19580\nMonghsu    109.15790 198.35391 340.42789  80.86834 367.19820 237.34578\nTaunggyi   399.84278 503.75471 697.98323 429.54386 226.24011 252.26066\nPangwaun   381.51246 512.13162 580.13146 356.37963 523.44632 338.35194\nKyethi     202.92551 175.54012 287.29358 189.47065 442.07679 360.17247\nLoilen     145.48666 293.61143 469.51621  91.56527 375.06406 217.19877\nManton     430.64070 402.42888 306.16379 405.83081 674.01120 560.16577\nMongyang   309.51302 475.93982 630.71590 286.03834 411.88352 233.56349\nKunhing    173.50424 318.23811 449.67218 141.58836 375.82140 197.63683\nMongyawng  214.21738 332.92193 570.56521 235.55497 193.49994 173.43078\nTangyan    195.92520 208.43740 324.77002 169.50567 448.59948 348.06617\nNamhsan    237.78494 228.41073 286.16305 214.33352 488.33873 385.88676\n               Pekon  Lawksawk Nawnghkio   Kyaukme      Muse    Laihka\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk   157.51129                                                  \nNawnghkio  113.15370  90.82891                                        \nKyaukme    202.12206 186.29066 157.04230                              \nMuse       614.56144 510.13288 533.68806 434.75768                    \nLaihka     182.23667 246.74469 211.88187 128.24979 526.65211          \nMongnai    151.60031 241.71260 182.21245 142.45669 571.97975 100.53457\nMawkmai    416.00669 567.52693 495.15047 512.02846 926.93007 429.96554\nKutkai     114.98048 224.64646 147.44053 170.93318 592.90743 144.67198\nMongton    208.14888 311.07742 225.81118 229.28509 634.71074 212.07320\nMongyai    242.52301 391.26989 319.57938 339.27780 763.91399 264.13364\nMongkaing  480.23965 625.18712 546.69447 586.05094 995.66496 522.96309\nLashio     303.80011 220.75270 230.55346 129.95255 313.15288 238.64533\nMongpan    243.30037 228.54223 172.84425 110.37831 447.49969 210.76951\nMatman     368.25761 515.39711 444.05061 505.52285 929.11283 443.25453\nTachileik  573.39528 441.82621 470.45533 429.15493 221.19950 549.08985\nNarphan    416.84901 523.69580 435.59661 420.30003 770.40234 392.32592\nMongkhet   342.08722 487.41102 414.10280 409.03553 816.44931 324.97428\nHsipaw     145.37542 249.35081 176.09570 163.95741 591.03355 128.42987\nMonghsat   225.64279 352.31496 289.83220 253.25370 663.76026 158.93517\nMongmao    293.70625 314.64777 257.76465 146.09228 451.82530 185.99082\nNansang    160.37607 188.78869 151.13185  60.32773 489.35308  78.78999\nLaukkaing  624.82399 548.83928 552.65554 428.74978 149.26996 507.39700\nPangsang   321.81214 345.91486 287.10769 175.35273 460.24292 214.19291\nNamtu      165.02707 260.95300 257.52713 270.87277 659.16927 185.86794\nMonghpyak  190.93173 142.31691  93.03711 217.64419 539.43485 293.22640\nKonkyan    421.48797 520.31264 439.34272 393.79911 704.86973 351.75354\nMongping   259.68288 396.47081 316.14719 330.28984 744.44948 272.82761\nHopong     138.86577 274.91604 204.88286 218.84211 648.68011 157.48857\nNyaungshwe 139.31874 104.17830  43.26545 126.50414 505.88581 201.71653\nHsihseng   105.30573 257.11202 209.88026 250.27059 677.66886 175.89761\nMongla     441.20998 393.18472 381.40808 241.58966 256.80556 315.93218\nHseni      243.98001 171.50398 164.05304  81.20593 381.30567 204.49010\nKunlong    249.36301 318.30406 285.04608 215.63037 547.24297 122.68682\nHopang     336.38582 321.16462 279.84188 154.91633 377.44407 230.78652\nNamhkan    442.77120 379.41126 367.33575 247.81990 238.67060 342.43665\nKengtung   297.67761 209.38215 208.29647 136.23356 330.08211 258.23950\nLangkho    219.21623 190.30257 156.51662  51.67279 413.64173 160.94435\nMonghsu    113.84636 242.04063 170.09168 200.77712 633.21624 163.28926\nTaunggyi   440.66133 304.96838 344.79200 312.60547 250.81471 425.36916\nPangwaun   423.81347 453.02765 381.67478 308.31407 541.97887 351.78203\nKyethi     162.43575 317.74604 267.21607 328.14177 757.16745 255.83275\nLoilen     181.94596 265.29318 219.26405 146.92675 560.43400  59.69478\nManton     403.82131 551.13000 475.77296 522.86003 941.49778 458.30232\nMongyang   363.58788 363.37684 323.32123 188.59489 389.59919 229.71502\nKunhing    213.46379 278.68953 206.15773 145.00266 533.00162 142.03682\nMongyawng  248.43910 179.07229 220.61209 181.55295 422.37358 211.99976\nTangyan    167.79937 323.14701 269.07880 306.78359 736.93741 224.29176\nNamhsan    207.16559 362.84062 299.74967 347.85944 778.52971 273.79672\n             Mongnai   Mawkmai    Kutkai   Mongton   Mongyai Mongkaing\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai    374.50873                                                  \nKutkai      91.15307 364.95519                                        \nMongton    131.67061 313.35220 107.06341                              \nMongyai    203.23607 178.70499 188.94166 159.79790                    \nMongkaing  456.00842 133.29995 428.96133 365.50032 262.84016          \nLashio     270.86983 638.60773 289.82513 347.11584 466.36472 708.65819\nMongpan    178.09554 509.99632 185.18173 200.31803 346.39710 563.56780\nMatman     376.33870 147.83545 340.86349 303.04574 186.95158 135.51424\nTachileik  563.95232 919.38755 568.99109 608.76740 750.29555 967.14087\nNarphan    329.31700 273.75350 314.27683 215.97925 248.82845 285.65085\nMongkhet   275.76855 115.58388 273.91673 223.22828 104.98924 222.60577\nHsipaw      52.68195 351.34601  51.46282  90.69766 177.33790 423.77868\nMonghsat   125.25968 275.09705 154.32012 150.98053 127.35225 375.60376\nMongmao    188.29603 485.52853 204.69232 206.57001 335.61300 552.31959\nNansang     92.79567 462.41938 130.04549 199.58124 288.55962 542.16609\nLaukkaing  551.56800 882.51110 580.38112 604.66190 732.68347 954.11795\nPangsang   204.25746 484.14757 228.33583 210.77938 343.30638 548.40662\nNamtu      209.35473 427.95451 225.28268 308.71751 278.02761 525.04057\nMonghpyak  253.26470 536.71695 206.61627 258.04282 370.01575 568.21089\nKonkyan    328.82831 339.01411 310.60810 248.25265 287.87384 380.92091\nMongping   202.99615 194.31049 182.75266 119.86993  65.38727 257.18572\nHopong      91.53795 302.84362  73.45899 106.21031 124.62791 379.37916\nNyaungshwe 169.63695 502.99026 152.15482 219.72196 327.13541 557.32112\nHsihseng   142.36728 329.29477 128.21054 194.64317 162.27126 411.59788\nMongla     354.10985 686.88950 388.40984 411.06668 535.28615 761.48327\nHseni      216.81639 582.53670 229.37894 286.75945 408.23212 648.04408\nKunlong    202.92529 446.53763 204.54010 270.02165 299.36066 539.91284\nHopang     243.00945 561.24281 263.31986 273.50305 408.73288 626.17673\nNamhkan    370.05669 706.47792 392.48568 414.53594 550.62819 771.39688\nKengtung   272.28711 632.54638 279.19573 329.38387 460.39706 692.74693\nLangkho    174.67678 531.08019 180.51419 236.70878 358.95672 597.42714\nMonghsu     84.11238 332.07962  62.60859 107.04894 154.86049 400.71816\nTaunggyi   448.55282 810.74692 450.33382 508.40925 635.94105 866.21117\nPangwaun   312.13429 500.68857 321.80465 257.50434 394.07696 536.95736\nKyethi     210.50453 278.85535 184.23422 222.52947 137.79420 352.06533\nLoilen      58.41263 388.73386 131.56529 176.16001 224.79239 482.18190\nManton     391.54062 109.08779 361.82684 310.20581 195.59882  81.75337\nMongyang   260.39387 558.83162 285.33223 295.60023 414.31237 631.91325\nKunhing    110.55197 398.43973 108.84990 114.03609 238.99570 465.03971\nMongyawng  275.77546 620.04321 281.03383 375.22688 445.78964 700.98284\nTangyan    180.37471 262.66006 166.61820 198.88460 109.08506 348.56123\nNamhsan    218.10003 215.19289 191.32762 196.76188  77.35900 288.66231\n              Lashio   Mongpan    Matman Tachileik   Narphan  Mongkhet\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan    172.33279                                                  \nMatman     628.11049 494.81014                                        \nTachileik  311.95286 411.03849 890.12935                              \nNarphan    525.63854 371.13393 312.05193 760.29566                    \nMongkhet   534.44463 412.17123 203.02855 820.50164 217.28718          \nHsipaw     290.86435 179.52054 344.45451 576.18780 295.40170 253.80950\nMonghsat   377.86793 283.30992 313.59911 677.09508 278.21548 167.98445\nMongmao    214.23677 131.59966 501.59903 472.95568 331.42618 375.35820\nNansang    184.47950 144.77393 458.06573 486.77266 398.13308 360.99219\nLaukkaing  334.65738 435.58047 903.72094 325.06329 708.82887 769.06406\nPangsang   236.72516 140.23910 506.29940 481.31907 316.30314 375.58139\nNamtu      365.88437 352.91394 416.65397 659.56458 494.36143 355.99713\nMonghpyak  262.09281 187.85699 470.46845 444.04411 448.40651 462.63265\nKonkyan    485.51312 365.87588 392.40306 730.92980 158.82353 254.24424\nMongping   454.52548 318.47482 201.65224 727.08969 188.64567 113.80917\nHopong     345.31042 239.43845 291.84351 632.45718 294.40441 212.99485\nNyaungshwe 201.58191 137.29734 460.91883 445.81335 427.94086 417.08639\nHsihseng   369.00833 295.87811 304.02806 658.87060 377.52977 256.70338\nMongla     179.95877 253.20001 708.17595 347.33155 531.46949 574.40292\nHseni       79.41836 120.66550 564.64051 354.90063 474.12297 481.88406\nKunlong    295.23103 288.03320 468.27436 595.70536 413.07823 341.68641\nHopang     170.63913 135.62913 573.55355 403.82035 397.85908 451.51070\nNamhkan    173.27153 240.34131 715.42102 295.91660 536.85519 596.19944\nKengtung    59.85893 142.21554 613.01033 295.90429 505.40025 531.35998\nLangkho    115.18145  94.98486 518.86151 402.33622 420.65204 428.08061\nMonghsu    325.71557 216.25326 308.13805 605.02113 311.92379 247.73318\nTaunggyi   195.14541 319.81385 778.45810 150.84117 684.20905 712.80752\nPangwaun   362.45608 232.52209 523.43600 540.60474 264.64997 407.02947\nKyethi     447.10266 358.89620 233.83079 728.87329 374.90376 233.25039\nLoilen     268.92310 207.25000 406.56282 573.75476 354.79137 284.76895\nManton     646.66493 507.96808  59.52318 910.23039 280.26395 181.33894\nMongyang   209.33700 194.93467 585.61776 448.79027 401.39475 445.40621\nKunhing    255.10832 137.85278 403.66587 532.26397 281.62645 292.49814\nMongyawng  172.70139 275.15989 601.80824 432.10118 572.76394 522.91815\nTangyan    429.84475 340.39128 242.78233 719.84066 348.84991 201.49393\nNamhsan    472.04024 364.77086 180.09747 754.03913 316.54695 170.90848\n              Hsipaw  Monghsat   Mongmao   Nansang Laukkaing  Pangsang\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat   121.78922                                                  \nMongmao    185.99483 247.17708                                        \nNansang    120.24428 201.92690 164.99494                              \nLaukkaing  569.06099 626.44910 404.00848 480.60074                    \nPangsang   205.04337 256.37933  57.60801 193.36162 408.04016          \nNamtu      229.44658 231.78673 365.03882 217.61884 664.06286 392.97391\nMonghpyak  237.67919 356.84917 291.88846 227.52638 565.84279 315.11651\nKonkyan    296.74316 268.25060 281.87425 374.70456 635.92043 274.81900\nMongping   168.92101 140.95392 305.57166 287.36626 708.13447 308.33123\nHopong      62.86179 100.45714 244.16253 167.66291 628.48557 261.51075\nNyaungshwe 169.92664 286.37238 230.45003 131.18943 520.24345 257.77823\nHsihseng   136.54610 153.49551 311.98001 193.53779 670.74564 335.52974\nMongla     373.47509 429.00536 216.24705 289.45119 202.55831 217.88123\nHseni      231.48538 331.22632 184.67099 136.45492 391.74585 214.66375\nKunlong    205.10051 202.31862 224.43391 183.01388 521.88657 258.49342\nHopang     248.72536 317.64824  78.29342 196.47091 331.67199  92.57672\nNamhkan    382.79302 455.10875 223.32205 302.89487 196.46063 231.38484\nKengtung   284.08582 383.72138 207.58055 193.67980 351.48520 229.85484\nLangkho    183.05109 279.52329 134.50170  99.39859 410.41270 167.65920\nMonghsu     58.55724 137.24737 242.43599 153.59962 619.01766 260.52971\nTaunggyi   462.31183 562.88102 387.33906 365.04897 345.98041 405.59730\nPangwaun   298.12447 343.53898 187.40057 326.12960 470.63605 157.48757\nKyethi     195.17677 190.50609 377.89657 273.02385 749.99415 396.89963\nLoilen      98.04789 118.65144 190.26490  94.23028 535.57527 207.94433\nManton     359.60008 317.15603 503.79786 476.55544 907.38406 504.75214\nMongyang   267.10497 312.64797  91.06281 218.49285 326.19219 108.37735\nKunhing     90.77517 165.38834 103.91040 128.20940 500.41640 123.18870\nMongyawng  294.70967 364.40429 296.40789 191.11990 454.80044 336.16703\nTangyan    167.69794 144.59626 347.14183 249.70235 722.40954 364.76893\nNamhsan    194.47928 169.56962 371.71448 294.16284 760.45960 385.65526\n               Namtu Monghpyak   Konkyan  Mongping    Hopong Nyaungshwe\nPindaya                                                                \nYwangan                                                                \nPinlaung                                                               \nMabein                                                                 \nKalaw                                                                  \nPekon                                                                  \nLawksawk                                                               \nNawnghkio                                                              \nKyaukme                                                                \nMuse                                                                   \nLaihka                                                                 \nMongnai                                                                \nMawkmai                                                                \nKutkai                                                                 \nMongton                                                                \nMongyai                                                                \nMongkaing                                                              \nLashio                                                                 \nMongpan                                                                \nMatman                                                                 \nTachileik                                                              \nNarphan                                                                \nMongkhet                                                               \nHsipaw                                                                 \nMonghsat                                                               \nMongmao                                                                \nNansang                                                                \nLaukkaing                                                              \nPangsang                                                               \nNamtu                                                                  \nMonghpyak  346.57799                                                   \nKonkyan    478.37690 463.39594                                         \nMongping   321.66441 354.76537 242.02901                               \nHopong     206.82668 267.95563 304.49287 134.00139                     \nNyaungshwe 271.41464 103.97300 432.35040 319.32583 209.32532           \nHsihseng   131.89940 285.37627 383.49700 199.64389  91.65458  225.80242\nMongla     483.49434 408.03397 468.09747 512.61580 432.31105  347.60273\nHseni      327.41448 200.26876 448.84563 395.58453 286.41193  130.86310\nKunlong    233.60474 357.44661 329.11433 309.05385 219.06817  285.13095\nHopang     408.24516 304.26577 348.18522 379.27212 309.77356  247.19891\nNamhkan    506.32466 379.50202 481.59596 523.74815 444.13246  333.32428\nKengtung   385.33554 221.47613 474.82621 442.80821 340.47382  177.75714\nLangkho    305.03473 200.27496 386.95022 343.96455 239.63685  128.26577\nMonghsu    209.64684 232.17823 331.72187 158.90478  43.40665  173.82799\nTaunggyi   518.72748 334.17439 650.56905 621.53039 513.76415  325.09619\nPangwaun   517.03554 381.95144 263.97576 340.37881 346.00673  352.92324\nKyethi     186.90932 328.16234 400.10989 187.43974 136.49038  288.06872\nLoilen     194.24075 296.99681 334.19820 231.99959 124.74445  206.40432\nManton     448.58230 502.20840 366.66876 200.48082 310.58885  488.79874\nMongyang   413.26052 358.17599 329.39338 387.80686 323.35704  294.29500\nKunhing    296.43996 250.74435 253.74202 212.59619 145.15617  189.97131\nMongyawng  262.24331 285.56475 522.38580 455.59190 326.59925  218.12104\nTangyan    178.69483 335.26416 367.46064 161.67411 106.82328  284.14692\nNamhsan    240.95555 352.70492 352.20115 130.23777 132.70541  315.91750\n            Hsihseng    Mongla     Hseni   Kunlong    Hopang   Namhkan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla     478.66210                                                  \nHseni      312.74375 226.82048                                        \nKunlong    231.85967 346.46200 276.19175                              \nHopang     370.01334 147.02444 162.80878 271.34451                    \nNamhkan    492.09476  77.21355 212.11323 375.73885 146.18632          \nKengtung   370.72441 202.45004  66.12817 317.14187 164.29921 175.63015\nLangkho    276.27441 229.01675  66.66133 224.52741 134.24847 224.40029\nMonghsu     97.82470 424.51868 262.28462 239.89665 301.84458 431.32637\nTaunggyi   528.14240 297.09863 238.19389 471.29032 329.95252 257.29147\nPangwaun   433.06326 319.18643 330.70182 392.45403 206.98364 310.44067\nKyethi      84.04049 556.02500 388.33498 298.55859 440.48114 567.86202\nLoilen     158.84853 338.67408 227.10984 166.53599 242.89326 364.90647\nManton     334.87758 712.51416 584.63341 479.76855 577.52046 721.86149\nMongyang   382.59743 146.66661 210.19929 247.22785  69.25859 167.72448\nKunhing    220.15490 306.47566 206.47448 193.77551 172.96164 314.92119\nMongyawng  309.51462 315.57550 173.86004 240.39800 290.51360 321.21112\nTangyan     70.27241 526.80849 373.07575 268.07983 412.22167 542.64078\nNamhsan    125.74240 564.02740 411.96125 310.40560 440.51555 576.42717\n            Kengtung   Langkho   Monghsu  Taunggyi  Pangwaun    Kyethi\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho    107.16213                                                  \nMonghsu    316.91914 221.84918                                        \nTaunggyi   186.28225 288.27478 486.91951                              \nPangwaun   337.48335 295.38434 343.38498 497.61245                    \nKyethi     444.26274 350.91512 146.61572 599.57407 476.62610          \nLoilen     282.22935 184.10672 131.55208 455.91617 331.69981 232.32965\nManton     631.99123 535.95620 330.76503 803.08034 510.79265 272.03299\nMongyang   217.08047 175.35413 323.95988 374.58247 225.25026 453.86726\nKunhing    245.95083 146.38284 146.78891 429.98509 229.09986 278.95182\nMongyawng  203.87199 186.11584 312.85089 287.73864 475.33116 387.71518\nTangyan    429.95076 332.02048 127.42203 592.65262 447.05580  47.79331\nNamhsan    466.20497 368.20978 153.22576 631.49232 448.58030  68.67929\n              Loilen    Manton  Mongyang   Kunhing Mongyawng   Tangyan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho                                                               \nMonghsu                                                               \nTaunggyi                                                              \nPangwaun                                                              \nKyethi                                                                \nLoilen                                                                \nManton     419.06087                                                  \nMongyang   246.76592 585.70558                                        \nKunhing    130.39336 410.49230 188.89405                              \nMongyawng  261.75211 629.43339 304.21734 295.35984                    \nTangyan    196.60826 271.82672 421.06366 249.74161 377.52279          \nNamhsan    242.15271 210.48485 450.97869 270.79121 430.02019  63.67613\n\n\n\n\n\nIn R, there are several packages provide hierarchical clustering function. In this hands-on exercise, hclust() of R stats will be used.\nhclust() employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).\nThe code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class hclust which describes the tree produced by the clustering process.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\nWe can then plot the tree by using plot() of R Graphics as shown in the code chunk below.\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be solved by using use agnes() function of cluster package. It functions like hclus(), however, with the agnes() function you can also get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\nWith reference to the output above, we can see that Ward’s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used.\n\n\n\nAnother technical challenge face by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\n\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used.\n\nset.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nAlso note that the hcut function used is from factoextra package.\nNext, we can visualise the plot by using fviz_gap_stat() of factoextra package\n\nfviz_gap_stat(gap_stat)\n\n\n\n\n\n\n\n\nWith reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.\nNote: In addition to these commonly used approaches, the NbClust package, published by Charrad et al., 2014, provides 30 indices for determining the relevant number of clusters and proposes to users the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods.\n\n\n\n\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument border is used to specify the border colors for the rectangles.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will learn how to perform visually-driven hiearchical clustering analysis by using heatmaply package.\nWith heatmaply, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform shan_ict data frame into a data matrix.\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\n\n\nIn the code chunk below, the heatmaply() of heatmaply package is used to build an interactive cluster heatmap.\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\n\n\n\n\nWith closed examination of the dendragram above, we have decided to retain six clusters.\ncutree() of R Base will be used in the code chunk below to derive a 6-cluster model.\n\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\nThe output is called groups. It is a list object.\nIn order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.\nThe code chunk below form the join in three steps:\n\nthe groups list object will be converted into a matrix;\ncbind() is used to append groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster; and\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nNext, qtm() of tmap package is used to plot the choropleth map showing the cluster formed.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used.\nSaving it for next hands on 10\n\nwrite_rds(shan_ict, \"data/rds/shan_ict.rds\")\nwrite_rds(shan_sf_cluster, \"data/rds/shan_sf_cluster.rds\")\nwrite_rds(proxmat, \"data/rds/proxmat.rds\")"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html",
    "href": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html",
    "title": "Hands-On Exercise 10: Skater Approach to Spatially Constrainted Clustering",
    "section": "",
    "text": "In this hands on we will carry on from Hands on 9 where we stocked on the hierarchical analysis, here we look at the different methods such as skater, ClustGeo and the visual interpretation of clusters."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#loading-packages",
    "href": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#loading-packages",
    "title": "Hands-On Exercise 10: Skater Approach to Spatially Constrainted Clustering",
    "section": "10.1.1 Loading Packages",
    "text": "10.1.1 Loading Packages\n\npacman::p_load(spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#read-file-from-hands-on-9",
    "href": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#read-file-from-hands-on-9",
    "title": "Hands-On Exercise 10: Skater Approach to Spatially Constrainted Clustering",
    "section": "10.1.2 Read File from Hands on 9",
    "text": "10.1.2 Read File from Hands on 9\n\nshan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\nshan_ict &lt;- read_rds(\"data/rds/shan_ict.rds\")\nshan_sf_cluster &lt;- read_rds(\"data/rds/shan_sf_cluster.rds\")\nproxmat &lt;- read_rds(\"data/rds/proxmat.rds\")"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#converting-into-spatialpolygonsdataframe",
    "href": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#converting-into-spatialpolygonsdataframe",
    "title": "Hands-On Exercise 10: Skater Approach to Spatially Constrainted Clustering",
    "section": "10.2.1 Converting into SpatialPolygonsDataFrame",
    "text": "10.2.1 Converting into SpatialPolygonsDataFrame\nFirst, we need to convert shan_sf into SpatialPolygonsDataFrame. This is because SKATER function only support sp objects such as SpatialPolygonDataFrame.\nThe code chunk below uses as_Spatial() of sf package to convert shan_sf into a SpatialPolygonDataFrame called shan_sp.\n\nshan_sp &lt;- as_Spatial(shan_sf)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#computing-neighbour-list",
    "href": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#computing-neighbour-list",
    "title": "Hands-On Exercise 10: Skater Approach to Spatially Constrainted Clustering",
    "section": "10.2.2 Computing Neighbour List",
    "text": "10.2.2 Computing Neighbour List\nNext, poly2nd() of spdep package will be used to compute the neighbours list from polygon list.\n\nshan.nb &lt;- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nWe can plot the neighbours list on shan_sp by using the code chunk below. Since we now can plot the community area boundaries as well, we plot this graph on top of the map. The first plot command gives the boundaries. This is followed by the plot of the neighbor list object, with coordinates applied to the original SpatialPolygonDataFrame (Shan state township boundaries) to extract the centroids of the polygons. These are used as the nodes for the graph representation. We also set the color to blue and specify add=TRUE to plot the network on top of the boundaries.\n\ncoords &lt;- st_coordinates(\n  st_centroid(st_geometry(shan_sf)))\n\n\nplot(st_geometry(shan_sf), \n     border=grey(.5))\nplot(shan.nb,\n     coords, \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\n\n\n\n\nNote that if weplot the network first and then the boundaries, some of the areas will be clipped. This is because the plotting area is determined by the characteristics of the first plot. In this example, because the boundary map extends further than the graph, we plot it first."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#computing-minimum-spanning-tree",
    "href": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#computing-minimum-spanning-tree",
    "title": "Hands-On Exercise 10: Skater Approach to Spatially Constrainted Clustering",
    "section": "10.2.3 Computing minimum spanning tree",
    "text": "10.2.3 Computing minimum spanning tree\n\n10.2.3.1 Calculating edge costs\nNext, nbcosts() of spdep package is used to compute the cost of each edge. It is the distance between it nodes. This function compute this distance using a data.frame with observations vector in each node.\nThe code chunk below is used to compute the cost of each edge.\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\nFor each observation, this gives the pairwise dissimilarity between its values on the five variables and the values for the neighbouring observation (from the neighbour list). Basically, this is the notion of a generalised weight for a spatial weights matrix.\nNext, We will incorporate these costs into a weights object in the same way as we did in the calculation of inverse of distance weights. In other words, we convert the neighbour list to a list weights object by specifying the just computed lcosts as the weights.\nIn order to achieve this, nb2listw() of spdep package is used as shown in the code chunk below.\nNote that we specify the style as B to make sure the cost values are not row-standardised.\n\nshan.w &lt;- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#computing-minimum-spanning-tree-1",
    "href": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#computing-minimum-spanning-tree-1",
    "title": "Hands-On Exercise 10: Skater Approach to Spatially Constrainted Clustering",
    "section": "10.2.4 Computing minimum spanning tree",
    "text": "10.2.4 Computing minimum spanning tree\nThe minimum spanning tree is computed by mean of the mstree() of spdep package as shown in the code chunk below.\n\nshan.mst &lt;- mstree(shan.w)\n\nAfter computing the MST, we can check its class and dimension by using the code chunk below.\n\nclass(shan.mst)\n\n[1] \"mst\"    \"matrix\"\n\n\n\ndim(shan.mst)\n\n[1] 54  3\n\n\nNote that the dimension is 54 and not 55. This is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes.\nWe can display the content of shan.mst by using head() as shown in the code chunk below.\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   16   34 119.86993\n[2,]   34   24 113.80917\n[3,]   16   13 131.67061\n[4,]   13   28  92.79567\n[5,]   28   12  78.78999\n[6,]   12   49  59.69478\n\n\nThe plot method for the MST include a way to show the observation numbers of the nodes in addition to the edge. As before, we plot this together with the township boundaries. We can see how the initial neighbour list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.\n\nplot(st_geometry(shan_sf), \n                 border=gray(.5))\nplot.mst(shan.mst, \n         coords, \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#computing-spatially-constrained-clusters-using-skater-method",
    "href": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#computing-spatially-constrained-clusters-using-skater-method",
    "title": "Hands-On Exercise 10: Skater Approach to Spatially Constrainted Clustering",
    "section": "10.2.5 Computing spatially constrained clusters using SKATER method",
    "text": "10.2.5 Computing spatially constrained clusters using SKATER method\nThe code chunk below compute the spatially constrained cluster using skater() of spdep package.\n\nclust6 &lt;- spdep::skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\nThe skater() takes three mandatory arguments: - the first two columns of the MST matrix (i.e. not the cost), - the data matrix (to update the costs as units are being grouped), and - the number of cuts. Note: It is set to one less than the number of clusters. So, the value specified is not the number of clusters, but the number of cuts in the graph, one less than the number of clusters.\nThe result of the skater() is an object of class skater. We can examine its contents by using the code chunk below.\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 45 55 52 37 34 16 25 54 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 45 37 34 16 52 25 16 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nThe most interesting component of this list structure is the groups vector containing the labels of the cluster to which each observation belongs (as before, the label itself is arbitary). This is followed by a detailed summary for each of the clusters in the edges.groups list. Sum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.\nWe can check the cluster assignment by using the conde chunk below.\n\nccs6 &lt;- clust6$groups\nccs6\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\nWe can find out how many observations are in each cluster by means of the table command. Parenthetially, we can also find this as the dimension of each vector in the lists contained in edges.groups. For example, the first list has node with dimension 12, which is also the number of observations in the first cluster.\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nLastly, we can also plot the pruned tree that shows the five clusters on top of the townshop area.\n\nplot(st_geometry(shan_sf), \n     border=gray(.5))\nplot(clust6, \n     coords, \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005, \n     add=TRUE)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#visualising-the-clusters-in-choropleth-map",
    "href": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#visualising-the-clusters-in-choropleth-map",
    "title": "Hands-On Exercise 10: Skater Approach to Spatially Constrainted Clustering",
    "section": "10.2.6 Visualising the clusters in choropleth map",
    "text": "10.2.6 Visualising the clusters in choropleth map\nThe code chunk below is used to plot the newly derived clusters by using SKATER method.\n\ngroups_mat &lt;- as.matrix(clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\n\n\n\n\nFor easy comparison, it will be better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other.\n\nhclust.map &lt;- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map &lt;- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#a-short-note-about-clustgeo-package",
    "href": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#a-short-note-about-clustgeo-package",
    "title": "Hands-On Exercise 10: Skater Approach to Spatially Constrainted Clustering",
    "section": "10.3.1 A short note about ClustGeo package",
    "text": "10.3.1 A short note about ClustGeo package\nClustGeo package is an R package specially designed to support the need of performing spatially constrained cluster analysis. More specifically, it provides a Ward-like hierarchical clustering algorithm called hclustgeo() including spatial/geographical constraints.\nIn the nutshell, the algorithm uses two dissimilarity matrices D0 and D1 along with a mixing parameter alpha, whereby the value of alpha must be a real number between [0, 1]. D0 can be non-Euclidean and the weights of the observations can be non-uniform. It gives the dissimilarities in the attribute/clustering variable space. D1, on the other hand, gives the dissimilarities in the constraint space. The criterion minimised at each stage is a convex combination of the homogeneity criterion calculated with D0 and the homogeneity criterion calculated with D1.\nThe idea is then to determine a value of alpha which increases the spatial contiguity without deteriorating too much the quality of the solution based on the variables of interest. This need is supported by a function called choicealpha()."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#ward-like-hierarchical-clustering-clustgeo",
    "href": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#ward-like-hierarchical-clustering-clustgeo",
    "title": "Hands-On Exercise 10: Skater Approach to Spatially Constrainted Clustering",
    "section": "10.3.2 Ward-like hierarchical clustering: ClustGeo",
    "text": "10.3.2 Ward-like hierarchical clustering: ClustGeo\nClustGeo package provides function called hclustgeo() to perform a typical Ward-like hierarchical clustering just like hclust() you learned in previous section.\nTo perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix as shown in the code chunk below.\n\nnongeo_cluster &lt;- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\nNote that the dissimilarity matrix must be an object of class dist, i.e. an object obtained with the function dist(). For sample code chunk, please refer to 5.7.6 Computing proximity matrix\n\n10.3.2.1 Mapping the clusters formed\nSimilarly, we can plot the clusters on a categorical area shaded map by using the steps we learned in 5.7.12 Mapping the clusters formed.\n\ngroups &lt;- as.factor(cutree(nongeo_cluster, k=6))\n\n\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#spatially-constrained-hierarchical-clustering",
    "href": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#spatially-constrained-hierarchical-clustering",
    "title": "Hands-On Exercise 10: Skater Approach to Spatially Constrainted Clustering",
    "section": "10.3.3 Spatially Constrained Hierarchical Clustering",
    "text": "10.3.3 Spatially Constrained Hierarchical Clustering\nBefore we can performed spatially constrained hierarchical clustering, a spatial distance matrix will be derived by using st_distance() of sf package.\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\n\nNotice that as.dist() is used to convert the data frame into matrix.\nNext, choicealpha() will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.\n\ncr &lt;- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWith reference to the graphs above, alpha = 0.2 will be used as shown in the code chunk below.\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.2)\n\nNext, cutree() is used to derive the cluster objecct.\n\ngroups &lt;- as.factor(cutree(clustG, k=6))\n\nWe will then join back the group list with shan_sf polygon feature data frame by using the code chunk below.\n\nshan_sf_Gcluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nWe can now plot the map of the newly delineated spatially constrained clusters.\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#visualising-individual-clustering-variable",
    "href": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#visualising-individual-clustering-variable",
    "title": "Hands-On Exercise 10: Skater Approach to Spatially Constrainted Clustering",
    "section": "10.4.1 Visualising individual clustering variable",
    "text": "10.4.1 Visualising individual clustering variable\nCode chunk below is used to reveal the distribution of a clustering variable (i.e RADIO_PR) by cluster.\n\nggplot(data = shan_sf_ngeo_cluster,\n       aes(x = CLUSTER, y = RADIO_PR)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nThe boxplot reveals Cluster 3 displays the highest mean Radio Ownership Per Thousand Household. This is followed by Cluster 2, 1, 4, 6 and 5."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#multivariate-visualisation",
    "href": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#multivariate-visualisation",
    "title": "Hands-On Exercise 10: Skater Approach to Spatially Constrainted Clustering",
    "section": "10.4.2 Multivariate Visualisation",
    "text": "10.4.2 Multivariate Visualisation\nPast studies shown that parallel coordinate plot can be used to reveal clustering variables by cluster very effectively. In the code chunk below, ggparcoord() of GGally package\n\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TV and mobile-phone. On the other hand, households in Cluster 5 tends to own the lowest of all the five ICT.\nNote that the scale argument of ggparcoor() provide several methods to scale the clustering variables. They are:\n\nstd: univariately, subtract mean and divide by standard deviation.\nrobust: univariately, subtract median and divide by median absolute deviation.\nuniminmax: univariately, scale so the minimum of the variable is zero, and the maximum is one.\nglobalminmax: no scaling is done; the range of the graphs is defined by the global minimum and the global maximum.\ncenter: use uniminmax to standardize vertical height, then center each variable at a value specified by the scaleSummary param.\ncenterObs: use uniminmax to standardize vertical height, then center each variable at the value of the observation specified by the centerObsID param\n\nThere is no one best scaling method to use. You should explore them and select the one that best meet your analysis need.\nLast but not least, we can also compute the summary statistics such as mean, median, sd, etc to complement the visual interpretation.\nIn the code chunk below, group_by() and summarise() of dplyr are used to derive mean values of the clustering variables.\n\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%\n  group_by(CLUSTER) %&gt;%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#skater-approach-key-takeaways-and-steps",
    "href": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#skater-approach-key-takeaways-and-steps",
    "title": "Hands-On Exercise 10: Skater Approach to Spatially Constrainted Clustering",
    "section": "10.5.1 SKATER Approach – Key Takeaways and Steps",
    "text": "10.5.1 SKATER Approach – Key Takeaways and Steps\nThe SKATER approach, available through the spdep package, constructs clusters using a Minimum Spanning Tree (MST) to connect all nodes (spatial units) with minimal total edge costs. This method emphasizes minimizing the distance or dissimilarity between neighboring spatial units. It is particularly useful for small to medium-sized datasets with clearly defined neighbors.\n\n10.5.1.1 Key Concepts:\n\nMST (Minimum Spanning Tree):\nThe MST connects all nodes with the smallest possible sum of edge costs. It ensures no cycles exist and provides the basis for forming clusters.\nNumber of Cuts:\nThe number of cuts determines how the tree is partitioned into clusters. A higher number of cuts produces more clusters.\nWeights and Edge Costs:\nWeights are assigned to edges based on the dissimilarity between neighboring units. These weights are used to determine the optimal way to form clusters.\nCluster Formation:\nThe skater() function divides the MST into clusters by cutting the tree into a specified number of segments.\n\n\n\n10.5.1.2 Steps to Implement SKATER:\n\nConvert to SpatialPolygonsDataFrame:\nConvert the sf object into sp format using as_Spatial().\n\nshan_sp &lt;- as_Spatial(shan_sf)\n\nCreate Neighbor List:\nUse poly2nb() to generate a list of neighboring polygons.\n\nshan.nb &lt;- poly2nb(shan_sp)\n\nCompute Edge Costs\nCalculate the costs of connecting neighboring polygons using nbcosts().\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\nGenerate MST:\nCreate an MST using the neighbor list and edge costs with mstree().\n\nshan.mst &lt;- mstree(nb2listw(shan.nb, lcosts, style = \"B\"))\n\nApply SKATER Clustering:\nPartition the MST into clusters by specifying the number of cuts.\n\nclust6 &lt;- skater(edges = shan.mst[, 1:2], data = shan_ict, ncuts = 5)\n\nVisualize Clusters:\nPlot the clusters to interpret spatial patterns.\n\nplot(st_geometry(shan_sf), border = gray(0.5))\nplot(clust6, coords, col = \"blue\", add = TRUE)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#clustgeo-method-key-takeaways-and-steps",
    "href": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#clustgeo-method-key-takeaways-and-steps",
    "title": "Hands-On Exercise 10: Skater Approach to Spatially Constrainted Clustering",
    "section": "10.5.2 ClustGeo Method – Key Takeaways and Steps",
    "text": "10.5.2 ClustGeo Method – Key Takeaways and Steps\nThe ClustGeo method from the ClustGeo package provides a more flexible way to create spatially constrained clusters by balancing attribute similarity and geographic proximity. It extends the traditional hierarchical clustering algorithm by introducing spatial constraints through two dissimilarity matrices.\n\n10.5.2.1 Key Concepts:\n\nDissimilarity Matrices (D0 and D1):\n\nD0 measures the difference between units based on attributes (e.g., socioeconomic data).\nD1 measures the geographic distance between units.\n\nAlpha Parameter:\n\nAlpha (ranging from 0 to 1) controls the trade-off between D0 and D1. A lower value prioritizes attribute similarity, while a higher value emphasizes geographic continuity.\n\nChoice of Alpha:\nThe choicealpha() function helps determine the optimal alpha value that balances spatial and attribute-based clustering.\nHierarchical Clustering:\nThe hclustgeo() function performs clustering with the selected alpha value, generating spatially constrained clusters.\n\n\n\n10.5.2.2 Steps to Implement ClustGeo:\n\nCreate Attribute and Distance Matrices:\nCalculate the distance matrix using st_distance().\n\ndistmat &lt;- as.dist(st_distance(shan_sf))\n\nDetermine Optimal Alpha:\nUse choicealpha() to find the best balance between attributes and spatial proximity.\n\ncr &lt;- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K = 6, graph = TRUE)\n\nPerform Hierarchical Clustering:\nApply hclustgeo() with the optimal alpha value.\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.2)\n\nGenerate Final Clusters:\nUse cutree() to define the number of clusters.\n\ngroups &lt;- cutree(clustG, k = 6)\n\nVisualize Clusters:\nPlot the clusters on a choropleth map for comparison.\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#key-considerations-and-comparison-between-skater-and-clustgeo-methods",
    "href": "Hands_On_Exercises/Hands_On_Exercise_10/Hands_On_Exercise10.html#key-considerations-and-comparison-between-skater-and-clustgeo-methods",
    "title": "Hands-On Exercise 10: Skater Approach to Spatially Constrainted Clustering",
    "section": "10.5.3 Key Considerations and Comparison Between SKATER and ClustGeo Methods",
    "text": "10.5.3 Key Considerations and Comparison Between SKATER and ClustGeo Methods\n\n\n\n\n\n\n\n\nAspect\nSKATER\nClustGeo\n\n\n\n\nApproach\nConstructs clusters using a Minimum Spanning Tree (MST) for minimal distance between neighboring units.\nUses hierarchical clustering with two dissimilarity matrices: one for attributes (D0) and one for geographic distance (D1).\n\n\nControl over Spatial and Attribute Trade-off\nNo explicit control; clusters are purely based on minimizing spatial distance.\nOffers flexibility through the alpha parameter, balancing attribute similarity and spatial continuity.\n\n\nDataset Size Suitability\nWorks best with small to medium-sized datasets with clearly defined neighbors.\nSuitable for larger, more complex datasets that require a balance between multiple factors.\n\n\nComputational Efficiency\nFaster and easier to implement due to reliance on MST.\nComputationally intensive, especially for large datasets, due to hierarchical clustering and alpha optimization.\n\n\nInterpretation of Results\nSimple interpretation through MST visualization and cluster boundaries.\nProvides deeper insights using parallel coordinate plots, box plots, and attribute-based comparisons.\n\n\nScalability\nLimited scalability; performance declines with larger datasets.\nScales better with larger datasets, though it may require more computing resources.\n\n\nVisualization Capabilities\nFocuses on visualizing MST and cluster boundaries.\nSupports both spatial and multivariate visualization through choropleth maps and statistical plots.\n\n\nFlexibility in Cluster Formation\nRelies on MST structure, limiting flexibility.\nGreater flexibility by adjusting alpha to balance between spatial and attribute-based clustering.\n\n\nLimitations\n- Limited control over trade-offs between spatial and attribute similarity.\n- Less effective with large datasets.\n- Requires careful alpha selection, which can be time-consuming.\n- More computationally demanding."
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_10/In_Class_Exercise10.html",
    "href": "In_Class_Exercises/In_Class_Exercise_10/In_Class_Exercise10.html",
    "title": "In Class Exercise 10: Geospatial Data Science",
    "section": "",
    "text": "In Class 10:"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_10/In_Class_Exercise10.html#loading-packages",
    "href": "In_Class_Exercises/In_Class_Exercise_10/In_Class_Exercise10.html#loading-packages",
    "title": "In Class Exercise 10: Geospatial Data Science",
    "section": "1.1 Loading Packages",
    "text": "1.1 Loading Packages\n\npacman::p_load(spdep, tmap, sf, ClustGeo,ggpubr, cluster, factoextra, NbClust, heatmaply, corrplot, psych, tidyverse, GGally)"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_10/In_Class_Exercise10.html#read-file-from-hands-on-9",
    "href": "In_Class_Exercises/In_Class_Exercise_10/In_Class_Exercise10.html#read-file-from-hands-on-9",
    "title": "In Class Exercise 10: Geospatial Data Science",
    "section": "1.2 Read File from Hands on 9",
    "text": "1.2 Read File from Hands on 9\n\nshan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\nshan_ict &lt;- read_rds(\"data/rds/shan_ict.rds\") \nshan_sf_cluster &lt;- read_rds(\"data/rds/shan_sf_cluster.rds\")\nproxmat &lt;- read_rds(\"data/rds/proxmat.rds\")"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_10/In_Class_Exercise10.html#computing-spatial-distance-matrix",
    "href": "In_Class_Exercises/In_Class_Exercise_10/In_Class_Exercise10.html#computing-spatial-distance-matrix",
    "title": "In Class Exercise 10: Geospatial Data Science",
    "section": "3.1 Computing Spatial Distance Matrix",
    "text": "3.1 Computing Spatial Distance Matrix\n\nStep 1: Computing Nearest Neighbours\n\nshan.nb &lt;- poly2nb(shan_sf)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\n\n\nStep 2: Visualizing the neighbours\n\nplot(st_geometry(shan_sf), border=grey(0.5))\npts &lt;- st_coordinates(st_centroid(shan_sf))\nplot(shan.nb,\n      pts,\n      col = 'blue',\n      add = TRUE\n      )"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_10/In_Class_Exercise10.html#step-3-computing-minimum-spanning-tree",
    "href": "In_Class_Exercises/In_Class_Exercise_10/In_Class_Exercise10.html#step-3-computing-minimum-spanning-tree",
    "title": "In Class Exercise 10: Geospatial Data Science",
    "section": "Step 3: Computing Minimum Spanning Tree",
    "text": "Step 3: Computing Minimum Spanning Tree\n\nCalculating Edge CostsIncorporating These costs into a weights objectComputing MSTVIsualising MST\n\n\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\n\n\nStyle have to have B,\n\nshan.w &lt;- nb2listw(shan.nb,\n                   lcosts,\n                   style = \"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\n\n\n\nshan.mst &lt;- mstree(shan.w)\n\n\n\n\nplot(st_geometry((shan_sf), baorder=gray(0.5)))\nplot.mst(shan.mst, pts,\n         col=\"blue\",\n         cex.lab = 0.7, \n         cex.circles = 0.005,\n         add= TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nComputing Spatially Constraint Clusters using SKATER Method\n\nCodeSkater TreeThe Code to plot\n\n\n\nskater.clust6 &lt;- skater(edges = shan.mst[,1:2],\n                        data = shan_ict,\n                        method = \"euclidean\",\n                        ncuts = 5\n                        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot(st_geometry(shan_sf), border = gray(0.5))\n\n# Plot the skater clusters with better parameter alignment\nplot(skater.clust6,\n     coords = pts,                  # Specify coordinates\n     cex.lab = 1,                   # Adjust label size for clarity\n     groups.colors = c(\"red\", \"green\", \"blue\", \"brown\", \"pink\"),\n     cex.circles = 0.005,             # Adjust the circle size\n     add = TRUE)                    # Overlay on the previous plot"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_10/In_Class_Exercise10.html#computing-spatially-constrained-clusters-using-skater-method",
    "href": "In_Class_Exercises/In_Class_Exercise_10/In_Class_Exercise10.html#computing-spatially-constrained-clusters-using-skater-method",
    "title": "In Class Exercise 10: Geospatial Data Science",
    "section": "Computing Spatially Constrained Clusters using SKATER method",
    "text": "Computing Spatially Constrained Clusters using SKATER method\n\nPlotCode\n\n\n\ngroups_mat &lt;- as.matrix(skater.clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename('skater_CLUSTER' = 'as.factor.groups_mat.')\nqtm(shan_sf_spatialcluster, \"skater_CLUSTER\")\n\n\n\n\n\n\n\n\n\n\n\ngroups_mat &lt;- as.matrix(skater.clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename('skater_CLUSTER' = 'as.factor.groups_mat.')\nqtm(shan_sf_spatialcluster, \"skater_CLUSTER\")"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_10/In_Class_Exercise10.html#computing-spatial-distance-matrix-1",
    "href": "In_Class_Exercises/In_Class_Exercise_10/In_Class_Exercise10.html#computing-spatial-distance-matrix-1",
    "title": "In Class Exercise 10: Geospatial Data Science",
    "section": "4.1 Computing Spatial Distance Matrix",
    "text": "4.1 Computing Spatial Distance Matrix\n\nComputing Spatial Distance MatrixThe Cluster GraphsThe CodeSaving ClustGeoOutput\n\n\nST_distance() of sf package is used to compute the distance matrix.\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncr &lt;- choicealpha(proxmat, distmat,\n                  range.alpha = seq(0, 1, 0.1),\n                  K=6, graph = TRUE\n                  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclust6 &lt;- hclustgeo(proxmat, distmat, alpha = 0.2)\ngroups &lt;- as.factor(cutree(clust6, k=6))\nshan_sf_clustGeo &lt;- cbind( shan_sf, \n                            as.matrix(groups)) %&gt;%\n  rename(\"clustGEO\" = \"as.matrix.groups.\" )"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_10/In_Class_Exercise10.html#visualizing-the-map",
    "href": "In_Class_Exercises/In_Class_Exercise_10/In_Class_Exercise10.html#visualizing-the-map",
    "title": "In Class Exercise 10: Geospatial Data Science",
    "section": "4.2 Visualizing the map",
    "text": "4.2 Visualizing the map\n\nqtm(shan_sf_clustGeo, \"clustGEO\")"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_11/Hands_On_Exercise11.html",
    "href": "Hands_On_Exercises/Hands_On_Exercise_11/Hands_On_Exercise11.html",
    "title": "Hands-On Exercise 11 Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, you will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_11/Hands_On_Exercise11.html#overview",
    "href": "Hands_On_Exercises/Hands_On_Exercise_11/Hands_On_Exercise11.html#overview",
    "title": "Hands-On Exercise 11 Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, you will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_11/Hands_On_Exercise11.html#the-data",
    "href": "Hands_On_Exercises/Hands_On_Exercise_11/Hands_On_Exercise11.html#the-data",
    "title": "Hands-On Exercise 11 Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "11.2 The Data",
    "text": "11.2 The Data\nTwo data sets will be used in this model building exercise, they are:\n\nURA Master Plan subzone boundary in shapefile format (i.e. MP14_SUBZONE_WEB_PL)\ncondo_resale_2015 in csv format (i.e. condo_resale_2015.csv)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_11/Hands_On_Exercise11.html#getting-started",
    "href": "Hands_On_Exercises/Hands_On_Exercise_11/Hands_On_Exercise11.html#getting-started",
    "title": "Hands-On Exercise 11 Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "11.3 Getting Started",
    "text": "11.3 Getting Started\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\nThe R packages needed for this exercise are as follows:\n\nR package for building OLS and performing diagnostics tests\n\nolsrr\n\nR package for calibrating geographical weighted family of models\n\nGWmodel\n\nR package for multivariate data visualisation and analysis\n\ncorrplot\n\nSpatial data handling\n\nsf\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_11/Hands_On_Exercise11.html#a-short-note-about-gwmodel",
    "href": "Hands_On_Exercises/Hands_On_Exercise_11/Hands_On_Exercise11.html#a-short-note-about-gwmodel",
    "title": "Hands-On Exercise 11 Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "11.4 A short note about GWmodel",
    "text": "11.4 A short note about GWmodel\nGWmodel package provides a collection of localised spatial statistical methods, namely: GW summary statistics, GW principal components analysis, GW discriminant analysis and various forms of GW regression; some of which are provided in basic and robust (outlier resistant) forms. Commonly, outputs or parameters of the GWmodel are mapped to provide a useful exploratory tool, which can often precede (and direct) a more traditional or sophisticated statistical analysis."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_11/Hands_On_Exercise11.html#geospatial-data-wrangling",
    "href": "Hands_On_Exercises/Hands_On_Exercise_11/Hands_On_Exercise11.html#geospatial-data-wrangling",
    "title": "Hands-On Exercise 11 Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "11.5 Geospatial Data Wrangling",
    "text": "11.5 Geospatial Data Wrangling\n\n11.5.1 Importing geospatial data\nThe geospatial data used in this hands-on exercise is called MP14_SUBZONE_WEB_PL. It is in ESRI shapefile format. The shapefile consists of URA Master Plan 2014’s planning subzone boundaries. Polygon features are used to represent these geographic boundaries. The GIS data is in svy21 projected coordinates systems.\nThe code chunk below is used to import MP_SUBZONE_WEB_PL shapefile by using st_read() of sf packages.\n\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\jiale\\Desktop\\IS415\\IS415-GAA\\Hands_On_Exercises\\Hands_On_Exercise_11\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n11.5.2 Updating CRS information\nThe code chunk below updates the newly imported mpsz with the correct ESPG code (i.e. 3414)\n\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)\n\nAfter transforming the projection metadata, you can varify the projection of the newly transformed mpsz_svy21 by using st_crs() of sf package.\nThe code chunk below will be used to varify the newly transformed mpsz_svy21.\n\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG: is indicated as 3414 now.\nNext, we will reveal the extent of mpsz_svy21 by using st_bbox() of sf package.\n\nst_bbox(mpsz_svy21) #view extent\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_11/Hands_On_Exercise11.html#aspatial-data-wrangling",
    "href": "Hands_On_Exercises/Hands_On_Exercise_11/Hands_On_Exercise11.html#aspatial-data-wrangling",
    "title": "Hands-On Exercise 11 Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "11.6 Aspatial Data Wrangling",
    "text": "11.6 Aspatial Data Wrangling\n\n11.6.1 Importing the aspatial data\nThe condo_resale_2015 is in csv file format. The codes chunk below uses read_csv() function of readr package to import condo_resale_2015 into R as a tibble data frame called condo_resale.\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nRows: 1436 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (23): LATITUDE, LONGITUDE, POSTCODE, SELLING_PRICE, AREA_SQM, AGE, PROX_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe codes chunks below uses glimpse() to display the data structure of will do the job.\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             &lt;dbl&gt; 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            &lt;dbl&gt; 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nhead(condo_resale$LONGITUDE) #see the data in XCOORD column\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\n\nhead(condo_resale$LATITUDE) #see the data in YCOORD column\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\nNext, summary() of base R is used to display the summary statistics of cond_resale tibble data frame.\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n\n11.6.2 Converting aspatial data frame into a sf object\nCurrently, the condo_resale tibble data frame is aspatial. We will convert it to a sf object. The code chunk below converts condo_resale data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %&gt;%\n  st_transform(crs=3414)\n\nNotice that st_transform() of sf package is used to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).\nNext, head() is used to list the content of condo_resale.sf object.\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\nNotice that the output is in point feature data frame."
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_11/Hands_On_Exercise11.html#exploratory-data-analysis-eda",
    "href": "Hands_On_Exercises/Hands_On_Exercise_11/Hands_On_Exercise11.html#exploratory-data-analysis-eda",
    "title": "Hands-On Exercise 11 Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "11.7 Exploratory Data Analysis (EDA)",
    "text": "11.7 Exploratory Data Analysis (EDA)\nIn the section, you will learn how to use statistical graphics functions of ggplot2 package to perform EDA.\n\n11.7.1 EDA using statistical graphics\nWe can plot the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\nStatistically, the skewed dsitribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nNow, you can plot the LOG_SELLING_PRICE using the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\n\nNotice that the distribution is relatively less skewed after the transformation.\n\n\n11.7.2 Multiple Histogram Plots distribution of variables\nIn this section, you will learn how to draw a small multiple histograms (also known as trellis plot) by using ggarrange() of ggpubr package.\nThe code chunk below is used to create 12 histograms. Then, ggarrange() is used to organised these histogram into a 3 columns by 4 rows small multiple plot.\n\nAREA_SQM &lt;- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE &lt;- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)\n\n\n\n\n\n\n\n\n\n\n11.7.3 Drawing Statistical Point Map\nLastly, we want to reveal the geospatial distribution condominium resale prices in Singapore. The map will be prepared by using tmap package.\nFirst, we will turn on the interactive mode of tmap by using the code chunk below.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n\nNext, the code chunks below is used to create an interactive point symbol map.\n\ntmap_options(check.and.fix = TRUE)\n\ntm_shape(mpsz_svy21)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\n\n\n\n\nNotice that tm_dots() is used instead of tm_bubbles().\nset.zoom.limits argument of tm_view() sets the minimum and maximum zoom level to 11 and 14 respectively.\nBefore moving on to the next section, the code below will be used to turn R display into plot mode.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "Hands_On_Exercises/Hands_On_Exercise_11/Hands_On_Exercise11.html#hedonic-pricing-modelling-in-r",
    "href": "Hands_On_Exercises/Hands_On_Exercise_11/Hands_On_Exercise11.html#hedonic-pricing-modelling-in-r",
    "title": "Hands-On Exercise 11 Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "11.8 Hedonic Pricing Modelling in R",
    "text": "11.8 Hedonic Pricing Modelling in R\nIn this section, you will learn how to building hedonic pricing models for condominium resale units using lm() of R base.\n\n11..8.1 Simple Linear Regression Method\nFirst, we will build a simple linear regression model by using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\n\ncondo.slr &lt;- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nlm() returns an object of class “lm” or for multiple responses of class c(“mlm”, “lm”).\nThe functions summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n*y = -258121.1 + 14719x1*\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\nTo visualise the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFigure above reveals that there are a few statistical outliers with relatively high selling prices.\n\n\n11.8.2 Multiple Linear Regression Method\n\n11.8.2.1 Visualising the relationships of the independent variables\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building.\n\n\n\n11.8.3 Building a hedonic pricing model using multiple linear regression method\nThe code chunk below using lm() to calibrate the multiple linear regression model.\n\ncondo.mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16\n\n\n\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nCoefficients:\n         (Intercept)              AREA_SQM                   AGE  \n            481728.4               12708.3              -24440.8  \n            PROX_CBD        PROX_CHILDCARE      PROX_ELDERLYCARE  \n            -78669.8             -351617.9              171029.4  \nPROX_URA_GROWTH_AREA    PROX_HAWKER_MARKET     PROX_KINDERGARTEN  \n             38474.5               23746.1              147469.0  \n            PROX_MRT             PROX_PARK      PROX_PRIMARY_SCH  \n           -314599.7              563280.5              180186.1  \nPROX_TOP_PRIMARY_SCH    PROX_SHOPPING_MALL      PROX_SUPERMARKET  \n              2280.0             -206604.1              -44991.8  \n       PROX_BUS_STOP           NO_Of_UNITS       FAMILY_FRIENDLY  \n            683121.3                -231.2              140340.8  \n            FREEHOLD  \n            359913.0  \n\n\n\n\n11.8.4 Preparing Publication Quality Table: olsrr method\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing those variables which are not statistically significant.\nNow, we are ready to calibrate the revised model by using the code chunk below.\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n\n11.8.5 Preparing Publication Quality Table: gtsummary method\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression report.\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\n(Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n\n\nAREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n\n\nAGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n\n\nPROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n\n\nPROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n\n\nPROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n\n\nPROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n\n\nPROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n\n\nPROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n\n\nPROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n\n\nPROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n\n\nPROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n\n\nNO_Of_UNITS\n-245\n-418, -73\n0.005\n\n\nFAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n\n\nFREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\nWith gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() as shown in the code chunk below.\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %&gt;% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\n11.8.5.1 Checking for multicolinearity\nIn this section, we would like to introduce you a fantastic R package specially programmed for performing OLS regression. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\nIn the code chunk below, the ols_vif_tol() of olsrr package is used to test if there are sign of multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\n11.8.5.2 Test for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\n\n\n\n\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n11.8.5.3 Test for Normality Assumption\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\nIf you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chun below.\n\nols_test_normality(condo.mlr1)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n\n11.8.5.4 Testing for Spatial Autocorrelation\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\nIn order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\nNext, we will join the newly created data frame with condo_resale.sf object.\n\ncondo_resale.res.sf &lt;- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\nNext, we will convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\nThe code chunk below will be used to perform the data conversion process.\n\ncondo_resale.sp &lt;- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n\nThe code chunks below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\nVariable(s) \"MLR_RES\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\nRemember to switch back to “plot” mode before continue.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nThe figure above reveal that there is sign of spatial autocorrelation.\nTo proof that our observation is indeed true, the Moran’s I test will be performed\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\nnb &lt;- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw() of spdep packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.\n\nnb_lw &lt;- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nNext, lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_9/In_Class_Exercise9.html",
    "href": "In_Class_Exercises/In_Class_Exercise_9/In_Class_Exercise9.html",
    "title": "In Class Exercise 9: Geospatial Data Science",
    "section": "",
    "text": "There is no in class 9 :D"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_11/In_Class_Exercise11.html",
    "href": "In_Class_Exercises/In_Class_Exercise_11/In_Class_Exercise11.html",
    "title": "In Class Exercise11: Geospatial Data Science",
    "section": "",
    "text": "pacman::p_load(olsrr, ggstatsplot, sf, \n               tmap, tidyverse, gtsummary,\n               performance, see, sfdep)"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_11/In_Class_Exercise11.html#forward",
    "href": "In_Class_Exercises/In_Class_Exercise_11/In_Class_Exercise11.html#forward",
    "title": "In Class Exercise11: Geospatial Data Science",
    "section": "Forward",
    "text": "Forward\n\ncondo_fw_mlr &lt;- ols_step_forward_p(\n  condo_mlr,\n  p_value = 0.05,\n  details = FALSE\n)\ncondo_fw_mlr\n\n\n                                     Stepwise Summary                                      \n-----------------------------------------------------------------------------------------\nStep    Variable                   AIC          SBC         SBIC         R2       Adj. R2 \n-----------------------------------------------------------------------------------------\n 0      Base Model              44449.068    44459.608    40371.745    0.00000    0.00000 \n 1      AREA_SQM                43587.753    43603.562    39510.883    0.45184    0.45146 \n 2      PROX_CBD                43243.523    43264.602    39167.182    0.56928    0.56868 \n 3      PROX_PARK               43177.691    43204.039    39101.331    0.58915    0.58829 \n 4      FREEHOLD                43125.474    43157.092    39049.179    0.60438    0.60327 \n 5      AGE                     43069.222    43106.109    38993.167    0.62010    0.61878 \n 6      PROX_ELDERLYCARE        43046.515    43088.672    38970.548    0.62659    0.62502 \n 7      PROX_SHOPPING_MALL      43020.990    43068.417    38945.209    0.63367    0.63188 \n 8      PROX_URA_GROWTH_AREA    43009.092    43061.788    38933.407    0.63720    0.63517 \n 9      PROX_MRT                42999.058    43057.024    38923.483    0.64023    0.63796 \n 10     PROX_BUS_STOP           42984.951    43048.186    38909.582    0.64424    0.64175 \n 11     FAMILY_FRIENDLY         42981.085    43049.590    38905.797    0.64569    0.64296 \n 12     NO_Of_UNITS             42975.246    43049.021    38900.092    0.64762    0.64465 \n 13     PROX_CHILDCARE          42971.858    43050.902    38896.812    0.64894    0.64573 \n 14     PROX_PRIMARY_SCH        42966.758    43051.072    38891.872    0.65067    0.64723 \n 15     PROX_KINDERGARTEN       42965.558    43055.141    38890.764    0.65145    0.64777 \n 16     LEASEHOLD_99YR          42966.461    43061.315    38891.719    0.65172    0.64779 \n-----------------------------------------------------------------------------------------\n\nFinal Model Output \n------------------\n\n                             Model Summary                               \n------------------------------------------------------------------------\nR                            0.807       RMSE                750874.428 \nR-Squared                    0.652       MSE                5.70567e+11 \nAdj. R-Squared               0.648       Coef. Var               43.134 \nPred R-Squared               0.638       AIC                  42966.461 \nMAE                     411897.724       SBC                  43061.315 \n------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                   ANOVA                                     \n----------------------------------------------------------------------------\n                    Sum of                                                  \n                   Squares          DF     Mean Square       F         Sig. \n----------------------------------------------------------------------------\nRegression    1.515012e+15          16    9.468826e+13    165.955    0.0000 \nResidual      8.096346e+14        1419     5.70567e+11                      \nTotal         2.324647e+15        1435                                      \n----------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     519699.927    128234.561                   4.053    0.000     268150.245     771249.608 \n            AREA_SQM      12702.113       369.007        0.580     34.422    0.000      11978.255      13425.971 \n            PROX_CBD     -75476.279      5819.468       -0.258    -12.970    0.000     -86891.965     -64060.594 \n           PROX_PARK     576878.778     65530.431        0.152      8.803    0.000     448331.849     705425.707 \n            FREEHOLD     297996.146     77131.262        0.116      3.863    0.000     146692.595     449299.698 \n                 AGE     -24816.754      2755.044       -0.168     -9.008    0.000     -30221.151     -19412.358 \n    PROX_ELDERLYCARE     180555.137     39950.132        0.087      4.520    0.000     102187.473     258922.800 \n  PROX_SHOPPING_MALL    -223969.967     36591.526       -0.117     -6.121    0.000    -295749.265    -152190.670 \nPROX_URA_GROWTH_AREA      40625.098     11767.501        0.063      3.452    0.001      17541.531      63708.665 \n            PROX_MRT    -320213.443     58238.187       -0.122     -5.498    0.000    -434455.636    -205971.249 \n       PROX_BUS_STOP     703885.644    135632.439        0.138      5.190    0.000     437824.008     969947.280 \n     FAMILY_FRIENDLY     145777.182     46903.196        0.057      3.108    0.002      53770.128     237784.236 \n         NO_Of_UNITS       -221.684        89.137       -0.048     -2.487    0.013       -396.539        -46.829 \n      PROX_CHILDCARE    -316772.357    109911.190       -0.083     -2.882    0.004    -532378.234    -101166.479 \n    PROX_PRIMARY_SCH     166247.757     60327.564        0.064      2.756    0.006      47906.964     284588.549 \n   PROX_KINDERGARTEN     135556.889     79957.482        0.028      1.695    0.090     -21290.680     292404.458 \n      LEASEHOLD_99YR     -79734.853     76595.123       -0.031     -1.041    0.298    -229986.694      70516.988 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\nplot(condo_fw_mlr)"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_11/In_Class_Exercise11.html#backwards",
    "href": "In_Class_Exercises/In_Class_Exercise_11/In_Class_Exercise11.html#backwards",
    "title": "In Class Exercise11: Geospatial Data Science",
    "section": "Backwards",
    "text": "Backwards\n\ncondo_bw_mlr &lt;- ols_step_backward_p(\n  condo_mlr,\n  p_value = 0.05,\n  details = FALSE\n)\ncondo_fw_mlr\n\n\n                                     Stepwise Summary                                      \n-----------------------------------------------------------------------------------------\nStep    Variable                   AIC          SBC         SBIC         R2       Adj. R2 \n-----------------------------------------------------------------------------------------\n 0      Base Model              44449.068    44459.608    40371.745    0.00000    0.00000 \n 1      AREA_SQM                43587.753    43603.562    39510.883    0.45184    0.45146 \n 2      PROX_CBD                43243.523    43264.602    39167.182    0.56928    0.56868 \n 3      PROX_PARK               43177.691    43204.039    39101.331    0.58915    0.58829 \n 4      FREEHOLD                43125.474    43157.092    39049.179    0.60438    0.60327 \n 5      AGE                     43069.222    43106.109    38993.167    0.62010    0.61878 \n 6      PROX_ELDERLYCARE        43046.515    43088.672    38970.548    0.62659    0.62502 \n 7      PROX_SHOPPING_MALL      43020.990    43068.417    38945.209    0.63367    0.63188 \n 8      PROX_URA_GROWTH_AREA    43009.092    43061.788    38933.407    0.63720    0.63517 \n 9      PROX_MRT                42999.058    43057.024    38923.483    0.64023    0.63796 \n 10     PROX_BUS_STOP           42984.951    43048.186    38909.582    0.64424    0.64175 \n 11     FAMILY_FRIENDLY         42981.085    43049.590    38905.797    0.64569    0.64296 \n 12     NO_Of_UNITS             42975.246    43049.021    38900.092    0.64762    0.64465 \n 13     PROX_CHILDCARE          42971.858    43050.902    38896.812    0.64894    0.64573 \n 14     PROX_PRIMARY_SCH        42966.758    43051.072    38891.872    0.65067    0.64723 \n 15     PROX_KINDERGARTEN       42965.558    43055.141    38890.764    0.65145    0.64777 \n 16     LEASEHOLD_99YR          42966.461    43061.315    38891.719    0.65172    0.64779 \n-----------------------------------------------------------------------------------------\n\nFinal Model Output \n------------------\n\n                             Model Summary                               \n------------------------------------------------------------------------\nR                            0.807       RMSE                750874.428 \nR-Squared                    0.652       MSE                5.70567e+11 \nAdj. R-Squared               0.648       Coef. Var               43.134 \nPred R-Squared               0.638       AIC                  42966.461 \nMAE                     411897.724       SBC                  43061.315 \n------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                   ANOVA                                     \n----------------------------------------------------------------------------\n                    Sum of                                                  \n                   Squares          DF     Mean Square       F         Sig. \n----------------------------------------------------------------------------\nRegression    1.515012e+15          16    9.468826e+13    165.955    0.0000 \nResidual      8.096346e+14        1419     5.70567e+11                      \nTotal         2.324647e+15        1435                                      \n----------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     519699.927    128234.561                   4.053    0.000     268150.245     771249.608 \n            AREA_SQM      12702.113       369.007        0.580     34.422    0.000      11978.255      13425.971 \n            PROX_CBD     -75476.279      5819.468       -0.258    -12.970    0.000     -86891.965     -64060.594 \n           PROX_PARK     576878.778     65530.431        0.152      8.803    0.000     448331.849     705425.707 \n            FREEHOLD     297996.146     77131.262        0.116      3.863    0.000     146692.595     449299.698 \n                 AGE     -24816.754      2755.044       -0.168     -9.008    0.000     -30221.151     -19412.358 \n    PROX_ELDERLYCARE     180555.137     39950.132        0.087      4.520    0.000     102187.473     258922.800 \n  PROX_SHOPPING_MALL    -223969.967     36591.526       -0.117     -6.121    0.000    -295749.265    -152190.670 \nPROX_URA_GROWTH_AREA      40625.098     11767.501        0.063      3.452    0.001      17541.531      63708.665 \n            PROX_MRT    -320213.443     58238.187       -0.122     -5.498    0.000    -434455.636    -205971.249 \n       PROX_BUS_STOP     703885.644    135632.439        0.138      5.190    0.000     437824.008     969947.280 \n     FAMILY_FRIENDLY     145777.182     46903.196        0.057      3.108    0.002      53770.128     237784.236 \n         NO_Of_UNITS       -221.684        89.137       -0.048     -2.487    0.013       -396.539        -46.829 \n      PROX_CHILDCARE    -316772.357    109911.190       -0.083     -2.882    0.004    -532378.234    -101166.479 \n    PROX_PRIMARY_SCH     166247.757     60327.564        0.064      2.756    0.006      47906.964     284588.549 \n   PROX_KINDERGARTEN     135556.889     79957.482        0.028      1.695    0.090     -21290.680     292404.458 \n      LEASEHOLD_99YR     -79734.853     76595.123       -0.031     -1.041    0.298    -229986.694      70516.988 \n-----------------------------------------------------------------------------------------------------------------"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_11/In_Class_Exercise11.html#both-direction",
    "href": "In_Class_Exercises/In_Class_Exercise_11/In_Class_Exercise11.html#both-direction",
    "title": "In Class Exercise11: Geospatial Data Science",
    "section": "Both Direction",
    "text": "Both Direction\n\ncondo_bidirectional_mlr &lt;- ols_step_both_p(\n  condo_mlr,\n  p_value = 0.05,\n  details = FALSE\n)\ncondo_fw_mlr\n\n\n                                     Stepwise Summary                                      \n-----------------------------------------------------------------------------------------\nStep    Variable                   AIC          SBC         SBIC         R2       Adj. R2 \n-----------------------------------------------------------------------------------------\n 0      Base Model              44449.068    44459.608    40371.745    0.00000    0.00000 \n 1      AREA_SQM                43587.753    43603.562    39510.883    0.45184    0.45146 \n 2      PROX_CBD                43243.523    43264.602    39167.182    0.56928    0.56868 \n 3      PROX_PARK               43177.691    43204.039    39101.331    0.58915    0.58829 \n 4      FREEHOLD                43125.474    43157.092    39049.179    0.60438    0.60327 \n 5      AGE                     43069.222    43106.109    38993.167    0.62010    0.61878 \n 6      PROX_ELDERLYCARE        43046.515    43088.672    38970.548    0.62659    0.62502 \n 7      PROX_SHOPPING_MALL      43020.990    43068.417    38945.209    0.63367    0.63188 \n 8      PROX_URA_GROWTH_AREA    43009.092    43061.788    38933.407    0.63720    0.63517 \n 9      PROX_MRT                42999.058    43057.024    38923.483    0.64023    0.63796 \n 10     PROX_BUS_STOP           42984.951    43048.186    38909.582    0.64424    0.64175 \n 11     FAMILY_FRIENDLY         42981.085    43049.590    38905.797    0.64569    0.64296 \n 12     NO_Of_UNITS             42975.246    43049.021    38900.092    0.64762    0.64465 \n 13     PROX_CHILDCARE          42971.858    43050.902    38896.812    0.64894    0.64573 \n 14     PROX_PRIMARY_SCH        42966.758    43051.072    38891.872    0.65067    0.64723 \n 15     PROX_KINDERGARTEN       42965.558    43055.141    38890.764    0.65145    0.64777 \n 16     LEASEHOLD_99YR          42966.461    43061.315    38891.719    0.65172    0.64779 \n-----------------------------------------------------------------------------------------\n\nFinal Model Output \n------------------\n\n                             Model Summary                               \n------------------------------------------------------------------------\nR                            0.807       RMSE                750874.428 \nR-Squared                    0.652       MSE                5.70567e+11 \nAdj. R-Squared               0.648       Coef. Var               43.134 \nPred R-Squared               0.638       AIC                  42966.461 \nMAE                     411897.724       SBC                  43061.315 \n------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                   ANOVA                                     \n----------------------------------------------------------------------------\n                    Sum of                                                  \n                   Squares          DF     Mean Square       F         Sig. \n----------------------------------------------------------------------------\nRegression    1.515012e+15          16    9.468826e+13    165.955    0.0000 \nResidual      8.096346e+14        1419     5.70567e+11                      \nTotal         2.324647e+15        1435                                      \n----------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     519699.927    128234.561                   4.053    0.000     268150.245     771249.608 \n            AREA_SQM      12702.113       369.007        0.580     34.422    0.000      11978.255      13425.971 \n            PROX_CBD     -75476.279      5819.468       -0.258    -12.970    0.000     -86891.965     -64060.594 \n           PROX_PARK     576878.778     65530.431        0.152      8.803    0.000     448331.849     705425.707 \n            FREEHOLD     297996.146     77131.262        0.116      3.863    0.000     146692.595     449299.698 \n                 AGE     -24816.754      2755.044       -0.168     -9.008    0.000     -30221.151     -19412.358 \n    PROX_ELDERLYCARE     180555.137     39950.132        0.087      4.520    0.000     102187.473     258922.800 \n  PROX_SHOPPING_MALL    -223969.967     36591.526       -0.117     -6.121    0.000    -295749.265    -152190.670 \nPROX_URA_GROWTH_AREA      40625.098     11767.501        0.063      3.452    0.001      17541.531      63708.665 \n            PROX_MRT    -320213.443     58238.187       -0.122     -5.498    0.000    -434455.636    -205971.249 \n       PROX_BUS_STOP     703885.644    135632.439        0.138      5.190    0.000     437824.008     969947.280 \n     FAMILY_FRIENDLY     145777.182     46903.196        0.057      3.108    0.002      53770.128     237784.236 \n         NO_Of_UNITS       -221.684        89.137       -0.048     -2.487    0.013       -396.539        -46.829 \n      PROX_CHILDCARE    -316772.357    109911.190       -0.083     -2.882    0.004    -532378.234    -101166.479 \n    PROX_PRIMARY_SCH     166247.757     60327.564        0.064      2.756    0.006      47906.964     284588.549 \n   PROX_KINDERGARTEN     135556.889     79957.482        0.028      1.695    0.090     -21290.680     292404.458 \n      LEASEHOLD_99YR     -79734.853     76595.123       -0.031     -1.041    0.298    -229986.694      70516.988 \n-----------------------------------------------------------------------------------------------------------------"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_11/In_Class_Exercise11.html#step-1-exporting-residual-hedonic-pricing-as-df",
    "href": "In_Class_Exercises/In_Class_Exercise_11/In_Class_Exercise11.html#step-1-exporting-residual-hedonic-pricing-as-df",
    "title": "In Class Exercise11: Geospatial Data Science",
    "section": "Step 1: Exporting Residual Hedonic Pricing as DF",
    "text": "Step 1: Exporting Residual Hedonic Pricing as DF\n\nmlr_output &lt;- as.data.frame(condo_fw_mlr$model$residuals) %&gt;%\n  rename(`FW_MLR_RES` = `condo_fw_mlr$model$residuals`)"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_11/In_Class_Exercise11.html#step-2-join-newly-created-df-with-condo_resale_sf-object",
    "href": "In_Class_Exercises/In_Class_Exercise_11/In_Class_Exercise11.html#step-2-join-newly-created-df-with-condo_resale_sf-object",
    "title": "In Class Exercise11: Geospatial Data Science",
    "section": "Step 2: Join newly Created DF with condo_resale_sf object",
    "text": "Step 2: Join newly Created DF with condo_resale_sf object\n\ncondo_resale_sf &lt;- cbind(condo_resale_sf, \n                        mlr_output$FW_MLR_RES) %&gt;%\n  rename(`MLR_RES` = `mlr_output.FW_MLR_RES`)"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_11/In_Class_Exercise11.html#step-3-visualizing-the-distribution-of-residual-on-interactive-map",
    "href": "In_Class_Exercises/In_Class_Exercise_11/In_Class_Exercise11.html#step-3-visualizing-the-distribution-of-residual-on-interactive-map",
    "title": "In Class Exercise11: Geospatial Data Science",
    "section": "Step 3: Visualizing the distribution of residual on interactive map",
    "text": "Step 3: Visualizing the distribution of residual on interactive map\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(mpsz)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale_sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") \n\nVariable(s) \"MLR_RES\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_11/In_Class_Exercise11.html#step-1-compute-the-distance-based-weight-matrix-by-using-dnearneigh-function-of-spdep.",
    "href": "In_Class_Exercises/In_Class_Exercise_11/In_Class_Exercise11.html#step-1-compute-the-distance-based-weight-matrix-by-using-dnearneigh-function-of-spdep.",
    "title": "In Class Exercise11: Geospatial Data Science",
    "section": "Step 1: compute the distance-based weight matrix by using dnearneigh() function of spdep.",
    "text": "Step 1: compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\ncondo_resale_sf &lt;- condo_resale_sf %&gt;%\n  mutate(nb = st_knn(geometry, k=6,\n                     longlat = FALSE),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)"
  },
  {
    "objectID": "In_Class_Exercises/In_Class_Exercise_11/In_Class_Exercise11.html#step-2-global_moran_perm-of-sfdep-is-used-to-perform-global-moran-permutation-test.",
    "href": "In_Class_Exercises/In_Class_Exercise_11/In_Class_Exercise11.html#step-2-global_moran_perm-of-sfdep-is-used-to-perform-global-moran-permutation-test.",
    "title": "In Class Exercise11: Geospatial Data Science",
    "section": "Step 2: global_moran_perm() of sfdep is used to perform global Moran permutation test.",
    "text": "Step 2: global_moran_perm() of sfdep is used to perform global Moran permutation test.\n\nglobal_moran_perm(condo_resale_sf$MLR_RES, \n                  condo_resale_sf$nb, \n                  condo_resale_sf$wt, \n                  alternative = \"two.sided\", \n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.3215, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than the alpha value of 0.05. Hence, we reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.32017 which is greater than 0, we can infer that the residuals resemble cluster distribution."
  }
]