---
title: "In Class Exercise 6 : Geospatial Data Science"
author: "Jiale SO"
date: "August 18, 2024"
date-modified: "last-modified"
execute: 
  eval: true
  echo: true
  freeze: true
---

# 1.0 Installing and Loading the R Packages

```{r}
pacman::p_load(sf, spdep, tmap, tidyverse, sfdep)
```

# 2.0 Importing the data

Two data sets will be used in this hands-on exercise, they are:

-   Hunan county boundary layer. This is a geospatial data set in ESRI shapefile format.

-   Hunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.

::: panel-tabset
## ShapeFile

```{r}
hunan <- st_read(dsn = "data/geospatial", layer = "Hunan")

hunan <- st_transform(hunan, crs = 4490)

```

## CSVFile with Left Join

```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv") 
hunan_GDPPC <- left_join(hunan,hunan2012) %>% 
  select(1:4, 7, 15)
```
:::

# 3.0 Global Measures of Spatial Association

## 3.1 Step 1: Deriving Queen's Contiguity Weights: SFDep Methods

```{r}
wm_q <- hunan_GDPPC %>%
  mutate(
        nb = st_contiguity(geometry),
        wt = st_weights(nb, style = "W"),
        .before = 1
  )
```

## 3.2 Step 2: Computing Global Moran' I

```{r}
moranI <- global_moran(wm_q$GDPPC, 
                       wm_q$nb,
                       wm_q$wt
                       )

glimpse(moranI)
```

K is the average number that they found

## 3.3 Step 3: performing Global Moran's I Test

```{r}
global_moran_test(wm_q$GDPPC,
                  wm_q$nb,
                  wm_q$wt
                  )
```

This is basically the idea that MORAN I shows there's clustering but not a strong one and since the P value is low, we do it.

Look at the p-value first, then we do not have the statistical analysis.

## 3.4 Step 4: Performing Global Moran's I Permutation Test (Use this for Take Home -2)

Do this for statistical test, to ensure it's reproducible, set seed.

```{r}
set.seed(1234)
global_moran_perm(wm_q$GDPPC,
                  wm_q$nb,
                  wm_q$wt,
                  nsim = 99
                  )
```

This simulates and permutates the the test permutation test. So basically we do 100 test and see if the p-value to reject or not.

# 4.0 Local Measures of Spatial Association

Compute Local Moran's I of GDPPC at county level by using local_moran() of spdep package

-   The code takes the `wq_q` data frame (which contains geographical data and information about spatial neighbors and weights).

-   It calculates the **Local Moran's I** for the **GDPPC** variable, taking into account the spatial relationships (through `nb` and `wt`) and running 99 simulations to evaluate significance.

-   The results of the **Local Moran's I** (which may include the Moran’s I statistic, z-scores, and pseudo p-values) are placed in a new column called `local_moran`.

-   Finally, **`unnest()`** flattens the result, so all the relevant information (e.g., Moran's I statistic, p-value) is available in separate columns for easier interpretation.

Summary of steps

-   **Calculate Local Moran's I** for GDPPC.

-   **Incorporate the contiguity neighbor list and spatial weights**.

-   **Run 99 simulations** to determine statistical significance.

-   **Unnest** the results to make them easier to analyze

```{r}
lisa <- wm_q %>%
  mutate( local_moran = local_moran(
    GDPPC, nb ,wt, nsim = 99),
    .before = 1) %>%
    unnest(local_moran)

lisa
```

There will be three p_values,

1.  `P_ii` is the base method
2.  `P_ii_sim` base on simulation
3.  `P_folded_sim` (use kfold)

stay consistent and use `p_ii_sum` .

Mean, median pysal for how deviation

IF Skew follows normal distribution, use median,

If Skewness is close to 0 use mean.

1.  `Mean` -\> for clustering
2.  `Median ->` for clustering
3.  `pysal`

## 4.1 Visualising the Local Moran's I

```{r}
tmap_mode("plot")
tm_shape(lisa) +
  tm_fill("ii") +
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of GDPPC",
            main.title.size = 2)
```

##  

```{r}
tmap_mode("plot")
tm_shape(lisa) +
  tm_fill("p_ii") +
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of GDPPC",
            main.title.size = 2)
```

## 4.3 Visualising the Local Moran's I P value and II

```{r, fig.width=10, fig.height=8}
map1 <-
tm_shape(lisa) +
  tm_fill("ii") +
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of GDPPC",
            main.title.size = 2) 

map2 <- tm_shape(lisa) +
  tm_fill("p_ii") +
  # breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf) 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of GDPPC",
            main.title.size = 2)

tmap_arrange(map1, map2, ncol =2)
```

# 5.0 Visualising LISA Map

```{r}
lisa_sig <- lisa %>%
  filter(p_ii < 0.05)

tmap_mode("plot")
tm_shape(lisa) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig) +
  tm_fill("mean") +
  tm_borders(alpha = 0.4)
```

# 6.0 Computing Local Gi\* statssitics

spatial weight matrix

```{r}
wm_idw <- hunan_GDPPC %>%
  mutate( nb = st_contiguity(geometry),
          wts = st_inverse_distance(nb, geometry,
                                    scale = 1,
                                    alpha = 1),
          .before = 1)
```

::: callout-note
GI\* and Local Gi\* are distanced-based spatial statistics. Hence, distance methods instead of contiguity methods should be used to derive the spatial weight matrix.
:::

Compute the local Gi\* by using the code cchunk

```{r}
HCSA <- wm_idw %>%
  mutate(local_Gi = local_gstar_perm(
    GDPPC, nb, wy, nsim = 99),
    .before = 1) %>%
  unnest(local_Gi)

HCSA
```

# 7.0 visualisating Gi\*

Be clear on the hotspot and clustering. terminology . LISA keep it to cluster, and HSCA hot/cold

## Visualising hotspot and cold spot areas. with signifcant values

```{r}
HCSA_sig <- HCSA %>%
  filter(p_sim <0.05)

tmap_mode("plot")
tm_shape(HCSA) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(HCSA_sig) +
  tm_fill("cluster") +
  tm_borders(alpha = 0.4)
```
